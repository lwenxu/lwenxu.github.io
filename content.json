{"meta":{"title":"昨夜凛雨","subtitle":"技术的道路十年如一日","description":null,"author":"lwen","url":"http://lwenxu.coding.me","root":"/"},"pages":[{"title":"categories","date":"2017-04-26T09:47:43.000Z","updated":"2019-03-14T20:21:08.000Z","comments":true,"path":"categories/index.html","permalink":"http://lwenxu.coding.me/categories/index.html","excerpt":"","text":""},{"title":"archives","date":"2017-04-26T09:47:43.000Z","updated":"2019-03-14T23:40:24.000Z","comments":true,"path":"archives/index.html","permalink":"http://lwenxu.coding.me/archives/index.html","excerpt":"","text":""},{"title":"Tagcloud","date":"2017-04-26T09:47:43.000Z","updated":"2019-03-14T20:16:06.000Z","comments":true,"path":"tags/index.html","permalink":"http://lwenxu.coding.me/tags/index.html","excerpt":"","text":""},{"title":"关于我","date":"2019-09-28T09:18:52.000Z","updated":"2019-09-28T11:56:01.875Z","comments":true,"path":"about/index.html","permalink":"http://lwenxu.coding.me/about/index.html","excerpt":"","text":"技术的道路上，十年如一日 DO WHAT YOU LOVE , AND MASTER IT ! 我是 lwen 19 届本科毕业生，热爱技术，专注于 Java 也对前端和机器学习非常感兴趣。 兴趣广泛，喜欢阅读、摄影、后期、画画、唱歌 、动漫。虽然没一样能拿出手，为生活调味还是很棒的，hahaha～ 在做技术的路上走了很多弯路，这个博客记录了我一路的经历和成长（PS：其中有50多篇文章丢了，数据真的很重要啊～），希望在学习提升的同时也能帮助到一些和我一样在路上努力的人。 最后打个广告～ 我目前就职于 阿里巴巴-淘系技术部-营销平台，目前平台大量招开发、算法、前端 欢迎大家来到阿里巴巴，简历可投递到 xpf199741@outlook.com 。"}],"posts":[{"title":"AE 技巧","slug":"Photo/AE 技巧学习","date":"2019-10-27T13:40:24.000Z","updated":"2019-10-27T12:51:43.003Z","comments":true,"path":"2019/10/27/Photo/AE 技巧学习/","link":"","permalink":"http://lwenxu.coding.me/2019/10/27/Photo/AE 技巧学习/","excerpt":"","text":"TypeMonkey这个脚本是用来生成一个文字的动画的，就是文字的闪出，我们经常看到的一些黑底白字的一些打电话的视频","categories":[{"name":"视频后期","slug":"视频后期","permalink":"http://lwenxu.coding.me/categories/视频后期/"}],"tags":[{"name":"视频后期","slug":"视频后期","permalink":"http://lwenxu.coding.me/tags/视频后期/"}]},{"title":"PR 技巧","slug":"Photo/PR 技巧","date":"2019-10-27T13:40:24.000Z","updated":"2019-10-28T16:22:57.105Z","comments":true,"path":"2019/10/27/Photo/PR 技巧/","link":"","permalink":"http://lwenxu.coding.me/2019/10/27/Photo/PR 技巧/","excerpt":"","text":"基本的工具 波纹剪辑工具 B，在剪辑前一段素材的时候能够看到后一段素材第一帧的样子 滚动编辑工具和波纹剪辑工具类似 N ，但是影响的是两段素材，也就是增加第一段长度后面第二端也在减少，相当于把第二段删掉了一些 比率拉伸工具就是快慢镜头，快慢放一个东西 内滑：保证时间线长度不变 ，被鼠标选中的素材长度不变但是这个素材两侧的素材的入点和出点被改变 外滑：保证鼠标选中的这个素材的出点和入点不变素材在上边滑动 也就是说截取的素材的总长度是固定的就是素材需要展示的片段不一样而已 视频导入导出格式 PR 批处理技巧 对于效果的重复应用可以 ctrl+c 赋值效果，然后到 master 上粘贴效果 那么对于同一个素材的所有的片段都会被加上统一效果 对于一些效果我们希望给到另外一些素材，注意跨素材的方式上面的技巧就不适用了，我们使用 ctrl+c 复制，然后使用 ctrl+alt+v 粘贴效果 对于音频则是可以多个轨道批处理，首先选择音轨混合器立体声子轨道，然后需要的一起调整的轨道放到一个子混合里面直接调整子混合就 ok 了 快捷键添加视频&amp;音频转场 shift+D单独添加视频转场 Ctrl+D单独添加音频转 Ctrl+shift+D切分素材 Ctrl+K波纹剪辑 Q&amp;W延长剪辑至时间轴 Shift+Q&amp;W匹配帧 FShift+R 反向匹配帧(反斜杠) 快速缩放ctrl+(反斜杠） 隐藏项目栏lt+方向键 移动素材（需要激活轨道）Alt+Shift+方向键 快速移动素材I/O 设置工作区 ；删除选区’ 抽取片段ctrl+加减号 缩放轨道宽度shift+加减号 扩展/缩小所有轨道宽度shift+123 快速切换窗口 Luts这个东西的全名是 LookUpTable 也就是将画面中的颜色批量的替换成另外的颜色，Luts 大致分为两类，矫正 Luts 和风格 Luts ，一般我们会在添加 Luts 之前对画面的颜色进行调整，这样的效果是会被 Luts 再进行二次的映射，所以总的效果是在 Luts 的风格之下的。那么另外的就是如果在 Luts 之后调整就很容易突破 Luts 的限定，所以根据需求在添加 Luts 前后进行颜色风格的调整。 一般的我们可以建立一个控制调整图层来应用 Luts 然后整个的格调是统一的，然后我们分着对每一部分进行调整。 还有我们需要将所有的 Luts 导入到 PR 中避免每次都需要一个个选择。我们直接在 PR 中就可以预览我们的 Luts 最后我们调整好的 Luts 还可以直接导出 cube 然后给其他人用。 脱机文件在我们的文件名在系统中修改了以后 pr 找不到对应的文件，然后就显示脱机，我们可以使用查找然后手动关联这些更改后的文件。 多个素材顺序自动插入首先选择多个素材，然后点击自动序列匹配 无间隔删除shift+delete 删除素材以后后面的素材会跟上来 提升和提取提升就是把这段选中的出入点之间的素材删除掉，后面的素材不跟上来 提取则是删除并且后面的素材跟上 注意一点就是我们所有的操作在只会被应用到指定的轨道上面，如果那个轨道没有被激活则不会对他生效。 在我们选择提升的时候提升操作只会被作用域我们激活的视频或者音频轨道，例如这里只激活了音频关闭了视频。 假如我们使用提取的话就不一样了，视频和音频都会被干掉抽出，因为这个时候视频音频同步锁定的。我们取消视频和音频的同步锁定就好了。可以看到后面有因为去掉了音频的时间差。 插入素材我们按住 ctrl 键+ 拖入素材素材会被插入到以前的素材中，而不会覆盖以前的素材 滚动条放大选择一个面板使用 +/- 可以放大滚动条和缩小 使用 ctrl+ +/- 可以放大视频轨道 使用连续预览视频就可以看到更多的帧照片了。 默认插入素材的轨道 在最左边有两个 a 和 v 只能激活一个视频一个音频所以这个就是插入的时候默认的一个轨道 子剪辑可以理解为素材中截取一段作为一个新的素材，我们选择入点和出点然后直接拖动到素材箱中就生成了一个子剪辑，但是这个的子剪辑名字所有的信息和原素材一样，而且在时间线上可以看到他有一个小三角也就是他的长度被限定了，我们希望生成子剪辑的时候限定一下名称和是否裁剪可以按 ctrl+拖动素材 取消修建的话在时间线上我们可以修改出入点的位置然后拖动而选中后就不行了，被裁减后的视频会有一个小三脚 标记在时间线上打的标记就在时间线上然后在素材监视器中的标记就是素材上的。都可以用 M 来做标记 可以切换到标记面板直接查看我们标记点详细信息","categories":[{"name":"视频后期","slug":"视频后期","permalink":"http://lwenxu.coding.me/categories/视频后期/"}],"tags":[{"name":"视频后期","slug":"视频后期","permalink":"http://lwenxu.coding.me/tags/视频后期/"}]},{"title":"视频拍摄技巧杂记","slug":"Photo/暂时整理的杂记","date":"2019-10-27T13:40:24.000Z","updated":"2019-10-28T14:58:13.204Z","comments":true,"path":"2019/10/27/Photo/暂时整理的杂记/","link":"","permalink":"http://lwenxu.coding.me/2019/10/27/Photo/暂时整理的杂记/","excerpt":"","text":"切镜1.跳切人的动作不断的跳动，然后中间有一结是没有了 这就是被跳切了 2.贴合切将人物的一个动作和另外一个细节动作相贴合 比如一开始人走过来 然后细节到 脚上 最后又到人走到镜头跟前。中间的细节部分就是我们的表现主体的一个时间和空间的位移 。 3.离切和贴合切一样，但是不一样的是中间的细节转换成另外一个表现主体的一个画面，比如移动到一个鸟上。 相机的基本参数调整 对于曝光，我们可以使用曝光直方图来进行曝光检测，直方图的横向就是 0-255 纵向就是像素个数。我们最完美的曝光是能够让直方图均匀分布，并且两遍的位置都处于差点过爆差点欠爆的状态。除此之外外我们还可以使用斑马纹，对于过爆的地方就会显示出斑马条纹，提醒我们进行曝光减了。我们的曝光规则并不是宁欠勿过，而是宁右勿左。 对于光圈就是我们镜头里面的几个小扇叶，我们看到的 f1.4 f2 这类的参数就是光圈了，这个数值越大表示光圈越小，那么越小的话就意味更少的进量光整个画面也会更加的暗。因此我们可以通过调节光圈拍摄暗场景。同时光圈还决定了景深，光圈越大景深越浅，那么我们对焦点前后清晰区间就更小。会产生一个背景虚化的效果。但是注意光圈太大太小都不好。另外为什么是 f1.4 的下一档 f 2 因为光圈的计算公式是 光圈 F 值=焦距/光圈直径 而透光面积是 pi x r2 所以是和平方的倒数一致 ，那么 1.4x1.4 =1.9 2*2=4 所以是两档的区别 视频和拍照的快门速度，这个东西一般都是 1/50 这个东西因为在交流电的光下如果你的快门速度超过或者小于他就会导致频闪，可以调高快门获得额外的曝光，避免频闪就可以使用自然光或者打光 ISO 他就是放大电路的值，所以会将所有的值放大，那么噪点自然就有了，而我们需要注意的就是这个东西并不是越低越好，也不是越高越好，因为有一个默认的 ISO 值，在默认的情况下他的画面是最纯净的，通常拍摄夜景的时候会把 ISO 放在光圈快门之后来获得最纯净的画面。","categories":[{"name":"视频后期","slug":"视频后期","permalink":"http://lwenxu.coding.me/categories/视频后期/"}],"tags":[{"name":"视频后期","slug":"视频后期","permalink":"http://lwenxu.coding.me/tags/视频后期/"}]},{"title":"九月份 Review：「遇见一群有意思的人」","slug":"Life/九月份 review","date":"2019-09-28T11:36:04.000Z","updated":"2019-09-30T10:01:31.928Z","comments":true,"path":"2019/09/28/Life/九月份 review/","link":"","permalink":"http://lwenxu.coding.me/2019/09/28/Life/九月份 review/","excerpt":"","text":"​ 在车上看着路边飘扬着的红旗，才意识到九月就要结束了。这一个月发生了很多难过、开心和有趣的事情，想通过这篇文章总结一下，或者说记录这些美好，以后的某一天再看这篇文章依旧能够嘴角上扬。 应接不暇的需求​ 从入职到九月将近一个月的时间，这一个月基本在熟悉流程用了一两个需求熟悉开发流程和集团中间件。接下来就是 99 大促 和 双11 需求的支持和稳定性保障。 ​ 这次 99大促章鱼狂欢城，是我第一次作为开发参与 S 级大促系统开发和稳定性保障，整个过程充满了挑战和艰辛，同时暴漏出自身大量的问题和不足，在技术、业务、思考方式等方面都有不同程度的纰漏和待改进的点。 技术​ 每次大促都是排期短需求多，所以对于开发速度上有很高的要求，并且对于频繁变化的需求也要有相应的心里准备和代码框架设计，对可能变化的节点预测，留出足够的扩展点。 关于轮子​ 在这次开发过程中有很明显的感触到如果很多代码不做抽象，下次需要用到相似的功能只能拷贝以前的代码做修改，代码中会出现大量的冗余，而且必须要一行行的理解别人的代码，有时候会觉得还不如自己写来的省事。但是注意一旦意识到这部分本来是可复用、可抽象、可被封装，那么这部分代码一定要有充分的设计，让这部分轮子具有较好的扩展性、健壮性以及易用性，否则你只是在逼迫下一个人必须造轮子，下一个看到你代码的人就是你现在的处境。既然花了时间投入到轮子的开发就应该产出优质的通用的代码。 ​ 举个简单的例子，对于常常使用的 Excel 导出，我们通常会将 MapList 或者 BeanList 作为数据源，那么对于 BeanList 这种规整的结构使用注解驱动最合适不过了，后续的使用只需在 Bean 上写对应的注解。而 MapList 应该也有对应的工具将数据和列名绑定，最后我们只需要关心列信息。但事实上很多人都有使用到导出 Excel 功能，但是这些代码都分散在各个业务代码当中，一方面破坏了业务流程的完整性，另外没有可复用性。 代码规范​ 看了项目中的很多代码，很少有人能写出自表达的代码，一方面是因为历史包袱，前面没有设计，而业务快速迭代导致后人只能加判断条件在原有代码上堆叠。另一方面需求多任务重时间紧，所以没有抽象只想着尽快实现功能尽快上线。而后者常常就是导致前者出现的原因。 ​ 在互联网公司，快速迭代是最基本的要求，毕竟国内互联网公司不像外企对代码质量进行严格把控，项目时间也拖的很长。行业现状很难会有变化，而开发人员在短期内很难把自身水准提升到能写出自表达代码，所以目前最行至有效的解法是 注释 + 规范 对于复杂的业务逻辑尽量多用一些注释进行说明业务框架和思路，另外严格遵守 《阿里巴巴编码规范》中提到的点，保持代码风格统一。 效率​ 在编码过程中，经常为了快速响应需求解决问题，看完 PRD 就开始 coding ，往往后来会发现这样一味的堆代码会导致很多问题变得难解，或者写出来的代码质量很差，有种拆东墙补西墙的感觉。 ​ 所以理解和思考完需求后的第一件事应该是打草稿，画出业务流图，设计业务框架，明晰如何组织包和类，对于流程中的核心点算法如何实现，可以采用哪些设计模式明晰业务结构，可以使用哪些轮子简化开发等等…… ​ 然后进行快速编码阶段，编码需要保证精力集中，避免因为被打断出现思维断线造成的 bug ，编码结束后使用静态检查工具，扫描可能存在的问题。尽量一次编码跑通，不要反复修改，减少部署系统所花费的时间。 后期规划​ 看的代码太少，只有看的多了才会知道好代码是什么样子，才会明白原来这些地方有更好的设计。后面保持阅读优秀的二方包和集团中间件。目前只看了 Pandora 源码，总结成了 ATA ，后面计划整理 Diamond 和 MateQ 源码，整理笔记。另外再看一遍 Pandora 主要看框架的设计，而非流程。 ​ 以前的好习惯不能丢，对于出现的错误要勤于记录，错误原因 -&gt; 排查思路 -&gt; 耗时 -&gt; 排查经验 -&gt; 避免方案 给思维打补丁，让自己逻辑更缜密，对于一些常见报错，快速 troubleshooting 。 可以把这写问题记录都放到 csdn 上，形成自己的问题引擎。 ​ 要保持对开源项目的接触和学习，来集团以后感觉和外部的技术脱节了，99 % 技术都是集团内部中间件，很少使用到新技术，保持对新技术的学习保持对技术的敏感度。 ​ 个人博客 好久没更新了 ，最新的一篇是在入职前写的，最近忙了也变懒了。保持输出，技术，思考，感想。保持每个月两篇博客。 业务平台业务​ 对于招商部分的业务不够了解，本来的预期是熟悉营销工作台中常见的功能，对于其中的一些专有名词也要熟知含义，理解系统中的业务层次，画出大致的结构图。重要的是每部分业务应该自己创建测试然后尝试跑通一个流程，并且要和代码对应上，这是一个长期的工作内容，因为把这个系统搞清楚是一件比较困难的事情，系统的复杂度和人员参与度都太高，以及额外的 DTS Job ，只能先一点点的摸索着部分业务和代码，归纳总结系统架构，熟悉大家的代码风格，和已经存在的轮子，至少要有些印象避免重复的轮子。 数据中心​ 最近将近两个月的时间一直在做数据中心的建设工作，主要对阿里表格活动现场重写，还有双十一数据看板。为了以后更多的数据产品的出现应该有更详细的框架设计，沉淀系统快速响应能力，配置化能力，自动化能力。另外需要与前端打通，产出更多的业务组件与约定。 只见树木，不见森林​ 大部分时间都被埋没在需求和修复问题中，很难看到自己所负责模块的全貌，对于部分熟悉但却不明白这部分的所处的位置和意义，这也是因为对于整体业务不够熟悉对平台的现状不能很好的把握导致的。这部分欠缺很难在短时间内得到填补，需要长时间沉淀和对业务的持续思考，才会有质的变化。 ​ 看书对形成电商思维和框架是一种简单而行之有效的方式，多看看马老师写的书，多关注电商领域的行业动态。 百年阿里紧张&amp;期待​ 很明白自己不太善于沟通，所以对这次百阿之旅带着紧张，对于快融入团队并不是很有信心。但是也很期待，期待够能突破自己，发现自己新的可能，简单来说变得更 Open ，认识一些小伙伴。令人欣喜的是，这份期待没有被辜负～ 缘分​ 缘分真的是一个很神奇的东西，一群来自不同城市、不同部门、不同年龄的人组成了这么温暖、团结、活力的 1227 百阿班。很幸运来到 1227 ，很幸运来到 三生万物 ，很幸运遇到你们，遇见新的自己 ～ ​ 感谢百阿让我遇到这么一群，有趣的、热情的、可爱的、灵动的、温情脉脉的人。 破冰​ 一圈自我介绍后，其实我一个人名都没记住，虽然当时每个人自我介绍完后我都会重复好几遍，重复着重复着就忘了～原谅我的烂记性不是不想记住你们！！！不过最后认人名 PK 环节，我可是能叫出全班人的名字，得瑟一下。 ​ 印象比较深刻的是五个小游戏任务，大家在互相还不熟悉的情况下能够做到相互信任、团结一致、互相帮助，用智慧和合作共同创造价值，取得成果。很多环节很辛苦也充满了困难，但我们在短时间内形成的超强凝聚力和执行力，让团队势如破竹，朝着目标冲刺。在这个过程中出现了很多小彩蛋，在 “达芬奇密码” 环节大家看完规则你一句我一句着的说着游戏规则，我还没听懂规则是啥，天相突然跳出来说了一个听起来很牛逼的调度算法，目瞪狗呆。又是一个算法怪兽，规则看完调度算法就出来了，感觉智商受到了降维打击….. ​ 由于算法对于调度者依赖性太高，对调度内存是一个很大的考验，为了保险起见我们采用了两趟遍历，虽然中间出了小插曲，导致牌序混乱。大家都一脸懵逼的时候，天相挺身而出力挽狂澜，终于体会到什么叫做：“此时此刻，非我莫属！”。 游戏任务 十只脚落地 安全部门合影 凝聚经过第一天的破冰，第二天大家慢慢开始变得熟悉起来，尤其是在这次的土话的探寻中，团队更加凝聚。第一次见到阿里土话是在公司的大屏上：“此时此刻，非我莫属” 这是我记得最清楚的一句，也是最感动我的一句。 因为信任，所以简单。整个探寻任务从分工到执行只在很短的时间，没有过多的担心某个环节出问题了怎么办？某些子任务完不成怎么办？我们相信大家都能够把自己的那一部分做的很精彩，都很自觉的专注于自己的部分，相信伙伴，一切变得简单起来。 一点多才开始剪视频，又感受了一把速度与激情，有一种五点前赶发布的感觉。既要冷静又要快速响应，在大家的共同努力下，开讲前视频渲染结束。 晚上一起去庆功呀～ 5号食堂！ 结束后，弦柱在群里说了一句，“今天聊的很开心，好像又回到了学生时代！”对的！就是这种感觉，好放松～ 变化昨天还在一块团队任务，马上就要因为另外的任务分开。“拥抱变化” ，变化来的如此之快。在弦柱的带领下我们完成了对飞猪业务的探寻，让我重新认识了飞猪，她的历史，现状，困难与机遇。对于从来没接触过的 OTA 也有初步的了解。 在这个团队最大的感受就是有活力，因为我们的队长 — 弦柱（未来的杭州市旅游局局长） 就是一个很有活力的人！对团队也非常认真负责，带着我们去飞猪部门探索，采访！准备演讲到凌晨两点多，辛苦啦～ 夜谈对这个环节印象也非常深刻，每一个人的分享都好像是一本十分值的回味的书，透过他们的讲述读到不同的精彩故事。通过他们的精彩看到自身的不足，通过他们的失落看到逆境中的坚韧，每个人的经历都很有意思，可惜时间不够不然肯定整整一晚都在谈心交流。 不得不说十分佩服 泰伯，一个敢闯、敢拼、敢探索。知道自己想要什么，追求的是什么，并且付诸于行动，很少人能有这种想法和魄力。放一张大佬的照片，像不像香港扛把子 , haha~ 公益公益真的是一件帮助他人幸福自己的事情，在这个过程中能认识到自己的价值，也能为他人创造价值。公益能够感染身边的人，让更多的人以一颗柔软的心来对待这个世界。有很多同学反映在做公益的过程看到很多许多人的善举，就像马老师所说的要时刻保持爱，对社会、对自然、对身边的人，爱的力量小而强大。做一个内心温暖而强大的人。 公益后的 “总裁局” 也是让人十分放松和开心，好久没和这么多人一起开开心心吃吃喝喝玩玩了。 阿里这就是阿里，以前我们会说：“这是阿里”，但是现在我们会告诉别人：“这就是阿里！”。因为现在的我们是一个不追求大，不追求强，我们追求成为一家活102年，截止到2036年，服务20亿消费者，创造1亿就业机会，帮助1000万家中小企业盈利的好公司。 对于新六脉神剑价值观，并不是为了改变我们的想法，或是束缚我们，而是在这个共识下选择同路人。价值观并非口号而是我们看到不论是少年阿里还是成年后的他一直都在用实际 另外对于年轻人，保持自己的好恶和棱角很重要，每个人都拥有对机会的选择权！ 在阿里必须要遵守规则，在自身利益和公司里冲突的时候以公司利益优先，保证公司数据安全，不要做触碰公司红线的事情。 “活着”来到阿里的第一年最重要的是 “活下来” ，因为作为一个新人很难融入到节奏走么快，业务难度这么高，新人培训少的团体。我们最重要的不是说想着如何实现集团的大目标，保证自己能够活下来，landing — 技术落地，业务落地。要明白自己生存在一个什么样的环境，去了解这个环境，适应这个环境。 而三到五年的沉淀，才能真正成为一个真正的阿里人，这个时候就需要面对更过的变化和更快的节奏，多从自身去思考问题。 伙伴感谢在这次遇到的优秀的小伙伴们，因为我相信 无论我遇见谁，他/她都是我生命该出现的人，绝非偶然，他/她一定会教会你一些什么。 属七：感谢我的小天使，看得出来你是一个温暖的、热爱生活的人。从礼物的包装上，看得出你花了不少心思，真的非常感动。尤其是你的赠言充满了鼓励与期待，谢谢！你的字写的真的很棒～ 弦柱(局长)：阳光、帅气、自信、具有少年感。跟他待在一块感觉自己又回到了大学校园，轻松愉悦！ 余征：认真、严肃、细致。短短几个月就减掉 1/3 的体重的毅力，令人钦佩。 泰伯：敢闯、敢拼、有想法。看起来是一个很严肃的大佬，其实是很好相处的大佬！感谢鼓励陪伴！ 拾月：博学、美丽、有气质。第一眼就被气场震撼到了，除了气质还有博学多识！ 星吟：自律、美丽、脑洞大。每次不鸣则已，一鸣惊人，一句吐槽能让我笑一两分钟，苹果肌要坏掉了～ 珺兮：聪明、文静、可爱。都是应届生相似点还蛮多的，也能说到一块去。可爱！有趣！ 天相：自信、认真、有责任、有主见。令我印象深刻的不用一次性杯子盛可乐，因为不环保！！！ 迪奇：聪明、好奇心、冷幽默。我们的数据中台，反应快，技术强，感觉内心也很萌哈哈，我们技术人的楷模。 久谙：幽默、有趣、情商高。思维太活跃了，想象力也超级棒，一句话带动全场气氛！ 山魏：认真、戏精、沉稳、可靠。因为角色投入一炮而红，红遍大江南北！但是也非常的可靠，做事认真、结果导向～ 顺序不分先后 ，按照 “总裁饭局” 次序，希望下次再相见，我们还能按照这个顺序坐在一起，聊天喝酒！ 优秀的人大多会玩儿，幽默，会来事儿，正是因为这些特质，能够吸引并凝聚一波人，作为一个不太说话的程序员，应该培养锻炼自己让自己变的活跃，open！这次百阿是一个良好的开端。感谢认识你们，真的很开心～","categories":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/categories/生活/"},{"name":"阿里巴巴","slug":"生活/阿里巴巴","permalink":"http://lwenxu.coding.me/categories/生活/阿里巴巴/"},{"name":"开心","slug":"生活/阿里巴巴/开心","permalink":"http://lwenxu.coding.me/categories/生活/阿里巴巴/开心/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/tags/生活/"},{"name":"百阿","slug":"百阿","permalink":"http://lwenxu.coding.me/tags/百阿/"},{"name":"开心","slug":"开心","permalink":"http://lwenxu.coding.me/tags/开心/"}]},{"title":"百年阿里","slug":"Life/百阿之旅","date":"2019-09-28T11:36:04.000Z","updated":"2019-10-28T16:26:34.082Z","comments":true,"path":"2019/09/28/Life/百阿之旅/","link":"","permalink":"http://lwenxu.coding.me/2019/09/28/Life/百阿之旅/","excerpt":"","text":"百年阿里 紧张&amp;期待 很明白自己不太善于沟通，所以对这次百阿之旅带着紧张，对于较快融入团队并不是很有信心。但是也很期待，期待够能突破自己，发现自己新的可能，简单来说变得更 Open ，认识一些小伙伴。令人欣喜的是，这份期待没有被辜负～ 缘分 缘分真的是一个很神奇的东西，一群来自不同城市、不同部门、不同年龄的人组成了这么温暖、团结、活力的 1227 百阿班。很幸运来到 1227 ，很幸运来到 三生万物 ，很幸运遇到你们，遇见新的自己 ～ 感谢百阿让我遇到这么一群，有趣的、热情的、可爱的、灵动的、温情脉脉的人。 破冰 一圈自我介绍后，其实我一个人名都没记住，虽然当时每个人自我介绍完后我都会重复好几遍，重复着重复着就忘了～原谅我的烂记性不是不想记住你们！！！不过最后认人名 PK 环节，我可是能叫出全班人的名字的人，得瑟一下。 印象比较深刻的是五个小游戏任务，大家在互相还不熟悉的情况下能够做到相互信任、团结一致、互相帮助，用智慧和合作共同创造价值，取得成果。很多环节很辛苦也充满了困难，但我们在短时间内形成的超强凝聚力和执行力，让团队势如破竹，朝着目标冲刺。在这个过程中出现了很多小彩蛋，在 “达芬奇密码” 环节大家看完规则后，你一句我一句着的说着游戏规则，我还没听懂规则是啥，天相突然跳出来说了一个听起来很牛逼的调度算法，目瞪狗呆。又是一个算法怪兽，规则看完调度算法就出来了，感觉智商受到了降维打击….. 由于算法对于调度者依赖性太高，对调度内存是一个很大的考验，为了保险起见我们采用了两趟遍历，虽然中间出了小插曲，导致牌序混乱。大家都一脸懵逼的时候，天相挺身而出力挽狂澜，终于体会到什么叫做 “此时此刻，非我莫属！”。 游戏任务 十只脚落地 安全部门合影 凝聚经过第一天的破冰，第二天大家慢慢开始变得熟悉起来，尤其是在这次的土话的探寻中，团队更加凝聚。第一次见到阿里土话是在公司的大屏上：“此时此刻，非我莫属” 这是我记得最清楚的一句，也是最感动我的一句。 因为信任，所以简单。整个探寻任务从分工到执行只在很短的时间，没有过多的担心某个环节出问题了怎么办？某些子任务完不成怎么办？我们相信大家都能够把自己的那一部分做的很精彩，都很自觉的专注于自己的部分，相信伙伴！ 一点多才开始剪视频，又感受了一把速度与激情，有一种五点前赶发布的感觉。既要冷静又要快速响应，在大家的共同努力下，开讲前视频渲染结束。 晚上一起去庆功呀～ 5号食堂！ 结束后，弦柱在群里说了一句，“今天聊的很开心，好像又回到了学生时代！”对的！就是这种感觉，好放松～ 变化昨天还在一起团队任务，马上就要因为另外的任务分开。“拥抱变化” ，变化来的如此之快。在弦柱的带领下我们完成了对飞猪业务的探寻，让我重新认识了飞猪，她的历史，现状，困难与机遇。对于从来没接触过的 OTA 也有了初步的了解。 在这个团队最大的感受就是有活力，因为我们的队长 — 弦柱（未来的杭州市旅游局局长） 就是一个很有活力的人！对团队也非常认真负责，带着我们去飞猪部门探索，采访！准备演讲到凌晨两点多，辛苦啦～ 夜谈对这个环节印象也非常深刻，每一个人的分享都好像是一本十分值的回味的书，透过他们的讲述读到不同的精彩故事。通过他们的精彩看到自身的不足，通过他们的失落看到逆境中的坚韧，每个人的经历都很有意思，可惜时间很短不然肯定整整一晚都在谈心交流。 不得不说，十分佩服泰伯，一个敢闯、敢拼、敢探索。知道自己想要什么，追求的是什么，并且付诸于行动，很少人能有这种想法和魄力。放一张大佬的照片，像不像香港扛把子 , haha~ 公益公益真的是一件帮助他人幸福自己的事情，在这个过程中能认识到自己的价值，也能为他人创造价值。公益能够感染身边的人，让更多的人以一颗柔软的心来对待这个世界。有很多同学反映在做公益的过程受到许多人的帮助，就像马老师所说的要时刻保持爱，对社会、对自然、对身边的人，爱的力量小而强大。做一个内心温暖而强大的人。 公益后的 “总裁局” 也是让人十分放松和开心，好久没和这么多人一起开开心心吃吃喝喝玩玩了。 阿里这就是阿里，以前我们会说：“这是阿里”，但是现在我们会告诉别人：“这就是阿里！”。因为现在的我们是一个不追求大，不追求强，我们追求成为一家活102年，截止到2036年，服务20亿消费者，创造1亿就业机会，帮助1000万家中小企业盈利的好公司。 对于新六脉神剑价值观，并不是为了改变我们的想法，或是束缚我们，而是在这个共识下选择同路人。价值观并非口号。可以看到不论是少年阿里还是成年后的他一直都在用实际行动诠释着价值观里的每一条。 另外对于年轻人，保持自己的好恶和棱角很重要，每个人都拥有对机会的选择权！ 做一个守则的阿里人，在自身利益和公司里冲突的时候以公司利益优先，保证公司数据安全，不要触碰公司红线。 活着来到阿里的第一年最重要的是 “活下来” ，因为作为一个新人很难融入到节奏走么快，业务难度这么高，新人培训少的团体。我们最重要的不是说想着如何实现集团的大目标，保证自己能够活下来，landing — 技术落地，业务落地。要明白自己生存在一个什么样的环境，去了解这个环境，适应这个环境。 而三到五年的沉淀，才能真正成为一个真正的阿里人，这个时候就需要面对更过的变化和更快的节奏，多从自身去思考问题。 伙伴感谢在这次遇到的优秀的小伙伴们，因为我相信 无论我遇见谁，他/她都是我生命该出现的人，绝非偶然，他/她一定会教会你一些什么。 属七：感谢我的小天使，看得出来你是一个温暖的、热爱生活的人。从礼物的包装上，看得出你花了不少心思，真的非常感动。尤其是你的赠言充满了鼓励与期待，谢谢！你的字写的真的很棒～ 弦柱(局长)：阳光、帅气、自信、具有少年感。跟他待在一块感觉自己又回到了大学校园，轻松愉悦！ 余征：认真、严肃、细致。短短几个月就减掉 1/3 的体重的毅力，令人钦佩。 泰伯：敢闯、敢拼、有想法。看起来是一个很严肃的大佬，其实是很好相处的大佬！感谢鼓励陪伴！ 拾月：博学、美丽、有气质。第一眼就被气场震撼到了，除了气质还有博学多识！ 星吟：自律、美丽、脑洞大。每次不鸣则已，一鸣惊人，一句吐槽能让我笑一两分钟，苹果肌要坏掉了～ 珺兮：聪明、文静、可爱。都是应届生相似点还蛮多的，也能说到一块去。可爱！有趣！ 天相：自信、认真、有责任、有主见。令我印象深刻的就是 不使用一次性杯子盛可乐，因为不环保！！！ 迪奇：聪明、好奇心、冷幽默。我们的数据中台，反应快，技术强，感觉内心也很萌哈哈，我们技术人的楷模。 久谙：幽默、有趣、情商高。思维太活跃了，想象力也超级棒，一句话带动全场气氛！ 山魏：认真、戏精、沉稳、可靠。因为角色投入一炮而红，红遍大江南北！但是也非常的可靠，做事认真。 顺序不分先后 ，按照 “总裁饭局” 席位，希望下次再相见，我们还能按照这个顺序坐在一起，聊天喝酒！ 优秀的人大多会玩儿，幽默，会来事儿，正是因为这些特质，能够吸引并凝聚一波人，作为一个不太说话的程序员，应该培养锻炼自己让自己变的活跃，open！这次百阿是一个良好的开端。感谢认识你们，真的很开心～","categories":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/categories/生活/"},{"name":"阿里巴巴","slug":"生活/阿里巴巴","permalink":"http://lwenxu.coding.me/categories/生活/阿里巴巴/"},{"name":"开心","slug":"生活/阿里巴巴/开心","permalink":"http://lwenxu.coding.me/categories/生活/阿里巴巴/开心/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/tags/生活/"},{"name":"百阿","slug":"百阿","permalink":"http://lwenxu.coding.me/tags/百阿/"},{"name":"开心","slug":"开心","permalink":"http://lwenxu.coding.me/tags/开心/"}]},{"title":"oh-my-zsh主题体验","slug":"Tools/OhMyZsh主题体验","date":"2019-07-24T02:17:46.000Z","updated":"2019-07-24T02:57:20.000Z","comments":true,"path":"2019/07/24/Tools/OhMyZsh主题体验/","link":"","permalink":"http://lwenxu.coding.me/2019/07/24/Tools/OhMyZsh主题体验/","excerpt":"","text":"以前一直使用的 oh-my-zsh 的默认主题，这是因为一直找不到一款钟爱的主题，powerline 一开始看起来比较有科技感其实也不是很耐看，而且配置很麻烦啊。 后来想着干脆直接用 随机主题 好了，你永远不知道下次他会给你什么惊喜。 下面是在使用随机主题的时候看到的一些比较漂亮的一些主题，整理出来最后直接保留这些主题，那么再怎么 random 都是我喜欢的主题啦~ pygmalion-virtualenv.zsh-theme","categories":[{"name":"工具集","slug":"工具集","permalink":"http://lwenxu.coding.me/categories/工具集/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://lwenxu.coding.me/tags/工具/"},{"name":"终端","slug":"终端","permalink":"http://lwenxu.coding.me/tags/终端/"},{"name":"oh-my-zsh","slug":"oh-my-zsh","permalink":"http://lwenxu.coding.me/tags/oh-my-zsh/"},{"name":"主题","slug":"主题","permalink":"http://lwenxu.coding.me/tags/主题/"}]},{"title":"RemoveNthNodeEndOfList-19","slug":"Leet Code/RemoveNthNodeEndOfList-19","date":"2019-07-24T02:00:50.000Z","updated":"2019-07-24T02:57:20.000Z","comments":true,"path":"2019/07/24/Leet Code/RemoveNthNodeEndOfList-19/","link":"","permalink":"http://lwenxu.coding.me/2019/07/24/Leet Code/RemoveNthNodeEndOfList-19/","excerpt":"","text":"Given a linked list, remove the n-th node from the end of list and return its head. Example: 1234&gt; Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2.&gt; &gt; After removing the second node from the end, the linked list becomes 1-&gt;2-&gt;3-&gt;5.&gt; Note: Given n will always be valid. Follow up: Could you do this in one pass? 题目要求就是通过一次遍历删除倒数第 n 个元素。 思路 一开始想着就是 链表长度 - n 这样遍历到这个位置把这个节点跳过就行了。可是这样的话需要遍历链表两次。 那么我们要想办法一边遍历一边跳过节点，这个时候想到了数组中删除某个节点使用了 p,q 指针，那么这里是否可以呢？ 确实，我们 pq 指针开始指示的位置不同，q指针指向 n 节点后的位置，这样只要 q 指针到了链表的结尾我们就能找到 需要删除的节点就是 p 的位置。 优化经过上面的一些想法基本形成了解题思路但是在实现的时候会有几个特例这个算法过不了比如 [1] 1 [1,2] 2 ,一开始我还尝试使用了一些方案来修补代码，但是这样总觉得不是很好，算法没有比较好的适用性。然后我想到这种状态主要是head指针一开始指向一个空节点那么删除head元素的时候就不会出现各种问题了。所以有下面的代码。 代码123456789101112131415161718192021222324252627/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode removeNthFromEnd(ListNode head, int n) &#123; // add null head ListNode nullNode = new ListNode(0); nullNode.next = head; head = nullNode; ListNode first = head, second = head; for (int i = 0; i &lt; n; i++) &#123; second = second.next; &#125; while (second != null &amp;&amp; second.next != null) &#123; first = first.next; second = second.next; &#125; first.next = first.next.next; return head.next; &#125;&#125; 结果 Runtime: 0 ms, faster than 100.00% of Java online submissions for Remove Nth Node From End of List. Memory Usage: 35 MB, less than 100.00% of Java online submissions for Remove Nth Node From End of List.","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"设计模式 - 装饰者模式","slug":"DesignPattern/设计模式-装饰者模式","date":"2019-06-04T10:30:28.000Z","updated":"2019-06-04T02:40:54.000Z","comments":true,"path":"2019/06/04/DesignPattern/设计模式-装饰者模式/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/DesignPattern/设计模式-装饰者模式/","excerpt":"","text":"装饰者模式 本文转载自 屈定’s Blog 装饰者模式实际上是一直提倡的组合代替继承的实践方式,个人认为要理解装饰者模式首先需要理解为什么需要组合代替继承,继承又是为什么让人深恶痛绝. 为什么建议使用组合代替继承?面向对象的特性有继承与封装,但两者却又有一点矛盾,继承意味子类依赖了父类中的实现,一旦父类中改变实现则会对子类造成影响,这是打破了封装性的一种表现.而组合就是巧用封装性来实现继承功能的代码复用.举一个Effective Java中的案例,当前需求是为HashSet提供一个计数,要求统计它创建以来曾经添加了多少个元素,那么可以写出下面的代码. 12345678910111213141516171819public class InstrumentedHashSet &lt;E&gt; extends HashSet&lt;E&gt; &#123; private int addCount = 0; @Override public boolean add(E e) &#123; this.addCount++; return super.add(e); &#125; @Override public boolean addAll(Collection&lt;? extends E&gt; c) &#123; this.addCount += c.size(); return super.addAll(c); &#125; public int getAddCount() &#123; return this.addCount; &#125;&#125; 下面测试代码会抛出异常,正确结果是6,是不是匪夷所思,这种匪夷所思需要你去看HashSet的具体实现,其addAll实际上是调用了add方法. 123InstrumentedHashSet&lt;String&gt; hashSet = new InstrumentedHashSet&lt;&gt;(); hashSet.addAll(Arrays.asList(&quot;张三&quot;, &quot;李四&quot;, &quot;王二&quot;)); Assert.assertEquals(hashSet.getAddCount(), 3); 这个案例说明了继承导致子类变得很脆弱,其不知道父类的细节,但是却实实在在的依赖了父类的实现.出现了问题也很难找出bug.本质原因是HashSet并不是专门为继承所设计的类,因此强行继承那会出现意想不到的问题.有关什么时候该用继承在设计模式–模板方法模式的思考一文章有相关讨论,感兴趣的可以去看看. 回到正题那么换成组合模式,让InstrumentedHashSet持有HashSet的私有实例,add以及addAll方法由HashSet的私有实例代理执行.这就是组合所带来的优势,充分利用其它类的特点,降低耦合度,我只需要你已完成的功能,相比继承而并不受到你内部实现的制约. 1234567891011121314151617181920public class InstrumentedHashSet &lt;E&gt;&#123; private int addCount = 0; private HashSet&lt;E&gt; hashSet = new HashSet&lt;&gt;(); public boolean add(E e) &#123; this.addCount++; return hashSet.add(e); &#125; public boolean addAll(Collection&lt;? extends E&gt; c) &#123; this.addCount += c.size(); return hashSet.addAll(c); &#125; public int getAddCount() &#123; return this.addCount; &#125;&#125; 装饰者模式装饰者模式定义为:动态的给一对象添加一些额外的职责,对该对象进行功能性的增强.(只是增强,并没有改变使用原对象的意图)装饰器模式类图:以上是标准的装饰器模式,其中AbstractDecorator为一个装饰器模板,目的是为了提高代码复用,简化具体装饰器子类的实现成本,当然不需要的话也是可以省略的,其最主要的功能是持有了ComponentInterface这个被装饰者对象,然后子类可以利用类似AOP环绕通知形式来在被装饰类执行sayHello()前后执行自己的逻辑.这是装饰者模式的本质. 比如ContreteDecoratorA增强了sayHello() 12345678910111213public class ContreteDecoratorA extends AbstractDecorator &#123; public ContreteDecoratorA(ComponentInterface componentInterface) &#123; super(componentInterface); &#125; @Override public void sayHello() &#123; System.out.println(&quot;A start&quot;); super.sayHello(); System.out.println(&quot;A end&quot;); &#125;&#125; 具体使用方式 1234public static void main(String[] args) &#123; final ContreteDecoratorA decoratorA = new ContreteDecoratorA(new ComponentInterfaceImpl()); decoratorA.sayHello(); &#125; 输出 123A starthello worldA end 其中默认实现ComponentInterfaceImpl的sayHello()功能被装饰后增强. Java I/O与装饰者字节流Java I/O框架就是一个很好的装饰者模式的实例.如下InputStream关系图其中FileInputStream,ObjectInputStream等直接实现类提供了最基本字节流读取功能.而FilterInputStream作为装饰者,其内部引用了另一个InputStream(实际被装饰的对象),然后以AOP环绕通知的形式来进行功能增强,笔者认为这里应该把该类定义为abstract更为合适.其承担的角色只是代码复用,帮助具体的装饰者类更加容易的实现功能增强.具体的装饰者BufferedInputStream为其他字节流提供了缓冲输入的支持.DataInputStream则提供了直接解析Java原始数据流的功能. 由于装饰者模式的存在,原本一个字节一个字节读的FileInputStream只需要嵌套一层BufferedInputStream即可支持缓冲输入, 1BufferedInputStream br = new BufferedInputStream(new FileInputStream(new File(&quot;path&quot;))); 字符流相比较字节流,字符流这边的关系则有点混乱,主要集中在BufferedReader与FilterReader,其两个角色都是装饰者,而FilterReader是更加基本的装饰者其相对于字节流中的FilterInputStream已经升级为abstract了,目的就是便于具体装饰者实现类更加容易的编写.那么为什么BufferedReader不继承FilterReader呢?这个问题暂时不知道答案,有兴趣的可以关注下知乎,等大牛回答.为什么BufferedReader 不是 FilterReader的子类，而直接是Reader的子类？ 不过从另一个角度来说,设计模式并不是套用模板,其最主要的是思想,对于装饰者模式最重要的是利用组合代替了继承,原有逻辑交给内部引用的类来实现,而自己只做增强功能,只要符合这一思想都可以称之为装饰者模式. Mybatis与装饰者Mybatis中有不少利用到装饰者模式,比如二级缓存Cache,另外其Executor也正在朝着装饰者模式改变.这里以Cache接口为主,类图如下:从类图来看和装饰者模式似乎无半毛钱关系,实际上其省略了AbstractDecorator这一公共的装饰者基类.那么要实现装饰者其实现类中必须有一个Cache的被装饰对象,以LruCache为例. 123456789101112public class LruCache implements Cache &#123; private final Cache delegate; private Map&lt;Object, Object&gt; keyMap; private Object eldestKey; @Override public String getId() &#123; return delegate.getId(); &#125; ....&#125; 其内部拥有Cache delegate这一被装饰者,也就是无论什么Cache,只要套上了LruCache那么就有了LRU这一特性.在org.apache.ibatis.mapping.CacheBuilder#setStandardDecorators构造时则根据配置参数来决定增强哪些功能,下面代码则很好的体现了装饰者模式的优势,还望好好体会. 1234567891011121314151617181920212223private Cache setStandardDecorators(Cache cache) &#123; try &#123; MetaObject metaCache = SystemMetaObject.forObject(cache); if (size != null &amp;&amp; metaCache.hasSetter(&quot;size&quot;)) &#123; metaCache.setValue(&quot;size&quot;, size); &#125; if (clearInterval != null) &#123; cache = new ScheduledCache(cache); ((ScheduledCache) cache).setClearInterval(clearInterval); &#125; if (readWrite) &#123; cache = new SerializedCache(cache); &#125; cache = new LoggingCache(cache); cache = new SynchronizedCache(cache); if (blocking) &#123; cache = new BlockingCache(cache); &#125; return cache; &#125; catch (Exception e) &#123; throw new CacheException(&quot;Error building standard cache decorators. Cause: &quot; + e, e); &#125;&#125; 线程安全与装饰者装饰者模式的功能是增强原有类，因此其经常被用来包装一个非线程安全的类，使其提供线程安全的访问，在JDK中的体现则是Collections.synchronizedXXX方法以及与其类似的一些方法。以synchronizedList为例，其本意是将线程不安全的List实例包装成线程安全的实例，包装方式是使用SynchronizedList提供同步包装，如下所示：对相关方法都使用独占锁来修饰，保证了并发访问的线程安全性。 123456789101112131415161718192021static class SynchronizedList&lt;E&gt; extends SynchronizedCollection&lt;E&gt; implements List&lt;E&gt; &#123; final List&lt;E&gt; list; SynchronizedList(List&lt;E&gt; list) &#123; super(list); this.list = list; &#125; public E get(int index) &#123; synchronized (mutex) &#123; return list.get(index); &#125; &#125; public void add(int index, E element) &#123; synchronized (mutex) &#123; list.add(index, element); &#125; &#125; ....&#125; 函数式编程与装饰者在函数式编程中因为函数是一等公民，因此互相嵌套是常有的事情，比如以下对于加锁解锁的一个函数封装调用 12345678public static &lt;T&gt; T lockTemplate(Lock lock, Supplier&lt;T&gt; supplier) &#123; lock.lock(); try &#123; return supplier.get(); &#125; finally &#123; lock.unlock(); &#125;&#125; 该函数接收一个锁以及一个supplier提供者，其使用方式也很简单，比如下面方式使得i++变得线程安全。 12345678ReentrantLock lock = new ReentrantLock(); int[] boxInt = new int[1]; Integer value = LockTemplate.lockTemplate(lock, () -&gt; &#123; // 线程不安全的操作 return boxInt[0]++; &#125;); 由于Java是面向对象范式语言，对函数式编程支持的并不是很好，所以这个例子并不能很好的描述函数式编程，不过思想上来看这是一种装饰者模式的实践，只不过装饰者与被装饰都变成了函数，装饰者函数的功能也是对被装饰者功能的增强。 装饰者模式与桥接模式这两个模式起初笔者很疑惑，两者的本质都是组合，并且从类图上来看两者几乎是一致的，那么他们的区别是什么呢？我认为从继承树上来看装饰者模式的目的是纵向的扩展类（增加树的深度），从而为现有的实现类提供更强大的支援。桥接模式则是水平扩展（增加树的宽度），以现有的类为代码复用的基础，然后在这个基础上水平扩展出另外的业务实现，这里更加注重的是解耦，把变化的与不变的分离开。 另外就是组合模式，基本看起来他的结构和装饰者模式一模一样，只是他们的用法是不一样的，两个都是继承一个，并且里面包含实例，但是装饰者时使用了实例的功能，而组合模式则是为了形成一个结构，比如Mybatis里面的SqlNode。 另外设计模式本身之间相互影响，没必要纠结于是某一种特定的模式，只要理解其背后的思想就可以了。 总结装饰者模式本质上来说是AOP思想的一种实现方式，其持有被装饰者，因此可以控制被装饰者的行为从而达到了AOP的效果。 扩展偶然看到一篇博文: 项目中用到的一个小工具类(字符过滤器),里面运用了装饰者设计模式,工厂模式,模板方法模式设计了这样一个符合开闭原则的工具类.感兴趣的也可以看看.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://lwenxu.coding.me/categories/设计模式/"}],"tags":[{"name":"设计模式,装饰者","slug":"设计模式-装饰者","permalink":"http://lwenxu.coding.me/tags/设计模式-装饰者/"}]},{"title":"设计模式 - 责任链模式","slug":"DesignPattern/设计模式-责任链模式","date":"2019-06-04T10:00:28.000Z","updated":"2019-06-04T02:16:18.000Z","comments":true,"path":"2019/06/04/DesignPattern/设计模式-责任链模式/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/DesignPattern/设计模式-责任链模式/","excerpt":"","text":"责任链模式 本文转载自屈定’s Blog 标准责任链模式责任链模式: 客户端发出的请求,客户端本身并不知道被哪一个对象处理,而直接扔给对象链,该请求在对象链中共享,由对象本身决定是否处理. 当请求被处理后该链终止.本质目的是把客户端请求与接收者解耦,但是解耦的太彻底了,只能让接收者一个个来看看是不是自己该处理的请求.标准的责任链模式一个请求只被一个对象处理,一旦处理成功后则链终止,请求不再被继续传递.标准的责任链模式并不是很通用,这种一对一模式大多场景可以用策略模式来代替,只有在客户端并不清楚具体的执行者是哪个对象的时候,责任链才比较适合.举个例子:你想在天朝办理一个证,但是你不知道去哪比较好,因此你的选择就是一条链路,先去A局,A局让你去B局,B局让你去C局等等,直到解决你的问题,当然也存在白跑一趟的结果.这也是标准责任链的缺点,产生了太多没必要的调用.标准的责任链实际上应用场景并不是很多,而常使用的是升级版的功能链. 功能链功能链是责任链的演变,结构上并没有实质的变化,只是每一个节点都可以处理请求,处理完转向下一个,也就是每一个请求都经历全部的链.这种应用场景就比较多了,比如我要办一件事,先去A再去B最后去C,这个例子还有点说明ABC三者的关系,取决于构造链时的顺序,另外每一步没处理好可以自由的选择退出链.文字说的不是很理解,下面举几个实际中的代码实例. Java中Filter链对于Filter,其是由FilterChain来进行链的组合调用,请求的request与返回response实际上是共享的上下文信息,每一个处理的Filter都可以查看与修改. 1234public interface FilterChain &#123; public void doFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException;&#125; 在Tomcat中实现类为org.apache.catalina.core.ApplicationFilterChain,其结构如下图:其中数组filters就是所谓的filter链,利用pos(当前执行到的位置)与n(filter链长度)来进行链的调用.那么怎么让链节点选择继续执行还是停止执行呢?答案的Filter的doFilter方法,该方法把责任链作为参数FilterChain一直传递下去,继续就调用chain的doFilter方法,不继续则不调用. 12void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException; Spring Security中拦截链Spring Security中的链实际上是由SecurityFilterChain接口所定义,其很简单的就是暴露出一个list的链.其中matches判断请求是否是这条链来处理. 123456public interface SecurityFilterChain &#123; boolean matches(HttpServletRequest request); List&lt;Filter&gt; getFilters();&#125; 在其入口处类org.springframework.security.web.FilterChainProxy中包含着多条链. 1private List&lt;SecurityFilterChain&gt; filterChains; 每一个链处理的是一类请求.Spring Security使用简单的for循环判断定位到具体执行的链. 12345678private List&lt;Filter&gt; getFilters(HttpServletRequest request) &#123; for (SecurityFilterChain chain : filterChains) &#123; if (chain.matches(request)) &#123; return chain.getFilters(); &#125; &#125; return null; &#125; 那么这个结构因为这个设计模式就很清晰了(这也是熟悉了设计模式之后的优势,看源码可以有一种全局把控感) 还有一个问题,链是如何自由执行的?这一点与Java Filter一模一样,Spring Security实现了一个org.springframework.security.web.FilterChainProxy.VirtualFilterChain类,该类同样实现了FilterChain接口,里面的调用逻辑也与tomcat方式一致.具体就不讨论了. 另外Spring Security也提供了一种数据共享的方式,利用ThreadLocal保证线程安全,达到共享数据的目的.另外这里的SecurityContextHolderStrategy是策略模式的一种应用,值得一看. 12345678910111213141516171819202122232425262728final class ThreadLocalSecurityContextHolderStrategy implements SecurityContextHolderStrategy &#123; private static final ThreadLocal&lt;SecurityContext&gt; contextHolder = new ThreadLocal&lt;SecurityContext&gt;(); public void clearContext() &#123; contextHolder.remove(); &#125; public SecurityContext getContext() &#123; SecurityContext ctx = contextHolder.get(); if (ctx == null) &#123; ctx = createEmptyContext(); contextHolder.set(ctx); &#125; return ctx; &#125; public void setContext(SecurityContext context) &#123; Assert.notNull(context, &quot;Only non-null SecurityContext instances are permitted&quot;); contextHolder.set(context); &#125; public SecurityContext createEmptyContext() &#123; return new SecurityContextImpl(); &#125;&#125; Mybatis中插件链Mybatis中插件使用的是类似责任链的一种模式,当然也可以称之为责任链模式,毕竟思想都是类似的.其中插件是通过Interceptor接口实现的,其中plugin方法就是为目标对象套上该链的一个节点. 12345678public interface Interceptor &#123; Object intercept(Invocation invocation) throws Throwable; Object plugin(Object target); void setProperties(Properties properties);&#125; 那么如何构造这个链?在InterceptorChain中有如下方法,InterceptorChain是在构造配置时组装好的,燃后对目标使用pluginAll方法,构造完整链. 12345678910public class InterceptorChain &#123; private final List&lt;Interceptor&gt; interceptors = new ArrayList&lt;Interceptor&gt;(); public Object pluginAll(Object target) &#123; for (Interceptor interceptor : interceptors) &#123; target = interceptor.plugin(target); &#125; return target; &#125;...&#125; 其中plugin官方推荐Plugin.wrap(target, this)方法,该方法本质上是用代理模式嵌套住目标类 123456789101112public static Object wrap(Object target, Interceptor interceptor) &#123; Map&lt;Class&lt;?&gt;, Set&lt;Method&gt;&gt; signatureMap = getSignatureMap(interceptor); Class&lt;?&gt; type = target.getClass(); Class&lt;?&gt;[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length &gt; 0) &#123; return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &#125; return target;&#125; 那么这种构造出的链大概如下面这种嵌套结构,这种链可以说是彻底的功能链,其一旦组装好就无法变化了.当然这种也适合Mybatis这种从配置中就定死了执行链. 业务开发中可以常用到的链在业务开发中常常能遇到这类需求,比如退款操作,退款后可以恢复商品库存,恢复活动库存,退掉用户的优惠券,退掉用户的活动资格等等,该一系列的操作就是一条线性链,那么就可以利用责任链的思想来完成在这样的需求.先提取出一个公共接口,链节点实现该接口,完成具体的退款操作 123456789public interface RegainAfterRefundOrder &#123; /** * 退回操作 * @param bo 该订单,可能是子订单,也可能是主订单,自行判断 * @param operator 操作人 * @return true成功 */ boolean regain(BizOrderDO bo, Long operator);&#125; 接下来是链的统一管理,也就是需要Chain这个类来管理,可以按照下面的实现,其调用链只是简单的在applyAllPlugin循环调用,该过程可以按照Spring Security等方式实现更加灵活的调用.可以根据需求设计为一旦创建就不可改变的类,包括类中的interceptors,这样使得代码更加健壮. 12345678910111213141516171819@Componentpublic class RefundOrderAndRegainChain &#123; private final List&lt;RegainAfterRefundOrder&gt; interceptors = new ArrayList&lt;&gt;(); public void applyAllPlugin(BizOrderDO bo, Long operator) &#123; for (RegainAfterRefundOrder interceptor : interceptors) &#123; interceptor.regain(bo, operator); &#125; &#125; public void addInterceptor(RegainAfterRefundOrder interceptor) &#123; interceptors.add(interceptor); &#125; public List&lt;RegainAfterRefundOrder&gt; getInterceptors() &#123; return Collections.unmodifiableList(interceptors); &#125;&#125; 最后是借助IOC实现链的组装,假设有RegainCoupon,RegainInventoryCount,RegainInvitationCodeWithDraw等RegainAfterRefundOrder的实现类,依次在Spring的Configuration类中实现注入,并构造出需要的RefundOrderAndRegainChain.最后再业务需要的地方直接注入该Chain即可.对于这种逻辑实现了解耦与灵活的组合. 123456789101112131415161718@Configurationpublic class RefundOrderAndRegainConfig &#123; @Bean public RefundOrderAndRegainChain paidToRefund( RegainInventoryCount regainInventoryCount, RegainCoupon regainCoupon, RegainPromotionRegistered regainPromotionRegistered, RegainInvitationCodeWithDraw regainInvitationCode) &#123; RefundOrderAndRegainChain chain = new RefundOrderAndRegainChain(); chain.addInterceptor(regainInventoryCount); chain.addInterceptor(regainPromotionRegistered); chain.addInterceptor(regainCoupon); chain.addInterceptor(regainInvitationCode); return chain; &#125;&#125; 责任链模式的本质 让请求者不关心具体接收者是谁,只需要得到自己的具体结果 在一个请求对应多个接收者情况下(Spring Security这种),接收者之间可以自由组合,灵活性很高 新增接收者处理也只需要增加链中的一个节点,不需要改动太多.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://lwenxu.coding.me/categories/设计模式/"}],"tags":[{"name":"设计模式,责任链","slug":"设计模式-责任链","permalink":"http://lwenxu.coding.me/tags/设计模式-责任链/"}]},{"title":"设计模式 - 模板方法模式","slug":"DesignPattern/设计模式-模板方法模式","date":"2019-06-04T09:20:28.000Z","updated":"2019-06-04T01:21:34.000Z","comments":true,"path":"2019/06/04/DesignPattern/设计模式-模板方法模式/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/DesignPattern/设计模式-模板方法模式/","excerpt":"","text":"设计模式–模板方法模式的思考 本文转载自屈定’s Blog 模板方法同样也是一种很实用的方法,目的是提高代码复用,并且统一大体的算法流程,比如一个一台电脑主机,定义好放置CPU,硬盘,内存等空位后,就形成了一个骨架,那么这个就是模板,具体的CPU,内存,硬盘是什么牌子型号则不需要考虑,这些是具体到业务中的实现类所负责的事情. 模板方法模式模板方法模式可以说是抽象类的一种特性,可以定义抽象(abstract)方法与常规方法,抽象方法延迟到子类中实现.因此标准的模板方法一般是一个抽象类+具体的实现子类,抽象类(AbstractClass)负责整个执行流程的定义,而子类(ConcreteClass)负责某一具体流程的实现策略,类图如下: Mybatis中的模板方法模式实际中由于模板方法很好的兼容性,因此经常与其他设计模式混用,并且在模板类之上增加一个接口来提高系统的灵活性.因此模板类经常作为中间层来使用,比如Mybatis的Executor的设计,其中在Executor与具体实现类之间增加中间层BaseExecutor作为模板类. 作为模板类的BaseExecutor到底做了什么呢?举一个代码比较短的例子,下面的代码是Mybatis缓存中获取不到时执行去DB查询所需要的结果,顺便再放入缓存中的流程.其中doQuery()方法便是一个抽象方法,其被延迟到子类中来实现.而缓存是所有查询都需要的功能,因此每一个查询都会去执行. 123456789101112131415private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; // doQuery具体查询策略延迟到子类中来实现 list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125; BaseExecutor作为模板类的同时其还是抽象父类,因此还可以实现一些子类锁需要的公共方法,比如事务的提交与回滚,模板类的本质还是抽象类,同时也是父类,当然可以有这些公共方法的定义. 12345678910111213141516171819202122232425@Overridepublic void commit(boolean required) throws SQLException &#123; if (closed) &#123; throw new ExecutorException(&quot;Cannot commit, transaction is already closed&quot;); &#125; clearLocalCache(); flushStatements(); if (required) &#123; transaction.commit(); &#125;&#125;@Overridepublic void rollback(boolean required) throws SQLException &#123; if (!closed) &#123; try &#123; clearLocalCache(); flushStatements(true); &#125; finally &#123; if (required) &#123; transaction.rollback(); &#125; &#125; &#125;&#125; 总结来说模板方法类作为上级,那么其要做的事情就是针对接口提出的需求进行规划,自己实现一部分,然后把需求拆分成更加细小的任务延迟到子类中实现,这是模板的责任与目的. Spring JDBC中的模板方法模式模板的另一种实现方式就是Java的接口回调机制,固定好方法模板后接收一个行为策略接口作为参数,模板中执行该接口的方法,比如Spring中的JdbcTemplate就是这样的设计. 12345678910public &lt;T&gt; T execute(StatementCallback&lt;T&gt; action) throws DataAccessException &#123; ... stmt = con.createStatement(); applyStatementSettings(stmt); // 执行传入的策略接口 T result = action.doInStatement(stmt); handleWarnings(stmt); return result; ...&#125; 因为篇幅原因,这里删减了很多代码,但是可以看出来这种方式实现有点策略模式的味道.其需要两个东西 方法模板,在这里是该execute()方法 策略接口,这里是StatementCallback,其本质上是一个函数是接口. 这种模式的好处自然是灵活,通过策略接口可以把行为分离出来并且可以灵活的在运行时替换掉对应的行为,雨点策略模式的味道.那么这种到底是策略模式还是模板方法模式呢?个人认为没必要纠结这些,说他是哪个都有挺充分的理由,但是设计模式本身就是思想的体现,很多模式与模式之间都互相有思想的重叠,具体业务场景不同选择不同. 总结模板方法在我看来更像是一个产品经理,而接口就是需求方,面对需求方模板做的事情是制定合理的统一执行计划,然后把需求拆分成更加细小的任务,分配到对应的程序员身上.另外模板方法模式是一种变与不变的思想体现,固定不变的,提出变化的,这样增加系统的灵活性,就像圆规画圆一样,先固定中心点,然后另一个脚随意扩展.这种思想是很实用,比如产品往往提出需求后,程序员就需要考虑具体的对象模型,那么此时比较好的做法就是尽早固定出不会变化的对象,然后其他功能在此基础上做关联来扩展,最后希望本文对你有启发. 扩展想法在日常的业务开发中我很少看到继承相关的代码,可能是和面向对象设计中提到多用组合少用继承这一原则有关.在Effective Java中第16条: 复合优先于继承这一小节中中举了如下例子:实现HashSet的计数功能,因此复写了add,addAll方法,然而因为对于父类实现逻辑的不了解(addAll实际上是循环调用add)导致了bug. 123456789101112131415public class InstrumentedHashSet&lt;E&gt; extends HashSet&lt;E&gt; &#123; private Integer count; @Override public boolean add(E e) &#123; count++; return super.add(e); &#125; @Override public boolean addAll(Collection&lt;? extends E&gt; c) &#123; count = count + c.size(); return super.addAll(c); &#125;&#125; 这个问题的根本原因是什么?我认为是 HashSet并不是专门为继承设计的类,因此去继承就出现了上述的问题.这么就代表代码中不应该使用继承吗?当然不是. 随后在第17条: 要么为继承而设计,并提供说明文档,要么就禁止继承指出为继承而设计是一种可取的行为,在我看来模板方法设计模式就是一种为继承而设计的方式.模板方法设计模式主要有两点本意:1.尽早的使用模板类,也就是Abstract或者Base开头的类来让实现类分叉,分叉的越早,对于结构上的理解就越清晰,比如下方Spring MVC对URL的处理,可以很清晰的看到一种处理是定位到具体的执行方法AbstractHandlerMethodMapping,一种是定位到另一个URL,可能是静态资源,可能是其他页面AbstractUrlHandlerMapping. 2.降低子类的实现接口的复杂度,主要是模板类中实现了接口的方法,然后把不变的固定,变化的使用抽象接口延迟到子类中,让子类的任务更加清晰合理.比如Mybatis的BaseExector就通过doQuery()把变化的查询步骤延迟到了子类中实现.另外有一种模板类是单纯的提供代码复用,其可以当成是不含有业务属性的一个方法库,提供对所有子类都有用的公共方法.这个我在我公司订单系统中采用,如下图所示(这里只列出一部分,实际上最下层的Service还会承担更多角色),AbstractOrderService只是单纯的提供数据获取,比如获取用户信息,获取优惠券信息等方法,具体的创建逻辑在子类中,比如BizVipOrderService创建vip订单,BizResearchOrderService创建研究员订单.当子类有通性是则可以在上层增加专属抽象类来提前分叉,最终保证每一个订单创建走的流程都是可控的,当要修改某一个订单的规则时,比如vip订单可以使用优惠券,则只需要改其子类而不用担心对其他的订单类型创建有影响.最后通过组合类提供对外的入口访问.降低外部操作的复杂性.另外最底层子类也可以实现其他接口,比如观察者来实现状态更改的通知处理. 那么这种设计就是为继承而设计,这种设计出来的类有一个特点,通常是以Abstract/Base开头,其就是为了继承,而不想让其他人实例化自身.最后继承作为面向对象的一大特性,掖着不用还能叫面向对象编程吗?","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://lwenxu.coding.me/categories/设计模式/"}],"tags":[{"name":"设计模式,模板方法","slug":"设计模式-模板方法","permalink":"http://lwenxu.coding.me/tags/设计模式-模板方法/"}]},{"title":"设计模式 - 策略设计模式","slug":"DesignPattern/设计模式-策略设计模式","date":"2019-06-04T09:20:28.000Z","updated":"2019-06-04T03:33:28.000Z","comments":true,"path":"2019/06/04/DesignPattern/设计模式-策略设计模式/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/DesignPattern/设计模式-策略设计模式/","excerpt":"","text":"策略设计模式 本文转载自屈定’s Blog 策略模式是一种简单的设计模式,但是其在业务开发中是一种非常有用的设计模式.举个例子,当你的业务需要针对不同的场景(可以简单理解为枚举类),执行不同的策略时那么使用策略模式可以帮助你更好的写出低耦合与高可扩展的代码. 标准策略模式策略模式: 把具体的算法从业务逻辑中分离出来,使得业务类不必膨胀,并且业务与具体算法分离,便于扩展新算法.类图如下:使用策略模式往往策略上有着相似的输入参数以及输出结果,或者有一个公共的上下文,便于抽象出策略接口Strategy,然后对应的业务Service只需要引用StrategyContext填充具体的策略完成自己的需求. 1new StrategyContext(new CouponStrategy()).sendPrize(uid, prize) 这是标准的策略模式,这种模式在如今的IOC下应用场景并不是很多,该模式有不少缺点 客户端必须知道所有的策略,然后手动选择具体的策略放入到Context中执行. 仍旧无法避免if/else逻辑,针对大多数场景下都是根据条件分支判断来选择具体的策略,那么在客户端耦合具体策略的情况下这个是没法避免的 策略枚举模式Java的枚举类可以实现接口,而且枚举常量天然的可以与具体行为绑定,那么两者结合起来就是一种很棒的策略枚举模式(笔者自己起的名字). 123456789101112131415161718192021public enum StrategyEnum implements Strategy&#123; COUPON(1) &#123; @Override public boolean sendPrize(Long uid, String prize) &#123; //发放优惠券 return true; &#125; &#125;, RMB(2) &#123; @Override public boolean sendPrize(Long uid, String prize) &#123; //发放RMB return true; &#125; &#125; ; private int code; StrategyEnum(int code) &#123; this.code = code; &#125;&#125; 相比标准的模式,该模式省掉了Context类,而且符合大多数场景,比如用户获得礼品,该礼品对应的是Mysql的一条记录,该记录有type标识是优惠券(Coupon)还是RMB,当DAO从DB查询出来后根据typeCode,定位到具体的枚举类,然后执行其sendPrize(Long uid, String prize)完成逻辑.这个流程很清晰.基于枚举的策略模式也有一些问题: 枚举类无法外部实例化,因此无法被IOC管理,往往策略实现都是复杂的依赖众多其他服务,那么这种时候枚举类就无从下手 IOC配合下的策略模式实践中,客户端往往不关心具体的实现类是如何实现的,他只需要知道有这个实现类的存在,其能帮我完成任务,得到我要的结果,所以在标准的策略模式基础上,扩展Context类,让其担任选择策略的能力,而不是客户端手动选择具体的策略,也就是具体策略实现与客户端解耦,转用枚举常量来代表其所希望的策略.改进后的Context(依赖Spring IOC)如下: 1234567891011121314151617181920212223@Componentpublic class StrategyContext implements InitializingBean &#123; @Resource private Strategy couponStrategy; @Resource private Strategy RMBStrategy; /** * 保存策略与具体实现的Map */ private static Map&lt;StrategyEnum, Strategy&gt; strategyMap = new HashMap&lt;&gt;(2); public Strategy getStrategy(StrategyEnum strategyEnum) &#123; return strategyMap.get(strategyEnum); &#125; @Override public void afterPropertiesSet() throws Exception &#123; strategyMap.put(StrategyEnum.COUPON, couponStrategy); strategyMap.put(StrategyEnum.RMB, RMBStrategy); &#125;&#125; 客户端调用时使用 1strategyContext.getStrategy(StrategyEnum.COUPON).sendPrize(uid,prize) 这里的Context相当于中间层,提供的是外观模式的功能,当新增策略时只需要新增对应的枚举类,以及具体的实现策略,在Context中添加一个新的枚举与实现类关系.客户端代码基本不要任何改变.补充: 更加优雅的做法是利用Spring的事件机制,在Spring初始化完毕后再构建整个策略Map,可以参考我在观察者模式中所使用到的方法.设计模式–观察者模式的思考 策略模式的本质策略模式的本质是把复杂的算法从一个类中提取出来,用一种合理的方式管理起来,避免业务类的膨胀.对于扩展只需要新增策略,而不需要怎么动业务代码.对于修改也只需要修改具体的策略类.业务类与策略成功的实现了低耦合.与IOC的配合下可以更加彻底的与业务类解耦,其间只需要枚举类与策略接口进行联系,对于代码的扩展性更加有力. 与状态模式的关系状态设计模式的类图结构与策略模式几乎是一致的.从逻辑上状态是平行的无法互相替换,但是策略与策略之间是可以完全替换的,只是实现方式的不同.在选择设计模式的时候是根据这一点来区分,代码上的体现是对于状态设计模式以State结尾,对于策略设计模式以Strategy结尾,让开发人员第一眼看过去就能明白整个设计的思路最佳.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://lwenxu.coding.me/categories/设计模式/"}],"tags":[{"name":"设计模式,策略设计模式","slug":"设计模式-策略设计模式","permalink":"http://lwenxu.coding.me/tags/设计模式-策略设计模式/"}]},{"title":"设计模式 - 适配器模式","slug":"DesignPattern/设计模式-适配器模式","date":"2019-06-04T08:49:28.000Z","updated":"2019-06-04T00:50:52.000Z","comments":true,"path":"2019/06/04/DesignPattern/设计模式-适配器模式/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/DesignPattern/设计模式-适配器模式/","excerpt":"","text":"设计模式–适配器模式的思考 本文转载自屈定’s Blog 个人认为适配器模式是一种加中间层来解决问题的思想,为的是减少开发工作量,提高代码复用率.另外在对于第三方的服务中使用适配器层则可以很好的把自己系统与第三方依赖解耦,降低依赖. 什么是适配器模式适配器模式: 将一个类的接口转换为客户所期望的另一个接口.适配器让原本接口不兼容的类可以合作无间.类图如下: Client: 调用方Target: 需要提供的新功能AdaptedObject: 系统中原本存在的类似本次需要提供的新功能的类Adapter: Target的实现类,主要负责该功能的实现,其内部持有AdaptedObject的对象,利用其对象完成本次需要提供的新功能. 整个流程大概如下:1.客户通过目标接口调用适配器的方法发出请求.2.适配器(Adapter)使用被适配器(AdaptedObject)已有的功能完成客户所期望的新功能3.客户收到调用结果,但是并不知道是适配器起到的转换作用.那么Adapter利用已经完成的AdaptedObject类实现本次提供的新功能,这一过程就是适配. Java I/O中的适配器在Java I/O中有把字节流转换为字符流的类java.io.InputStreamReader以及java.io.OutputStreamWriter.那么这两个类实际上使用的就是适配器模式以InputStreamReader为例,其继承了Reader类,所提供的功能是把字节流转换为字符流,其内部拥有StreamDecoder这一实例,所有的转换工作是由该实例完成. 1234public int read(char cbuf[], int offset, int length) throws IOException &#123; // 使用被适配器的功能 return sd.read(cbuf, offset, length);&#125; 那么在这个例子中Client是调用方,也就是我们开发人员Target是Reader这个抽象类.AdaptedObject是StreamDecoder,利用的是其功能.Adapter是InputStreamReader Java Set集合中的适配器Java中的Set集合有者无序,唯一元素,查找复杂度O(1)等特性.这些特性Map数据结构的key是完全符合的,那么就可以利用适配器模式来完成Set的功能.以HashSet为例,其内部持有的是一个值为固定Object的Map,如下图 其所有的操作会通过HashSet这个适配器来操作HashMap这个被适配器.比如: 123456public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator();&#125; public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; Client是调用方,也就是我们开发人员Target是Set这个接口.AdaptedObject是HashMap,利用的是其功能.Adapter是HashSet Mybatis中的适配器模式Mybatis作为一款通用框架,对于日志处理必然需要适配到各种日志框架,比如slf4j,log4j,logback等,每个日志的API多多少少有点不同,这种情况下适配器模式就起到了转换的作用.以下图由于实现类太多,只列取了几个.Mybatis有自己的org.apache.ibatis.logging.Log接口,框架内部使用的都是自己的Log,具体使用哪一个Log是由配置中的适配器决定的.以org.apache.ibatis.logging.log4j2.Log4j2LoggerImpl适配器为例,org.apache.logging.log4j.Logger为被适配者.Log4j2LoggerImpl是适配器,起到了转换的作用. 12345678910111213141516public class Log4j2LoggerImpl implements Log &#123; private static final Marker MARKER = MarkerManager.getMarker(LogFactory.MARKER); //被适配者 private final org.apache.logging.log4j.Logger log; public Log4j2LoggerImpl(Logger logger) &#123; log = logger; &#125; @Override public boolean isDebugEnabled() &#123; return log.isDebugEnabled(); &#125; .....&#125; 与装饰者模式的区别个人认为这两种设计模式是完全不同的思想:装饰者模式本意是增强功能,其装饰者与被装饰者对于调用方是很清晰的,比如ContreteDecoratorA decoratorA = new ContreteDecoratorA(new ComponentInterfaceImpl());就很清晰的知道使用ContreteDecoratorA装饰了ComponentInterfaceImpl.另外ContreteDecoratorA并没有改变ComponentInterfaceImpl的功能提供出去,而是为其进行了增强处理.适配器模式本意是复用已有的代码,对已经存在的功能进行包装转换,以另一种形式提供出去.比如HashSet,对于调用方来说其内部使用的HashMap是不可见的,调用方不关心内部被适配者是谁,只是关注该功能本身也就是Set接口.要说相同点的话那就是都是组合复用思想对一个对象进行包装,但其目的有着本质的区别.还望好好理解. 与外观模式的区别外观模式本意是把一组复杂的关联行为进行包装,提供一个面向开发人员更为简单的使用方式.举个例子,你觉得JDBC方式不太好用,因此写了个DBUtils这种封装类,实际上就是一种外观模式,与适配器还是有着很大的区别.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://lwenxu.coding.me/categories/设计模式/"}],"tags":[{"name":"设计模式,适配器","slug":"设计模式-适配器","permalink":"http://lwenxu.coding.me/tags/设计模式-适配器/"}]},{"title":"你写的代码,是别人的噩梦吗","slug":"SoftwareEngineer/你写的代码是别人的噩梦吗","date":"2019-06-04T08:01:28.000Z","updated":"2019-06-04T01:19:44.000Z","comments":true,"path":"2019/06/04/SoftwareEngineer/你写的代码是别人的噩梦吗/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/SoftwareEngineer/你写的代码是别人的噩梦吗/","excerpt":"","text":"你写的代码,是别人的噩梦吗 本文转自屈定’s Blog Frank，是来自阿里国际技术事业部的高级技术专家，从业十年，也是一位英语说到飞起的型男。今天他将与大家聊聊关于企业应用架构实践的话题。 从业这么多年，接触过银行的应用，Apple的应用，eBay的应用和现在阿里的应用，虽然分属于不同的公司，使用了不同的架构，但有一个共同点就是都很复杂。导致复杂性的原因有很多，如果从架构的层面看，主要有两点，一个是架构设计过于复杂，层次太多能把人绕晕。另一个是根本就没架构，ServiceImpl作为上帝类包揽一切，一杆捅到DAO（就简单场景而言，这种Transaction Script也还凑合，至少实现上手都快），这种人为的复杂性导致系统越来越臃肿，越来越难维护，酱缸的老代码发出一阵阵恶臭，新来的同学，往往要捂着鼻子抠几天甚至几个月，才能理清系统和业务脉络，然后又一头扎进各种bug fix，业务修补的恶性循环中，暗无天日！CRM作为阿里最老的应用系统，自然也逃不过这样的宿命。不甘如此的我们开始反思到底是什么造成了系统复杂性？我们到底能不能通过架构来治理这种复杂性？基于这个出发点，我们团队开始了一段非常有意义的架构重构之旅（Redefine theArch），期间我们参考了SalesForce，TMF2.0，汇金和盒马的架构，从他们那里汲取了很多有价值的输入，再结合我们自己的思考最终形成了我们自己现在的基于扩展点+元数据+CQRS+DDD的应用架构。该架构的特点是可扩展性好，很好的贯彻了OO思想，有一套完整的规范标准，并采用了CQRS和领域建模技术，在很大程度上可以降低应用的复杂度。本文主要阐述了我们的思考过程和架构实现，希望能对在路上的你有所帮助。 复杂性来自哪里？经过我们分析、讨论，发现造成现在系统异常复杂的罪魁祸首主要来自以下四个方面： 可扩展性差对于只有一个业务的简单场景，并不需要扩展，问题也不突出，这也是为什么这个点经常被忽略的原因，因为我们大部分的系统都是从单一业务开始的。但是随着支持的业务越来越多，代码里面开始出现大量的if-else逻辑，这个时候代码开始有坏味道，没闻到的同学就这么继续往上堆，闻到的同学会重构一下，但因为系统没有统一的可扩展架构，重构的技法也各不相同，这种代码的不一致性也是一种理解上的复杂度。久而久之，系统就变得复杂难维护。 像我们CRM应用，有N个业务方，每个业务方又有N个租户，如果都要用if-else判断业务差异，那简直就是惨绝人寰。其实这种扩展点（ExtensionPoint），或者叫插件（Plug-in）的设计在架构设计中是非常普遍的。比较成功的案例有eclipse的plug-in机制，集团的TMF2.0架构。还有一个扩展性需求就是字段扩展，这一点对SaaS应用尤为重要，因为有很多客户定制化需求，但是我们很多系统也没有统一的字段扩展方案。 面向过程是的，不管你承认与否，很多时候，我们都是操着面向对象的语言干着面向过程的勾当。面向对象不仅是一个语言，更是一种思维方式。在我们追逐云计算、深度学习、区块链这些技术热点的时候，静下心来问问自己我们是不是真的掌握了OOD；在我们强调工程师要具备业务Sense，产品Sense，数据Sense，算法Sense，XXSense的时候，是不是忽略了对工程能力的要求。 据我观察大部分工程师（包括我自己）的OO能力还远没有达到精通的程度，这种OO思想的缺乏主要体现在两个方面，一个是很多同学不了解SOLID原则，不懂设计模式，不会画UML图，或者只是知道，但从来不会运用到实践中；另一个是不会进行领域建模，关于领域建模争论已经很多了，我的观点是DDD很好，但不是银弹，用和不用取决于场景。但不管怎样，请你抛开偏见，好好的研读一下EricEvans的《领域驱动设计》，如果有认知升级的感悟，恭喜你，你进阶了。 我个人认为DDD最大的好处是将业务语义显现化，把原先晦涩难懂的业务算法逻辑，通过领域对象（Domain Object），统一语言（Ubiquitous Language）将领域概念清晰的显性化表达出来。相信我，这种表达带来的代码可读性的提升，会让接手你代码的人对你心怀感恩的。借用Abelson的一句话是 Programs must be written for people to read, and only incidentally for machines to execute. 所以强烈谴责那些不顾他人感受的编码行为。 分层不合理俗话说的好，All problemsin computer science can be solved by another level of indirection（计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决），怎样？是不是感受到间接层的强大了。分层最大的好处就是分离关注点，让每一层只解决该层关注的问题，从而将复杂的问题简化，起到分而治之的作用。我们平时看到的MVC，pipeline，以及各种valve的模式，都是这个道理。 好吧，那是不是层次越多越好，越灵活呢。当然不是，就像我开篇说的，过多的层次不仅不能带来好处，反而会增加系统的复杂性和降低系统性能。就拿ISO的网络七层协议来说，你这个七层分的很清楚，很好，但也很繁琐，四层就够了嘛。再比如我前面提到的过度设计的例子，如果没记错的话应该是Apple的Directory Service应用，整个系统有7层之多，把什么validator，assembler都当成一个层次来对待，能不复杂么。所以分层太多和没有分层都会导致系统复杂度的上升，因此我们的原则是不可以没有分层，但是只分有必要的层。 随心所欲随心所欲是因为缺少规范和约束。这个规范非常非常非常的重要（重要事情说三遍），但也是最容易被无视的点，其结果就是架构的consistency被严重破坏，代码的可维护性将急剧下降，国将不国，架构将形同虚设。有同学会说不就是个naming的问题么，不就是个分包的问题么，不就是2个module还是3个module的问题么，只要功能能跑起来，这些问题都是小问题。是的，对于这些同学，我再丢给你一句名言“Just because you can, doesn’t mean you should”。就拿package来说，它不仅仅是一个放一堆类的地方，更是一种表达机制，当你将一些类放到Package中时，相当于告诉下一位看到你设计的开发人员要把这些类放在一起考虑。 理想很丰满，现实很骨感，规范的执行是个大问题，最好能在架构层面进行约束，例如在我们架构中，扩展点必须以ExtPt结尾，扩展实现必须以Ext结尾，你不这么写就会给你抛异常。但是架构的约束毕竟有限，更多的还是要靠Code Review，暂时没想到什么更好的办法。这种对架构约束的近似严苛follow，确保了系统的consistency，最终形成了一个规整的收纳箱（如下图所示），就像我和团队说的，我们在评估代码改动点时，应该可以像Hash查找一样，直接定位到对应的module，对应的package里面对应的class。而不是到“一锅粥”里去慢慢抠。本章节最后，上一张我们老系统中比较典型的代码，也许你可以从中看到你自己应用的影子。知道了问题所在，接下来看下我们是如何一个个解决这些问题的。回头站在山顶再看这些解决方案时，每个都不足为奇，但当你还“身在此山中”的时候，这个拨开层层迷雾，看到山的全貌的过程，并不是想象的那么容易。庆幸的是我团队在艰难跋涉之后，终有所收获。 1、扩展点设计扩展点的设计思想主要得益于TMF2.0的启发，其实这种设计思想也一直在用，但都是在局部的代码重构和优化，比如基于Strategy Pattern的扩展，但是一直没有找到一个很好的固化到框架中的方法。直到毗卢到团队分享，给了我们两个关键的提示，一个是业务身份识别，用他的话说，如果当时TMF1.0如果有身份识别的话，就没有TMF2.0什么事了；另一个是抽象的扩展点机制。 身份识别业务身份识别在我们的应用中非常重要，因为我们的CRM系统要服务不同的业务方，而且每个业务方又有多个租户。比如中供销售，中供拍档，中供商家都是不同的业务方，而拍档下的每个公司，中供商家下的每个供应商又是不同的租户。所以传统的基于多租户（TenantId）的业务身份识别还不能满足我们的要求，于是在此基础上我们又引入了业务码（BizCode）来标识业务。 所以我们的业务身份实际上是（BizCode，TenantId）二元组。在每一个业务身份下面，又可以有多个扩展点（ExtensionPoint），所以一个扩展点实现（Extension）实际上是一个三维空间中的向量。借鉴Maven Coordinate的概念我给它起了个名字叫扩展坐标（Extension Coordinate），这个坐标可以用（ExtensionPoint，BizCode，TenantId）来唯一标识。 扩展点扩展点的设计是这样的，所有的扩展点（ExtensionPoint）必须通过接口申明，扩展实现（Extension）是通过Annotation的方式标注的，Extension里面使用BizCode和TenantId两个属性用来标识身份，框架的Bootstrap类会在Spring启动的时候做类扫描，进行Extension注册，在Runtime的时候，通过TenantContext来选择要使用的Extension。TenantContext是通过Interceptor在调用业务逻辑之前进行初始化的。整个过程如下图所示： 2、面向对象领域建模准确的说DDD不是一个架构，而是思想和方法论。所以在架构层面我们并没有强制约束要使用DDD，但对于像我们这样的复杂业务场景，我们强烈建议使用DDD代替事务脚本（TS: Transaction Script）。因为TS的贫血模式，里面只有数据结构，完全没有对象（数据+行为）的概念，这也是为什么我们叫它是面向过程的原因。然而DDD是面向对象的，是一种知识丰富的设计（Knowledge Rich Design），怎么理解？，就是通过领域对象（Domain Object），领域语言（Ubiquitous Language）将核心的领域概念通过代码的形式表达出来，从而增加代码的可理解性。这里的领域核心不仅仅是业务里的“名词”，所有的业务活动和规则如同实体一样，都需要明确的表达出来。 例如前面典型代码图中所展示的，分配策略（DistributionPolicy）你把它隐藏在一堆业务逻辑中，没有人知道它是干什么的，也不会把它当成一个重要的领域概念去重视。但是你把它抽出来，凸显出来，给它一个合理的命名叫DistributionPolicy，后面的人一看就明白了，哦，这是一个分配策略，这样理解和使用起来就容易的多了，添加新的策略也更方便，不需要改原来的代码了。 所以说好的代码不仅要让程序员能读懂，还要能让领域专家也能读懂。再比如在CRM领域中，公海和私海是非常重要领域概念，是用来做领地（Territory）划分的，每个销售人员只能销售私海（自己领地）内的客户，不能越界。但是在我们的代码中却没有这两个实体（Entity），也没有相应的语言和其对应，这就导致了领域专家描述的，和我们日常沟通的，以及我们模型和代码呈现的都是相互割裂的，没有关联性。这就给后面系统维护的同学造成了极大的困扰，因为所有关于公海私海的操作，都是散落着各处的repeat itself的逻辑代码，导致看不懂也没办法维护。 所以当尚学把这两个领域概念抽象成实体之后，整个模型和代码都一下子变清晰很多。在加上上面介绍的把业务规则显现化，极大的提升了代码的可读性和可扩展性。用尚学的话说，用DDD写代码，他找到了创作的感觉，而不仅仅是码农式Coding。下图是销售域的简要领域模型，但基本上能表达出销售域的核心领域概念。关于CQRS简要说一下，我们只使用了Command，Query分离的概念，并没有使用Event Sourcing，原因很简单—不需要。关于Command的实现我们使用了命令模式，因此以前的ServiceImpl的职责就只是一个Facade，所有的处理逻辑都在CommandExecutor里面。 SOLIDSOLID是单一职责原则(SRP)，开闭原则(OCP)，里氏替换原则(LSP)，接口隔离原则(ISP)和依赖倒置原则(DIP)的缩写，原则是要比模式（Design Pattern）更基础更重要的指导准则，是面向对象设计的Bible。深入理解后，会极大的提升我们的OOD能力和代码质量。比如我在开篇提到的ServiceImpl上帝类的例子，很明显就是违背了单一职责，你一个类把所有事情都做了，把不是你的功能也往自己身上揽，所以你的内聚性就会很差，内聚性差将导致代码很难被复用，不能复用，只能复制（Repeat Yourself），其结果就是一团乱麻。再比如在java应用中使用logger框架有很多选择，什么log4j，logback，common logging等，每个logger的API和用法都稍有不同，有的需要用isLoggable()来进行预判断以便提高性能，有的则不需要。对于要切换不同的logger框架的情形，就更是头疼了，有可能要改动很多地方。产生这些不便的原因是我们直接依赖了logger框架，应用和框架的耦合性很高。 怎么破？ 遵循下依赖倒置原则就能很容易解决，依赖倒置就是你不要直接依赖我，你和我都同时依赖一个接口（所以有时候也叫面向接口的编程），这样我们之间就解耦了，依赖和被依赖方都可以自由改动了。在我们的框架设计中，这种对SOLID的遵循也是随处可见，Service Facade设计思想来自于单一职责SRP；扩展点设计符合关闭原则OCP；日志设计，以及Repository和Tunnel的交互就用到了依赖倒置DIP原则，这样的点还有很多，就不一一枚举了。当然了，SOLID不是OO的全部。抽象能力，设计模式，架构模式，UML，以及阅读优秀框架源码（我们的Command设计就是参考了Activiti的Command）也都很重要。只是SOLID更基础，更重要，所以我在这里重点拿出来讲一下，希望能得到大家的重视。 3、分层设计这一块的设计比较直观，整个应用层划分为三个大的层次，分别是App层，Domain层和Repostiory层。 1.App层主要负责获取输入，组装context，做输入校验，发送消息给领域层做业务处理，监听确认消息，如果需要的话使用MetaQ进行消息通知； 2.Domain层主要是通过领域服务（Domain Service），领域对象（Domain Object）的交互，对上层提供业务逻辑的处理，然后调用下层Repository做持久化处理； 3.Repository层主要负责数据的CRUD操作，这里我们借用了盒马的数据通道（Tunnel）的概念，通过Tunnel的抽象概念来屏蔽具体的数据来源，来源可以是MySQL，NoSql，Search，甚至是HSF等。这里需要注意的是从其他系统获取的数据是有界上下文（Bounded Context）下的数据，为了弥合Bounded Context下的语义Gap，通常有两种方式，一个是用大领域（Big Domain）把两边的差异都合起来，另一个是增加防腐层（Anticorruption Layer）做转换。什么是Bounded Context？ 简单阐述一下，就是我们的领域概念是有作用范围的（Context）的，例如摇头这个动作，在中国的Context下表示NO，但是在印度的Context下却是YES。 4、规范设计我们规范设计主要是要满足收纳原则的两个约束：放对位置东西不要乱放，我们的每一个组件（Module），每一个包（Package）都有明确的职责定义和范围，不可以放错，例如extension包就只是用来放扩展实现的，不允许放其他东西，而Interceptor包就只是放拦截器的，validator包就只是放校验器的。我们的主要构件如下图所示： 贴好标签东西放在合适位置后还要贴上合适的标签，也就是要按照规范合理命名，例如我们架构里面和数据有关的Object，主要有Client Object，Domain Object和Data Object，Client Object是放在二方库中和外部交互使用的DTO，其命名必须以CO结尾，相应的Data Object主要是持久层使用的，命名必须以DO结尾。这个类名应该是自明的（self-evident)，也就是看到类名就知道里面是干了什么事，这也就反向要求我们的类也必须是单一职责的（Single Responsibility）的，如果你做的事情不单纯，自然也就很难自明了。如果我们Class Name是自明的，Package Name是自明的，Module Name也是自明的，那么我们整个应用系统就会很容易被理解，看起来就会很舒服，维护效率会提高很多。我们的命名规则如下图所示：经过上面的长篇大论，我希望我把我们的架构理念阐述清楚了，最后再从整体上看下我们的架构吧。如果觉得不错，也可以把framework code拉下来自己玩一下。 整体架构我们的架构原则很简单，即在高内聚，低耦合，可扩展，易理解大的指导思想下，尽可能的贯彻OO的设计思想和原则。我们最终形成的架构是集成了扩展点+元数据+CQRS+DDD的思想，关于元数据前面没怎么提到，这里稍微说一下，对于字段扩展，简单一点的解决方案就是预留扩展字段，复杂一点的就是使用元数据引擎。 使用元数据的好处是不仅能支持字段扩展，还提供了丰富的字段描述，等于是为以后的SaaS化配置提供了可能性，所以我们选择了使用元数据引擎。和DDD一样，元数据也是可选的，如果对没有字段扩展的需求，就不要用。最后的整体架构图如下：","categories":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/categories/Spark/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/tags/Spark/"}]},{"title":"设计模式 - 组合模式","slug":"DesignPattern/设计模式-组合模式","date":"2019-06-04T07:48:28.000Z","updated":"2019-06-04T02:16:18.000Z","comments":true,"path":"2019/06/04/DesignPattern/设计模式-组合模式/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/DesignPattern/设计模式-组合模式/","excerpt":"","text":"设计模式–组合模式的思考 本文转载自屈定’s Blog 组合模式是一种抽象树形结构的模式,其在业务开发中也是一种很有用的设计模式,下面开始分析. 组合模式业务中有很多树形结构的表示,比如下面的目录结构 1234567-- 男装 -- 上衣 -- 品牌1 -- 品牌2 -- 裤子 -- 品牌1 -- 品牌3 针对男装可以认为其是树的根节点,上衣,裤子这种下面还可以有节点的称为树枝节点,品牌这种下面不再有分支的称为叶子节点那么转换成面向对象该怎么表示呢? 一般做法12345678910111213// 根节点public class RootNode &#123; private List&lt;CompositeNode&gt; compositeNodes;// 针对节点区别对待,导致处理麻烦 private List&lt;LeafNode&gt; leafNodes; // 针对节点区别对待,导致处理麻烦&#125;// 树枝节点public class CompositeNode &#123; private List&lt;LeafNode&gt; leafNodes; private List&lt;CompositeNode&gt; compositeNodes; &#125;// 叶子节点public class LeafNode &#123;&#125; 这种做法是面向对象的思想,但是其最大的问题是对这三种类型的节点区别对待了,那么客户端就必须明确的得知这个节点到底是根还是树枝或者是叶子,那么对于客户端来说无疑是比较辛苦的,另外从功能上来说节点之间区别并不是很大,可以说是完全一样的.那么组合模式的作用就是统一这三种类型的节点,让客户端当成一种节点来处理.下面是组合模式下的方式 组合设计1234567891011// 其为节点的约束,主要暴露给客户端,客户端不需要了解子类是什么.public abstract class Node &#123;&#125;// 树枝节点,当然也可以是根节点public class CompositeNode extends Node &#123; // 持有Node集合,可以无限往下延伸 private List&lt;Node&gt; nodes;&#125;// 叶子节点,其下面不再有其他节点public class LeafNode extends Node &#123;&#125; 那么相比之前的设计好在了哪里?组合体现在了哪里? 相比之前设计,这里用了一个抽象类暴露出去给客户端,只需要把客户端需要的方法定义在抽象类中,那么大大减少了客户端的理解成本,对于客户端来说节点都是一个性质的,没必要区分根,树枝,叶子等. 组合体现在CompositeNode节点的设计,其内部引用的是Node抽象类实例,也就是可以一直往下延伸. 组合模式更多的是一种面向接口编程的思想,大多数日常开发中总会有意无意的使用了这种模式思想. Mybatis中的组合模式应用开发中我们写的动态Sql,Mybatis会按照下面方式去理解这个结构,比如 12345678910&lt;select id=&quot;findById&quot; resultMap=&quot;RM-CLASSROOM&quot;&gt; SELECT &lt;include refid=&quot;RM-CLASSROOM-ALLCOLS&quot;/&gt; FROM classroom WHERE status = 0 &lt;if test=&quot;!ids.isEmpty()&quot;&gt; AND id in &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/if&gt;&lt;/select&gt; Mybatis解析后大概会是下面的这种树形结构,最后在拼接成需要的Sql. 12345678-- select 根节点 -- select 叶子节点 -- &lt;include refid=&quot;RM-CLASSROOM-ALLCOLS&quot;/&gt; 叶子节点 -- where status = 1 叶子节点 -- &lt;if test=&quot;!ids.isEmpty()&quot; 树枝节点 -- AND id IN 叶子节点 -- &lt;foreach item=&quot;list&quot; ..... 树枝节点 -- #&#123;item&#125; 叶子节点 那么这种情况下是很适合用组合模式,因此Mybatis抽象出SqlNode接口暴露给客户端 123public interface SqlNode &#123; boolean apply(DynamicContext context);&#125; 其有如下子类(子类太多,省略了一些),按照这些子类再翻译下上面的sql 12345678-- select MixedSqlNode -- select StaticTextSqlNode -- &lt;include refid=&quot;RM-CLASSROOM-ALLCOLS&quot;/&gt; StaticTextSqlNode -- where status = 1 StaticTextSqlNode -- &lt;if test=&quot;!ids.isEmpty()&quot; IfSqlNode 内部的contents为MixedSqlNode -- AND id IN StaticTextSqlNode -- &lt;foreach item=&quot;list&quot; ..... ForEachSqlNode 内部的contents为MixedSqlNode -- #&#123;item&#125; StaticTextSqlNode 从结构上来说,非叶子节点,例如IfSqlNode,ForEachSqlNode是可以一直嵌套的,所实现的关键就是SqlNode接口与MixedSqlNode实现类.从客户端角度来说里面的节点这些都是不关心的,其只需要拿到SqlNode rootSqlNode实例,然后调用下rootSqlNode.apply(context)即可获取到自己想要的sql原型.这两个也是组合模式要解决的问题. SpringMVC中的组合模式SpringMVC中对参数的解析使用的是HandlerMethodArgumentResolver接口,该类有一个实现类为HandlerMethodArgumentResolverComposite,该类为一个组合类,其结构如下:其本身实现了HandlerMethodArgumentResolver接口,又持有其他HandlerMethodArgumentResolver对象,那么这种设计就是组合模式设计.,在它的实现方法中是对其他组合模式中的节点进行循环处理,从而选择最适合的一个. 12345678910111213private HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) &#123; HandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter); if (result == null) &#123; // 对其所拥有的对象循环,找到最适合处理的一个 for (HandlerMethodArgumentResolver methodArgumentResolver : this.argumentResolvers) &#123; if (methodArgumentResolver.supportsParameter(parameter)) &#123; result = methodArgumentResolver; break; &#125; &#125; &#125; return result;&#125; 对于HandlerMethodArgumentResolver来说,其虽然拥有众多子类,但是对于调用方来说却只关心参数所解析的结果,它并不知道该使用哪一个具体的子类,它所希望的是能以整体的形式去访问这些子类,从而选择最适合自己的一个参数解析器.那么HandlerMethodArgumentResolverComposite在这里扮演的就是一个整体的角色,对客户端来说调用的是这个整体. Netty中的组合模式Netty中的CompositeByteBuf使用了组合设计模式，但是其有点特殊，Netty所描述的零拷贝是应用层面上不做任意的数据复制，而是使用组合的方式拷贝，比如有两个Buf，headByteBuf与tailByteBuf，那么现在的需求是把两个合在一起，很自然的想到先创建一个新的buf，然后把headByteBuf复制进去，再把tailByteBuf复制进去，这个过程中涉及到两次应用层面的拷贝，自然不是高效的做法，那么CompositeByteBuf的实现是什么样子的呢？ CompositeByteBuf的意思是组合，他所采取的方式是把headByteBuf与tailByteBuf组合起来，对外相当于一个新的Buf，这样的方式不会产生任何应用层面的数据拷贝，原理如下示意图所示： 那么这也是一种组合设计模式的思想，更可以说是一种妙用。 安全性与透明性透明性所谓的透明性是客户在使用组合模式对象时不需要关心这个节点到底是根还是树枝或者是叶子,对于自己来说都是组件对象,只需要获取一个起始点就能拿到自己想要的东西,所谓的透明性表现在接口中暴露出了所有节点的公共方法,比如添加子节点,移除子节点等,那么就必然会存在叶子节点的添加子节点功能不支持的情况,此时调用应该抛出UnsupportedOperationException.举个反例Mybatis中客户只需要拿到SqlNode rootSqlNode就可以获取到想要的sql,对于客户端唯一的入口就是这个rootSqlNode.apply(context)获取到对应的sql,客户端本身无法修改这个节点.那么这种行为是非透明的. 安全性非透明性实现一般就是安全性的实现,所谓的安全性保证就是一旦节点构建完毕,客户端就无法更改,只需要获取到自己想要的东西就好.SqlNode就是一种安全性的实现,所谓的安全性表现在SqlNode接口中没有暴露修改的方法,节点是在构造阶段就组装完毕的. 具体选择哪种,需要根据业务来定夺,如果是类似Mybatis这种先准备好所有数据再执行的模式,那么安全性实现则是最好的选择.如果是业务处理模式下边处理边构造,则透明性最佳. 总结 组合模式在于结构上的统一,对外接口的一致,给客户端提供更加统一或者只提供必要的操作. 组合模式是面向接口编程的思想体现,通过接口实现客户端的操作便捷与约束,同时实现更加灵活的自由组合.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://lwenxu.coding.me/categories/设计模式/"}],"tags":[{"name":"设计模式,组合模式","slug":"设计模式-组合模式","permalink":"http://lwenxu.coding.me/tags/设计模式-组合模式/"}]},{"title":"设计模式 - 观察者模式","slug":"DesignPattern/设计模式-观察者模式","date":"2019-06-04T07:30:28.000Z","updated":"2019-06-04T02:16:18.000Z","comments":true,"path":"2019/06/04/DesignPattern/设计模式-观察者模式/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/DesignPattern/设计模式-观察者模式/","excerpt":"","text":"设计模式 - 观察者模式 本文转载自屈定’s Blog 观察者模式观察者模式描述的是一种一对多的关系,这里的一可能是某个状态发生变化,也可能是某一个事件产生.举个例子,针对订单付款,这一事件产生后可能需要经过很多个处理步骤,比如积分,入库,消费排行榜之类的操作,这些操作之间并没有任何关联性甚至可以并行处理,那么就可以理解为订单付款与处理步骤之间的一对多关系.还有一个特点就是单向依赖,处理步骤对于订单付款是单向依赖的,比如有订单付款,才能有处理步骤.但是反之就不依赖,订单付款对于有没有处理步骤是不关心的,这一点在下文实战中会详细讲解. 观察者模式结构观察者模式主要结构如下: Subject: 负责事件产生后通知到具体观察者的角色,所谓的通知实际上是循环调用其所持有的观察者接口 Observer: 负责对事件的处理,该接口可以很好的做到任务分离,每一个不同的任务都是其一个实现子类,互相不关心对方,很好的描述了业务上的关系. 那么本质什么?用一个Subject来聚合所有的Observer,那么调用者只需要关心对应的Subject就可以.为什么可以这样? 因为Observer之间没有任何关系,只是单纯的做自己要做的事情,也并不需要返回值之类的东西. 观察者模式的实战案例如笔者一开始描述的需求,再订单付款完成之后执行一些处理步骤,具体如下: 如果是虚拟产品订单,那么就发放虚拟产品 如果是会员订单那么就开通会员 根据付款金额增加积分 如果有消费排行榜活动则更新用户金额. ….. 这种是开发中很常见的付款后一些对应的操作需求,并且随着活动之类的增加后续还很容易增加其他的处理步骤需求,对于观察者模式其符合以下两点特征: 订单付款完成这一事件对应对个处理步骤,典型一对多关系 处理步骤之间并无关联性,每一个都是独立的处理 观察者模式设计上述用观察模式可以设计出如下结构: OrderPaidHandlerObserver其是观察者需要实现的接口,主要功能是判断是不是自己可以处理,可以处理的话就处理,其子类各司其职,比如IntegralOrderService是处理积分相关的观察者,VipOrderService则是处理会员相关的Service. 12345678910111213public interface OrderPaidHandlerObserver &#123; /** * 是否支持处理该消息 * @param paidMsg 消息体 * @return true 支持 */ boolean supportHandler(OrderPaidMsgDTO paidMsg); /** * 处理方法 * @param paidMsg 消息体 */ void handler(OrderPaidMsgDTO paidMsg);&#125; OrderPaidHandlerSubject其是负责通知所有观察者的接口,实现了该接口就有了通知观察者的义务. 1234567public interface OrderPaidHandlerSubject &#123; /** * 提醒所有的观察者 * @param paidMsg 付款消息 */ void notifyObservers(OrderPaidMsgDTO paidMsg);&#125; OrderCompositeService其是OrderPaidHandlerSubject的实现类,主要实现负责通知所有观察者的逻辑,所谓的通知本质上就是调用自己所持有的观察者对象,那么当订单付款事件产生后OrderCompositeService只需要调用下notifyObservers()方法就可以完成通知,完成所有的处理步骤. 12345678910111213141516171819public class OrderCompositeService implements OrderPaidHandlerSubject &#123; private List&lt;OrderPaidHandlerObserver&gt; observers; @Override public void notifyObservers(OrderPaidMsgDTO paidMsg) &#123; // 所谓的通知本质上就是调用对应观察者的方法 for (OrderPaidHandlerObserver observer : observers) &#123; try &#123; if (observer.supportHandler(paidMsg)) &#123; observer.handler(paidMsg); &#125; &#125; catch (Exception e) &#123; log.error(&quot;OrderPaidHandlerObserver fail&quot;, e); &#125; &#125; &#125;...&#125; 使用Spring管理观察者OrderCompositeService作为Subject来说,其持有了全部的Observer,那么如果利用IOC把Observer全部注入进该类中,那么当下次新增加一个Observer实现类时就不需要改这边的任何代码,完完全全的解耦.思路是利用IOC管理所有的观察者,当Spring容器启动完毕后获取所有的观察者,添加到对应的observers集合中,具体做法就是让OrderCompositeService实现ApplicationListener&lt;ContextRefreshedEvent&gt;接口,Spring在启动完毕后会发出通知,在该接口中利用BeanFactoryUtils初始化所需要的观察者集合. 12345678910111213141516171819202122/** * 容器初始化完毕后所执行的事件 */ @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; initPaidObserver(event); &#125; /** * 初始化订单付款所要执行的事件 */ private void initPaidObserver(ContextRefreshedEvent event) &#123; // 从Spring容器中取出所有的观察者 Map&lt;String, OrderPaidHandlerObserver&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(event.getApplicationContext(), OrderPaidHandlerObserver.class, true, false); // 实例化观察者集合 this.observers = Collections.unmodifiableList(Lists.newArrayList(matchingBeans.values())); if (this.observers.size() &lt;= 0) &#123; throw new IllegalStateException(&quot;OrderPaidHandlerObserver not found&quot;); &#125; else &#123; log.info(&quot;initPaidObserver finish, observer is &#123;&#125;&quot;, matchingBeans.keySet()); &#125; &#125; 这样做的好处就是把观察者的实例化与Subject解耦,对于观察者只需要知道自己一旦实现了观察者接口,那么就一定会有相应的Subject通知自己就足够了. 观察者的 “感兴趣” 粒度在观察者模式中Observer会像Subject注册自己,那么当Subject对应多个事件时怎么处理呢?1.Subject管理多组Observer在Subject中存放着多组Observer,当一个事件触发时只会通知其中一组.这样做法个人感觉是比较合理的.缺点是管理不方便,对于Subject来说要管理多组,对应的removeOvserver或者addObserver就会比较麻烦了,此时可以依赖IOC等工具完成这个过程.2.Observer多角色这种方案下,对于一个Subject他管理的只有一组Observer,但是Observer本身要承担多个责任,并且对自己不感兴趣的责任要留空方法处理.Observer可能只对一件事情感兴趣却不得不实现一堆空方法,不符合最少知道原则.Java的AWT就是这种设计.3.使用弱类型参数JDK自带的Observer就是类似的形式,其使用Object作为观察者参数,当接收到消息时需要用instance判断是否是自己感兴趣的事件,然后才执行逻辑,当事件很少的话这种方式是比较合适的,事件多的话则对一堆事件要分开处理,依然很麻烦.Eclipse的SWT是这种设计.","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://lwenxu.coding.me/categories/设计模式/"}],"tags":[{"name":"设计模式,观察者","slug":"设计模式-观察者","permalink":"http://lwenxu.coding.me/tags/设计模式-观察者/"}]},{"title":"Filter 链","slug":"Java SE/Fliter链","date":"2019-06-04T02:49:28.000Z","updated":"2019-06-04T00:47:52.000Z","comments":true,"path":"2019/06/04/Java SE/Fliter链/","link":"","permalink":"http://lwenxu.coding.me/2019/06/04/Java SE/Fliter链/","excerpt":"","text":"在写JavaWeb的时候我们经常会遇到一个概念就是 Filter 链，比如对于路由拦截，以及文件目录拦截都有一个Filter 和Filter链，那么他们底层具体到底是怎么工作的呢？ 听到Filter 链这个名词我们觉得一个 Filter 链应该可以进行链式调用，来判断我们的条件是否成立，也就是类似于下面的规则: 1filterChain.doFilter(pattern).doFilter(pattern) 这样想是没错，那每次就需要返回下一个 Filter 这么想是没错，可是我们怎么知道下一次 Filter 是谁呢？ 链表！ 对滴，这时候链表就起作用了，我们直接采用了 LinkedList 就能把这些 Filter 串起来。然后根据当前的 Filter 找出下一个 Filter 。 实际上在某些框架之中不是这么实现了的，但是基本的思路已经非常对了。例如这里是 SpringSecurity 中的 Filter 的简单实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.util.LinkedList;import java.util.List;public class Test1 &#123; interface Filter&#123; public void doFilter(FilterChain filterChain); &#125; static class MyFilter implements Filter &#123; @Override public void doFilter(FilterChain filterChain) &#123; System.out.println(\"filter invoke\"); filterChain.doFilter(); &#125; &#125; interface FilterChain&#123; public void doFilter(); &#125; static class MyFilterChain implements FilterChain&#123; List&lt;Filter&gt; filters; int pos = 0; MyFilterChain(List&lt;Filter&gt; filters) &#123; this.filters = filters; &#125; @Override public void doFilter() &#123; if (pos == filters.size()) &#123; System.out.println(\"end\"); return; &#125; Filter filter = filters.get(pos++); filter.doFilter(this); &#125; &#125; public static void main(String[] args) &#123; LinkedList&lt;Filter&gt; list = new LinkedList&lt;&gt;(); list.add(new MyFilter()); list.add(new MyFilter()); list.add(new MyFilter()); new MyFilterChain(list).doFilter(); &#125;&#125;","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Filter","slug":"Filter","permalink":"http://lwenxu.coding.me/tags/Filter/"}]},{"title":"Java 新特性之 Stream","slug":"Java SE/Java 新特性 - Stream","date":"2019-05-11T09:49:28.000Z","updated":"2019-06-04T03:36:28.000Z","comments":true,"path":"2019/05/11/Java SE/Java 新特性 - Stream/","link":"","permalink":"http://lwenxu.coding.me/2019/05/11/Java SE/Java 新特性 - Stream/","excerpt":"","text":"Stream使用这个方法创建一个 Stream 对象。 1new ArrayList&lt;&gt;().stream() Filter过滤器，里面传递一个函数，这个函数的返回结果如果为 true 则保留这个元素，否则的话丢弃这个元素。 1234stringCollection .stream() .filter((s) -&gt; s.startsWith(\"a\")) .forEach(System.out::println); Foreach遍历，消费。 1234stringCollection .stream() .filter((s) -&gt; s.startsWith(\"a\")) .forEach(System.out::println); Map这个功能也是遍历，但是他是有返回值的，而上面的 Foreach 是没有返回值的，仅仅是单纯的消费。而且 Foreach 不能够链式调用，因为没有返回值，但是 Map 没问题。 12345stringCollection .stream() .map(String::toUpperCase) .sorted(Comparator.reverseOrder()) .forEach(System.out::println); Sorted这个方法是用来排序的，里面传递的函数就是一个比较器，也可以不传递参数，使用默认的就好。 12345stringCollection .stream() .sorted(( x, y)-&gt; y.length()-x.length()) .filter((s) -&gt; s.startsWith(\"a\")) .forEach(System.out::println); Match根据在给定的 stream 对象中是否含有指定内容返回 true 或者 false 。 具体的有： allMatch anyMatch noneMatch 1234567891011boolean anyStartsWithA = stringCollection .stream() .anyMatch((s) -&gt; s.startsWith(&quot;a&quot;));boolean allStartsWithA = stringCollection .stream() .allMatch((s) -&gt; s.startsWith(&quot;a&quot;));boolean noneStartsWithZ = stringCollection .stream() .noneMatch((s) -&gt; s.startsWith(&quot;z&quot;)); count计算集合中的元素的个数。 1234long startsWithB = stringCollection .stream() .filter((s) -&gt; s.startsWith(\"b\")) .count(); reduce这个函数就是类似于斐波那契数列，每次传递的参数是上一次的结果和从集合中取出的新元素。第一次默认取出了第一个元素和第二个元素。 简单的例子就是，第一次取出 0,1 第二次取出 第一次reduce的结果作为第一个参数，取出 2 作为第二个参数，以此类推。 12345Optional&lt;String&gt; reduced = stringCollection .stream() .sorted() .reduce((s1, s2) -&gt; s1 + \"#\" + s2); parallelStream并行的 steam 流，可以进行并行处理，这样会效率更高。在使用stream.foreach时这个遍历没有线程安全问题，但是使用parallelStream就会有线程安全问题，所有在parallelStream里面使用的外部变量，比如集合一定要使用线程安全集合，不然就会引发多线程安全问题。如果说需要保证安全性需要使用 reduce 和 collect，不过这个用起来超级麻烦！！！ 1long count = values.parallelStream().sorted().count(); IntStream.range(a,b)可以直接生成 从 a 到 b 的整数这里还是遵循编程语言的大多数约定，那就是含头不含尾。 12IntStream.range(0, 10) .forEach(System.out::println); 输出的结果是 123456789100123456789 new Random().ints()获取一系列的随机值，这个接口出来的数据是连续不断的，所以需要用limit来限制一下。 1new Random().ints().limit(10).forEach(System.out::println); Supplier12Supplier&lt;String&gt; stringSupplier=String::new;stringSupplier.get(); 该接口就一个抽象方法get方法,不用传入任何参数,直接返回一个泛型T的实例.就如同无参构造一样 Consumer1. accept方法​ 该函数式接口的唯一的抽象方法,接收一个参数,没有返回值. 2. andThen方法​ 在执行完调用者方法后再执行传入参数的方法. 123456789101112public class ConsumerTest &#123; public static void main(String[] args) &#123; Consumer&lt;Integer&gt; consumer = (x) -&gt; &#123; int num = x * 2; System.out.println(num); &#125;; Consumer&lt;Integer&gt; consumer1 = (x) -&gt; &#123; int num = x * 3; System.out.println(num); &#125;; consumer.andThen(consumer1).accept(10); &#125; 先执行了 consumer.accept(10) 然后执行了 consumer1.accept(10) ifPresent针对一个optional 如果有值的话就执行否则不执行。 12345678910IntStream .builder() .add(1) .add(3) .add(5) .add(7) .add(11) .build() .average() .ifPresent(System.out::println); average 执行结果就是一个 optional Collect他有两种调用方式 12345 &lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner);&lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector); 下面主要介绍一下这两种方式的使用方法： 1. 函数第一种调用方式的接口如下 123&lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner); supplier 这个参数就是提供一个容器，可以看到最后 collect 操作的结果是一个 R 类型变量，而 supplier 接口最后需要返回的也是一个 R 类型的变量，所以说这里返回的是收集元素的容器。 accumulator 参数，看到这个函数的定义是传入一个 R 容器，后面则是 T 类型的元素，需要将这个 T 放到 R 容器中，即这一步是用来将元素添加到容器中的操作。 conbiner 这个参数是两个容器，即当出现多个容器的时候容器如何进行聚合。 一个简单的例子： 123String concat = stringStream.collect(StringBuilder::new, StringBuilder::append,StringBuilder::append).toString();//等价于上面,这样看起来应该更加清晰String concat = stringStream.collect(() -&gt; new StringBuilder(),(l, x) -&gt; l.append(x), (r1, r2) -&gt; r1.append(r2)).toString(); 2. Collector 接口第二种方案是更高级的用法采用了 Collector 接口： 1&lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector); 可以看到他返回的还是一个 R 类型的变量，也就是容器。 Collector接口是使得collect操作强大的终极武器,对于绝大部分操作可以分解为旗下主要步骤,提供初始容器-&gt;加入元素到容器-&gt;并发下多容器聚合-&gt;对聚合后结果进行操作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static class CollectorImpl&lt;T, A, R&gt; implements Collector&lt;T, A, R&gt; &#123; private final Supplier&lt;A&gt; supplier; private final BiConsumer&lt;A, T&gt; accumulator; private final BinaryOperator&lt;A&gt; combiner; private final Function&lt;A, R&gt; finisher; private final Set&lt;Characteristics&gt; characteristics; CollectorImpl(Supplier&lt;A&gt; supplier, BiConsumer&lt;A, T&gt; accumulator, BinaryOperator&lt;A&gt; combiner, Function&lt;A,R&gt; finisher, Set&lt;Characteristics&gt; characteristics) &#123; this.supplier = supplier; this.accumulator = accumulator; this.combiner = combiner; this.finisher = finisher; this.characteristics = characteristics; &#125; CollectorImpl(Supplier&lt;A&gt; supplier, BiConsumer&lt;A, T&gt; accumulator, BinaryOperator&lt;A&gt; combiner, Set&lt;Characteristics&gt; characteristics) &#123; this(supplier, accumulator, combiner, castingIdentity(), characteristics); &#125; @Override public BiConsumer&lt;A, T&gt; accumulator() &#123; return accumulator; &#125; @Override public Supplier&lt;A&gt; supplier() &#123; return supplier; &#125; @Override public BinaryOperator&lt;A&gt; combiner() &#123; return combiner; &#125; @Override public Function&lt;A, R&gt; finisher() &#123; return finisher; &#125; @Override public Set&lt;Characteristics&gt; characteristics() &#123; return characteristics; &#125; &#125; 可以看到我们可以直接 new CollectorImpl 然后将这些函数传入，另外还有一种简单的方式就是 使用 Collector.of()依然可以直接传入函数。和 new CollectorImpl 是等价的。 3. 工具函数1. toList()容器: ArrayList::new加入容器操作: List::add多容器合并: left.addAll(right); return left; 123456public static &lt;T&gt; Collector&lt;T, ?, List&lt;T&gt;&gt; toList() &#123; return new CollectorImpl&lt;&gt;((Supplier&lt;List&lt;T&gt;&gt;) ArrayList::new, List::add, (left, right) -&gt; &#123; left.addAll(right); return left; &#125;, CH_ID); &#125; 2.joining()容器: StringBuilder::new加入容器操作: StringBuilder::append多容器合并: r1.append(r2); return r1;聚合后的结果操作: StringBuilder::toString 123456public static Collector&lt;CharSequence, ?, String&gt; joining() &#123; return new CollectorImpl&lt;CharSequence, StringBuilder, String&gt;( StringBuilder::new, StringBuilder::append, (r1, r2) -&gt; &#123; r1.append(r2); return r1; &#125;, StringBuilder::toString, CH_NOID);&#125; 3.groupingBy()roupingBy是toMap的一种高级方式,弥补了toMap对值无法提供多元化的收集操作,比如对于返回Map&lt;T,List&lt;E&gt;&gt;这样的形式toMap就不是那么顺手,那么groupingBy的重点就是对Key和Value值的处理封装.分析如下代码,其中classifier是对key值的处理,mapFactory则是指定Map的容器具体类型,downstream为对Value的收集操作. 123456public static &lt;T, K, D, A, M extends Map&lt;K, D&gt;&gt; Collector&lt;T, ?, M&gt; groupingBy(Function&lt;? super T, ? extends K&gt; classifier, Supplier&lt;M&gt; mapFactory, Collector&lt;? super T, A, D&gt; downstream) &#123; ....... &#125; 一个简单的例子 1234567891011121314151617181920//原生形式 Lists.&lt;Person&gt;newArrayList().stream() .collect(() -&gt; new HashMap&lt;Integer,List&lt;Person&gt;&gt;(), (h, x) -&gt; &#123; List&lt;Person&gt; value = h.getOrDefault(x.getType(), Lists.newArrayList()); value.add(x); h.put(x.getType(), value); &#125;, HashMap::putAll );//groupBy形式Lists.&lt;Person&gt;newArrayList().stream() .collect(Collectors.groupingBy(Person::getType, HashMap::new, Collectors.toList()));//因为对值有了操作,因此我可以更加灵活的对值进行转换Lists.&lt;Person&gt;newArrayList().stream() .collect(Collectors.groupingBy(Person::getType, HashMap::new, Collectors.mapping(Person::getName,Collectors.toSet())));// 还有一种比较简单的使用方式 只需要传递一个参数按照key来划分Map&lt;Integer, List&lt;Person&gt;&gt; personsByAge = persons .stream() .collect(Collectors.groupingBy(p -&gt; p.age)); 4.reducing()reducing是针对单个值的收集,其返回结果不是集合家族的类型,而是单一的实体类T容器: boxSupplier(identity),这里包裹用的是一个长度为1的Object[]数组,至于原因自然是不可变类型的锅加入容器操作: a[0] = op.apply(a[0], t)多容器合并: a[0] = op.apply(a[0], b[0]); return a;聚合后的结果操作: 结果自然是Object[0]所包裹的数据a -&gt; a[0]优化操作状态字段: CH_NOID 123456789public static &lt;T&gt; Collector&lt;T, ?, T&gt; reducing(T identity, BinaryOperator&lt;T&gt; op) &#123; return new CollectorImpl&lt;&gt;( boxSupplier(identity), (a, t) -&gt; &#123; a[0] = op.apply(a[0], t); &#125;, (a, b) -&gt; &#123; a[0] = op.apply(a[0], b[0]); return a; &#125;, a -&gt; a[0], CH_NOID); &#125; 简单来说这个地方做的事情和 reduce 是一样的，第一个 id 传入的就是 reduce 的初始值，只是他把它包装成一个 长度为1的数组了。 1234567891011//原生操作final Integer[] integers = Lists.newArrayList(1, 2, 3, 4, 5) .stream() .collect(() -&gt; new Integer[]&#123;0&#125;, (a, x) -&gt; a[0] += x, (a1, a2) -&gt; a1[0] += a2[0]);//reducing操作final Integer collect = Lists.newArrayList(1, 2, 3, 4, 5) .stream() .collect(Collectors.reducing(0, Integer::sum)); //当然Stream也提供了reduce操作final Integer collect = Lists.newArrayList(1, 2, 3, 4, 5) .stream().reduce(0, Integer::sum)","categories":[{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://lwenxu.coding.me/tags/Java8/"}]},{"title":"Java 新特性之 Time","slug":"Java SE/Java 新特性 - Time","date":"2019-05-10T02:49:28.000Z","updated":"2019-05-11T02:45:28.000Z","comments":true,"path":"2019/05/10/Java SE/Java 新特性 - Time/","link":"","permalink":"http://lwenxu.coding.me/2019/05/10/Java SE/Java 新特性 - Time/","excerpt":"","text":"日期类 LocalDate能够简单的获取当天的日期，并且可以方便的对日期进行加减。 他是通过静态方法或者 from/of 等方法创建对象的。 这个类不存储时区，所以他没有时区的概念，如果需要时区的话需要使用 ZonedDateTime 这个类只能进行日期的相关操作，没有具体的时间。 下面介绍常用的几个方法 atTime生成一个带有时间的日期，返回结果是 LocalDateTime 所以很明显这个就是带有时间的日期类。 12LocalDateTime time = LocalDate.now().atTime(12, 3, 22,232);System.out.println(time); //2019-05-10T12:03:22.000000232 compareTo()比较两个时间返回的值是 int ，大于 0 则是比较者大，否则是被比较者大，为0相等。 format()格式化时间，需要传递一个时间的 formatter 类型为 [DateTimeFormatter] parse()同上第一个参数是解析的字符串，第二个就是传入formatter plus/minus对日期进行加减，第一个参数传入的是 int 第二个就是单位，单位使用 ChronoUnit 枚举类型 12345678910111213141516171819202122232425262728293031323334353637public class LocalDate1 &#123; public static void main(String[] args) &#123; LocalDate today = LocalDate.now(); // 添加时间 LocalDate i22day = today.plusDays(22); LocalDate tomorrow = today.plus(1, ChronoUnit.DAYS); // 减去时间 LocalDate s22day = today.minus(22, ChronoUnit.DAYS); LocalDate yesterday = tomorrow.minusDays(2); System.out.println(today); System.out.println(tomorrow); System.out.println(yesterday); System.out.println(i22day); System.out.println(s22day); LocalDate independenceDay = LocalDate.of(2014, Month.JULY, 4); DayOfWeek dayOfWeek = independenceDay.getDayOfWeek(); System.out.println(dayOfWeek); // FRIDAY DateTimeFormatter germanFormatter = DateTimeFormatter .ofLocalizedDate(FormatStyle.MEDIUM) .withLocale(Locale.GERMAN); DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(\"yyyy/mm/dd hh:mm:ss\"); LocalDate xmas = LocalDate.parse(\"24.12.2014\", germanFormatter); // System.out.println(LocalDate.parse(\"2014/02/01 12:03:22\", dateTimeFormatter)); System.out.println(xmas); // 2014-12-24 System.out.println(LocalDate.now().atStartOfDay()); LocalDateTime time = LocalDate.now().atTime(12, 3, 22,232); System.out.println(time); &#125; 时间 LocalDateTime这个和上面类似是一个时间类，不仅仅有日期还是时间。 atZone产生带有时区日期 format格式化时间 of从一个时间创建对象 of(int year, int month, int dayOfMonth, int hour, int minute, int second) parse解析时间 **parse**([CharSequence]text, [DateTimeFormatter] 123456789101112131415161718192021222324252627282930313233public class LocalDateTime1 &#123; public static void main(String[] args) &#123; LocalDateTime sylvester = LocalDateTime.of(2014, Month.DECEMBER, 31, 23, 59, 59); DayOfWeek dayOfWeek = sylvester.getDayOfWeek(); System.out.println(dayOfWeek); // WEDNESDAY Month month = sylvester.getMonth(); System.out.println(month); // DECEMBER long minuteOfDay = sylvester.getLong(ChronoField.MINUTE_OF_DAY); System.out.println(minuteOfDay); // 1439 Instant instant = sylvester .atZone(ZoneId.systemDefault()) .toInstant(); Date legacyDate = Date.from(instant); System.out.println(legacyDate); // Wed Dec 31 23:59:59 CET 2014 DateTimeFormatter formatter = DateTimeFormatter .ofPattern(\"MMM dd, yyyy - HH:mm\"); LocalDateTime parsed = LocalDateTime.parse(\"Nov 03, 2014 - 07:13\", formatter); String string = parsed.format(formatter); System.out.println(string); // Nov 03, 2014 - 07:13 &#125;&#125; LocalTime这个类是上面的LocaDateTime中的 Time 部分，也就是只具有时间没有日期。 12345678910111213141516171819202122232425262728293031323334353637public class LocalDate1 &#123; public static void main(String[] args) &#123; LocalDate today = LocalDate.now(); // 添加时间 LocalDate i22day = today.plusDays(22); LocalDate tomorrow = today.plus(1, ChronoUnit.DAYS); // 减去时间 LocalDate s22day = today.minus(22, ChronoUnit.DAYS); LocalDate yesterday = tomorrow.minusDays(2); System.out.println(today); System.out.println(tomorrow); System.out.println(yesterday); System.out.println(i22day); System.out.println(s22day); LocalDate independenceDay = LocalDate.of(2014, Month.JULY, 4); DayOfWeek dayOfWeek = independenceDay.getDayOfWeek(); System.out.println(dayOfWeek); // FRIDAY DateTimeFormatter germanFormatter = DateTimeFormatter .ofLocalizedDate(FormatStyle.MEDIUM) .withLocale(Locale.GERMAN); DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(&quot;yyyy/mm/dd hh:mm:ss&quot;); LocalDate xmas = LocalDate.parse(&quot;24.12.2014&quot;, germanFormatter); // System.out.println(LocalDate.parse(&quot;2014/02/01 12:03:22&quot;, dateTimeFormatter)); System.out.println(xmas); // 2014-12-24 System.out.println(LocalDate.now().atStartOfDay()); LocalDateTime time = LocalDate.now().atTime(12, 3, 22,232); System.out.println(time); &#125; Clock这个类可以获取当前的时间戳 12345678910111213141516171819public class Clock1 &#123; public static void main(String[] args) &#123; Clock millis = Clock.tickMillis(ZoneOffset.UTC); Clock seconds = Clock.tickSeconds(ZoneOffset.UTC); Clock minutes = Clock.tickMinutes(ZoneOffset.UTC); // 精确到毫秒的时间戳 System.out.println(millis.millis()); // 精确到秒的时间戳 System.out.println(seconds.millis()); // 精确到分钟的时间戳 System.out.println(minutes.millis()); // 精确到毫秒的时间 System.out.println(millis.instant()); // 精确到秒的时间 System.out.println(seconds.instant()); // 精确到分钟的时间 System.out.println(minutes.instant()); &#125;&#125; 上面的输出结果是： 1234561557567339397155756733900015575673000002019-05-11T09:35:39.397Z2019-05-11T09:35:39Z2019-05-11T09:35:00Z Map初始化小技巧再看Clock类中的 ZoneId 接口的时候发现了这个接口中使用了一个Map，然对Map做了初始化。一般初始化必须使用 put 放数据，这里采用了 ofEntries 来初始化多组数据。 123456789101112131415161718192021222324252627282930public static final Map&lt;String, String&gt; SHORT_IDS = Map.ofEntries( entry(\"ACT\", \"Australia/Darwin\"), entry(\"AET\", \"Australia/Sydney\"), entry(\"AGT\", \"America/Argentina/Buenos_Aires\"), entry(\"ART\", \"Africa/Cairo\"), entry(\"AST\", \"America/Anchorage\"), entry(\"BET\", \"America/Sao_Paulo\"), entry(\"BST\", \"Asia/Dhaka\"), entry(\"CAT\", \"Africa/Harare\"), entry(\"CNT\", \"America/St_Johns\"), entry(\"CST\", \"America/Chicago\"), entry(\"CTT\", \"Asia/Shanghai\"), entry(\"EAT\", \"Africa/Addis_Ababa\"), entry(\"ECT\", \"Europe/Paris\"), entry(\"IET\", \"America/Indiana/Indianapolis\"), entry(\"IST\", \"Asia/Kolkata\"), entry(\"JST\", \"Asia/Tokyo\"), entry(\"MIT\", \"Pacific/Apia\"), entry(\"NET\", \"Asia/Yerevan\"), entry(\"NST\", \"Pacific/Auckland\"), entry(\"PLT\", \"Asia/Karachi\"), entry(\"PNT\", \"America/Phoenix\"), entry(\"PRT\", \"America/Puerto_Rico\"), entry(\"PST\", \"America/Los_Angeles\"), entry(\"SST\", \"Pacific/Guadalcanal\"), entry(\"VST\", \"Asia/Ho_Chi_Minh\"), entry(\"EST\", \"-05:00\"), entry(\"MST\", \"-07:00\"), entry(\"HST\", \"-10:00\") );","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://lwenxu.coding.me/tags/Java8/"}]},{"title":"扬帆起航","slug":"Life/扬帆起航","date":"2019-04-14T01:33:55.000Z","updated":"2019-04-24T19:10:26.000Z","comments":true,"path":"2019/04/14/Life/扬帆起航/","link":"","permalink":"http://lwenxu.coding.me/2019/04/14/Life/扬帆起航/","excerpt":"","text":"扬帆起航其实很早就想写这篇文章，只是一直不知道从何说起。或者说，没能腾出一片完整的时间，给自己的大学生活写一个完整的回忆录。其实细细想来，这段时光更像是平静的水面，偶然也有湍急之处泛着白色的浪花。 开始​ 和大多数人一样，以萌新的身份来到大学，看着即将成为自己学长学姐的那群人，一时不知道从哪里开始了解这个陌生而又神秘的校园。好，美好的大学生活就先从图书馆开始。良好的习惯是成功一半，也得要先熟悉熟悉自己以后学习的地方。 ​ 摸索了挺久，才找到了计算机学科的阅览室。怎么说呢，被一大堆《Photoshop 从入门到精通》、《21 天精通 C 语言》、《JAVA语言精粹》吸引，幻想着自己真的能21天完成菜鸟到码神的逆袭。 ​ 好吧… 想多了，不过，我还是爱上了这个地方。接下来的一学期，就是扎根图书馆，进行名词式学习了。之所以称之为名词式学习，是真的觉得自己的学习，没有正确的方式。一股脑的恨不得把没听过的东西都去学一遍，没见过的语言都想办法 『21天精通』 。于是，我成了一个彻底的 “宅男” ，只不过宅的是图书馆。 ​ 所以还是想说，要在正确的路上做正确的事。这时候，一个好的引导者就显得尤为重要。他会带着你，踩尽量少的坑，走弯路更少的路。这个人，可以是你的老师，你的学长学姐，偶然发现的你们班里的大神。记得，找最适合自己的人，走最适合自己的路。 LAMP - 光​ 庆幸的是，我的野路子并没有持续太久，我找到了方向——加入实验室。这就是我想说的另一点了，加入实验室。任何时候都不要说 “等我在多学点，再怎么怎么样”。要知道，实验室本身就是，可以更好的更快的学习新东西并快速实践的地方。 ​ 我在大一下学期就进入了网络中心，也是在这里下定了决心一门心思的去做开发，不再一味的折腾 Linux 。（PS：如果不是想要看内核源码或者做系统运维，就不用花大量时间折腾 Linux 软件了，时间上比较不划算） ​ 加入了正规军，也接受了更正规的训练。我更加清楚，作为一名计算机专业的学生，我以后要走的是一条什么样的路，要成为一个怎么样的人。我们的团队叫做 “LMAP” ，取自我们开发使用的技术栈，同时也有 “光” 的含义！在这里，我度过了我的整个大学时光。 ​ 已经说不清楚，那些曾经帮助过我的老师和学长们，是我所尊敬的师长，还是陪我一起成长的家人了。我们一起撸过凌晨两点的小院烧烤，也一起看过凌晨四点钟的西大，我想在这里特别感谢帮助过我的 『杨建丰』老师，以及 『金刚』 学长， 『文科』 学长！ 嘉木​ 我想说一件，我大学里很骄傲的事。也许没什么人听过，但确确实实是我大学里很珍贵的财富。事情源于大二上学期，在一个学长的组织下我们准备建设西北大学自己的 PT 站点。奈何出师未捷身先死，本来组建的团队还没开始开发就解散了。我很感谢20岁的我，可以那么勇敢得，去一个人做我现在可能有顾虑的事。 ​ 项目基于开源的 “NexusPHP 项目” 。其实关于这个项目的案例很多，但是资料很少，很多高校采用了这套代码，并且进行了魔改，但是遗憾的是并没有开源。怀着雄心壮志，我一个人上路了。我想把它做好，然后开源出去，哪怕困难重重（事实证明遇到的困恼是重重重重重）。 ​ 项目从九月中旬一直到十二月份，出了三个测试版本。这段时间基本除了上课时间我都是坐在电脑前面赶项目。由于 NexusPHP 是 2006 年开发的，当时的开发团队采用了比较原始的前后端夹杂的方式，代码基本没有可维护性而言，大部分还是 function block 基本不存在 OO 设计，HTML 和 CSS 基本全部嵌在 PHP 中，一个文件 1000 - 3000 行，甚至还有 15000 行的。那段时间真的是日常崩溃 ，不知道因为改代码电脑死机多少次，又熬了多少次夜。经常为了一个问题和功能，想到睡不着觉，有时候做梦都在写代码，想要看着自己的成果，早点问世。 ​ 十二月份，第一个上线的版本终于确定了，第一周的注册量只有 500 。不过，当时上线的时间确实也是选择的不对，那时候快要期末考试，大家一门心思复习，没什么时间关注别的东西。第二年又对界面进行了重构，基本是全新的 UI。之后，我们也想了很多办法去提高用户量。我们组织了一些宣传活动有推出了嘉木的纪念文化衫，还想了很多办法降低用户使用站点的门槛，但是最终用户活跃度始终稳定在几百人，并没有达到预期。 ​ 最终，站点只运行了一年，由于多方面的问题被关停。这次的失败也让我明白，一个产品的孵化并不简简单单的依靠技术，产品的运营和团队管理是上层建筑。没有好的运营和管理，再好的产品也没有办法发挥价值。 ​ 另外比较庆幸的是，这次之后，我确实发现自己的技术得到了质的飞跃——毕竟 10 多万行代码的编码经验和调试上的经验比看书来的要真切的多，也算是真切的体会到 “纸上得来终觉浅，绝知此事要躬行” 。 迷茫​ 其实在嘉木比较稳定运行期间，就没有太多额外的开发工作了。那段时间除了处理实验室老师交代的任务之外，就全身心的投入到 ThinkPHP 和 OneThink 的源码。其实源码看了会很容易忘掉，所以不仅仅是看，看完以后我都会凭着印象和思路再敲一遍，实现框架和系统的核心部分。 ​ 我在阅读读 OneThink 源码时就明显感觉到了自己和巨佬们之间的差距。虽然说 OneThink 源码不是那种 “Bible 级别” ，但官方对 TP 的运用确实称的上炉火纯青。一边阅读，一边发现原来ThinkPHP 可以这么写，原来那么多特性是可以这么使用的，原来一个简单的模块需要这么多代码保证高扩展性，健壮性，和稳定性。 ​ 大二快结束时，我心里却越来越觉得慌张。自己只熟悉 PHP 一门语言，其他的只能算是入门，这样还怎么成为*『全栈工程师』 *？还怎么愉快的写 Bug ？加上那段敏感时间里，实验室学长们也都签了不错的工作，有去 BAT 的，也有去其他知名互联网公司的。他们的离开让我觉得到伤感和不舍。偶尔还会思考，实验室的下一批成员会是什么样的，我们会不会相处的很好，已经成为学长的我，能不能像我的学长们那样，给别人提供正确的引导和帮助？ 选择​ 空闲期的时间总是过得异常的快，转眼自己就已经大三了。突然发现，热爱了这么久的计算机，捣鼓着写了两年的代码，自己却没有一门能够拿得出手的技术。按照自己的规划，我是希望能够找一个不错的实习的。打开招聘网站却发现很多公司并没有 PHP 职位。当时的我，除了PHP就只会写前端了，还只能勉强算是个半吊子前端。我明确地，感受到了自己的压力和慌张。 ​ 想了段时间，我觉得剩下的一年里，学一门纯正的面向对象语言吧！可是具体要猛攻哪一门呢？ Java 在大一的有学过一段时间，但是很久不写，很多基本语法都已经不记得了。C++ 吧，当时确实用功学了半年，高级特性，内存管理，STL ，Boost 也都有好好看，只是后来也没好好用它写过项目。 ​ 其实这个问题我纠结了很久。也许很多人说 “其实不论什么编程语言只要你精通了一门，如果你能融汇贯通其实其他的语言也一样”。其实我是很抵触这种说法的，简单对于 C++ 和 Java 来说，就算你敢说你熟悉 C++ 我觉得短时间熟悉 Java 语法，能使用 Java 做开发是没问题的。就像我在大一的很大一段时间内是使用的以前编写 C++ 的思维去 Java 写的，这样不仅不能表现出这个语言的特性和优雅，反而会觉得使用起来有些蹩脚。就像一个长时间写驱动和系统软件的人去接手一个大型的 Web 项目，我想他很可能会写出垃圾代码来。 ​ 经过综合各方面的原因，我选择了Java。我知道，当我选择了一条路，另一条路上的风景便与我无关。一旦选择，我便不再摇摆不定。之后，全身心的学习Java是我每天都习以为常的事了。偶尔想想自己真的在面向‘’对象‘’编程，生活倒也怡然自得。 转折​ 良好的基础决定了成功的一半。当时的我，把 《疯狂 Java 讲义》 和 《 JDK 1.8 API 》 里面重要章节 Demo 都敲了一遍，把语言基础、集合框架、OO、IO、反射、多线程、Servlet、JSP、Hibernate … 理解的异常透彻，日常觉得自己是一个 “人工语法分析器” 。 ​ 可是当我掌握这些东西以后，我发现我好像一直停留在使用的阶段。这是一种有力气没出事的难受。后来，我开始思考，为什么我不去深入到底层探一探究竟？JDK 里的 集合框架、并发工具包、IO 究竟是如何实现的？Java 虚拟机是怎么运行起来的？JVM 的内存、GC、类加载、性能优化是怎么做到的？那些主流框架是如何设计的？DB 作为一个很重要的部分，我又该如何优化、如何做运维呢？这样的思考让我恐慌，却也促进了我的进步。我开始从另一个角度学习了。 ​ 回想那段时间，内心还是会燃气一股热血。那是知识的输入和输出都到达最大化的一个阶段。基本两天我就可以刷掉一本 200 - 400 页的书，然后整理笔记。记不起来的、感觉模糊的、牵扯到其他不理解的继续看书，找博客，弄清楚之后把自己的理解写在笔记上。有时候一天就坐在那敲一篇几万字的读书笔记。其实说不清痛苦还是快乐 … ​ 当时差不多看了 30 多本经典书籍，也算是形成了比较完整的知识结构。那种高强度的训练让我把从大一学到的各种计算机专业知识都串起来了，好像突然打通了任督二脉，总能通过一个知识点发散出很多很多相关的知识。算得上是，真正跨入了开发的门槛。 四月​ 2018 年刚开学我就泡在图书馆看书了。看以前写的笔记，整理博客，重新思考之前刷过的错题。我发现不论是以前学习的东西还是以前做的项目都还有很大的提升空间。对于以前看的书做的笔记，我又重新做了一遍，发现自己又有了很多新的理解。对于项目也会思考以前为什么那么实现，现在让我实现会不会有更好的实现方式呢？剩下的就是刷题了，LeetCode 、牛客，熟悉一些常用的算法，为找实习做准备。 ​ 三月尾，我试着投了一些简历。四月初就开始陆陆续续面试了。说到面试，其实第一次面试大家都会紧张的，但是不要让过度的紧张让自己看起来应接不暇就可以了。之后的面试就会慢慢放松下来。其实面试，也就是一个双向的沟通学习，展示自己的过程，本没有太恐怖。找准定位，变现自己，就做到了能到到的最好了。 ​ 后面就是 腾讯、阿里、百度 、携程的面试了，基本这几家面试官都很和善的，一路也算是比较顺利，只是当时腾讯最后一个主管面的时候直接给了五道算法题，还必须用 C 写，然后下载一个 gcc + CLion 基本时间过去一大半了，最后只有十多分钟做了两道题，然后就没有然后了… ​ 这里面印象比较好的就是阿里和携程了。阿里问的技术点都很深入，主要是因为问的点都偏向实际应用，我个人又更加喜欢这种关于实际开发的问题，另外也是我并不擅长算法。携程面试官则是对应聘者很热情，虽然当时面试场地没有腾讯那么大，但是面试官很 nice 的给我提了很多建议。 ​ 最后我还是去了阿里，毕竟那里是 Javaer 的天堂，也是我学Java最初的心愿了。 实习​ 阿里的师兄和师姐们都非常的 nice ，并且 对于新人的培养非常的用心。虽然感觉他们也特别忙碌，但师兄始终都很关心我，并给我找了很多资料让我熟悉业务，还抽出自己的空闲时间给我讲业务逻辑和项目结构。虽然在短时间内不能完全弄清楚公司业务，但是师兄的讲解还是让我受益颇多！ ​ 另外，在阿里的实习也让我再一次发现自己真的很渺小。我会发现原来还有这么多自己不知道的框架、系统和工具。于是我又开始宅了，只不过这一次，我宅的地方变成了公司。我每天熟悉系统的业务模型和组内维护的系统代码，还要安排时间学习集团内的新技术。忙碌而紧张的学习甚至让我来不及为自己的进步开心，只是在内心深处觉得自己应该在多学一点，在努力一点。不仅仅是为了对得起自己最初的心愿，也是为了对得起那些默默支持着我的，默默帮助着我的人。 前行​ 大四的时间过得异常的快，对于我来说，还没有好好感受过感受大学的美好就要匆匆说再见了。虽然我总是会在与别人交谈时避免谈到毕业的问题，可是自己心里清楚，自己留下了多少的遗憾。那些没有用心欣赏的玉兰花，没有好好感受过的西操场的风，以及那些来不及参与的一次次的同学聚会。 ​ 大四的生活也没有我曾经以为的那么空闲。我还是写着代码，改着论文，过着平凡而又规律的生活。也许有人会觉得，只有奋斗的大学不会遗憾吗？会的，当然会。可是，没有奋斗的大学可能就不只是遗憾了，而是悔恨。也许是习惯了忙碌而充实的生活，也许是自己骨子里无趣又枯燥的灵魂，总之，我想我还是会继续这般生活——全力以赴，问心无愧。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"http://lwenxu.coding.me/categories/生活感悟/"}],"tags":[{"name":"生活感悟","slug":"生活感悟","permalink":"http://lwenxu.coding.me/tags/生活感悟/"}]},{"title":"Spring 源码分析(一)","slug":"Spring/Spring 源码分析(一)","date":"2019-03-15T07:02:37.000Z","updated":"2019-03-15T17:05:56.000Z","comments":true,"path":"2019/03/15/Spring/Spring 源码分析(一)/","link":"","permalink":"http://lwenxu.coding.me/2019/03/15/Spring/Spring 源码分析(一)/","excerpt":"","text":"Spring 源码分析 (一)","categories":[{"name":"Spring 源码分析","slug":"Spring-源码分析","permalink":"http://lwenxu.coding.me/categories/Spring-源码分析/"},{"name":"Spring","slug":"Spring-源码分析/Spring","permalink":"http://lwenxu.coding.me/categories/Spring-源码分析/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lwenxu.coding.me/tags/Spring/"},{"name":"Spring 源码","slug":"Spring-源码","permalink":"http://lwenxu.coding.me/tags/Spring-源码/"},{"name":"源码","slug":"源码","permalink":"http://lwenxu.coding.me/tags/源码/"}]},{"title":"WebStrom 使用技巧","slug":"FrontEnd/WebStrom 技巧","date":"2019-01-21T07:28:28.000Z","updated":"2019-01-20T23:49:26.000Z","comments":true,"path":"2019/01/21/FrontEnd/WebStrom 技巧/","link":"","permalink":"http://lwenxu.coding.me/2019/01/21/FrontEnd/WebStrom 技巧/","excerpt":"","text":"1. React live template state this.state sst this.setState rpc 生成组件类 rsfp 生成组件函数 rrc 具有redux的组件类 rpt propTypes ren render 方法 ptsr string required pts string 类型 pto object 类型 ptor object required ptn/ptnr ptf/ptfr ptb/ptbf pta/ptar number / function / bool /array props this.props est this.state={} cdm componentDidMount","categories":[{"name":"工具","slug":"工具","permalink":"http://lwenxu.coding.me/categories/工具/"}],"tags":[{"name":"工具 WebStrom JetBrains","slug":"工具-WebStrom-JetBrains","permalink":"http://lwenxu.coding.me/tags/工具-WebStrom-JetBrains/"}]},{"title":"React 实战","slug":"FrontEnd/React 实战","date":"2019-01-17T03:20:28.000Z","updated":"2019-01-20T23:26:40.000Z","comments":true,"path":"2019/01/17/FrontEnd/React 实战/","link":"","permalink":"http://lwenxu.coding.me/2019/01/17/FrontEnd/React 实战/","excerpt":"","text":"1.目录 2.依赖安装1234cnpm install antd-mobile -S //组件按需加载 第二个是用来做react脚手架的二次配置的，因为我们看不到Webpack的配置文件了 https://www.cnblogs.com/xiaohuochai/p/8491055.htmlcnpm install --save-dev babel-plugin-import react-app-rewired@2.0.2-next.0 //注意指定版本号否则不兼容cnpm install --save-dev less@2.7.3 less-loader 3.配置项目1.修改index添加触摸事件123456789101112&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no\" /&gt;&lt;script src=\"https://as.alipayobjects.com/g/component/fastclick/1.0.6/fastclick.js\"&gt;&lt;/script&gt; &lt;script&gt; if ('addEventListener' in document) &#123; document.addEventListener('DOMContentLoaded', function() &#123; FastClick.attach(document.body); &#125;, false); &#125; if(!window.Promise) &#123; document.writeln('&lt;script src=\"https://as.alipayobjects.com/g/component/es6-promise/3.2.2/es6-promise.min.js\"'+'&gt;'+'&lt;'+'/'+'script&gt;'); &#125;&lt;/script&gt; 2.添加 antd 配置文件 config-overrides.js注意这个文件不是在 src 下面而是在整个项目的与 package,json 同级的目录。定义加载配置的 js 模块 ! 123456const &#123;injectBabelPlugin&#125; = require('react-app-rewired');module.exports = function override(config, env) &#123;config = injectBabelPlugin(['import', &#123;libraryName: 'antd-mobile', style: 'css'&#125;],config);return config;&#125; 修改配置: package.json 123456\"scripts\": &#123; \"start\": \"react-app-rewired start\", \"build\": \"react-app-rewired build\", \"test\": \"react-app-rewired test --env=jsdom\", \"eject\": \"react-scripts eject\"&#125; 这是关于自定义配置的内容 Antd配置","categories":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://lwenxu.coding.me/categories/FrontEnd/"}],"tags":[{"name":"React","slug":"React","permalink":"http://lwenxu.coding.me/tags/React/"}]},{"title":"MangoDB 入门","slug":"DataBase/MangoDB 入门","date":"2019-01-16T01:53:28.000Z","updated":"2019-01-16T00:28:04.000Z","comments":true,"path":"2019/01/16/DataBase/MangoDB 入门/","link":"","permalink":"http://lwenxu.coding.me/2019/01/16/DataBase/MangoDB 入门/","excerpt":"","text":"1. 设置为windows启动项1mongod -dbpath \"C:\\Program Files\\MongoDB\\Server\\4.0\\data\" -logpath \"C:\\Program Files\\MongoDB\\Server\\4.0\\log\\MongoDB.log\" -install -serviceName \"MongoDB\" 2.基本概念 数据库（database）:数据的仓库可以在仓库中存放集合 集合（collection）：集合是数组可以在集合中存放文档 文档（document）：存储操作的都是文档，文档是数据库中最小的单位。 在MongoDB中，数据库和集合都不需要手动创建，当我们创建文档时，如果文档所在的集合或数据库不存在会自动创建数据库和集合.MongoDB的文档的属性值也可以是一个文档，当一个文档的属性值是一个文档时，我们称这个文档叫做 内嵌文档 1db.users.update(&#123;username:&quot;sunwukong&quot;&#125;,&#123;$set:&#123;hobby:&#123;cities:[&quot;beijing&quot;,&quot;shanghai&quot;,&quot;shenzhen&quot;] , movies:[&quot;sanguo&quot;,&quot;hero&quot;]&#125;&#125;&#125;); 3.基本指令1. 显示数据库12show dbsshow databases 2.进入到指定的数据库中1use 数据库名 ​ 如果我们use了一个不存在的数据库他也不会报错而是在我们第一次创建文档的时候创建这个数据库，在MongoDB中所有的数据库和集合都不需要我们去创建的 。 3.当前所处的数据库1db 注意一下 db 就类似于 this 只想当前的上下文，我们在后面的 crud 操作可以直接使用数据库名也可以在进入到数据库之后直接使用 db 4.显示数据库中所有的集合1show collections 5.数据库的CRUD（增删改查）的操作1.向数据库中插入文档1db.&lt;collection&gt;.insert() 向集合中插入一个或多个文档 当我们向集合中插入文档时，如果没有给文档指定_id属性，则数据库会自动为文档添加 _id 该属性用来作为文档的唯一标识 , _id我们可以自己指定，如果我们指定了数据库就不会在添加了，如果自己指定_id 也必须确保它的唯一性 12db.collection.insertOne() 插入一个文档对象db.collection.insertMany() 插入多个文档对象 上面的是在3.2 版本中新加的操作，为了语义更加的明确。 例子：向test数据库中的，stus集合中插入一个新的学生对象{name:”孙悟空”,age:18,gender:”男”} 12345678910db.stus.insert(&#123;name:&quot;孙悟空&quot;,age:18,gender:&quot;男&quot;&#125;)test.stus.insert(&#123;name:“lwne”,age:12,gender:“女”&#125;)use test;db.stus.insert(&#123;name:&quot;lwen&quot;,age:12&#125;)db.stus.insert([&#123;name:&quot;lwen&quot;,age:12&#125;,&#123;name:&quot;lwen&quot;,age:12&#125;,&#123;name:&quot;lwen&quot;,age:12&#125;])db.stus.find() 2.查询1db.collection.find() find()用来查询集合中所有符合条件的文档，find()可以接收一个对象作为条件参数{} 空对象或者{ }表示查询集合中所有的文档{属性:值} 查询属性是指定值的文档 find()返回的是一个数组 1db.collection.findOne() 用来查询集合中符合条件的第一个文档 ，findOne()返回的是一个文档对象 1db.collection.find(&#123;&#125;).count() 查询所有结果的数量 MongoDB支持直接通过内嵌文档的属性进行查询，如果要查询内嵌文档则可以通过.的形式来匹配如果要通过内嵌文档来对文档进行查询，此时属性名必须使用引号 1db.users.find(&#123;&apos;hobby.movies&apos;:&quot;hero&quot;&#125;); 逻辑条件查询： 19.查询numbers中num大于5000的文档 1234567db.numbers.find(&#123;num:&#123;$gt:500&#125;&#125;); 大于500db.numbers.find(&#123;num:&#123;$eq:500&#125;&#125;); 等于500db.numbers.find().limit(10); 查看numbers集合中的前10条数据db.numbers.find(); 开发时，我们绝对不会执行不带条件的查询db.numbers.find().skip(10).limit(10);db.emp.find(&#123;sal:&#123;$lt:2000 , $gt:1000&#125;&#125;); 查询工资在1000-2000之间的员工db.emp.find(&#123;$or:[&#123;sal:&#123;$lt:1000&#125;&#125; , &#123;sal:&#123;$gt:2500&#125;&#125;]&#125;); 查询工资小于1000或大于2500的员工 skip()用于跳过指定数量的数据 1skip((页码-1) * 每页显示的条数).limit(每页显示的条数); 数据分页 12345db.stus.find(&#123;_id:&quot;hello&quot;&#125;);db.stus.find(&#123;age:16 , name:&quot;白骨精&quot;&#125;);db.stus.find(&#123;age:28&#125;);db.stus.findOne(&#123;age:28&#125;);db.stus.find(&#123;&#125;).count(); 3.修改 db.collection.update(查询条件,新对象) update()默认情况下会使用新对象来替换旧的对象 如果需要修改指定的属性，而不是替换需要使用“修改操作符”来完成修改$set 可以用来修改文档中的指定属性$unset 可以用来删除文档的指定属性 $push 用于向数组中添加一个新的元素$addToSet 向数组中添加一个新元素 ， 如果数组中已经存在了该元素，则不会添加 12db.users.update(&#123;username:&quot;tangseng&quot;&#125;,&#123;$push:&#123;&quot;hobby.movies&quot;:&quot;Interstellar&quot;&#125;&#125;);db.users.update(&#123;username:&quot;tangseng&quot;&#125;,&#123;$addToSet:&#123;&quot;hobby.movies&quot;:&quot;Interstellar&quot;&#125;&#125;); update()默认只会修改一个 1db.collection.updateMany() 同时修改多个符合条件的文档 1db.collection.updateOne() 修改一个符合条件的文档 1db.collection.replaceOne() 替换一个文档 123456789101112131415161718192021222324252627282930313233343536373839//替换db.stus.update(&#123;name:&quot;沙和尚&quot;&#125;,&#123;age:28&#125;);db.stus.update( &#123;&quot;_id&quot; : ObjectId(&quot;59c219689410bc1dbecc0709&quot;)&#125;, &#123;$set:&#123; gender:&quot;男&quot;, address:&quot;流沙河&quot; &#125;&#125; )db.stus.update( &#123;&quot;_id&quot; : ObjectId(&quot;59c219689410bc1dbecc0709&quot;)&#125;, &#123;$unset:&#123; address:1 &#125;&#125; )db.stus.updateMany( &#123;&quot;name&quot; : &quot;猪八戒&quot;&#125;, &#123; $set:&#123; address:&quot;猪老庄&quot; &#125; &#125; ); db.stus.update( &#123;&quot;name&quot; : &quot;猪八戒&quot;&#125;, &#123; $set:&#123; address:&quot;呵呵呵&quot; &#125; &#125; , &#123; multi:true &#125; ) 4.删除1db.collection.remove() 删除一个或多个，可以第二个参数传递一个true，则只会删除一个 如果传递一个空对象作为参数，则会删除所有的 1234db.collection.deleteOne()db.collection.deleteMany()db.collection.drop() 删除集合db.dropDatabase() 删除数据库 一般数据库中的数据都不会删除，所以删除的方法很少调用，一般会在数据中添加一个字段，来表示数据是否被删除 6.排序投影查询文档时，默认情况是按照_id的值进行排列（升序），sort()可以用来指定文档的排序的规则,sort()需要传递一个对象来指定排序规则 1表示升序 -1表示降序 12//limit skip sort 可以以任意的顺序进行调用db.emp.find(&#123;&#125;).sort(&#123;sal:1,empno:-1&#125;); 在查询时，可以在第二个参数的位置来设置查询结果的 投影 1db.emp.find(&#123;&#125;,&#123;ename:1 , _id:0 , sal:1&#125;); 4. mongoose1. 连接数据库 下载安装Mongoose ​ npm i mongoose –save 在项目中引入mongoose ​ var mongoose = require(“mongoose”); 连接MongoDB数据库 mongoose.connect(‘mongodb://数据库的ip地址:端口号/数据库名’, { useMongoClient: true});如果端口号是默认端口号（27017） 则可以省略不写 断开数据库连接(一般不需要调用) MongoDB数据库，一般情况下，只需要连接一次，连接一次以后，除非项目停止服务器关闭，否则连接一般不会断开mongoose.disconnect() 监听MongoDB数据库的连接状态 在mongoose对象中，有一个属性叫做connection，该对象表示的就是数据库连接.通过监视该对象的状态，可以来监听数据库的连接与断开 数据库连接成功的事件 ​ mongoose.connection.once(“open”,function(){})} ​ 2. 数据库断开的事件 ​ mongoose.connection.once(“close”,function(){}); 123456789101112131415//引入var mongoose = require(&quot;mongoose&quot;);//连接数据库mongoose.connect(&quot;mongodb://127.0.0.1/mongoose_test&quot; , &#123; useMongoClient: true&#125;);mongoose.connection.once(&quot;open&quot;,function()&#123; console.log(&quot;数据库连接成功~~~&quot;);&#125;);mongoose.connection.once(&quot;close&quot;,function()&#123; console.log(&quot;数据库连接已经断开~~~&quot;);&#125;);//断开数据库连接mongoose.disconnect(); 2. Schema这个东西可以看做我们的关系数据库的表的约束。比如哪些字段必须有，而且他的值是什么类型，默认值是什么，这样我们在语言中就不会出现类型转换错误的情况，并且在mongoose中也会帮我们去做转换。 12345678910111213141516171819202122232425262728293031323334353637383940var mongoose = require(&quot;mongoose&quot;);mongoose.connect(&quot;mongodb://127.0.0.1/mongoose_test&quot;,&#123;useMongoClient:true&#125;);mongoose.connection.once(&quot;open&quot;,function () &#123; console.log(&quot;数据库连接成功~~~&quot;);&#125;);//将mongoose.Schema 赋值给一个变量var Schema = mongoose.Schema;//创建Schema（模式）对象var stuSchema = new Schema(&#123; name:String, age:Number, gender:&#123; type:String, default:&quot;female&quot; &#125;, address:String&#125;);//通过Schema来创建Model//Model代表的是数据库中的集合，通过Model才能对数据库进行操作//mongoose.model(modelName, schema)://modelName 就是要映射的集合名 mongoose会自动将集合名变成复数var StuModel = mongoose.model(&quot;student&quot; , stuSchema);//向数据库中插入一个文档//StuModel.create(doc, function(err)&#123;&#125;);StuModel.create(&#123; name:&quot;白骨精&quot;, age:16, address:&quot;白骨洞&quot;&#125;,function (err) &#123; if(!err)&#123; console.log(&quot;插入成功~~~&quot;); &#125;&#125;); 3. Model有了Model，我们就可以来对数据库进行增删改查的操作了 ​ Model.create(doc(s), [callback]) 用来创建一个或多个文档并添加到数据库中 参数： ​ doc(s) 可以是一个文档对象，也可以是一个文档对象的数组 ​ callback 当操作完成以后调用的回调函数 查询的： 123Model.find(conditions, [projection], [options], [callback]) 查询所有符合条件的文档 总会返回一个数组Model.findById(id, [projection], [options], [callback]) 根据文档的id属性查询文档Model.findOne([conditions], [projection], [options], [callback]) 查询符合条件的第一个文档 总和返回一个具体的文档对象 conditions 查询的条件 projection 投影 需要获取到的字段，两种方式 {name:1,_id:0} “name -_id” options 查询选项（skip limit） ​ skip:3 , limit:1} callback 回调函数，查询结果会通过回调函数返回 ​ 回调函数必须传，如果不传回调函数，压根不会查询 使用Model进行增删改查12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485StuModel.find(&#123;name:\"唐僧\"&#125;,function (err , docs) &#123; if(!err)&#123; console.log(docs); &#125;&#125;);StuModel.find(&#123;&#125;,&#123;name:1 , _id:0&#125;,function (err , docs) &#123; if(!err)&#123; console.log(docs); &#125;&#125;);StuModel.find(&#123;&#125;,\"name age -_id\", &#123;skip:3 , limit:1&#125; , function (err , docs) &#123; if(!err)&#123; console.log(docs); &#125;&#125;);StuModel.findOne(&#123;&#125; , function (err , doc) &#123; if(!err)&#123; console.log(doc); &#125;&#125;);StuModel.findById(\"59c4c3cf4e5483191467d392\" , function (err , doc) &#123; if(!err)&#123; //console.log(doc); //通过find()查询的结果，返回的对象，就是Document，文档对象 //Document对象是Model的实例 console.log(doc instanceof StuModel); &#125;&#125;);StuModel.create([ &#123; name:\"沙和尚\", age:38, gender:\"male\", address:\"流沙河\" &#125;],function (err) &#123; if(!err)&#123; console.log(arguments); &#125;&#125;);/* 修改 Model.update(conditions, doc, [options], [callback]) Model.updateMany(conditions, doc, [options], [callback]) Model.updateOne(conditions, doc, [options], [callback]) - 用来修改一个或多个文档 - 参数： conditions 查询条件 doc 修改后的对象 options 配置参数 callback 回调函数 Model.replaceOne(conditions, doc, [options], [callback])* */StuModel.updateOne(&#123;name:\"唐僧\"&#125;,&#123;$set:&#123;age:20&#125;&#125;,function (err) &#123; if(!err)&#123; console.log(\"修改成功\"); &#125;&#125;);/*删除： Model.remove(conditions, [callback]) Model.deleteOne(conditions, [callback]) Model.deleteMany(conditions, [callback])*/StuModel.remove(&#123;name:\"白骨精\"&#125;,function (err) &#123; if(!err)&#123; console.log(\"删除成功~~\"); &#125;&#125;); Model.count(conditions, [callback]) - 统计文档的数量的StuModel.count(&#123;&#125;,function (err , count) &#123; if(!err)&#123; console.log(count); &#125;&#125;); 4.document​ Document 和 集合中的文档一一对应 ， Document是Model的实例，通过Model查询到结果都是Document 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108var mongoose = require(\"mongoose\");mongoose.connect(\"mongodb://127.0.0.1/mongoose_test\",&#123;useMongoClient:true&#125;);mongoose.connection.once(\"open\",function () &#123; console.log(\"数据库连接成功~~~\");&#125;);var Schema = mongoose.Schema;var stuSchema = new Schema(&#123; name:String, age:Number, gender:&#123; type:String, default:\"female\" &#125;, address:String&#125;);var StuModel = mongoose.model(\"student\" , stuSchema);/* Document 和 集合中的文档一一对应 ， Document是Model的实例 通过Model查询到结果都是Document *///创建一个Documentvar stu = new StuModel(&#123; name:\"奔波霸\", age:48, gender:\"male\", address:\"碧波潭\"&#125;);/* document的方法 Model#save([options], [fn]) *//*stu.save(function (err) &#123; if(!err)&#123; console.log(\"保存成功~~~\"); &#125;&#125;);*/StuModel.findOne(&#123;&#125;,function (err , doc) &#123; if(!err)&#123; /* update(update,[options],[callback]) - 修改对象 remove([callback]) - 删除对象 */ //console.log(doc); /*doc.update(&#123;$set:&#123;age:28&#125;&#125;,function (err) &#123; if(!err)&#123; console.log(\"修改成功~~~\"); &#125; &#125;);*/ /*doc.age = 18; doc.save();*/ /*doc.remove(function (err) &#123; if(!err)&#123; console.log(\"大师兄再见~~~\"); &#125; &#125;);*/ /* get(name) - 获取文档中的指定属性值 set(name , value) - 设置文档的指定的属性值 id - 获取文档的_id属性值 toJSON() ****** - 转换为一个JSON对象 toObject() - 将Document对象转换为一个普通的JS对象 转换为普通的js对象以后，注意所有的Document对象的方法或属性都不能使用了 */ //console.log(doc.get(\"age\")); //console.log(doc.age); //doc.set(\"name\",\"猪小小\"); //doc.name = \"hahaha\"; //console.log(doc._id); //var j = doc.toJSON(); //console.log(j); //var o = doc.toObject(); //console.log(o); doc = doc.toObject(); delete doc.address; console.log(doc._id); &#125;&#125;);","categories":[{"name":"数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/categories/数据库/"}],"tags":[{"name":"DB MangoDB","slug":"DB-MangoDB","permalink":"http://lwenxu.coding.me/tags/DB-MangoDB/"}]},{"title":"块级元素居中方案","slug":"FrontEnd/块级元素居中方案","date":"2019-01-10T14:01:28.000Z","updated":"2019-01-13T09:30:20.000Z","comments":true,"path":"2019/01/10/FrontEnd/块级元素居中方案/","link":"","permalink":"http://lwenxu.coding.me/2019/01/10/FrontEnd/块级元素居中方案/","excerpt":"","text":"1. 方案一html: 1&lt;div class=&quot;main&quot;&gt;&lt;/main&gt; css: 12345678910.main&#123; width:400px; height:200px; background:#eee; position:absolute; left:50%; top:50%; margin-left:-200px; margin-top:-100px;&#125; 利用定位，移动宽高的一半，然后margin负值回去一半的一半。 2.方案二html: 1&lt;div class=&quot;main&quot;&gt;&lt;/div&gt; css: 1234567891011121314body &#123; height: 100%;&#125;.main&#123; width: 400px; height: 200px; background:#eee; position:absolute; top: 0; left: 0; bottom: 0; right: 0; margin: auto;&#125; 最常用，直接一个布局搞定，在水平方向垂直方向都可以自定义的居中。 3.方案三html: 123&lt;div class=&quot;main&quot;&gt; hello world&lt;/div&gt; css: 1234567.main&#123; background:#eee; position:absolute; left:50%; top:50%; transform: translate(-50%,-50%);&#125; 这个其实和第一个非常类似，他们是做了一个位移，位移的方位分别是 x 和 y 两个轴上。移动自身的 50% 注意这个地方位移不是指外部容器的 50% 而是自身。 Stack Overflow中的解释 4.方案四html: 1234&lt;body&gt; &lt;div class=&quot;main&quot;&gt; &lt;/div&gt;&lt;/body&gt; css： 12345678910111213html,body&#123; width: 100%; height: 100%; display: -webkit-flex; display: flex; justify-content:center; align-items:center;&#125;.container&#123; width: 400px; height: 200px; background: #ccc;&#125;","categories":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://lwenxu.coding.me/categories/FrontEnd/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"http://lwenxu.coding.me/tags/CSS/"}]},{"title":"Webpack 入门","slug":"FrontEnd/webpack 入门","date":"2019-01-10T07:20:28.000Z","updated":"2019-01-13T09:30:20.000Z","comments":true,"path":"2019/01/10/FrontEnd/webpack 入门/","link":"","permalink":"http://lwenxu.coding.me/2019/01/10/FrontEnd/webpack 入门/","excerpt":"","text":"从 webpack v4.0.0 开始，可以不用引入一个配置文件。然而，webpack 仍然还是高度可配置的。在开始前你需要先理解四个核心概念： 入口(entry) 输出(output) loader 插件(plugins) 1.入口(entry)入口起点(entry point)指示 webpack 应该使用哪个模块，来作为构建其内部依赖图的开始。进入入口起点后，webpack 会找出有哪些模块和库是入口起点（直接和间接）依赖的。 123module.exports = &#123; entry: './path/to/my/entry/file.js'&#125;; 2.出口(output)output 属性告诉 webpack 在哪里输出它所创建的 bundles，以及如何命名这些文件，默认值为 ./dist。 123456789const path = require('path');module.exports = &#123; entry: './path/to/my/entry/file.js', output: &#123; path: path.resolve(__dirname, 'dist'), filename: 'my-first-webpack.bundle.js' &#125;&#125;; 3.loaderloader 让 webpack 能够去处理那些非 JavaScript 文件（webpack 自身只理解 JavaScript 和 Json）。loader 可以将所有类型的文件转换为 webpack 能够处理的有效模块，然后你就可以利用 webpack 的打包能力，对它们进行处理。 在更高层面，在 webpack 的配置中 loader 有两个目标： test 属性，用于标识出应该被对应的 loader 进行转换的某个或某些文件。 use 属性，表示进行转换时，应该使用哪个 loader。 1234567891011121314const path = require('path');const config = &#123; output: &#123; filename: 'my-first-webpack.bundle.js' &#125;, module: &#123; rules: [ &#123; test: /\\.txt$/, use: 'raw-loader' &#125; ] &#125;&#125;;module.exports = config; 4.插件(plugins)​ loader 被用于转换某些类型的模块，而插件则可以用于执行范围更广的任务。插件的范围包括，从打包优化和压缩，一直到重新定义环境中的变量。插件接口功能极其强大，可以用来处理各种各样的任务。 ​ 想要使用一个插件，你只需要 require() 它，然后把它添加到 plugins 数组中。多数插件可以通过选项(option)自定义。你也可以在一个配置文件中因为不同目的而多次使用同一个插件，这时需要通过使用 new 操作符来创建它的一个实例。 123456789101112131415const HtmlWebpackPlugin = require('html-webpack-plugin'); // 通过 npm 安装const webpack = require('webpack'); // 用于访问内置插件const config = &#123; module: &#123; rules: [ &#123; test: /\\.txt$/, use: 'raw-loader' &#125; ] &#125;, plugins: [ new HtmlWebpackPlugin(&#123;template: './src/index.html'&#125;) ]&#125;;module.exports = config; webpack 提供许多开箱可用的插件！查阅我们的插件列表获取更多信息。 5.模式通过选择 development 或 production 之中的一个，来设置 mode 参数，你可以启用相应模式下的 webpack 内置的优化 123module.exports = &#123; mode: 'production'&#125;;","categories":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://lwenxu.coding.me/categories/FrontEnd/"}],"tags":[{"name":"Webpack","slug":"Webpack","permalink":"http://lwenxu.coding.me/tags/Webpack/"}]},{"title":"JavaScript 模块化","slug":"FrontEnd/JavaScript 模块化","date":"2019-01-10T04:20:28.000Z","updated":"2019-01-13T09:30:20.000Z","comments":true,"path":"2019/01/10/FrontEnd/JavaScript 模块化/","link":"","permalink":"http://lwenxu.coding.me/2019/01/10/FrontEnd/JavaScript 模块化/","excerpt":"","text":"1. 模块化过程1. 全局函数123456789101112/** * 全局函数模式: 将不同的功能封装成不同的全局函数 * 问题: Global被污染了, 很容易引起命名冲突 *///数据let data = 'atguigu.com'function foo() &#123; console.log('foo()')&#125;function bar() &#123; console.log('bar()')&#125; 2. 对象空间1234567891011121314/** * namespace模式: 简单对象封装 * 作用: 减少了全局变量 * 问题: 不安全(数据不是私有的, 外部可以直接修改) */let myModule = &#123; data: 'atguigu.com', foo() &#123; console.log(`foo() $&#123;this.data&#125;`) &#125;, bar() &#123; console.log(`bar() $&#123;this.data&#125;`) &#125;&#125; 3. 立即执行函数123456789101112131415161718192021222324252627/** * IIFE模式: 匿名函数自调用(闭包) * IIFE : immediately-invoked function expression(立即调用函数表达式) * 作用: 数据是私有的, 外部只能通过暴露的方法操作 * 问题: 如果当前这个模块依赖另一个模块怎么办? */(function (window) &#123; //数据 let data = 'atguigu.com' //操作数据的函数 function foo() &#123; //用于暴露有函数 console.log(`foo() $&#123;data&#125;`) &#125; function bar() &#123;//用于暴露有函数 console.log(`bar() $&#123;data&#125;`) otherFun() //内部调用 &#125; function otherFun() &#123; //内部私有的函数 console.log('otherFun()') &#125; //暴露行为 window.myModule = &#123;foo, bar&#125;&#125;)(window) 4.依赖注入的自执行函数1234567891011121314151617181920212223242526/** * IIFE模式增强 : 引入依赖 * 这就是现代模块实现的基石 */(function (window, $) &#123; //数据 let data = 'atguigu.com' //操作数据的函数 function foo() &#123; //用于暴露有函数 console.log(`foo() $&#123;data&#125;`) $('body').css('background', 'red') &#125; function bar() &#123;//用于暴露有函数 console.log(`bar() $&#123;data&#125;`) otherFun() //内部调用 &#125; function otherFun() &#123; //内部私有的函数 console.log('otherFun()') &#125; //暴露行为 window.myModule = &#123;foo, bar&#125;&#125;)(window, jQuery) 2.CommonJS​ commonJs 是同步进行依赖引入的，并且他是相当于一个文件一个模块，对于模块的导出采用了 module.exports={} 或者使用 exports={} 来完成的，而模块的引入则是通过 let mo=require(&quot;./module.js&quot;) 但是注意 nodejs 采用的就是 CommonJs 所以他是直接可用这个语句的，但是浏览器不行，所以浏览器需要使用 bowserify 工具打包编译才能让浏览器识别。 1.在服务端应用1.下载安装node.js2.创建项目结构 12345678910|-modules |-module1.js |-module2.js |-module3.js|-app.js|-package.json &#123; &quot;name&quot;: &quot;commonJS-node&quot;, &quot;version&quot;: &quot;1.0.0&quot; &#125; 3.下载第三方模块 npm install uniq –save 4.模块化编码 module1.js 12345module.exports = &#123; foo() &#123; console.log(&apos;moudle1 foo()&apos;) &#125;&#125; module2.js 123module.exports = function () &#123; console.log(&apos;module2()&apos;)&#125; module3.js 1234567exports.foo = function () &#123; console.log(&apos;module3 foo()&apos;)&#125;exports.bar = function () &#123; console.log(&apos;module3 bar()&apos;)&#125; app.js 123456789101112131415161718192021222324252627/** 1. 定义暴露模块: module.exports = value; exports.xxx = value; 2. 引入模块: var module = require(模块名或模块路径); */&quot;use strict&quot;;//引用模块let module1 = require(&apos;./modules/module1&apos;)let module2 = require(&apos;./modules/module2&apos;)let module3 = require(&apos;./modules/module3&apos;)let uniq = require(&apos;uniq&apos;)let fs = require(&apos;fs&apos;)//使用模块module1.foo()module2()module3.foo()module3.bar()console.log(uniq([1, 3, 1, 4, 3]))fs.readFile(&apos;app.js&apos;, function (error, data) &#123; console.log(data.toString())&#125;) 5.通过node运行app.js命令: node app.js 2.在浏览器的运行1.创建项目结构 12345678910111213|-js |-dist //打包生成文件的目录 |-src //源码所在的目录 |-module1.js |-module2.js |-module3.js |-app.js //应用主源文件|-index.html|-package.json &#123; &quot;name&quot;: &quot;browserify-test&quot;, &quot;version&quot;: &quot;1.0.0&quot; &#125; 2.下载browserify 全局: npm install browserify -g 局部: npm install browserify –save-dev 定义模块代码 module1.js 12345module.exports = &#123; foo() &#123; console.log(&apos;moudle1 foo()&apos;) &#125;&#125; module2.js 123module.exports = function () &#123; console.log(&apos;module2()&apos;)&#125; module3.js 1234567exports.foo = function () &#123; console.log(&apos;module3 foo()&apos;)&#125;exports.bar = function () &#123; console.log(&apos;module3 bar()&apos;)&#125; app.js (应用的主js) 1234567891011121314//引用模块let module1 = require(&apos;./module1&apos;)let module2 = require(&apos;./module2&apos;)let module3 = require(&apos;./module3&apos;)let uniq = require(&apos;uniq&apos;)//使用模块module1.foo()module2()module3.foo()module3.bar()console.log(uniq([1, 3, 1, 4, 3])) 3.打包处理js: browserify js/src/app.js -o js/dist/bundle.js 4.页面使用引入:1&lt;script type=&quot;text/javascript&quot; src=&quot;js/dist/bundle.js&quot;&gt;&lt;/script&gt; 3. AMD异步模块定义。显示声明依赖注入 定义模块采用 define 导出模块在回调函数中 return 引入模块使用 require 1.下载require.js, 并引入 官网: http://www.requirejs.cn/ github : https://github.com/requirejs/requirejs 将require.js导入项目: js/libs/require.js 2.创建项目结构12345678|-js |-libs |-require.js |-modules |-alerter.js |-dataService.js |-main.js|-index.html 3.定义require.js的模块代码 dataService.js 123456789define(function () &#123; let msg = &apos;test&apos; function getMsg() &#123; return msg.toUpperCase() &#125; return &#123;getMsg&#125;&#125;) alerter.js 12345678910define([&apos;dataService&apos;, &apos;jquery&apos;], function (dataService, $) &#123; let name = &apos;Tom2&apos; function showMsg() &#123; $(&apos;body&apos;).css(&apos;background&apos;, &apos;gray&apos;) alert(dataService.getMsg() + &apos;, &apos; + name) &#125; return &#123;showMsg&#125;&#125;) 4.应用主(入口)js: main.js 12345678910111213141516(function () &#123; //配置 require.config(&#123; //基本路径 baseUrl: &quot;js/&quot;, //模块标识名与模块路径映射 paths: &#123; &quot;alerter&quot;: &quot;modules/alerter&quot;, &quot;dataService&quot;: &quot;modules/dataService&quot;, &#125; &#125;) //引入使用模块 require( [&apos;alerter&apos;], function(alerter) &#123; alerter.showMsg() &#125;)&#125;)() 6.页面使用模块:1&lt;script data-main=&quot;js/main&quot; src=&quot;js/libs/require.js&quot;&gt;&lt;/script&gt; 7.使用第三方基于require.js1.将jquery的库文件导入到项目:js/libs/jquery-1.10.1.js 2.在main.js中配置jquery路径123paths: &#123; &apos;jquery&apos;: &apos;libs/jquery-1.10.1&apos; &#125; 3.在alerter.js中使用jquery12345678define([&apos;dataService&apos;, &apos;jquery&apos;], function (dataService, $) &#123; var name = &apos;xfzhang&apos; function showMsg() &#123; $(&apos;body&apos;).css(&#123;background : &apos;red&apos;&#125;) alert(name + &apos; &apos;+dataService.getMsg()) &#125; return &#123;showMsg&#125;&#125;) 8.第三方不基于require.js的框架1.将angular.js和angular-messages.js导入项目 js/libs/angular.js js/libs/angular-messages.js 2.在main.js中配置123456789101112131415161718192021222324252627282930313233343536(function () &#123; require.config(&#123; //基本路径 baseUrl: &quot;js/&quot;, //模块标识名与模块路径映射 paths: &#123; //第三方库 &apos;jquery&apos; : &apos;libs/jquery-1.10.1&apos;, &apos;angular&apos; : &apos;libs/angular&apos;, &apos;angular-messages&apos; : &apos;libs/angular-messages&apos;, //自定义模块 &quot;alerter&quot;: &quot;modules/alerter&quot;, &quot;dataService&quot;: &quot;modules/dataService&quot; &#125;, /* 配置不兼容AMD的模块 exports : 指定导出的模块名 deps : 指定所有依赖的模块的数组 */ shim: &#123; &apos;angular&apos; : &#123; exports : &apos;angular&apos; &#125;, &apos;angular-messages&apos; : &#123; exports : &apos;angular-messages&apos;, deps : [&apos;angular&apos;] &#125; &#125; &#125;) //引入使用模块 require( [&apos;alerter&apos;, &apos;angular&apos;, &apos;angular-messages&apos;], function(alerter, angular) &#123; alerter.showMsg() angular.module(&apos;myApp&apos;, [&apos;ngMessages&apos;]) angular.bootstrap(document,[&quot;myApp&quot;]) &#125;)&#125;)() 3.页面1234&lt;form name=&quot;myForm&quot;&gt; 用户名: &lt;input type=&quot;text&quot; name=&quot;username&quot; ng-model=&quot;username&quot; ng-required=&quot;true&quot;&gt; &lt;div style=&quot;color: red;&quot; ng-show=&quot;myForm.username.$dirty&amp;&amp;myForm.username.$invalid&quot;&gt;用户名是必须的&lt;/div&gt;&lt;/form&gt; 4. ES6​ es6这种方式就是定义模块直接向我们定义一个对象或者函数一样，而需要导出就是采用 export 导出函数或者对象或变量。在一个模块中可以多次 export 但是在引入的时候必须采用对象解构的方式导入我们 export 的内容。 12345//------------------module.jsexport foo=()=&gt;&#123;&#125;export boo=()=&gt;&#123;&#125;//------------------main.jsimport &#123;foo,boo&#125; from './module.js' ​ 如果我们使用默认导出则是可以直接用一个变量来接受我们导出的内容。 12import module from './module.js'module.foo(); 1.定义package.json文件 1234&#123; &quot;name&quot; : &quot;es6-babel-browserify&quot;, &quot;version&quot; : &quot;1.0.0&quot;&#125; 2.安装babel-cli, babel-preset-es2015和browserify12npm install babel-cli browserify -g // babel 的命令行工具npm install babel-preset-es2015 --save-dev // babel的工具包，babel的工具包作用有很多比如这里 es6 转 es5 还有把jsx转html等 3.定义.babelrc文件123&#123; \"presets\": [\"es2015\"] //在babel工作之前会读取这个文件，然后表明babel调用什么模块做什么事情，这个就是 es6转es5 比如说还有 react 就是转jsx语法 &#125; 4.编码 js/src/module1.js 1234567export function foo() &#123; console.log(&apos;module1 foo()&apos;);&#125;export let bar = function () &#123; console.log(&apos;module1 bar()&apos;);&#125;export const DATA_ARR = [1, 3, 5, 1] js/src/module2.js 1234567891011let data = &apos;module2 data&apos;function fun1() &#123; console.log(&apos;module2 fun1() &apos; + data);&#125;function fun2() &#123; console.log(&apos;module2 fun2() &apos; + data);&#125;export &#123;fun1, fun2&#125; js/src/module3.js 123456export default &#123; name: &apos;Tom&apos;, setName: function (name) &#123; this.name = name &#125;&#125; js/src/app.js 1234567891011121314151617import &#123;foo, bar&#125; from &apos;./module1&apos;import &#123;DATA_ARR&#125; from &apos;./module1&apos;import &#123;fun1, fun2&#125; from &apos;./module2&apos;import person from &apos;./module3&apos;import $ from &apos;jquery&apos;$(&apos;body&apos;).css(&apos;background&apos;, &apos;red&apos;)foo()bar()console.log(DATA_ARR);fun1()fun2()person.setName(&apos;JACK&apos;)console.log(person.name); 5.编译 使用Babel将ES6编译为ES5代码(但包含CommonJS语法) : babel js/src -d js/lib 使用Browserify编译js : browserify js/lib/app.js -o js/lib/bundle.js 6.页面中引入测试1&lt;script type=&quot;text/javascript&quot; src=&quot;js/lib/bundle.js&quot;&gt;&lt;/script&gt; 7.引入第三方模块(jQuery)1.下载jQuery模块:npm install jquery@1 --save 2.在app.js中引入并使用12import $ from 'jquery'$('body').css('background', 'red')","categories":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://lwenxu.coding.me/categories/FrontEnd/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://lwenxu.coding.me/tags/JavaScript/"}]},{"title":"ECMAScript 从入门到精通","slug":"FrontEnd/ECMAScript 6","date":"2019-01-10T00:01:28.000Z","updated":"2019-01-13T09:30:20.000Z","comments":true,"path":"2019/01/10/FrontEnd/ECMAScript 6/","link":"","permalink":"http://lwenxu.coding.me/2019/01/10/FrontEnd/ECMAScript 6/","excerpt":"","text":"1. es51. 严格模式1.理解: 除了正常运行模式(混杂模式)，ES5添加了第二种运行模式：”严格模式”（strict mode）。 顾名思义，这种模式使得Javascript在更严格的语法条件下运行 2.目的/作用 消除Javascript语法的一些不合理、不严谨之处，减少一些怪异行为 消除代码运行的一些不安全之处，为代码的安全运行保驾护航 为未来新版本的Javascript做好铺垫3.使用 在全局或函数的第一条语句定义为: ‘use strict’; 如果浏览器不支持, 只解析为一条简单的语句, 没有任何副作用 4.语法和行为改变 必须用var声明变量 禁止自定义的函数中的this指向window，也就是不允许使用全局函数 创建eval作用域，本来的eval中定义的变量直接做变量提升为全局的作用域。可能会被攻击。 对象不能有重名的属性 2.object的拓展方法ES5给Object扩展了一些静态方法, 常用的2个: 1.Object.create(prototype, [descriptors]) 作用: 以指定对象为原型创建新的对象 为新的对象指定新的属性, 并对属性进行描述 value : 指定值 writable : 标识当前属性值是否是可修改的, 默认为false configurable: 标识当前属性是否可以被删除 默认为false enumerable： 标识当前属性是否能用for in 枚举 默认为false 1234567var obj = &#123;name : 'curry', age : 29&#125;obj1 = Object.create(obj, &#123; sex : &#123; value : '男', writable : true &#125; &#125;); obj1 的原型对象就是 obj，并企里面有一个 sex 值，但是要注意设置 sex的一些属性，比如现在 sex 就是只能够读写，不能被删除，也不能采用 for in 遍历。 2.Object.defineProperties(object, descriptors) 作用: 为指定对象定义扩展多个属性 get ：用来获取当前属性值得回调函数 set ：修改当前属性值得触发的回调函数，并且实参即为修改后的值 存取器属性：setter,getter一个用来存值，一个用来取值 12345678910111213141516var obj2 = &#123; firstName : 'curry', lastName : 'stephen'&#125;;Object.defineProperties(obj2, &#123; fullName : &#123; get : function () &#123; return this.firstName + '-' + this.lastName &#125;, set : function (data) &#123; var names = data.split('-'); this.firstName = names[0]; this.lastName = names[1]; &#125; &#125;&#125;); 可以看到新设置的 fullName 属性和其他的是不一样的，因为我们设置了 get 和 set 那么他就会惰性求值，只有我们在调用这个属性的时候会调用 get 方法求出元素的值，set 也是在设置值的时候才会调用。如果没有 get 就获取不到值，没有set则不能设置值。 除了上面这种设置 get 和 set 的方式之外还可以使用对象本身的方法： get propertyName(){} 用来得到当前属性值的回调函数 set propertyName(){} 用来监视当前属性值变化的回调函数 123456789101112var obj = &#123; firstName : 'kobe', lastName : 'bryant', get fullName()&#123; return this.firstName + ' ' + this.lastName &#125;, set fullName(data)&#123; var names = data.split(' '); this.firstName = names[0]; this.lastName = names[1]; &#125;&#125;; 代码同理。 3. Array 拓展 Array.prototype.indexOf(value) : 得到值在数组中的第一个下标 Array.prototype.lastIndexOf(value) : 得到值在数组中的最后一个下标 Array.prototype.forEach(function(item, index){}) : 遍历数组 Array.prototype.map(function(item, index){}) : 遍历数组返回一个新的数组，返回加工之后的值 Array.prototype.filter(function(item, index){}) : 遍历过滤出一个新的子数组， 返回条件为true的值 在原型上定义了这么多方法，意味着 array 的实例都可以调用这些方法。 4. 函数拓展1.Function.prototype.bind(obj)作用: 将函数内的this绑定为obj, 并将函数返回 2.区别bind()与call()和apply()?都能指定函数中的this，但是call()/apply()是立即调用函数而bind()是将函数返回。所以我们的 bind 一般是用来指定回调函数的 this。 2. es61. let1.作用: 与var类似, 用于声明一个变量 2.特点: 在块作用域内有效，以前只有文件和函数作用域，这个东西有块级作用域 不能重复声明，否则会报错 不会预处理, 不存在提升 3.应用: 循环遍历加监听 使用let取代var是趋势 2. const1.作用:定义一个常量 2.特点:不能修改其它特点同let 3.应用:保存不用改变的数据 3. 结构赋值1.理解:从对象或数组中提取数据, 并赋值给变量(多个) 2.对象的解构赋值1let &#123;n, a&#125; = &#123;n:&apos;tom&apos;, a:12&#125; 3.数组的解构赋值1let [a,b] = [1, &apos;atguigu&apos;]; 4.用途给多个形参赋值 5. 例子对象 1234let obj = &#123;name : 'kobe', age : 39,site:&#123;github:'aaa',weibo:'bbb'&#125;&#125;;//对象的解构赋值let &#123;age,site:&#123;github&#125;&#125; = obj;console.log(age,github); 数组 123let arr = ['abc', 23, true];let [, , c, d] = arr;console.log(c, d); //按照下标寻找 参数解构 1234function person1(&#123;name, age&#125;) &#123; console.log(name, age);&#125;person1(obj); 4.模板字符串 简化字符串的拼接,模板字符串必须用 `` 包含, 变化的部分使用${xxx}定义 1console.log(`我叫:$&#123;obj.name&#125;, 我的年龄是：$&#123;obj.age&#125;`); 5.对象的简写方法1.同名属性省略名字2.省略function关键字1234567let x = 1;let y = 2;let point = &#123; x, y, setX (x) &#123;this.x = x&#125;&#125;; 6.箭头函数1.作用: 定义匿名函数2.基本语法: 没有参数: () =&gt; console.log(‘xxxx’) 一个参数: i =&gt; i+2 大于一个参数: (i,j) =&gt; i+j 函数体不用大括号: 默认返回结果 函数体如果有多个语句, 需要用{}包围，若有需要返回的内容，需要手动返回 3.使用场景: 多用来定义回调函数4.箭头函数的特点： 简洁 箭头函数没有自己的this，箭头函数的this不是调用的时候决定的，而是在定义的时候处在的对象就是它的this 扩展理解： 箭头函数的this看外层的是否有函数，如果有，外层函数的this就是内部箭头函数的this，如果没有，则this是window。 1234567891011121314151617181920// 这个this是window因为内层的箭头函数往外找找到有函数，则就看他的this，而他往外找找不到说明就是windowlet obj = &#123; name : 'kobe', age : 39, getName : () =&gt; &#123; btn2.onclick = () =&gt; &#123; console.log(this);//obj &#125;; &#125;&#125;;// 这个this是window因为内层的箭头函数往外找找到有函数，则就看他的this，而他是一个普通函数就看是谁调用他了。如果是obj调用的话 this 就是 objlet obj = &#123; name : 'kobe', age : 39, getName : () =&gt; &#123; btn2.onclick = () =&gt; &#123; console.log(this);//obj &#125;; &#125;&#125;; 7. 打包解包运算符1.rest(可变)参数用来取代arguments 但比arguments灵活,他只能作为最后部分形参参数，也就是打包最后一部分形参 1234567function add(...values) &#123; let sum = 0; for(value of values) &#123; sum += value; &#125; return sum;&#125; 2.扩展运算符123let arr1 = [1,3,5];let arr2 = [2,...arr1,6];arr2.push(...arr1); 8. 形参默认值123function(a=1)&#123; &#125; 9. promise1.理解:​ Promise对象: 代表了未来某个将要发生的事件(通常是一个异步操作)，有了promise对象, 可以将异步操作以同步的流程表达出来, 避免了层层嵌套的回调函数(俗称’回调地狱’)，ES6的Promise是一个构造函数, 用来生成promise实例。 2.使用promise基本步骤(2步): 创建promise对象 123456789let promise = new Promise((resolve, reject) =&gt; &#123; //初始化promise状态为 pending //执行异步操作 if(异步操作成功) &#123; resolve(value);//自动修改promise的状态为 fullfilled ，设置了promise的状态以后然后调用then或者catch，根据promise的状态执行对应的then或者catch内容。或者说在then里面有两个函数，分别是成功和失败，他会地总调用。 里面的value 就就会传递给then里面的回调成功的入参。 &#125; else &#123; reject(errMsg);//自动修改promise的状态为 rejected &#125;&#125;) 调用promise的then() 1234promise.then(function( result =&gt; console.log(result), //这个result就是resolve里面的参数 errorMsg =&gt; alert(errorMsg))) 3.promise对象的3个状态 pending: 初始化状态 fullfilled: 成功状态 rejected: 失败状态 4.应用: 使用promise实现超时处理 使用promise封装处理ajax请求let request = new XMLHttpRequest();request.onreadystatechange = function () {}request.responseType = ‘json’;request.open(“GET”, url);request.send(); 5. 流程 10. symbolES5中对象的属性名都是字符串，容易造成重名，污染环境 1.概念：ES6中的添加了一种原始数据类型symbol(已有的原始数据类型：String, Number, boolean, null, undefined, 对象) 2.特点：​ 1、Symbol属性对应的值是唯一的，解决命名冲突问题​ 2、Symbol值不能与其他数据进行计算，包括同字符串拼串​ 3、for in, for of遍历时不会遍历symbol属性 3.使用：​ 1、调用Symbol函数得到symbol值 123let symbol = Symbol();let obj = &#123;&#125;;obj[symbol] = 'hello'; ​ 2、传参标识 ​ 2、传参标识 1234let symbol = Symbol('one');let symbol2 = Symbol('two');console.log(symbol);// Symbol('one')console.log(symbol2);// Symbol('two') ​ 3、内置Symbol值 ​ 3、内置Symbol值 除了定义自己使用的Symbol值以外，ES6还提供了11个内置的Symbol值，指向语言内部使用的方法。对象的Symbol.iterator属性，指向该对象的默认遍历器方法 11. iterator1.概念：iterator是一种接口机制，为各种不同的数据结构提供统一的访问机制 2.作用：为各种数据结构，提供一个统一的、简便的访问接口；使得数据结构的成员能够按某种次序排列ES6创造了一种新的遍历命令for…of循环，Iterator接口主要供for…of消费。 3.工作原理： 创建一个指针对象，指向数据结构的起始位置。 第一次调用next方法，指针自动指向数据结构的第一个成员 接下来不断调用next方法，指针会一直往后移动，直到指向最后一个成员 每调用next方法返回的是一个包含value和done的对象，{value: 当前成员的值,done: 布尔值} value表示当前成员的值，done对应的布尔值表示当前的数据的结构是否遍历结束。 当遍历结束的时候返回的value值是undefined，done值为false 原生具备iterator接口的数据(可用for of遍历)1、Array2、arguments3、set容器4、map容器5、String 4. 模拟为对象部署 iterator 接口12345678910111213let iteratorableObj=&#123; [Symbol.iteraor]:function()&#123; return &#123; let nextIndex=0; next:function()&#123; return &#123; value:this[nextIndex++], done:this.length==nextIndex &#125; &#125; &#125; &#125;&#125; 12. generator1.概念： ES6提供的解决异步编程的方案之一 Generator函数是一个状态机，内部封装了不同状态的数据， 用来生成遍历器对象 可暂停函数(惰性求值), yield可暂停，next方法可启动。每次返回的是yield后的表达式结果 2.特点： function 与函数名之间有一个星号 内部用yield表达式来定义不同的状态 例如：​ function* generatorExample(){​ let result = yield ‘hello’; // 状态值为hello​ yield ‘generator’; // 状态值为generator​ } generator函数返回的是指针对象({next:function{….}})，而不会执行函数内部逻辑 调用next方法函数内部逻辑开始执行，遇到yield表达式停止，返回{value: yield后的表达式结果/undefined, done: false/true} 再次调用next方法会从上一次停止时的yield处开始，直到最后 yield语句返回结果通常为undefined， 当调用next方法时传参内容会作为启动时yield语句的返回值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859function* generatorTest() &#123; console.log('函数开始执行'); let ret=yield 'hello'; console.log(ret); // 这个值就是 aaa 就是这次启动的时候next传入的值 console.log('函数暂停后再次启动'); yield 'generator';&#125;// 生成遍历器对象let Gt = generatorTest();// 执行函数，遇到yield后即暂停console.log(Gt); // 遍历器对象let result = Gt.next(); // 函数执行,遇到yield暂停console.log(result); // &#123;value: \"hello\", done: false&#125;result = Gt.next('aaa'); // 函数再次启动console.log(result); // &#123;value: 'generator', done: false&#125;result = Gt.next();console.log(result); // &#123;value: undefined, done: true&#125;表示函数内部状态已经遍历完毕// 真正的为对象部署接口采用Symbol.iterator属性;let myIterable = &#123;&#125;;myIterable[Symbol.iterator] = function* () &#123; yield 1; yield 2; yield 4;&#125;;for(let i of myIterable)&#123; console.log(i);&#125;let obj = [...myIterable];console.log(obj);console.log('-------------------------------');// 案例练习/** 需求：* 1、发送ajax请求获取新闻内容* 2、新闻内容获取成功后再次发送请求，获取对应的新闻评论内容* 3、新闻内容获取失败则不需要再次发送请求。* * */ function* sendXml() &#123; // url为next传参进来的数据 let url = yield getNews('http://localhost:3000/news?newsId=2'); yield getNews(url);&#125;function getNews(url) &#123; $.get(url, function (data) &#123; console.log(data); let commentsUrl = data.commentsUrl; let url = 'http://localhost:3000' + commentsUrl; // 当获取新闻内容成功，发送请求获取对应的评论内容 // 调用next传参会作为上次暂停是yield的返回值 sx.next(url); &#125;)&#125;let sx = sendXml();// 发送请求获取新闻内容sx.next(); 13. async这个其实是generator的语法糖，这个是 es2017 的内容，但是已经被广泛的用开了。 1.概念： 真正意义上去解决异步回调的问题，同步流程表达异步操作 2.语法：1234async function foo()&#123; await 异步操作; await 异步操作；&#125; 3.特点： 不需要像Generator去调用next方法，遇到await等待，当前的异步操作成功就往下执行 返回的总是Promise对象，可以用then方法进行下一步操作 async取代Generator函数的星号*，await取代Generator的yield 。await 的返回值就是 reslove 和 reject 的参数 语意上更为明确，使用简单，经临床验证，暂时没有任何副作用 123456789101112131415161718192021222324252627282930313233343536373839404142434445async function timeout(ms) &#123; return new Promise(resolve =&gt; &#123; setTimeout(resolve, ms); &#125;)&#125;async function asyncPrint(value, ms) &#123; console.log('函数执行', new Date().toTimeString()); await timeout(ms); console.log('延时时间', new Date().toTimeString()); console.log(value);&#125;console.log(asyncPrint('hello async', 2000));// await async function awaitTest() &#123; let result = await Promise.resolve('执行成功'); // 这个直接用来创建并设定 Promise 的状态 console.log(result); let result2 = await Promise.reject('执行失败'); // 这个直接用来创建并设定 Promise 的状态 console.log(result2); let result3 = await Promise.resolve('还想执行一次');// 执行不了，失败了就不会继续执行下去 console.log(result3);&#125;awaitTest();// 案例演示async function sendXml(url) &#123; return new Promise((resolve, reject) =&gt; &#123; $.ajax(&#123; url, type: 'GET', success: data =&gt; resolve(data), error: error =&gt; reject(error) &#125;) &#125;)&#125;async function getNews(url) &#123; let result = await sendXml(url); //如果这里报错了就会执行 reject 导致控制台抛异常，但是为了用户体验我们可以在错误的时候使用resolve但是要不让下面的函数继续执行。 let result2 = await sendXml(result.commentsUrl); console.log(result, result2);&#125;getNews('http://localhost:3000/news?id=2') 14. class 通过class定义类/实现类的继承 在类中通过constructor定义构造方法，因为原型中的 constructor 就是我们定义的工厂方法，在我们使用工厂方法的时候。 通过new来创建类的实例 通过extends来实现类的继承 通过super调用父类的构造方法 重写从父类中继承的一般方法 在class中写方法只能通过省略 function 的简写方式或者箭头函数书写，否则会报错 15. 数组扩展 Array.from(v) 将伪数组转成真数组 Array.of(v1,v2,v3….) 将一系列的元素变成数组 Array.find((value,index,arr)=&gt;{return true/false}) 找出第一个满足条件的元素 Array.findIndex((value,index,arr)=&gt;{return true/false}) 同上只是返回的不是元素而是下标 16.Obj拓展 Object.is(v1, v2) 判断2个数据是否完全相等 Object.assign(target, source1, source2..) 将源对象的属性复制到目标对象上 直接操作 proto 属性 12let obj2 = &#123;&#125;;obj2.__proto__ = obj1; 17. 深度克隆1、数据类型： 数据分为基本的数据类型(String, Number, boolean, Null, Undefined)和对象数据类型 基本数据类型：特点： 存储的是该对象的实际数据 对象数据类型：特点： 存储的是该对象在栈中引用，真实的数据存放在堆内存里 2、复制数据 基本数据类型存放的就是实际的数据，可直接复制let number2 = 2;let number1 = number2; 克隆数据：对象/数组1、区别： 浅拷贝/深度拷贝 判断： 拷贝是否产生了新的数据还是拷贝的是数据的引用 知识点：对象数据存放的是对象在栈内存的引用，直接复制的是对象的引用 let obj = {username: ‘kobe’} let obj1 = obj; // obj1 复制了obj在栈内存的引用2、常用的拷贝技术 1). arr.concat(): 数组浅拷贝 2). arr.slice(): 数组浅拷贝 3). JSON.parse(JSON.stringify(arr/obj)): 数组或对象深拷贝, 但不能处理函数数据 4). 浅拷贝包含函数数据的对象/数组 5). 深拷贝包含函数数据的对象/数组 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 复制的对象的方式// 浅度复制let obj = &#123;username: 'kobe', age: 39, sex: &#123;option1: '男', option2: '女'&#125;&#125;;let obj1 = obj;console.log(obj1);obj1.sex.option1 = '不男不女'; // 修改复制的对象会影响原对象console.log(obj1, obj);console.log('-----------');// Object.assign(); 浅复制let obj2 = &#123;&#125;;Object.assign(obj2, obj);console.log(obj2);obj2.sex.option1 = '男'; // 修改复制的对象会影响原对象console.log(obj2, obj);// 深度克隆(复制)function getObjClass(obj) &#123; let result = Object.prototype.toString.call(obj).slice(8, -1); if(result === 'Null')&#123; return 'Null'; &#125;else if(result === 'Undefined')&#123; return 'Undefined'; &#125;else &#123; return result; &#125;&#125;// for in 遍历数组的时候遍历的是下标let testArr = [1,2,3,4];for(let i in testArr)&#123; console.log(i); // 对应的下标索引&#125;// 深度克隆function deepClone(obj) &#123; let result, objClass = getObjClass(obj); if(objClass === 'Object')&#123; result = &#123;&#125;; &#125;else if(objClass === 'Array')&#123; result = []; &#125;else &#123; return obj; // 如果是其他数据类型不复制，直接将数据返回 &#125; // 遍历目标对象 for(let key in obj)&#123; let value = obj[key]; if(getObjClass(value) === \"Object\" || 'Array')&#123; result[key] = deepClone(value); &#125;else &#123; result[key] = obj[key]; &#125; &#125; return result;&#125;let obj3 = &#123;username: 'kobe',age: 39, sex: &#123;option1: '男', option2: '女'&#125;&#125;;let obj4 = deepClone(obj3);console.log(obj4);obj4.sex.option1 = '不男不女'; // 修改复制后的对象不会影响原对象console.log(obj4, obj3); 3.es7 指数运算符(幂): ** Array.prototype.includes(value) : 判断数组中是否包含指定value","categories":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://lwenxu.coding.me/categories/FrontEnd/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://lwenxu.coding.me/tags/JavaScript/"}]},{"title":"JavaScript 从入门到精通","slug":"FrontEnd/Javascript 详解","date":"2019-01-09T03:01:28.000Z","updated":"2019-01-13T09:30:20.000Z","comments":true,"path":"2019/01/09/FrontEnd/Javascript 详解/","link":"","permalink":"http://lwenxu.coding.me/2019/01/09/FrontEnd/Javascript 详解/","excerpt":"","text":"1. this​ 解析器在调用函数每次都会向函数内部传递进一个隐含的参数,这个隐含的参数就是this，this指向的是一个对象， 这个对象我们称为函数执行的 上下文对象，根据函数的调用方式的不同，this会指向不同的对象，以方法的形式调用时，this就是调用方法的那个对象。当我们直接调用一个全局的函数的时候其实就是 window 对像上面的方法。 1234567891011121314151617181920212223function fun()&#123; console.log(this.name);&#125;//创建一个对象var obj = &#123; name:\"孙悟空\", sayName:fun&#125;;var obj2 = &#123; name:\"沙和尚\", sayName:fun&#125;;var name = \"全局的name属性\";//以函数形式调用，this是window//fun();//以方法的形式调用，this是调用方法的对象//obj.sayName();obj2.sayName(); 2. 构造函数创建一个构造函数，专门用来创建Person对象的， 构造函数就是一个普通的函数，创建方式和普通函数没有区别,不同的是构造函数习惯上首字母大写构造函数和普通函数的区别就是调用方式的不同，普通函数是直接调用，而构造函数需要使用new关键字来调用构造函数的执行流程： 立刻创建一个新的对象 将新建的对象设置为函数中this,在构造函数中可以使用this来引用新建 逐行执行函数中的代码 将新建的对象作为返回值返回 使用同一个构造函数创建的对象，我们称为一类对象，也将一个构造函数称为一个类。我们将通过一个构造函数创建的对象，称为是该类的实例。 123456789101112131415161718function Person(name , age , gender)&#123; this.name = name; this.age = age; this.gender = gender; this.sayName = function()&#123; alert(this.name); &#125;;&#125;function Dog()&#123; &#125;var per = new Person(\"孙悟空\",18,\"男\");var per2 = new Person(\"玉兔精\",16,\"女\");var per3 = new Person(\"奔波霸\",38,\"男\");var dog = new Dog(); 使用instanceof可以检查一个对象是否是一个类的实例语法： 对象 instanceof 构造函数 如果是，则返回true，否则返回false 3. 原型​ 我们所创建的每一个函数，解析器都会向函数中添加一个属性prototype，这个属性对应着一个对象，这个对象就是我们所谓的原型对象，如果函数作为普通函数调用prototype没有任何作用，当函数以构造函数的形式调用时，它所创建的对象中都会有一个隐含的属性，指向该构造函数的原型对象，我们可以通过proto来访问该属性 原型对象就相当于一个公共的区域，所有同一个类的实例都可以访问到这个原型对象，我们可以将对象中共有的内容，统一设置到原型对象中。​ 当我们访问对象的一个属性或方法时，它会先在对象自身中寻找，如果有则直接使用，如果没有则会去原型对象中寻找，如果找到则直接使用。以后我们创建构造函数时，可以将这些对象共有的属性和方法，统一添加到构造函数的原型对象中，这样不用分别为每一个对象添加，也不会影响到全局作用域，就可以使每个对象都具有这些属性和方法了。 ​ 使用in检查对象中是否含有某个属性时，如果对象中没有但是原型中有，也会返回true。可以使用对象的hasOwnProperty() 来检查对象自身中是否含有该属性，使用该方法只有当对象自身中含有属性时，才会返回true。 ​ 原型对象也是对象，所以它也有原型，当我们使用一个对象的属性或方法时，会现在自身中寻找，自身中如果有，则直接使用，如果没有则去原型对象中寻找，如果原型对象中有，则使用， 如果没有则去原型的原型中寻找,直到找到Object对象的原型，Object对象的原型没有原型，如果在Object原型中依然没有找到，则返回 null。 1console.log(mc.__proto__.__proto__.hasOwnProperty(\"hasOwnProperty\")); 构造函数和让他的原型对象是互相引用的： 4. call 和 apply 这两个方法都是函数对象的方法，需要通过函数对象来调用 当对函数调用call()和apply()都会调用函数执行 在调用call()和apply()可以将一个对象指定为第一个参数 此时这个对象将会成为函数执行时的this call()方法可以将实参在对象之后依次传递 apply()方法需要将实参封装到一个数组中统一传递 this的情况： 1.以函数形式调用时，this永远都是window 2.以方法的形式调用时，this是调用方法的对象 3.以构造函数的形式调用时，this是新创建的那个对象 4.使用call和apply调用时，this是指定的那个对象 5. 数组的方法1. slice() 可以用来从数组提取指定元素 该方法不会改变元素数组，而是将截取到的元素封装到一个新数组中返回 参数： 1.截取开始的位置的索引,包含开始索引 2.截取结束的位置的索引,不包含结束索引 第二个参数可以省略不写,此时会截取从开始索引往后的所有索引可以传递一个负值，如果传递一个负值，则从后往前计算 -1 倒数第一个 -2 倒数第二个 2.splice() 可以用于删除数组中的指定元素 使用splice()会影响到原数组，会将指定元素从原数组中删除，并将被删除的元素作为返回值返回 参数： 第一个，表示开始位置的索引 第二个，表示删除的数量 第三个及以后，可以传递一些新的元素，这些元素将会自动插入到开始位置索引前边 3.concat()可以连接两个或多个数组，并将新的数组 该方法不会对原数组产生影响 4. join()​ 该方法可以将数组转换为一个字符串，该方法不会对原数组产生影响，而是将转换后的字符串作为结果返回，在join()中可以指定一个字符串作为参数，这个字符串将会成为数组中元素的连接符如果不指定连接符，则默认使用,作为连接符。 5. reverse()​ 该方法用来反转数组（前边的去后边，后边的去前边）该方法会直接修改原数组 6.sort()​ 可以用来对数组中的元素进行排序也会影响原数组，默认会按照Unicode编码进行排序. ​ 即使对于纯数字的数组，使用sort()排序时，也会按照Unicode编码来排序，所以对数字进排序时，可能会得到错误的结果。我们可以自己来指定排序的规则,我们可以在sort()添加一个回调函数，来指定排序规则。 6. Date创建一个Date对象如果直接使用构造函数创建一个Date对象，则会封装为当前代码执行的时间。创建一个指定的时间对象需要在构造函数中传递一个表示时间的字符串作为参数日期的格式 月份/日/年 时:分:秒 1. getDate()​ 获取当前日期对象是几日。 2. getDay()​ 获取当前日期对象时周几会返回一个0-6的值 0 表示周日1表示周一 3. getMonth()​ 获取当前时间对象的月份会返回一个0-11的值0 表示1月1 表示2月11 表示12月 4.getFullYear()​ 获取当前日期对象的年份 5. getTime()​ 获取当前日期对象的时间戳 7. Math1.Math.ceil() 可以对一个数进行向上取整，小数位只有有值就自动进1 2.Math.floor()可以对一个数进行向下取整，小数部分会被舍掉 3.Math.round()可以对一个数进行四舍五入取整 4.Math.random()可以用来生成一个0-1之间的随机数 8. 事件冒泡​ 所谓的冒泡指的就是事件的向上传导，当后代元素上的事件被触发时，其祖先元素的相同事件也会被触发。在开发中大部分情况冒泡都是有用的,如果不希望发生事件冒泡可以通过事件对象来取消冒泡。 1234567s1.onclick = function(event)&#123; event = event || window.event; alert(\"我是span的单击响应函数\"); //取消冒泡 //可以将事件对象的cancelBubble设置为true，即可取消冒泡 event.cancelBubble = true;&#125;; 1. 事件的委派​ 指将事件统一绑定给元素的共同的祖先元素，这样当后代元素上的事件触发时，会一直冒泡到祖先元素从而通过祖先元素的响应函数来处理事件。事件委派是利用了冒泡，通过委派可以减少事件绑定的次数，提高程序的性能。 2. 事件绑定addEventListener() 通过这个方法也可以为元素绑定响应函数，参数： 事件的字符串，不要on 回调函数，当事件触发时该函数会被调用 是否在捕获阶段触发事件，需要一个布尔值，一般都传false 使用addEventListener()可以同时为一个元素的相同事件同时绑定多个这样的事件。当事件被触发时，响应函数将会按照函数的绑定顺序执行。 3. 事件传播将事件传播分成了三个阶段 捕获阶段：在捕获阶段时从最外层的祖先元素，向目标元素进行事件的捕获，但是默认此时不会触发事件 目标阶段：事件捕获到目标元素，捕获结束开始在目标元素上触发事件 冒泡阶段：事件从目标元素向他的祖先元素传递，依次触发祖先元素上的事件 如果希望在捕获阶段就触发事件，可以将addEventListener()的第三个参数设置为true，一般情况下我们不会希望在捕获阶段触发事件，所以这个参数一般都是false。 8.数据类型undefined 指的是变量定义了但是没有赋值过，而 null 则是指他被赋值了，并且赋值为 null 9. 闭包​ 闭包在一个函数内部声明了一个内部函数，并且这个内部函数引用了外部函数的变量。 ​ 闭包：闭包是包含被引用变量的对象，或者简单的理解为嵌套的内部函数 ​ 闭包在执行外部函数的时候就产生了，不用等到内部不函数执行。 1.闭包的作用： 使用函数内部的变量在函数执行完后, 仍然存活在内存中(延长了局部变量的生命周期 让函数外部可以操作(读写)到函数内部的数据(变量/函数) 2. 生命周期 产生: 在嵌套内部函数定义执行完时就产生了(不是在调用) 死亡: 在嵌套的内部函数成为垃圾对象时 3. 应用​ 具有特定功能的js文件，将所有的数据和功能都封装在一个函数内部(私有的)，只向外暴露一个包信n个方法的对象或函数，模块的使用者, 只需要通过模块暴露的对象调用方法来实现对应的功能。 方案一： 12345678910111213141516function myModule() &#123; //私有数据 var msg = 'Hello' //操作数据的函数 function doSomething() &#123; console.log('doSomething() '+msg.toUpperCase()) &#125; function doOtherthing () &#123; console.log('doOtherthing() '+msg.toLowerCase()) &#125; //向外暴露对象(给外部使用的方法) return &#123; doSomething: doSomething, doOtherthing: doOtherthing &#125;&#125; 方案二： 12345678910111213141516(function () &#123; //私有数据 var msg = 'My atguigu' //操作数据的函数 function doSomething() &#123; console.log('doSomething() '+msg.toUpperCase()) &#125; function doOtherthing () &#123; console.log('doOtherthing() '+msg.toLowerCase()) &#125; //向外暴露对象(给外部使用的方法) window.myModule2 = &#123; doSomething: doSomething, doOtherthing: doOtherthing &#125;&#125;)() 4. 缺点及解决方案1.缺点 函数执行完后, 函数内的局部变量没有释放, 占用内存时间会变长 容易造成内存泄露 2.解决 能不用闭包就不用 及时释放，将闭包设置为null","categories":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://lwenxu.coding.me/categories/FrontEnd/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://lwenxu.coding.me/tags/JavaScript/"}]},{"title":"CSS3 从入门到精通","slug":"FrontEnd/CSS3 详解","date":"2019-01-08T13:01:28.000Z","updated":"2019-03-14T22:43:30.000Z","comments":true,"path":"2019/01/08/FrontEnd/CSS3 详解/","link":"","permalink":"http://lwenxu.coding.me/2019/01/08/FrontEnd/CSS3 详解/","excerpt":"","text":"1. 选择器1. 一些注意的点1. love &amp; hate (lvht)​ 这是什么意思呢？其实是我们在写 a 表的伪类的时候会有一些优先级的问题，如果说我们没有按照这个优先级写css 的话很可能会导致我们样式不生效或者说被覆盖的问题。具体来说就是 link , visited，hover，target 。 2. nth-child(n)​ 注意这个的 n 是从 1 开始的而不是 0 开始的，另外如果我们写了 #wrap p:nth-child(1) 的含义是指 id 为 wrap 下面的第一个子元素，并且这个字元素必须是 p 才会应用样式。 ​ 同样的还有一个类似的 就是 nth-of-type(n) 这个其实和上面的很像只是他的要求稍微低一些。#wrap p:nth-of-type(1) 比如这个就是表示 wrap 下面的第一个 p 标签。 ​ 上面两个的重要的区别(坑！)。就是 nth-of-type 是以元素标签为中心的，下面看个例子来理解这句话。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; #wrap .inner:nth-of-type(1)&#123; border: 1px solid; &#125; /*#wrap div:nth-of-type(1)&#123; border: 1px solid; &#125; #wrap p:nth-of-type(1)&#123; border: 1px solid; &#125; #wrap span:nth-of-type(1)&#123; border: 1px solid; &#125; #wrap h1:nth-of-type(1)&#123; border: 1px solid; &#125; #wrap h2:nth-of-type(1)&#123; border: 1px solid; &#125;*/ /*nth-of-type以元素为中心*/ &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"wrap\"&gt; &lt;div class=\"inner\"&gt;div&lt;/div&gt; &lt;p class=\"inner\"&gt;p&lt;/p&gt; &lt;span class=\"inner\"&gt;span&lt;/span&gt; &lt;h1 class=\"inner\"&gt;h1&lt;/h1&gt; &lt;h2 class=\"inner\"&gt;h2&lt;/h2&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; ​ 注意上面的代码看起来就是第一个被选中，但是由于它是以元素为中心的那么，他会被展开成下面的语法结构。所以说所有的都会被选中。而 nth-child 则是正常的选中第一个。 2. 字体图标​ 字体图标减少了页面的请求，而且不失真非常可靠，推荐使用。如果我们需要 使用一些特殊的紫图需要自定义字体因为为了兼容不同的用户，但是这样会增加网络负担。 1234@font-face&#123; font-family:&quot;test&quot;; src:url(&apos;&apos;);/*字体文件的位置*/&#125; ​ 使用字体图标，主要就是ttf，wof还有一个样式表，直接引入样式表就可以使用了。 3. 新的UI方案1. 文本新增样式1. opactiy​ 他不是继承属性。但是子元素也会被透明掉。 2. rgba​ 这个前三个就是 rgb 最后一个是透明度。正式有了这个现在的文字透明背景不透明或者背景透明文字不透明就好做了，直接给某一方设置rgba而另外一方设置正常的颜色就好。而不用opacity导致前后后透明。 123a&#123; color:rgba(1,1,1,.5);&#125; ​ 创建一个模糊背景的图片。首先需要有一个图片背景(让图片做背景一般都是图片有多大背景就能看到多少图片，为了让图片完全的铺满背景需要把 background-size:100% 100%)，然后需要对他做一个模糊使用了一个函数 filter:blur(10px) 就是把它模糊掉。然后需要一个外面的黑色遮罩，让他出现半透明的状态就可以看到后面的内容了。 ​ *小技巧：如果希望我们内层的元素铺满外层的内容区可以使用绝对定位然后让他的四个方向都为 0 * 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,user-scalable=no\" /&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; #wrap&#123; height: 100px; background: rgba(0,0,0,.5); position: relative; &#125; #wrap #bg&#123; position: absolute; left: 0; right: 0; top: 0; bottom: 0; background: url(img/avatar.jpg) no-repeat; background-size:100% 100% ; z-index: -1; filter: blur(10px); &#125; img&#123; margin: 24px 0 0 24px; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"wrap\"&gt; &lt;img src=\"img/avatar.jpg\" width=\"64px\" height=\"64px\"/&gt; &lt;div id=\"bg\"&gt;&lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 3. 文字阴影text-shadow用来为文字添加阴影，而且可以添加多层，阴影值之间用逗号隔开。（多个阴影时，第一个阴影在最上边） 默认值：none 不可继承 值​ ​ 可选。可以在偏移量之前或之后指定。如果没有指定颜色，则使用UA（用户代理）选择的颜色。​ ​ 必选。这些长度值指定阴影相对文字的偏移量。​ 指定水平偏移量，若是负值则阴影位于文字左边。​ 指定垂直偏移量，若是负值则阴影位于文字上面。​ 如果两者均为0，则阴影位于文字正后方(如果设置了 则会产生模糊效果)。​ ​ 可选。这是 值。如果没有指定，则默认为0。​ 值越大，模糊半径越大，阴影也就越大越淡 123h1&#123; text-shadow:gray 10px 10px 10px,pink 10px 10px 10px;&#125; 4. 文字排版​ 溢出显示省略号，最常用的！但是使用这个东西盒子需要是一个 block 12345678910111213141516171819202122&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;&lt;title&gt;无标题文档&lt;/title&gt;&lt;style&gt; div&#123; width: 200px; height: 200px; border: 1px solid; margin: 0 auto; /*这三样式是一直在一起的不能去掉，并且盒子不能靠内容撑开*/ white-space: nowrap; overflow: hidden; text-overflow: ellipsis; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 2. 盒模型阴影​ 首先是需要进行一个盒子的居中： 12345678910111213div&#123; position: absolute; left: 0; right: 0; bottom: 0; top: 0; margin: auto; width: 100px; height: 100px; background: pink; text-align: center; line-height: 100px;&#125; ​ 注意需要margin为auto而不能为0，盒子唏嘘也要有长宽。 box-shadow​ 以逗号分割列表来描述一个或多个阴影效果，可以用到几乎任何元素上。 如果元素同时设置了 border-radius ，阴影也会有圆角效果。多个阴影时和多个 text shadows 规则相同(第一个阴影在最上面)。 默认值: none 不可继承 值：​ inset​ 默认阴影在边框外。​ 使用inset后，阴影在边框内。​ ​ 这是头两个 值，用来设置阴影偏移量。​ 设置水平偏移量，如果是负值则阴影位于元素左边。​ 设置垂直偏移量，如果是负值则阴影位于元素上面。​ 如果两者都是0，那么阴影位于元素后面。​ 这时如果设置了 或 则有模糊效果。​ ​ 这是第三个 值。值越大，模糊面积越大，阴影就越大越淡。​ 不能为负值。默认为0，此时阴影边缘锐利。​ ​ 这是第四个 值。取正值时，阴影扩大；取负值时，阴影.收缩。默认为0，此时阴影与元素同样大。​ ​ 阴影颜色，如果没有指定，则由浏览器决定 123div&#123; box-shadow: -10px -10px 10px 0px black , 20px 20px 10px -10px deeppink;&#125; 3. box-sizing​ 由于我们一般的额 height 和 width 的值指的是内容区的大小，所以如果我们用了 padding的话会导致整个盒子的变化，那么为了不让这种计算出现，可以使用 box-sizing:border-box 就可以了。此时采用padding的话就是从内容区扣掉的。 4. border-radius​ 圆角 5. 背景 background-color 默认为transparent 也就是透明的 background-image 指定图片做背景，有的图片在z轴上面绘制，先写得图片会在最后绘制也就是层叠图片的时候是按照写得顺序从上往下绘制的。 no-repeat background-position 如果图片的大小大于框的大小，这个属性就可以决定图片是从哪开始显示的。 background-origin 表示图片是从哪开始渲染的，它有三个值：border-box ,padding-box ,content-box 分别就是从边框，内边距开始的地方，内容区开始的地方。 background-clip:从那个位置开始裁剪，属性值也是和origin一样的。 background-size：百分比： 指定背景图片相对背景区（background positioning area）的百分比。背景区由background-origin设置，默认为盒模型的内容区与内边距 auto： 以背景图片的比例缩放背景图片。 注意： 单值时，这个值指定图片的宽度，图片的高度隐式的为auto 两个值: 第一个值指定图片的宽度，第二个值指定图片的高度 6. 线性渐变​ 注意：渐变是针对于图片的而不是颜色。 为了创建一个线性渐变，你需要设置一个起始点和一个方向（指定为一个角度）。你还要定义终止色。终止色就是你想让浏览器去平滑的过渡过去，并且你必须指定至少两种，当然也会可以指定更多的颜色去创建更复杂的渐变效果。 ​ 如果在里面设置了透明度他也会跟着渐变的，就是 rgba -默认从上到下发生渐变​ linear-gradient(red,blue); -改变渐变方向：（top bottom left right）​ linear-gradient(to 结束的方向,red,blue); -使用角度​ linear-gradient(角度,red,blue); -颜色节点的分布（第一个不写为0%，最后一个不写为100%）​ linear-gradient(red 长度或者百分比,blue 长度或者百分比);-重复渐变​ repeating-linear-gradient(60deg,red 0,blue 30%); 123p&#123; background:repeating-linear-gradient(135deg,black 0px,black 10px,white 10px,white 20px);&#125; 注意这个写法他的意思就是1-10是黑到黑的渐变就是一个完整的黑色，而10-20 是白到白的渐变。为什么要这么做，主要就是我们使用了 repeating-linear-gradient 这个 repeat 就是重复的渐变，如果我们不是设置的渐变而是直接的纯色的话他就不会重复了。所以这种方式巧妙的让这些黑白重复了。发廊灯的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; html,body&#123; height: 100%; overflow: hidden; &#125; #wrap&#123; width: 40px; height: 300px; border: 1px solid; margin: 100px auto; overflow: hidden; &#125; #wrap &gt; .inner&#123; height: 600px; background:repeating-linear-gradient(135deg,black 0px,black 10px,white 10px,white 20px); &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"wrap\"&gt; &lt;div class=\"inner\"&gt;&lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;script type=\"text/javascript\"&gt; var inner = document.querySelector(\"#wrap &gt; .inner\"); var flag =0; setInterval(function()&#123; flag++; if(flag==300)&#123; flag=0; &#125; inner.style.marginTop = -flag+\"px\"; &#125;,1000/60) &lt;/script&gt;&lt;/html&gt; 光板动画，iPhone的开机动画： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; html,body&#123; height: 100%; overflow: hidden; background: black; text-align: center; &#125; h1&#123; /*transition: 3s;*/ margin-top: 50px; display: inline-block; color: rgba(255, 255, 255,.3); font:bold 80px \"微软雅黑\"; background: linear-gradient(120deg,rgba(255,255,255,0) 100px ,rgba(255,255,255,1) 180px ,rgba(255,255,255,0) 260px); background-repeat:no-repeat ; -webkit-background-clip: text ; &#125; /*h1:hover&#123; background-position: 500px 0; &#125;*/ &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;atguigu尚硅谷&lt;/h1&gt; &lt;/body&gt; &lt;script type=\"text/javascript\"&gt; var h1 = document.querySelector(\"h1\"); var flag =-160; setInterval(function()&#123; flag+=10; if(flag==600)&#123; flag=-160; &#125; h1.style.backgroundPosition = flag+\"px\"; &#125;,30) &lt;/script&gt;&lt;/html&gt; 7. 径向渐变12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; #test&#123; width: 400px; height: 300px; border: 1px solid; margin: 0 auto; background-image:radial-gradient( closest-corner circle at 20px 20px,yellow, green 50%,pink) ; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"test\"&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 4.过渡1. transition-property​ 这个属性是用来指定哪些属性需要做渐变的，而且并不是所有的属性都是可以做渐变的，可以在mdn上查询到。多个属性可以采用逗号分隔。默认值就是 all 2. transition-duration​ 这个用来规定动画间隔的时间，注意如果这个列表不满足上面的property的个数，他默认采用复制来匹配，比如上面有三个属性，而duration只有两个时间 3s,5s 那么最后的结果应该是 3s.5s.3s,5s 这样上面三个属性是 3s,5s ,3s 注意点就是他们需要带上单位。 3. transition-timing-function​ 这个就是用来指定整个动画的运行的过程或者速率： 属性值：​ 1、ease：（加速然后减速）默认值，ease函数等同于贝塞尔曲线(0.25, 0.1, 0.25, 1.0).​ 2、linear：（匀速），linear 函数等同于贝塞尔曲线(0.0, 0.0, 1.0, 1.0).​ 3、ease-in：(加速)，ease-in 函数等同于贝塞尔曲线(0.42, 0, 1.0, 1.0).​ 4、ease-out：（减速），ease-out 函数等同于贝塞尔曲线(0, 0, 0.58, 1.0).​ 5、ease-in-out：（加速然后减速），ease-in-out 函数等同于贝塞尔曲线(0.42, 0, 0.58, 1.0)​ 6、cubic-bezier： 贝塞尔曲线，这是一个函数里面传入对应的参数就可以呈现出不同的曲线 ​ http://cubic-bezier.com 在这个地址里面就能找到对应的被萨尔曲线对应的函数值和参数了。 比如说下面的这个曲线的意思就是横轴代表的是时间而纵轴代表的就是距离或者位置了，或者说速度。在这给对方代表的就是速度。 ​ 7、step-start：等同于steps(1,start)​ step-end：等同于steps(1,end) ​ start表示整个时间的开始，而end表示整个时间的结束。 ​ steps(,[,[start|end]]?)​ 第一个参数：必须为正整数，指定函数的步数​ 第二个参数：指定每一步的值发生变化的时间点（默认值end）在每步的时间开始还是结束的时候执行。 ​ 多个列表会使用默认值，如果不够的话。 4. transition-delay​ 表示在多久之后才开始动画。这个如果缺省了参数不够列表的长度的话也是会重复列表的。 5. transitionend​ 表示动画执行结束，这是一个js事件可以使用js事件来监听，他是基于属性的一个事件，也就是等一个属性变化完成以后他就会调用一次而不是针对于元素的。 12node.addEventListener(\"transitionend\",function()&#123;&#125;); //这种添加事件的方式是 dom2 事件node.ontransitionend(function()&#123;&#125;) //这种是 dom0 事件 6. 过渡的一些坑1. 浏览器解析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; html&#123; height: 100%; &#125; body&#123; width: 60%; height: 60%; border: 1px solid; margin: 100px auto 0; &#125; #test&#123; width: 100px; height: 100px; background: pink; text-align: center; position: absolute; left: 0; right: 0; bottom: 0; top: 0; margin: auto; transition-property: width; transition-duration: 2s; transition-timing-function: linear; &#125; body:hover #test&#123; transition-property: height; width: 200px; height: 200px; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"test\"&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 可以看到上面是鼠标画上去的时候回选中 test 这个元素，然后将它动画设置为 height 变化，由于浏览器解析 css 太快了，在划上去的瞬间内存被修改了也就是变换的元素被修改了所以一开始变化的应该是height。而移除的时候同理变化的是 width 2. transition在元素首次渲染还没有结束的情况下是不会触发的123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; html&#123; height: 100%; &#125; body&#123; width: 60%; height: 60%; border: 1px solid; margin: 100px auto 0; &#125; #test&#123; width: 100px; height: 100px; background: pink; text-align: center; position: absolute; left: 0; right: 0; bottom: 0; top: 0; margin: auto; transition-property: width; transition-duration: 2s; transition-timing-function: linear; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"test\"&gt; &lt;/div&gt; &lt;/body&gt; &lt;script type=\"text/javascript\"&gt; //transition在元素首次渲染还没有结束的情况下是不会被触发的 // window.onload=function()&#123; var test = document.querySelector(\"#test\"); test.style.width=\"300px\";// &#125; &lt;/script&gt;&lt;/html&gt; ​ 如果没有打开注释部分的内容我们的动画是不会执行的，而是直接跳到300的样子，如果我们打开了注释意外这我们所有的元素已经渲染完了，这个时候再去做上面的额动画是会被执行的。 ​ 那么这么想的话我们如果加上一个 settimeout 也是没问题的。 3.坑1. 在绝大部分变换样式切换时,如果变换函数的位置 个数不相同也不会触发过渡 2. transition必须在transform之后声明才有效！！！！ 5. 2D变幻注意所有的变幻都是和transition配合使用的。 1. transform1.rotate(angle) 旋转 正值:顺时针旋转 rotate(360deg) 负值:逆时针旋转 rotate(-360deg) 只能设单值。正数表示顺时针旋转，负数表示逆时针旋转 2. translate 移动X方向平移:transform: translateX(tx)Y方向平移:transform: translateY(ty)二维平移：transform: translate(tx[, ty])； 如果ty没有指定，它的值默认为0。 可设单值，也可设双值。​ 正数表示XY轴正向位移，负数为反向位移。设单值表示只X轴位移，Y轴坐标不变，​ 例如transform: translate(100px);等价于transform: translate(100px,0); 3. skew 倾斜transform:skewX(45deg);​ X方向倾斜:transform: skewX(angle)​ skewX(45deg):参数值以deg为单位 代表与y轴之间的角度​ Y方向倾斜:transform: skewY(angle)​ skewY(45deg):参数值以deg为单位 代表与x轴之间的角度​ 二维倾斜:transform: skew(ax[, ay]); 如果ay未提供，在Y轴上没有倾斜​ skew(45deg,15deg):参数值以deg为单位 第一个参数代表与y轴之间的角度​ 第二个参数代表与x轴之间的角度单值时表示只X轴扭曲，Y轴不变，如transform: skew(30deg);等价于 transform: skew(30deg, 0);考虑到可读性，不推荐用单值，应该用transform: skewX(30deg);。skewY表示只Y轴扭曲，X轴不变 正值:拉正斜杠方向的两个角 负值:拉反斜杠方向的两个角 4. scale 缩放transform:scale(2); X方向缩放:transform: scaleX(sx); Y方向缩放:transform: scaleY(sy); 二维缩放 :transform: scale(sx[, sy]); (如果sy 未指定，默认认为和sx的值相同) 要缩小请设0.01～0.99之间的值，要放大请设超过1的值。 例如缩小一倍可以transform: scale(.5);放大一倍可以transform: scale(2); 如果只想X轴缩放，可以用scaleX(.5)相当于scale(.5, 1)。 同理只想Y轴缩放，可以用scaleY(.5)相当于scale(1, .5) 正值:缩放的程度 负值:不推荐使用（有旋转效果） 单值时表示只X轴,Y轴上缩放粒度一样，如transform: scale(2);等价于transform: scale(2,2); 2. transform-origin参考点 transform-origin 这个值可以是： top left 左上 10px 10px 参照左上角的向右向下10px 10% 10% 同px参照的是自身的宽高。 6. 3D 旋转1. transform里面的一些函数和2D的一模一样只是多了 X,Y,Z的后缀例如 rotateY(360deg) 2. perspective​ 景深，让3D物体看起来有近大远小的感觉。但是这个属性只能用在舞台上，也就是如果要过三D动画，必须有两层外面一层叫做舞台，里面才是真实的物体。 3. transform-style建立有层级的 3d 舞台，他作用于舞台。 ### 7.动画1. 常用属性1. animation-name​ 指定所使用的关键帧的名字，比如 animation-name: move; 关键帧的样子： 12345678@keyframes move&#123; from&#123; transform: translateY(-100px); &#125; to&#123; transform: translateY(100px); &#125;&#125; 2. animation-duration​ 设置动画持续的时间。需要带上单位 animation-duration:3s ; 3.animation-direction​ 动画翻转，他变化的是关键帧的 from 到 to 的两个顺序，并且变化了animation-timing-function 动画的速度变化曲线。 ​ 他有四个值： normal 就是正常的每一次执行动画都是从 from 到 to 这样的执行。 reverse 这样关键帧执行的顺序从 to 到 from ，并且会让 animation-timing-function` 动画的速度变化曲线翻转。 alternate 如果有多次启动关键帧，表示从 from到to再从to到from 这样一直往返。 alternate-reverse 同上，只是方向是反的。 4.animation-delay​ 设置动画还有多久才开始，需要设置单位 animation-delay:1s; 5. animation-iteration-count​ 设置关键帧执行的次数，也就是动画执行的次数。 animation-iteration-count: 3; 6. animation-fill-mode​ 设置动画之外的状态，就是规定from和to在动画开始之前的位置和状态。 backwards：from之前的状态与form的状态保持一致 forwards：to之后的状态与to的状态保持一致 both：backwards+forwards 7.animation-play-state​ 表示当前的动画的状态，可以通过他来暂停动画和开始动画 running 启动动画 paused 暂停动画 8. animation-timing-function​ 规定了动画的速率，具体和 transition 是一样的。 2. 关键帧语法： 12345@keyframes animiationName&#123; keyframes-selector&#123; css-style; &#125; &#125; animiationName:必写项，定义动画的名称 keyframes-selector：必写项，动画所在的时间点 from等价于 0% 而 to等价于100%，我么也可以定义其他的一些百分比。 css-style：css声明 8. flex​ flex分为两个版本，分别为老版本的和新版本的，新版本的功能更强大但是他不支持很多的老的移动端。但是我们可以使用css后置处理器来处理这种兼容性问题。 1. 基本概念容器：就是flex布局的容器，也是一个包裹层然后里面样式设置为 flex 项目：item 就是在容器中排列的内容就是项目，项目永远在主轴的正方向排列 主轴：默认是x轴，正方向右 侧轴：默认y轴，正方向向下 2. 容器管理1. 设置容器老版本：display：-webkit-box 新版本：display：flex 2. 设置主轴老版本：-webkit-box-orient：vertical/horizontal 新版本：flex-direction:row/column 3. 设置排列方向，控制主轴方向老版本：-webkit-box-direction：normal/reverse 新版本：flex-direction:row/column/row-reverse/column-reverse 用一个属性设置主轴以及主轴的方向 4. 富裕空间管理主侧轴的空白的空间管理。他管理的是富裕空间的位置并不影响项目的空间大小 1.主轴老版本：-webkit-box-pack：start(右，下)/end(左，上)/center(两边)/jusity(项目之间) 与主轴无关，只和x，y轴有关，前面指的是x轴的情况，后面是y轴的情况 新版本：justify-content:flex-start(主轴正方向)/flex-end(主轴负方向)/center(主轴两边)/space-between(项目之间)/space-around(项目两边) 2. 侧轴老版本：-webkit-box-align：start(右，下)/end(左，上)/center(两边)/jusity(项目之间) 与主轴无关，只和x，y轴有关，前面指的是x轴的情况，后面是y轴的情况 新版本：align-items:flex-start(侧轴正方向)/flex-end(侧轴负方向)/content(侧轴两边)/base-line(按照基线)/strech(没有的，当没有高度的时候就是等高布局) 3. 项目管理弹性空间管理就是把富裕空间匀到每一个项目之上。 老版本：-webkit-box-flex：n 新版本：flex-grow:n 相当于每一个项目的弹性因子就是 n 那么我们的富裕空间的分配就是 (nx/n1+n2+n3+…+nx) * 富裕空间大小 简单来说这个弹性因子就表示将来会分到的富裕空间的比例。 4. 新版flex特性1.容器新增特性在新版的flex中使用 flex-wrap 来控制侧轴的方向 规定了侧轴的方向那么在元素在主轴的方向排列不下的时候不会对元素进行压缩而是采用向侧轴排列的方式进行，这样就会产生多行多列，此时我们侧轴的富裕空间 align-items 就失效了，必须采用 align-content 来解决。 1. flex-wrapflex-wrap 属性控制了容器为单行/列还是多行/列。并且定义了侧轴的方向，新行/列将沿侧轴方向堆砌。 默认值：nowrap 不可继承 值：nowrap | wrap | wrap-reverse 2.align-contentalign-content 属性定义弹性容器的侧轴方向上有额外空间时，如何排布每一行/列。当弹性容器只有一行/列时无作用默认值：stretch 不可继承 值：flex-start​ 所有行/列从侧轴起点开始填充。第一行/列的侧轴起点边和容器的侧轴起点边对齐。​ 接下来的每一行/列紧跟前一行/列。flex-end​ 所有弹性元素从侧轴末尾开始填充。最后一个弹性元素的侧轴终点和容器的侧轴终点对齐。​ 同时所有后续元素与前一个对齐。center​ 所有行/列朝向容器的中心填充。每行/列互相紧挨，相对于容器居中对齐。​ 容器的侧轴起点边和第一行/列的距离相等于容器的侧轴终点边和最后一行/列的距离。space-between​ 所有行/列在容器中平均分布。相邻两行/列间距相等。​ 容器的侧轴起点边和终点边分别与第一行/列和最后一行/列的边对齐。space-around​ 所有行/列在容器中平均分布，相邻两行/列间距相等。​ 容器的侧轴起点边和终点边分别与第一行/列和最后一行/列的距离是相邻两行/列间距的一半。stretch​ 拉伸所有行/列来填满剩余空间。剩余空间平均的分配给每一行/列 3. flex-flowflex-flow 属性是设置“flex-direction”和“flex-wrap”的简写 默认值：row nowrap 不可继承 控制主轴和侧轴的位置以及方向 2. 项目新增特性1.order设置项目在主轴的排列优先级，数字越大优先级越高。 2.align-self项目自己管理自己的侧轴的富裕空间，而不归 align-items 管了。 3. flex-basisflex-basis 在弹性空间管理的时候非常有用的，我们在上面的弹性空间管理的时候也就是 flex-grows 我们直接是把整个容器大小减去所有项目的大小然后除以增长因子的大小来计算的，实际上我们应该减去的不是容器的总大小而是flex-basis 的值，默认值就是容器的大小。所以他们的计算公式应该是： 可用空间 = (容器大小 - 所有相邻项目flex-basis的总和) 可扩展空间 = (可用空间/所有相邻项目flex-grow的总和) 每项获得的伸缩大小 = (伸缩基准值 + (可扩展空间 x flex-grow值)) 4.flex-shrink收缩因子，实际上就是我们所有的item的总大小大于容器的大小他就会进行收缩但是收缩也会有一个收缩因子，但是他的收缩因子的默认值不是 0 而是 1，计算公式： 1.计算收缩因子与基准值乘的总和 2.计算收缩因数​ 收缩因数=（项目的收缩因子*项目基准值）/第一步计算总和 3.移除空间的计算​ 移除空间= 项目收缩因数 x 负溢出的空间 5. flex应用1.等分布局根据规则我们就需要将赋予空间全部分配给每一个项目，而我们需要的全部的富裕空间就是容器的所有的宽度。 12345.item&#123; flex-grows:1; flex-shrink:1; flex-basis:1;&#125; 上面的这一堆代码为了等分布局，所以我们有一个简写的方式就是 123.item&#123; flex:1;&#125;","categories":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://lwenxu.coding.me/categories/FrontEnd/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"http://lwenxu.coding.me/tags/CSS/"}]},{"title":"CSS2 从入门到精通","slug":"FrontEnd/CSS2 详解","date":"2019-01-08T03:01:28.000Z","updated":"2019-01-13T09:34:48.000Z","comments":true,"path":"2019/01/08/FrontEnd/CSS2 详解/","link":"","permalink":"http://lwenxu.coding.me/2019/01/08/FrontEnd/CSS2 详解/","excerpt":"","text":"1. 常用的选择器1. 元素选择器 作用：通过元素选择器可以选择指定的元素 语法：tag{} 123456p&#123; color: red;&#125;h1&#123; color: red;&#125; 2. id 选择器 作用：通过元素的id属性值选中唯一的一个元素 用法: #id{} 123#p1&#123; font-size: 20px;&#125; 3.类选择器 通过元素的class属性值选中一组元素 语法：.class{} 1234567.p2&#123; color: red;&#125; .hello&#123; font-size: 50px;&#125; 4. 选择器分组 通过选择器分组可以同时选中多个选择器对应的元素,简单来说就是同时为这些选择的元素应用相同的样式。他也称作为 *并集选择器 *就是上面的每一个逗号分开的相当于一个集合，那么相当于把他们合并起来到一个集合中只要元素命中其中一条规则就会应用样式。 语法：选择器1,选择器2,选择器N{} 123#p1 , .p2 , h1&#123; background-color: yellow;&#125; 5. 通配选择器 他可以用来选中页面中的所有的元素 语法：*{} 123*&#123; color: red;&#125; 6. 交集选择器 作用：选择同时满足所有选择器规则的元素，所以也称作为交集选择器，元素必须命中所有的选择条件才能应用样式。下面的例子就相当于必须满足元素名为span并且拥有p3这个类 语法：选择器1选择器2选择器N{} 123span.p3&#123; background-color: yellow;&#125; 7. 后代选择器 作用：选中指定元素的指定后代元素，下面的例子就是选择id为d1的span后代，注意后代是不用和祖先元素相邻。 语法：祖先元素 后代元素{} 123#d1 span&#123; color: greenyellow;&#125; 8. 子选择器 作用：选中指定父元素的指定子元素,两者必须是相邻的 语法：父元素 &gt; 子元素 123div &gt; span&#123; background-color: yellow;&#125; Tips:父元素：直接包含子元素的元素子元素：直接被父元素包含的元素祖先元素：直接或间接包含后代元素的元素，父元素也是祖先元素后代元素：直接或间接被祖先元素包含的元素，子元素也是后代元素兄弟元素：拥有相同父元素的元素叫做兄弟元素 9. 伪类选择器伪类专门用来表示元素的一种的特殊的状态，比如：访问过的超链接，比如普通的超链接，比如获取焦点的文本框当我们需要为处在这些特殊状态的元素设置样式时，就可以使用伪类 1. :link 表示普通的链接（没访问过的链接）1a:link&#123;color: yellowgreen;&#125; 2. :visited 表示访问过的链接浏览器是通过历史记录来判断一个链接是否访问过,由于涉及到用户的隐私问题，所以使用visited伪类只能设置字体的颜色 3. :hover伪类表示鼠标移入4. :active表示的是超链接被点击的状态5.:focus 光标为获得焦点6.::selection选中的内容这个伪类在火狐中需要采用另一种方式编写::-moz-selection兼容火狐的 1p::-moz-selection&#123;background-color: orange;&#125; 兼容大部分浏览器的 1p::selection&#123;background-color: orange;&#125; 10. 伪元素选择器使用伪元素来表示元素中的一些特殊的位置. 1. :first-letter 内容中的第一个字母2. :first-line内容的第一行3.:before表示元素最前边的部分4. :after表示元素的最后边的部分 一般before和after都需要结合content这个样式一起使用， 通过content可以向before或after的位置添加一些内容:after 11. 属性选择器 作用：可以根据元素中的属性或属性值来选取指定元素 语法： [属性名] 选取含有指定属性的元素 [属性名=”属性值”] 选取含有指定属性值的元素 [属性名^=”属性值”] 选取属性值以指定内容开头的元素 [属性名$=”属性值”] 选取属性值以指定内容结尾的元素12. 子元素选择器1. :first-child 可以选中第一个子元素:2.last-child 可以选中最后一个子元素 1body &gt; p:first-child&#123;background-color: yellow;&#125;p:last-child&#123;background-color: yellow;&#125; 3. :nth-child 可以选中任意位置的子元素该选择器后边可以指定一个参数，指定要选中第几个子元素even 表示偶数位置的子元素odd 表示奇数位置的子元素 1p:nth-child(odd)&#123;background-color: yellow;&#125; :first-of-type,:last-of-type，:nth-of-type,:first-child这些非常的类似，只不过child，是在所有的子元素中排列而type，是在当前类型的子元素中排列 1p:first-of-type&#123;background-color: yellow;&#125; 13.兄弟选择器为挨着的兄弟元素添加样式，其中 + 表示后一个，而 ~ 则表示前一个 123456span ~ p&#123; background-color: yellow;&#125;span + p&#123; background-color: yellow;&#125; 2. 样式继承像儿子可以继承父亲的遗产一样，在CSS中，祖先元素上的样式，也会被他的后代元素所继承,利用继承，可以将一些基本的样式设置给祖先元素，这样所有的后代元素将会自动继承这些样式。但是并不是所有的样式都会被子元素所继承，比如：背景相关的样式都不会被继承 边框相关的样式 定位相关的 3. 样式优先级优先级的规则： 内联样式 ， 优先级 1000 id选择器，优先级 100 类和伪类， 优先级 10 元素选择器，优先级 1 通配* ， 优先级 0 继承的样式，没有优先级 并集选择器的优先级是单独计算 可以在样式的最后，添加一个!important，则此时该样式将会获得一个最高的优先级，将会优先于所有的样式显示甚至超过内联样式，但是在开发中尽量避免使用!important4. 长度单位1.像素 px像素是我们在网页中使用的最多的一个单位，一个像素就相当于我们屏幕中的一个小点，我们的屏幕实际上就是由这些像素点构成的但是这些像素点，是不能直接看见。不同显示器一个像素的大小也不相同，显示效果越好越清晰，像素就越小，反之像素越大。2. 百分比 %也可以将单位设置为一个百分比的形式，这样浏览器将会根据其父元素的样式来计算该值使用百分比的好处是，当父元素的属性值发生变化时，子元素也会按照比例发生改变在我们创建一个自适应的页面时，经常使用百分比作为单位3. emem和百分比类似，它是相对于当前元素的字体大小来计算的 1em = 1font-size 使用em时，当字体大小发生改变时，em也会随之改变当设置字体相关的样式时，经常会使用em4. 行间距在CSS并没有为我们提供一个直接设置行间距的方式， 我们只能通过设置行高来间接的设置行间距，行高越大行间距越大 使用line-height来设置行高 行高类似于我们上学单线本，单线本是一行一行，线与线之间的距离就是行高， 网页中的文字实际上也是写在一个看不见的线中的，而文字会默认在行高中垂直居中显示。行间距 = 行高 - 字体大小通过设置line-height可以间接的设置行高，可以接收的值：1.直接就收一个大小2.可以指定一个百分数，则会相对于字体去计算行高3.可以直接传一个数值，则行高会设置字体大小相应的倍数 12345p&#123; line-height: 200%; line-height: 20px; line-height: 2;&#125; 对于单行文本来说，可以将行高设置为和父元素的高度一致， 这样可以是单行文本在父元素中垂直居中 5. 文本样式1. text-transform可以用来设置文本的大小写可选值： none 默认值，该怎么显示就怎么显示，不做任何处理 capitalize 单词的首字母大写，通过空格来识别单词 uppercase 所有的字母都大写 lowercase 所有的字母都小写2.text-decoration可以用来设置文本的修饰可选值： none：默认值，不添加任何修饰，正常显示 underline 为文本添加下划线 overline 为文本添加上划线 line-through 为文本添加删除线 超链接会默认添加下划线，也就是超链接的text-decoration的默认值是underline如果需要去除超链接的下划线则需要将该样式设置为none 3.letter-spacing可以指定字符间距4. word-spacing可以设置单词之间的距离实际上就是设置词与词之间空格的大小 5.text-align用于设置文本的对齐方式可选值： left 默认值，文本靠左对齐 right ， 文本靠右对齐 center ， 文本居中对齐 justify ， 两端对齐通过调整文本之间的空格的大小，来达到一个两端对齐的目的6.text-indent用来设置首行缩进当给它指定一个正值时，会自动向右侧缩进指定的像素 如果为它指定一个负值，则会向左移动指定的像素, 通过这种方式可以将一些不想显示的文字隐藏起来 这个值一般都会使用em作为单位 6. 盒模型使用width来设置盒子内容区的宽度，使用height来设置盒子内容区的高度。width和height只是设置的盒子内容区的大小，而不是盒子的整个大小，盒子可见框的大小由内容区，内边距和边框共同决定。 **内联元素不能设置 height 和 width ，如果非要设置必须修改 display 。 1. 为元素设置边框要为一个元素设置边框必须指定三个样式 1. border-width:边框的宽度使用border-width可以分别指定四个边框的宽度如果在border-width指定了四个值，则四个值会分别设置给 上 右 下 左，按照顺时针的方向设置的 如果指定三个值，则三个值会分别设置给 上 左右 下 如果指定两个值，则两个值会分别设置给 上下 左右 如果指定一个值，则四边全都是该值 2.border-color:边框颜色和宽度一样，color也提供四个方向的样式，可以分别指定颜色 3. border-style:边框的样式 none，默认值，没有边框 solid 实线 dotted 点状边框 dashed 虚线 double 双线 2. 内边距（padding）指的是盒子的内容区与盒子边框之间的距离* 一共有四个方向的内边距,内边距会影响盒子的可见框的大小，元素的背景会延伸到内边距. 3. 外边距外边距指的是当前盒子与其他盒子之间的距离，他不会影响可见框的大小，而是会影响到盒子的位置。由于页面中的元素都是靠左靠上摆放的，所以注意当我们设置上和左外边距时，会导致盒子自身的位置发生改变。_margin还可以设置为auto，auto一般只设置给水平方向的margin如果只指定，左外边距或右外边距的margin为auto则会将外边距设置为最大值垂直方向外边距如果设置为auto，则外边距默认就是0如果将left和right同时设置为auto，则会将两侧的外边距设置为相同的值，就可以使元素自动在父元素中居中，所以我们经常将左右外边距设置为auto。 1. 垂直外边距重叠垂直外边距的重叠在网页中相邻垂直方向的外边距会发生外边距的重叠所谓的外边距重叠指兄弟元素之间的相邻外边距会取最大值而不是取和. 如果父子元素的垂直外边 距相邻 **了，则子元素的外边距会设置给父元素. 2. 如何解决外边距重叠 在两个元素之家加其他元素 添加 border 添加 padding 注意：内联元素是不支持垂直方向的外边距的，其他的都和块级元素相同。 7. 元素展示方式1. display将一个内联元素变成块元素， 通过display样式可以修改元素的类型可选值： inline：可以将一个元素作为内联元素显示 block: 可以将一个元素设置块元素显示 inline-block：将一个元素转换为行内块元素可以使一个元素既有行内元素的特点又有块元素的特点既可以设置宽高，又不会独占一行 none: 不显示元素，并且元素不会在页面中继续占有位置使用该方式隐藏的元素，不会在页面中显示，并且不再占据页面的位置2. visibility可以用来设置元素的隐藏和显示的状态可选值： visible 默认值，元素默认会在页面显示 hidden 元素会隐藏不显示,使用 visibility:hidden;隐藏的元素虽然不会在页面中显示，但是它的位置会依然保持 3. overflow子元素默认是存在于父元素的内容区中， 理论上讲子元素的最大可以等于父元素内容区大小 如果子元素的大小超过了父元素的内容区，则超过的大小会在父元素以外的位置显 超出父元素的内容，我们称为溢出的内容 父元素默认是将溢出内容，在父元素外边显示， 通过overflow可以设置父元素如何处理溢出内容： 可选值： - visible，默认值，不会对溢出内容做处理，元素会显示 - hidden, 溢出的内容，会被修剪，不会显示 - scroll, 会为父元素添加滚动条，通过拖动滚动条该属性不论内容是否溢出，都会添加水平 - auto，会根据需求自动添加滚动条，需要水平就添加水平需要垂直就添加垂直都不需要就都不加 8. 文档流文档流文档流处在网页的最底层，它表示的是一个页面中的位置，我们所创建的元素默认都处在文档流中元素在文档流中的特点 1.块元素1.块元素在文档流中会独占一行，块元素会自上向下排列。 2.块元素在文档流中默认宽度是父元素的100% 3.块元素在文档流中的高度默认被内容撑开 2.内联元素1.内联元素在文档流中只占自身的大小，会默认从左向右排列，如果一行中不足以容纳所有的内联元素，则换到下一行，继续自左向右。 2.在文档流中，内联元素的宽度和高度默认都被内容撑开 9. 浮动块元素在文档流中默认垂直排列， 如果希望块元素在页面中水平排列，可以使块元素脱离文档流使用float来使元素浮动，从而脱离文档流可选值： none，默认值，元素默认在文档流中排列 left，元素会立即脱离文档流，向页面的左侧浮动 right，元素会立即脱离文档流，向页面的右侧浮动 1. 浮动的规则当为一个元素设置浮动以后（float属性是一个非none的值）， 元素会立即脱离文档流，元素脱离文档流以后，它下边的元素会立即向上移动 元素浮动以后，会尽量向页面的左上或右上漂浮， 直到遇到父元素的边框或者其他的浮动元素如果浮动元素上边是一个没有浮动的块元素，则浮动元素不会超过块元素。浮动的元素不会超过他上边的兄弟元素，最多最多一边齐。浮动的元素不会盖住文字，文字会自动环绕在浮动元素的周围在文档流中，子元素的宽度默认占父元素的全部当元素设置浮动以后，会完全脱离文档流.块元素脱离文档流以后，高度和宽度都被内容撑开 开启span的浮动内联元素脱离文档流以后会变成块元素 2. 浮动后高度塌陷在文档流中，父元素的高度默认是被子元素撑开的，也就是子元素多高，父元素就多高。但是当为子元素设置浮动以后，子元素会完全脱离文档流，此时将会导致子元素无法撑起父元素的高度，导致父元素的高度塌陷。由于父元素的高度塌陷了，则父元素下的所有元素都会向上移动，这样将会导致页面布局混乱。 所以在开发中一定要避免出现高度塌陷的问题,我们可以将父元素的高度写死，以避免塌陷的问题出现，但是一旦高度写死，父元素的高度将不能自动适应子元素的高度，所以这种方案是不推荐使用的。 3. 解决高度塌陷问题1. 开启BFC根据W3C的标准，在页面中元素都一个隐含的属性叫做Block Formatting Context简称BFC，该属性可以设置打开或者关闭，默认是关闭的。当开启元素的BFC以后，元素将会具有如下的特性： 1.父元素的垂直外边距不会和子元素重叠 2.开启BFC的元素不会被浮动元素所覆盖 3.开启BFC的元素可以包含浮动的子元素如何开启元素的BFC 1.设置元素浮动使用这种方式开启，虽然可以撑开父元素，但是会导致父元素的宽度丢失而且使用这种方式也会导致下边的元素上移，不能解决问题。这是因为开启浮动的会计元素宽高都是默认被撑起来的，除非自动设置宽高。 2.设置元素绝对定位 3.设置元素为inline-block可以解决问题，但是会导致宽度丢失，不推荐使用这种方式 4.将元素的overflow设置为一个非visible的值*推荐方式：将overflow设置为hidden是副作用最小的开启BFC的方式。 *是在IE6及以下的浏览器中并不支持BFC，所以使用这种方式不能兼容IE6。在IE6中虽然没有BFC，但是具有另一个隐含的属性叫做hasLayout，该属性的作用和BFC类似，所在IE6浏览器可以通过开hasLayout来解决该问题开启方式很多，我们直接使用一种副作用最小的：直接将元素的zoom设置为1即可 zoom表示放大的意思，后边跟着一个数值，写几就将元素放大几倍 zoom:1表示不放大元素，但是通过该样式可以开启hasLayout zoom这个样式，只在IE中支持，其他浏览器都不支持 1234.parent&#123; zoom:1; overflow: hidden;&#125; 2. 清除浮动可以直接在高度塌陷的父元素的最后，添加一个空白的div， 然后在对其进行清除浮动， 由于这个div并没有受到浮动元素的影响，所以他应该处在原来的元素在的时候的位置这样就相当于原来的元素还在，所以是可以撑开父元素的高度的，这样可以通过这个空白的div来撑开父元素的 基本没有副作用使用这种方式虽然可以解决问题，但是会在页面中添加多余的结构。 123.clear&#123; clear: both;&#125; 3. 伪类通过after伪类，选中父元素的后边可以通过after伪类向元素的最后添加一个空白的块元素，然后对其清除浮动，这样做和添加一个div的原理一样，可以达到一个相同的效果，而且不会在页面中添加多余的div，这是我们最推荐使用的方式，几乎没有副作用。 12345678.clearfix:after&#123; /*添加一个内容*/ content: \"\"; /*转换为一个块元素*/ display: block; /*清除两侧的浮动*/ clear: both; &#125; 4. 最佳实践12345678910.clearfix:before,.clearfix:after&#123; content: \"\"; display: table; clear: both;&#125; .clearfix&#123; zoom: 1;&#125; 经过修改后的clearfix是一个多功能的,既可以解决高度塌陷，又可以确保父元素和子元素的垂直外边距不会重叠。子元素和父元素相邻的垂直外边距会发生重叠，子元素的外边距会传递给父元素 使用空的table标签可以隔离父子元素的外边距，阻止外边距的重叠 4. 清除浮动由于受到box1浮动的影响，box2整体向上移动了100px我们有时希望清除掉其他元素浮动对当前元素产生的影响，这时可以使用clear可以用来清除其他浮动元素对当前元素的影响可选值： none，默认值，不清除浮动 left，清除左侧浮动元素对当前元素的影响 right，清除右侧浮动元素对当前元素的影响 both，清除两侧浮动元素对当前元素的影响清除对他影响最大的那个元素的浮动 5. 总结​ 在元素浮动的时候我们将元素看成两层。上面一层是文字相关的而下面一层则是和盒模型相关的。而一个元素开启浮动那么这个元素就被提升了半层。也就是两个排列的 box1 box2 ，在box1 浮动以后由于他之浮动半层，所以box2的盒模型部分会插入到box1下面，也就是box1会有三层，而box2的文字那一层是被卡在外面了，不会进去。 10. 定位定位指的就是将指定的元素摆放到页面的任意位置 通过定位可以任意的摆放元素 通过position属性来设置元素的定位可选值： static：默认值，元素没有开启定位 relative：开启元素的相对定位 absolute：开启元素的绝对定位 fixed：开启元素的固定定位（也是绝对定位的一种） 当开启了元素的定位（position属性值是一个非static的值）时， 可以通过left right top bottom四个属性来设置元素的偏移量 left：元素相对于其定位位置的左侧偏移量 right：元素相对于其定位位置的右侧偏移量 top：元素相对于其定位位置的上边的偏移量 bottom：元素相对于其定位位置下边的偏移量 通常偏移量只需要使用两个就可以对一个元素进行定位， 一般选择水平方向的一个偏移量和垂直方向的偏移量来为一个元素进行定位 1. 相对定位当元素的position属性设置为relative时，则开启了元素的相对定位 当开启了元素的相对定位以后，而不设置偏移量时，元素不会发生任何变化 相对定位是相对于元素在文档流中原来的位置进行定位 相对定位的元素不会脱离文档流 相对定位会使元素提升一个层级 相对定位不会改变元素的性质，块还是块，内联还是内联 2. 绝对定位当position属性值设置为absolute时，则开启了元素的绝对定位绝对定位： 开启绝对定位，会使元素脱离文档流 开启绝对定位以后，如果不设置偏移量，则元素的位置不会发生变化 绝对定位是相对于离他最近的开启了定位的祖先元素进行定位的（一般情况，开启了子元素的绝对定位都会同时开启父元素的相对定位）如果所有的祖先元素都没有开启定位，则会相对于浏览器窗口进行定位 绝对定位会使元素提升一个层级 绝对定位会改变元素的性质，内联元素变成块元素，块元素的宽度和高度默认都被内容撑开3. 固定定位当元素的position属性设置fixed时，则开启了元素的固定定位 固定定位也是一种绝对定位，它的大部分特点都和绝对定位一样 不同的是： 固定定位永远都会相对于浏览器窗口进行定位 固定定位会固定在浏览器窗口某个位置，不会随滚动条滚动IE6不支持固定定位. 4. 总结浮动元素的包含块为最近的块级祖先元素。而定位则比较复杂： 初始包含块由用户浏览器创建，在html中就是html标签。但是有些浏览器也会采用body作为根元素，大多数浏览器中初始包含块都是一个视窗大小的矩形。但是视口不等于初始包含块。 对于非根元素如果是relative或者static则包含块是最近的块级框。（或者说是他本来应该处于的位置。） 对于非根元素如果是absolute则包含块是最近的开启定位的元素(非static)的内边距的边界，也就是说是由边框的边界确定的。 由于我们的行业规范是 div+css 所以我们不考虑内联元素的情况，因为div是块级元素。 定位是提升一层，和浮动不一样。 注意： 对于一些常用的一些样式我们需要知道他们的默认值是什么比如： left top right bottom width height 的默认值都是auto不是 0 也不是100% margin 和 padding 默认则是 0 如果我们采用百分比百分比参照的是父级元素的 width 的而不是当前元素的大小。 11. 常用布局1. 三列布局1.定位实现方式​ 三列的话我们可以让其中的两列分别使用绝对定位，然后由于绝对定位默认是依照浏览器的窗口（或者将body设为realtive 然后相对于 body），所以可以让两边的直接在两边，而中间的使用块元素直接让宽度充满整个空闲部分。 ​ 然后由于随着我们浏览器变小我们需要设置一个body的最小宽否则有可能让我们的中间部分压没了。 ​ 其实这个是有问题的，就是当我们压缩矿口的时候会出现滚动条如果我们设置了 min-width ，这样我们的右边以浏览器窗口对其就会有问题。 ​ 所以不推荐使用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; body&#123; /*2*left+right*/ min-width: 600px; &#125; div&#123; height: 100px; &#125; #left,#right&#123; width: 200px; background: pink; &#125; #middle&#123; background: deeppink; padding: 0 200px; &#125; #left&#123; position: absolute; left: 0; top: 0; &#125; #right&#123; position: absolute; right: 0; top: 0; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body style=\"position: relative;\"&gt; &lt;div id=\"left\"&gt;left&lt;/div&gt; &lt;div id=\"middle\"&gt;middle&lt;/div&gt; &lt;div id=\"right\"&gt;right&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 2. 使用浮动将左右两列用浮动分别让他们在两边展示，而中间的为块级元素这样他的盒子布局的那一层就会浮上去，而文字刚好就被卡住。但是这个东西的前提就是内容区必须放在最后内容区的第二层才会自动的浮动上去。这样一来就有一个问题就是内容区是在文档流中最后被加载的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;!-- 1.两边固定 当中自适应 2.当中列要完整显示 3.当中列要优先加载 --&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; body&#123; /*2*left+right*/ min-width: 600px; &#125; div&#123; height: 100px; &#125; #left,#right&#123; width: 200px; background: pink; &#125; #left&#123; float: left; &#125; #right&#123; float: right; &#125; #middle&#123; background: deeppink; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"left\"&gt;left&lt;/div&gt; &lt;div id=\"right\"&gt;right&lt;/div&gt; &lt;div id=\"middle\"&gt;middle&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 3. 圣杯布局​ 首先我们还是使用 float:left 让左右两部的元素浮动起来，但是由于我们的content是块级元素没办法让下面的元素上来，那么我们只能把它也设置为浮动，这样一来他的宽度就是被内容撑开了，我们需要设置他的宽度为body的100%，现在是content占据100%但是它允许下面浮动的元素上去。如果我们使用浮动让他们上去肯定就和上面的方法一样了，我们需要的是中间的元素有限加载也就是他应该出现在文档流的最前面。 ​ 可以采用负的margin，可以想象，我们的left的外边界和content是重叠的，那么我们如果移动他的外边界到content的起始位置那么他是不是就上去了呢？确实如此但是注意一个问题就是我们改变了外边距元素的位置实际上是不会动的，也就是在文档流中他还是在下面那一行，right的左边还是left这个块。所以我们right需要上去的时候必须margin为 -200 ​ 这样就好了，但是content的内容被挡住了。我们可以设把body变小，然后通过定位完成整个布局。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;!-- 1.两边固定 当中自适应 2.当中列要完整显示 3.当中列要优先加载 --&gt; &lt;!-- 浮动: 搭建完整的布局框架 margin 为赋值:调整旁边两列的位置(使三列布局到一行上) 使用相对定位:调整旁边两列的位置（使两列位置调整到两头） --&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; body&#123; min-width: 600px; &#125; #content&#123; padding: 0 200px; &#125; #header,#footer&#123; height: 20px; text-align: center; border: 1px solid deeppink; background: gray; &#125; #content .middle&#123; float: left; width: 100%; background: pink; /*padding: 0 200px;*/ &#125; #content .left&#123; position: relative; left: -200px; margin-left: -100%; float: left; width: 200px; background: yellow; &#125; #content .right&#123; position: relative; right: -200px; margin-left: -200px; float: left; width: 200px; background: yellow; &#125; .clearfix&#123; *zoom: 1; &#125; .clearfix:after&#123; content: \"\"; display: block; clear: both; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"header\"&gt;header&lt;/div&gt; &lt;div id=\"content\" class=\"clearfix\"&gt; &lt;div class=\"middle\"&gt; &lt;h4&gt;middle&lt;/h4&gt; &lt;/div&gt; &lt;div class=\"left\"&gt;left&lt;/div&gt; &lt;div class=\"right\"&gt;right&lt;/div&gt; &lt;/div&gt; &lt;div id=\"footer\"&gt;footer&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 4. 双飞翼布局​ 在上面的圣杯布局的基础之上做的改进，其实做到两边都浮动然后只是content的内容不能居中，那么他们之间的区别就是如何让内容居中上。 ​ 圣杯是把padding应用在外面的body上，然后使用定位让他们分到两边。我们会考虑为什么不能用padding在conten上呢，实际上我们在content浮动以后使用padding就会把整个元素变大变宽，那么我们以前设置的left和right的margin的值需要重新设置不然就是错乱的。所以他在内部加了一层结构然后使用padding，这样的话由于left和right的margin只和外面的content的外边界有关系，所以里面的padding并不能影响整体的布局。 2. 伪等高布局​ 如果我们两列高度不一样，需要让两列一一样高，我们采用的套路就是让他们的padding超级大，然后把整个的元素高度很高，然后让margin为负值把边界收回来，那么也就是他们的外部的盒子的外边距收回来了，此时再用 overflow:hidden;就好。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; #wrap&#123; width: 750px; border: 1px solid; margin: 0 auto; overflow: hidden; &#125; #wrap .left&#123; float: left; width: 200px; background: pink; padding-bottom: 1000px; margin-bottom: -1000px; &#125; #wrap .right&#123; float: left; width: 500px; background: deeppink; padding-bottom: 1000px; margin-bottom: -1000px; &#125; .clearfix&#123; *zoom: 1; &#125; .clearfix:after&#123; content: \"\"; display: block; clear: both; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"wrap\" class=\"clearfix\"&gt; &lt;div class=\"left\"&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; left &lt;br /&gt; &lt;/div&gt; &lt;div class=\"right\"&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; right&lt;br /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 12. 滚动条​ 一般的在我们内容大于浏览器视窗的时候会出现滚动条，这时滚动条是应用在文档上的不是在html也不是在body上。如果我们希望修改这个设置我们有一条规则就是： ​ 当我们只设置 body 和 html 中的overflow的时候他们这个属性是应用给文档的，但是如果两者同时使用这个属性那么html的设置给文档而body的设置给body。 ​ 实际上我们的固定定位和绝对定位的区别就在于滚动条上面，如果我们自己设置了滚动条那么就可以采用绝对定位来模拟固定定位。在移动端一般我们都是这么做的，因为我们需要禁用掉系统默认的滚动条。 ​ 注意：如果我们希望获得视窗的大小的话我们需要从html到body一层层的100%的继承下来不然height只会被内容撑开 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; html&#123; overflow: hidden; height: 100%; &#125; body&#123; overflow: auto; height: 100%; &#125; #test&#123; position: absolute; left: 50px; top: 50px; width: 100px; height: 100px; background: pink; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"test\"&gt; &lt;/div&gt; &lt;div style=\"height: 1000px;\"&gt; csjkahcjk &lt;br /&gt; csjkahcjk &lt;br /&gt; csjkahcjk &lt;br /&gt; csjkahcjk &lt;br /&gt; csjkahcjk &lt;br /&gt; csjkahcjk &lt;br /&gt; csjkahcjk &lt;br /&gt; csjkahcjk &lt;br /&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 13. 黏贴布局​ 黏贴布局就是当内容没有达到底部的时候我们的内容在底部不动，而内容太多的时候可以把我们的底部挤到下面去。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,user-scalable=no\"/&gt; &lt;title&gt;&lt;/title&gt; &lt;style type=\"text/css\"&gt; *&#123; margin: 0; padding: 0; &#125; html,body&#123; height: 100%; &#125; #wrap&#123; min-height: 100%; background: pink; text-align: center; overflow: hidden; &#125; #wrap .main&#123; padding-bottom:50px ; &#125; #footer&#123; height: 50px; line-height: 50px; background: deeppink; text-align: center; margin-top: -50px; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"wrap\" &gt; &lt;div class=\"main\"&gt; main &lt;br /&gt; main &lt;br /&gt; main &lt;br /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=\"footer\"&gt; footer &lt;/div&gt; &lt;/body&gt;&lt;/html&gt;","categories":[{"name":"FrontEnd","slug":"FrontEnd","permalink":"http://lwenxu.coding.me/categories/FrontEnd/"}],"tags":[{"name":"CSS","slug":"CSS","permalink":"http://lwenxu.coding.me/tags/CSS/"}]},{"title":"Composer 使用指南","slug":"PHP/Composer使用指南","date":"2019-01-05T12:08:33.000Z","updated":"2019-01-07T19:09:14.000Z","comments":true,"path":"2019/01/05/PHP/Composer使用指南/","link":"","permalink":"http://lwenxu.coding.me/2019/01/05/PHP/Composer使用指南/","excerpt":"","text":"1. 安装依赖1composer install 这个语句会检查当前目录下的 composer.json 然后检查是否有 composer.lock 如果有这个文件那么就按照 lock 文件中的版本号进行安装依赖，如果没有lock文件就按照 composer.json 中定义的版本进行安装。 这里就需要注意，composer.json 定义的版本号可能是一个区间也就是他可以是一个范围，随着类库的更新而更新，但是 lock文件保证了此项目的版本号是确定的，也就是项目组成员得到的版本号是一致的，就不会有很多麻烦问题了。 composer.json 中的版本的定义方式有： 名称 实例 描述 确切的版本号 1.0.2 你可以指定包的确切版本。 范围 &gt;=1.0 `&gt;=1.0,&lt;2.0``&gt;=1.0,&lt;1.1 &gt;=1.2` 通配符 1.0.* 你可以使用通配符*来指定一种模式。1.0.*与&gt;=1.0,&lt;1.1是等效的。 赋值运算符 ~1.2 一个常见的用法是标记你所依赖的最低版本，像 ~1.2 （允许1.2以上的任何版本，但不包括2.0）。~1.2 相当于 &gt;=1.2,&lt;2.0，而 ~1.2.3 相当于 &gt;=1.2.3,&lt;1.3。~1.2 只意味着 .2 部分可以改变，但是 1. 部分是固定的。 对的，这样就解决了项目成员的类库版本一致的问题，但是如果我们希望能够升级类库呢？那么就执行 1composer update 如果只想安装或更新一个依赖，你可以白名单它们： 1php composer.phar update monolog/monolog [...] 2. Packagistpackagist 是 Composer 的主要资源库。 一个 Composer 的库基本上是一个包的源：记录了可以得到包的地方。但是没必要去国外的网站下载，我们可以采用国内的镜像加速： 方法一： 修改 composer 的全局配置文件（推荐方式）打开命令行窗口（windows用户）或控制台（Linux、Mac 用户）并执行如下命令： 1composer config -g repo.packagist composer https://packagist.phpcomposer.com 方法二： 修改当前项目的 composer.json 配置文件：打开命令行窗口（windows用户）或控制台（Linux、Mac 用户），进入你的项目的根目录（也就是 composer.json 文件所在目录），执行如下命令： 1composer config repo.packagist composer https://packagist.phpcomposer.com 上述命令将会在当前项目中的 composer.json 文件的末尾自动添加镜像的配置信息（你也可以自己手工添加）： 123456\"repositories\": &#123; \"packagist\": &#123; \"type\": \"composer\", \"url\": \"https://packagist.phpcomposer.com\" &#125;&#125; 3. 类库自动加载除了库的下载，Composer 还准备了一个自动加载文件，它可以加载 Composer 下载的库中所有的类文件。使用它，你只需要将下面这行代码添加到你项目的引导文件中： 1require 'vendor/autoload.php'; 4. 创建项目 create-project你可以使用 Composer 从现有的包中创建一个新的项目。这相当于执行了一个 git clone 或 svn checkout 命令后将这个包的依赖安装到它自己的 vendor 目录。 此命令有几个常见的用途： 你可以快速的部署你的应用。 你可以检出任何资源包，并开发它的补丁。 多人开发项目，可以用它来加快应用的初始化。 要创建基于 Composer 的新项目，你可以使用 “create-project” 命令。传递一个包名，它会为你创建项目的目录。你也可以在第三个参数中指定版本号，否则将获取最新的版本。 如果该目录目前不存在，则会在安装过程中自动创建。 1php composer.phar create-project doctrine/orm path 2.2.* 此外，你也可以无需使用这个命令，而是通过现有的 composer.json 文件来启动这个项目。 默认情况下，这个命令会在 packagist.org 上查找你指定的包。","categories":[{"name":"PHP","slug":"PHP","permalink":"http://lwenxu.coding.me/categories/PHP/"}],"tags":[{"name":"PHP,包管理器","slug":"PHP-包管理器","permalink":"http://lwenxu.coding.me/tags/PHP-包管理器/"}]},{"title":"记一次微信支付踩过的坑","slug":"PHP/记一次微信支付踩过的坑","date":"2019-01-05T12:08:33.000Z","updated":"2019-01-05T05:52:56.000Z","comments":true,"path":"2019/01/05/PHP/记一次微信支付踩过的坑/","link":"","permalink":"http://lwenxu.coding.me/2019/01/05/PHP/记一次微信支付踩过的坑/","excerpt":"","text":"​ 最近在做一个微信小程序，然后里面涉及到了支付的内容，本来以为微信支付挺简单的，当我开始写支付后台去看微信提供的支付文档的时候我就崩溃了，文档写了跟没写一样。 ​ 本来是准备原生的php写后来觉得还是不太安全，而且真的文档不全很麻烦，就去找了一个类库。一会也会介绍一下这个类库的坑。 1 . 微信支付流程 ​ 好了，这大概就是微信支付的流程了。下面来具体的说一下： 首先是小程序调用 wx.login 获取用户当前登陆的 code 这个code是会变化的，并不能作为用户的标识 12345wx.login(&#123; success(res) &#123; console.log(res.code); //获取的code &#125;&#125; 然后把 code 当做参数请求微信接口获取 opencode 这个就是用户的标识。这一步操作我把它放在了服务端，也就是我们的服务器会去请求微信的接口获取 opencode 返回给小程序。 后端做的就是请求微信接口： 1$ret = curl_get_https(\"https://api.weixin.qq.com/sns/jscode2session?appid=&#123;$config['appId']&#125;&amp;secret=&#123;$config['secret']&#125;&amp;js_code=$code&amp;grant_type=authorization_code\"); 可以看到这里后台就是请求了这个 url 里面带了三个动态参数，有appid，secret都是在小程序的管理界面能看到的。code就是我们上一步获取到的，最后一个参数固定的。 获取到用户的opencode之后就可以让后台请求微信支付接口进行订单生成了。 后台请求支付接口，生成订单： 请求地址为：https://api.mch.weixin.qq.com/pay/unifiedorder 一些常见的必传参数是： 123456789101112'appid' 微信支付分配的公众账号ID（企业号corpid即为此appId） 'mch_id' 微信支付分配的商户号,这个需要登录商户平台，申请通过以后直接就能看到的'prepayid' $prepay_id'noncestr' 随机字符串，长度要求在32位以内，这个随便生成。'sign' 通过签名算法计算得出的签名值，这个就是把请求的所有参数按照key的字典序拼串key1=val1&amp;key2=val2，最后拼上密钥key 的key和value'package' prepay_id=$prepay_id'body' 商品简单描述'total_fee' 订单总金额，单位为分'notify_url' 异步接收微信支付结果通知的回调地址，通知url必须为外网可访问的url，不能携带参数。'out_trade_no' 商户系统内部订单号，要求32个字符内，只能是数字、大小写字母'spbill_create_ip' 支持IPV4和IPV6两种格式的IP地址。调用微信支付API的机器IP'trade_type ' JSAPI -JSAPI支付NATIVE -Native支付APP -APP支付 上述的操作完成以后，需要写一个通知回调的地址，这个地址里面的逻辑代码就是处理我们数据库订单的内容，比如把订单状态设置为已支付，或者创建订单将货物设置为已发货。这个回调在不出任何问题的情况下我们需要返回一段特定的字符串，否则微信认为逻辑没有执行成功，他会继续回调这个回调地址。如果你发现你的逻辑是错的他一直回调这个地址貌似没有办法让他停止回调，他可能有自己的策略在一定时间后停止回调。成功的字符串是： 1echo '&lt;xml&gt;&lt;return_code&gt;&lt;![CDATA[SUCCESS]]&gt;&lt;/return_code&gt;&lt;return_msg&gt;&lt;![CDATA[OK]]&gt;&lt;/return_msg&gt;&lt;/xml&gt;'; 注意不要再有其他的任何输出，并且字符串中不要有空格。 最后会返回订单的信息，此时只需要调用微信小程序的 wx.requestPayment 并且传递以下必要参数： 12345'timeStamp': data['timestamp'],'nonceStr': data['noncestr'],'package': data['package'],'signType': 'MD5','paySign': data['sign'], 这时小程序会自动拉起微信支付进行支付。 2. 微信支付类库解析","categories":[{"name":"PHP","slug":"PHP","permalink":"http://lwenxu.coding.me/categories/PHP/"}],"tags":[{"name":"PHP,微信","slug":"PHP-微信","permalink":"http://lwenxu.coding.me/tags/PHP-微信/"}]},{"title":"七牛云关联Windows图床","slug":"Tools/七牛云关联Windows图床","date":"2019-01-03T07:14:53.000Z","updated":"2019-01-02T23:38:08.000Z","comments":true,"path":"2019/01/03/Tools/七牛云关联Windows图床/","link":"","permalink":"http://lwenxu.coding.me/2019/01/03/Tools/七牛云关联Windows图床/","excerpt":"","text":"1. 注册七牛云七牛云 地址，需要在这里进行注册 2.完成实名认证需要上传身份证的正反面以及支付宝做一下认证即可。 首先进入个人中心 然后进行实名认证 由于我已经认证过了，所以显示认证完成，未认证的用户需要按照提示认证，一般来说 5分钟就能完成认证。 3. 创建对象存储 只需要填一下名字，然后因为是图床所以肯定是公开的访问权限。 4. 绑定域名配置完空间以后就是需要关联域名，配置 CNAME 绑定域名，这个域名需要是一个已经备案过的域名。 只需要填写域名这一项即可，最后就是需要到你的域名管理后台配置一个域名的解析，首先打开这个地址 https://portal.qiniu.com/cdn/domain/ 然后找到你的域名选择复制CNAME 然后需要做一个域名解析，比如到阿里云上 等一会会 https://portal.qiniu.com/cdn/domain/ 打开这个链接如果看到解析成功则说明配置完成了。 5. 关联 PicGo这款软件是一个跨平台的图床软件个人觉得很好用。直接百度就可以下载到。 做完配置，然后确定，设置为默认图床就可以在上传区上传文件了！","categories":[{"name":"工具","slug":"工具","permalink":"http://lwenxu.coding.me/categories/工具/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://lwenxu.coding.me/tags/工具/"}]},{"title":"Apache配置详解","slug":"Linux/Apache配置虚拟主机","date":"2019-01-03T03:08:33.000Z","updated":"2019-01-03T04:54:18.000Z","comments":true,"path":"2019/01/03/Linux/Apache配置虚拟主机/","link":"","permalink":"http://lwenxu.coding.me/2019/01/03/Linux/Apache配置虚拟主机/","excerpt":"","text":"1. 虚拟主机概念我们要想实现一个web站点，而且能够在互联网上被访问，首先它再能运行在操作系统，而且这个操作系统还要运行在物理主机上（第一它是一个主机）。在互联网上能够被访问，那我们需要一个主机，需要一个IP地址，需要一个时时在线的服务器，这需要多少资源？对众多小型站点来讲或者说对某种需求来讲，有可能都用不到服务器，也就是每天就10个人左右访问，只是需要我们在线而已，如果我们就为这一点点的需求就投入重大的资源的话是非常浪费的。我们就期望能够像我们使用虚拟机一样，虚拟的OS一样或虚拟的PC一样，能够在一台物理主机上虚拟出来多个可以同时运行的站点或者我们把它称为主机因此就把它称为虚拟主机。 2. Apache 主机的类型1. 中心主机2. 虚拟主机 基于IP: 端口相同，IP地址不同。 基于端口：IP相同，端口不同。 基于域名：IP地址相同，端口相同主机名不同 注意：所有的虚拟主机的配置我们都需要取消中心主机，也就是注释掉 DocumentRoot 这是配置虚拟主机的前提 3. 基于域名的虚拟主机例如我采用的 xampp 所以配置虚拟主机就在 C:\\xampp\\apache\\conf\\extra\\httpd-vhosts.conf 中配置，由于这个文件默认被 include 到主配置文件中了，所以在这里的修改都可以生效。 首先需要保证主配置文件中的中心主机被取消了也就是： 1#DocumentRoot \"C:/xampp/htdocs\" 然后打开 httpd-vhosts.conf 配置文件，按照下面的格式配置虚拟主机 123456789&lt;VirtualHost *:80&gt; DocumentRoot &quot;C:/xampp/htdocs&quot; ServerName localhost &lt;Directory &quot;C:/xampp/htdocs&quot;&gt; Options Indexes FollowSymLinks Includes ExecCGI AllowOverride All Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 1. &lt;VirtualHost *:80&gt; apache监听本机的所有 IP 和 80 端口做多域名虚拟主机 2. DocumentRoot表示服务器的根目录 3. ServerName就是表示域名，我们采用域名方式配置虚拟主机，所以每个虚拟主机的域名应该是不一样的才行 4. Directory对根目录的规则应用，其中涉及到对于目录的访问权限和其他配置问题 5. 对于 Directory 指令解析1. Options配置在特定目录使用哪些特性，常用的值和基本含义如下 ExecCGI: 在该目录下允许执行CGI脚本。 FollowSymLinks: 在该目录下允许文件系统使用符号连接。 Indexes: 当用户访问该目录时，如果用户找不到DirectoryIndex指定的主页文件(例如index.html),则返回该目录下的文件列表给用户。 SymLinksIfOwnerMatch: 当使用符号连接时，只有当符号连接的文件拥有者与实际文件的拥有者相同时才可以访问。 所以我们一般在配置 PHP 的时候所配置的内容是 1Options Indexes FollowSymLinks Includes ExecCGI 2. AllowOverride允许存在于.htaccess文件中的指令类型(.htaccess文件名是可以改变的，其文件名由AccessFileName指令决定)： None: 当AllowOverride被设置为None时。不搜索该目录下的.htaccess文件（可以减小服务器开销）。 All: 在.htaccess文件中可以使用所有的指令。 建议关闭这个选项，因为apache在文档中已经明确支持不建议使用它了，主要是会降低服务器性能，.htaccess 文件可以做到的我们都可以在 Directory 指令中做的更好。 3. Order控制在访问时Allow和Deny两个访问规则哪个优先，也就是黑白名单的匹配顺序 Allow：允许访问的主机列表(可用域名或子网，例如：Allow from 192.168.0.0/16)。 Deny：拒绝访问的主机列表。 更详细的用法可参看：order用法 匹配原则： 1Allow,Deny First, all Allow directives are evaluated; at least one must match, or the request is rejected. Next, all Deny directives are evaluated. If any matches, the request is rejected. Last, any requests which do not match an Allow or a Deny directive are denied by default. 1Deny,Allow First, all Deny directives are evaluated; if any match, the request is denied unless it also matches an Allow directive. Any requests which do not match any Allow or Deny directives are permitted. 4. DirectoryIndex主页文件设置 一般都是 index.html index.php 5. Deny /Allow黑白名单书写规则如下： 12345Allow from example.orgAllow from .net example.eduAllow from 10.1.2.3Allow from 192.168.1.104 192.168.1.205Allow all 4. 基于端口的虚拟主机对于同一个 ip 来做虚拟主机，就是需要监听不同的端口，首先需要在主配置文件中添加新的监听端口： 12Listen 80Listen 81 然后再虚拟主机里面配置 123456&lt;Virtualhost *:80&gt; DocumentRoot &quot;/var1&quot;&lt;/Virtualhost&gt;&lt;Virtualhost *:81&gt; DocumentRoot &quot;/var2&quot;&lt;/Virtualhost&gt; 5. 基于ip的虚拟主机这个就不过多赘述了，完全和基于端口的配置方式一样。也就是修改的是ip 而非端口、 6.服务器的优化 (MPM: Multi-Processing Modules)apache2主要的优势就是对多处理器的支持更好，在编译时同过使用–with-mpm选项来决定apache2的工作模式。如果知道当前的apache2使用什么工作机制，可以通过httpd -l命令列出apache的所有模块，就可以知道其工作方式： prefork：如果httpd -l列出prefork.c，则需要对下面的段进行配置。 1234567&lt;IfModule prefork.c&gt; StartServers 5 #启动apache时启动的httpd进程个数。 MinSpareServers 5 #服务器保持的最小空闲进程数。 MaxSpareServers 10 #服务器保持的最大空闲进程数。 MaxClients 150 #最大并发连接数。 MaxRequestsPerChild 1000 #每个子进程被请求服务多少次后被kill掉。0表示不限制，推荐设置为1000。 &lt;/IfModule&gt; 在该工作模式下，服务器启动后起动5个httpd进程(加父进程共6个，通过ps -ax|grep httpd命令可以看到)。当有用户连接时，apache会使用一个空闲进程为该连接服务，同时父进程会fork一个子进程。直到内存中的空闲进程达到MaxSpareServers。该模式是为了兼容一些旧版本的程序。我缺省编译时的选项。 worker：如果httpd -l列出worker.c，则需要对下面的段进行配置： 12345678&lt;IfModule worker.c&gt; StartServers 2 #启动apache时启动的httpd进程个数。 MaxClients 150 #最大并发连接数。 MinSpareThreads 25 #服务器保持的最小空闲线程数。 MaxSpareThreads 75 #服务器保持的最大空闲线程数。 ThreadsPerChild 25 #每个子进程的产生的线程数。 MaxRequestsPerChild 0 #每个子进程被请求服务多少次后被kill掉。0表示不限制，推荐设置为1000。 &lt;/IfModule&gt; 该模式是由线程来监听客户的连接。当有新客户连接时，由其中的一个空闲线程接受连接。服务器在启动时启动两个进程，每个进程产生的线程数是固定的(ThreadsPerChild决定)，因此启动时有50个线程。当50个线程不够用时，服务器自动fork一个进程，再产生25个线程。 perchild：如果httpd -l列出perchild.c，则需要对下面的段进行配置： 12345678&lt;IfModule perchild.c&gt; NumServers 5 #服务器启动时启动的子进程数 StartThreads 5 #每个子进程启动时启动的线程数 MinSpareThreads 5 #内存中的最小空闲线程数 MaxSpareThreads 10 #最大空闲线程数 MaxThreadsPerChild 2000 #每个线程最多被请求多少次后退出。0不受限制。 MaxRequestsPerChild 10000 #每个子进程服务多少次后被重新fork。0表示不受限制。 &lt;/IfModule&gt; 该模式下，子进程的数量是固定的，线程数不受限制。当客户端连接到服务器时，又空闲的线程提供服务。 如果空闲线程数不够，子进程自动产生线程来为新的连接服务。该模式用于多站点服务器。 7.别名设置对于不在DocumentRoot指定的目录内的页面，既可以使用符号连接，也可以使用别名。别名的设置如下： 12345678Alias /download/ &quot;/var/www/download/&quot; #访问时可以输入:http://www.custing.com/download/ &lt;Directory &quot;/var/www/download&quot;&gt; #对该目录进行访问控制设置 Options Indexes MultiViews AllowOverride AuthConfig Order allow,deny Allow from all &lt;/Directory&gt; 6、CGI设置123456789# 访问时可以：http://www.clusting.com/cgi-bin/，但是该目录下的CGI脚本文件要加可执行权限ScriptAlias /cgi-bin/ &quot;/mnt/software/apache2/cgi-bin/&quot; &lt;Directory &quot;/usr/local/apache2/cgi-bin&quot;&gt; #设置目录属性 AllowOverride None Options None Order allow,deny Allow from all &lt;/Directory&gt; 8、日志的设置(1) 错误日志的设置 ErrorLog logs/error_log :日志的保存位置 LogLevel warn #日志的级别 显示的格式日下： 1[Mon Oct 10 15:54:29 2005] [error] [client 192.168.10.22] access to /download/ failed, reason: user admin not allowed access (2) 访问日志设置日志的缺省格式有如下几种： LogFormat “%h %l %u %t “%r” %&gt;s %b “%{Referer}i” “%{User-Agent}i”” combined LogFormat “%h %l %u %t “%r” %&gt;s %b” common #common为日志格式名称 LogFormat “%{Referer}i -&gt; %U” referer LogFormat “%{User-agent}i” agent CustomLog logs/access_log common 格式中的各个参数如下： 123456789%h --客户端的ip地址或主机名 %l --The 这是由客户端 identd 判断的RFC 1413身份，输出中的符号 &quot;-&quot; 表示此处信息无效。 %u --由HTTP认证系统得到的访问该网页的客户名。有认证时才有效，输出中的符号 &quot;-&quot; 表示此处信息无效。 %t --服务器完成对请求的处理时的时间。 &quot;%r&quot; --引号中是客户发出的包含了许多有用信息的请求内容。 %&gt;s --这个是服务器返回给客户端的状态码。 %b --最后这项是返回给客户端的不包括响应头的字节数。 &quot;%&#123;Referer&#125;i&quot; --此项指明了该请求是从被哪个网页提交过来的。 &quot;%&#123;User-Agent&#125;i&quot; --此项是客户浏览器提供的浏览器识别信息。 下面是一段访问日志的实例： 123192.168.10.22 - bearzhang [10/Oct/2005:16:53:06 +0800] &quot;GET /download/ HTTP/1.1&quot; 200 1228 192.168.10.22 - - [10/Oct/2005:16:53:06 +0800] &quot;GET /icons/blank.gif HTTP/1.1&quot; 304 - 192.168.10.22 - - [10/Oct/2005:16:53:06 +0800] &quot;GET /icons/back.gif HTTP/1.1&quot; 304 – 9、用户认证的配置(1) httpd.conf用户认证配置:1234567AccessFileName .htaccess ......... Alias /download/ &quot;/var/www/download/&quot; &lt;Directory &quot;/var/www/download&quot;&gt; Options Indexes AllowOverride AuthConfig &lt;/Directory&gt; (2) create a password file:1/usr/local/apache2/bin/htpasswd -c /var/httpuser/passwords bearzhang (3) configure the server to request a password and tell the server which users are allowed access.1234567vi /var/www/download/.htaccess: AuthType Basic AuthName &quot;Restricted Files&quot; AuthUserFile /var/httpuser/passwords Require user bearzhang #Require valid-user #all valid user 10、虚拟主机的配置总结(1)基于IP地址的虚拟主机配置1234567891011Listen 80 &lt;VirtualHost 172.20.30.40&gt; DocumentRoot /www/example1 ServerName www.example1.com &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.50&gt; DocumentRoot /www/example2 ServerName www.example2.org &lt;/VirtualHost&gt; (2) 基于IP和多端口的虚拟主机配置123456789101112131415161718192021222324Listen 172.20.30.40:80 Listen 172.20.30.40:8080 Listen 172.20.30.50:80 Listen 172.20.30.50:8080 &lt;VirtualHost 172.20.30.40:80&gt; DocumentRoot /www/example1-80 ServerName www.example1.com &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.40:8080&gt; DocumentRoot /www/example1-8080 ServerName www.example1.com &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.50:80&gt; DocumentRoot /www/example2-80 ServerName www.example1.org &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.50:8080&gt; DocumentRoot /www/example2-8080 ServerName www.example2.org &lt;/VirtualHost&gt; (3) 单个IP地址的服务器上基于域名的虚拟主机配置：123456789101112131415161718# Ensure that Apache listens on port 80 Listen 80 # Listen for virtual host requests on all IP addresses NameVirtualHost *:80 &lt;VirtualHost *:80&gt; DocumentRoot /www/example1 ServerName www.example1.com ServerAlias example1.com. *.example1.com # Other directives here &lt;/VirtualHost&gt; &lt;VirtualHost *:80&gt; DocumentRoot /www/example2 ServerName www.example2.org # Other directives here &lt;/VirtualHost&gt; (4) 在多个IP地址的服务器上配置基于域名的虚拟主机：1234567891011121314151617181920Listen 80 # This is the &quot;main&quot; server running on 172.20.30.40 ServerName server.domain.com DocumentRoot /www/mainserver # This is the other address NameVirtualHost 172.20.30.50 &lt;VirtualHost 172.20.30.50&gt; DocumentRoot /www/example1 ServerName www.example1.com # Other directives here ... &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.50&gt; DocumentRoot /www/example2 ServerName www.example2.org # Other directives here ... &lt;/VirtualHost&gt; (5) 在不同的端口上运行不同的站点(基于多端口的服务器上配置基于域名的虚拟主机)：12345678910111213141516171819202122232425Listen 80 Listen 8080 NameVirtualHost 172.20.30.40:80 NameVirtualHost 172.20.30.40:8080 &lt;VirtualHost 172.20.30.40:80&gt; ServerName www.example1.com DocumentRoot /www/domain-80 &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.40:8080&gt; ServerName www.example1.com DocumentRoot /www/domain-8080 &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.40:80&gt; ServerName www.example2.org DocumentRoot /www/otherdomain-80 &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.40:8080&gt; ServerName www.example2.org DocumentRoot /www/otherdomain-8080 &lt;/VirtualHost&gt; (6) 基于域名和基于IP的混合虚拟主机的配置:123456789101112131415161718Listen 80 NameVirtualHost 172.20.30.40 &lt;VirtualHost 172.20.30.40&gt; DocumentRoot /www/example1 ServerName www.example1.com &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.40&gt; DocumentRoot /www/example2 ServerName www.example2.org &lt;/VirtualHost&gt; &lt;VirtualHost 172.20.30.40&gt; DocumentRoot /www/example3 ServerName www.example3.net &lt;/VirtualHost&gt; 11.SSL加密的配置首先在配置之前先来了解一些基本概念： a. 证书的概念：首先要有一个根证书，然后用根证书来签发服务器证书和客户证书，一般理解：服务器证书和客户证书是平级关系。SSL必须安装 服务器证书来认证。 因此：在此环境中，至少必须有三个证书：根证书，服务器证书，客户端证书。 在生成证书之前，一般会有一个私钥，同时用私钥生成证书请求，再利用证书服务器的根证来签发证书。 SSL所使用的证书可以自己生成，也可以通过一个商业性CA（如Verisign 或 Thawte）签署证书。 b. 签发证书的问题：如果使用的是商业证书，具体的签署方法请查看相关销售商的说明；如果是知己签发的证书，可以使用openssl自带的CA.sh 脚本工具。 如果不为单独的客户端签发证书，客户端证书可以不用生成，客户端与服务器端使用相同的证书。 (1) conf/ssl.conf 配置文件中的主要参数配置如下：1234567891011121314151617181920212223Listen 443 SSLPassPhraseDialog buildin #SSLPassPhraseDialog exec:/path/to/program SSLSessionCache dbm:/usr/local/apache2/logs/ssl_scache SSLSessionCacheTimeout 300 SSLMutex file:/usr/local/apache2/logs/ssl_mutex &lt;VirtualHost _default_:443&gt; # General setup for the virtual host DocumentRoot &quot;/usr/local/apache2/htdocs&quot; ServerName www.example.com:443 ServerAdmin you@example.com ErrorLog /usr/local/apache2/logs/error_log TransferLog /usr/local/apache2/logs/access_log SSLEngine on SSLCipherSuite ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP:+eNULL SSLCertificateFile /usr/local/apache2/conf/ssl.crt/server.crt SSLCertificateKeyFile /usr/local/apache2/conf/ssl.key/server.key CustomLog /usr/local/apache2/logs/ssl_request_log &quot;%t %h %&#123;SSL_PROTOCOL&#125;x %&#123;SSL_CIPHER&#125;x &quot;%r&quot; %b&quot; &lt;/VirtualHost&gt; (2) 创建和使用自签署的证书：a. Create a RSA private key for your Apache server 1/usr/local/openssl/bin/openssl genrsa -des3 -out /usr/local/apache2/conf/ssl.key/server.key 1024 b. Create a Certificate Signing Request (CSR) 1/usr/local/openssl/bin/openssl req -new -key /usr/local/apache2/conf/ssl.key/server.key -out /usr/local/apache2/conf/ssl.key/server.csr c. Create a self-signed CA Certificate (X509 structure) with the RSA key of the CA 1234/usr/local/openssl/bin/openssl req -x509 -days 365 -key /usr/local/apache2/conf/ssl.key/server.key -in /usr/local/apache2/conf/ssl.key/server.csr -out /usr/local/apache2/conf/ssl.crt/server.crt /usr/local/openssl/bin/openssl genrsa 1024 -out server.key /usr/local/openssl/bin/openssl req -new -key server.key -out server.csr /usr/local/openssl/bin/openssl req -x509 -days 365 -key server.key -in server.csr -out server.crt (3) 创建自己的CA（认证证书），并使用该CA来签署服务器的证书。12345678910mkdir /CA cd /CA cp openssl-0.9.7g/apps/CA.sh /CA ./CA.sh -newca openssl genrsa -des3 -out server.key 1024 openssl req -new -key server.key -out server.csr cp server.csr newreq.pem ./CA.sh -sign cp newcert.pem /usr/local/apache2/conf/ssl.crt/server.crt cp server.key /usr/local/apache2/conf/ssl.key/ 参考文章： 深入理解Apache虚拟主机 Apache配置文件httpd.conf详解 Apache文档","categories":[{"name":"服务器","slug":"服务器","permalink":"http://lwenxu.coding.me/categories/服务器/"},{"name":"Linux","slug":"服务器/Linux","permalink":"http://lwenxu.coding.me/categories/服务器/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://lwenxu.coding.me/tags/Linux/"}]},{"title":"优秀文章集锦","slug":"Article/优秀文章集锦","date":"2018-12-18T05:01:28.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/12/18/Article/优秀文章集锦/","link":"","permalink":"http://lwenxu.coding.me/2018/12/18/Article/优秀文章集锦/","excerpt":"","text":"1. 安全应用程序如何正确对用户密码进行加密 Java 8 中的 Streams API 详解","categories":[{"name":"文章","slug":"文章","permalink":"http://lwenxu.coding.me/categories/文章/"}],"tags":[{"name":"文章","slug":"文章","permalink":"http://lwenxu.coding.me/tags/文章/"}]},{"title":"SpringData笔记","slug":"SpringBoot/SpringData笔记","date":"2018-12-17T13:01:28.000Z","updated":"2019-01-30T22:10:50.000Z","comments":true,"path":"2018/12/17/SpringBoot/SpringData笔记/","link":"","permalink":"http://lwenxu.coding.me/2018/12/17/SpringBoot/SpringData笔记/","excerpt":"SpringData 笔记1. 配置项目1.pom.xml","text":"SpringData 笔记1. 配置项目1.pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;artifactId&gt;SpringData&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;!--MySQL Driver--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.3.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring data jpa--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.8.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;4.3.6.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.bean.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:jpa=\"http://www.springframework.org/schema/data/jpa\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa-1.3.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd\"&gt; &lt;!--1 配置数据源--&gt; &lt;bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/spring_data\"/&gt; &lt;/bean&gt; &lt;!--2 配置EntityManagerFactory--&gt; &lt;bean id=\"entityManagerFactory\" class=\"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"jpaVendorAdapter\"&gt; &lt;bean class=\"org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter\"/&gt; &lt;/property&gt; &lt;property name=\"packagesToScan\" value=\"com.lwen\"/&gt; &lt;property name=\"jpaProperties\"&gt; &lt;props&gt; &lt;prop key=\"hibernate.ejb.naming_strategy\"&gt;org.hibernate.cfg.ImprovedNamingStrategy&lt;/prop&gt; &lt;prop key=\"hibernate.dialect\"&gt;org.hibernate.dialect.MySQL5InnoDBDialect&lt;/prop&gt; &lt;prop key=\"hibernate.show_sql\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.format_sql\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.hbm2ddl.auto\"&gt;update&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--3 配置事务管理器--&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.orm.jpa.JpaTransactionManager\"&gt; &lt;property name=\"entityManagerFactory\" ref=\"entityManagerFactory\"/&gt; &lt;/bean&gt; &lt;!--4 配置支持注解的事务--&gt; &lt;tx:annotation-driven/&gt; &lt;!--5 配置spring data--&gt; &lt;jpa:repositories base-package=\"com.lwen\" entity-manager-factory-ref=\"entityManagerFactory\"/&gt; &lt;context:component-scan base-package=\"com.lwen\"/&gt;&lt;/beans&gt; 3.实体类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.lwen.entry;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;/** * Student实体类 */@Entitypublic class Student &#123; @Id@GeneratedValue private int id; private String name; private int age; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return \"Student&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", age=\" + age + '&#125;'; &#125;&#125; 这里注意的一点就是我们在使用注解的时候一定要注意导入的包，我们都是导入的javax中的类。 2.Repository1. 使用这个东西是SpringData的核心，但是我们实际去看的时候会发现他是一个空接口，也就是这个一个标记接口。我们自己的接口必须继承这个接口才会具备查询的功能，所以说我们的自定的查询器必须要继承这个接口。这个接口是泛型接口也就是我们需要输入两个参数，第一个就是我们查询器的类型，针对于那个表进行查询，另外一个就是表的Id的类型，这个类型必须是序列化接口的子类型，所以说不能使用基本类型，我们只能使用包装类型。 123public interface EmployeeRepository extends Repository&lt;Employee,Integer&gt; &#123; Employee findByName(String name);&#125; 但是我们还有另外一种方式，就是使用注解的方式不用继承这个接口。 123@RepositoryDefinition(domainClass = Student.class,idClass = Integer.class)public interface StudentRepository &#123;&#125; 2. 常用的子接口 CrudRepository：继承Repository，实现了CRUD相关的方法 PagingAndSortingRepository：继承CrudRepository，实现了分页排序相关的方法 JpaRepository：继承PagingAndSortingRepository，实现JPA规范相关的方法 这些接口的功能都是非常强大并且实用的我们在使用的时候就可以直接继承这些接口。 3.查询规则1.约定方法签名查询 2.手动查询 @Query1.复杂查询12@Query(\"select o from Employee o where id = (select max(id) from Employee)\")Employee getMaxIdEmployee(); 2.占位符查询12345@Query(\"select o from Employee o where name=?1 and age=?2\")Employee getByNameAndAge(String name,Integer age);@Query(\"select o from Employee o where name like %?1%\")Employee getByLikeName(String name); 3.命名参数12@Query(\"select o from Employee o where name=:name and age=:age\")Employee getByNameAndAge1(@Param(\"name\") String name,@Param(\"age\") Integer age); 4.原生态查询12@Query(nativeQuery = true,value = \"select * from spring_data.employee where name = ?1\")void getNative(String name)； 3. 更新删除操作在SpringData中使用插删改操作的时候我们必须定义一个Service层，然后我们在Service层调用Dao的Repository来更新数据库，接着我们需要将那个Repository的方法设置为 @Modifying ，最后最重要的就是我们在Service层的那个方法中写 @Transactional 注解。才能更新成功，所以所有的事务只能出现在 Service 层。但是注意因为我们的Service没有继承任何的Spring相关的东西我们要把它放到容器的时候需要使用@Service注解，否则是不行的。 123@Modifying@Query(\"update Employee o set o.name=:name where o.id=:id\")void update(@Param(\"id\") Integer id,@Param(\"name\") String name); 12345678910@Servicepublic class EmployeeService &#123; @Autowired EmployeeRepository repository; @Transactional //这个是javax里面的 public void update()&#123; repository.update(1, \"lwenxu\"); &#125;&#125; 小提示，很多时候我们发现有些东西在Spring中有在javax中也有，我们优先导入Javax中的，如果出现了什么方法无法调用估计就是包导错了。 3. 常用的Repository这三个高级的Repository实际上是从上到下依次继承的。 1. CrudRepository我们的Repository必须要继承这个接口，然后我们就有crud的一些操作了。接着我们需要创建service层，然后再service中使用事务，并且注入我们的Repository，这里我们用了一张新的表我们在bean上指定我们的表名就是使用@Table(name = “employee_test”) 注解。最后进行save操作。 1234@Transactionalpublic void saveAll(List&lt;Employee&gt; employees)&#123; employeeCrudRepository.save(employees);&#125; 123456EmployeeCrudRepository employeeCrudRepository = ctx.getBean(EmployeeCrudRepository.class);ArrayList&lt;Employee&gt; employees = new ArrayList&lt;Employee&gt;();for (int i = 0; i &lt; 100; i++) &#123; employees.add(new Employee(i, \"lwen\" + i, i));&#125;employeeCrudRepository.save(employees); 2.PagingAndSortingRespository他是分页和排序功能。 12345678910111213EmployeePageAndSortRepository pageAndSort = ctx.getBean(EmployeePageAndSortRepository.class);//创建一个排序器，是按照id的降续排列的Sort sort = new Sort(new Sort.Order(Sort.Direction.DESC, \"id\"));//第一个参数是当前的页码他是从0开始的//第二个参数就是每一页的大小//第三个参数是可选参数，传入一个sort，就是按照哪种方式分页 由于这里用的是降续所以出来的结果应该是 0 在最后一页 99在第一页Pageable pageable = new PageRequest(0, 9, sort);Page&lt;Employee&gt; page = pageAndSort.findAll(pageable);//获取当前页的内容System.out.println(page.getContent());//获取所有的页数System.out.println(page.getTotalPages()); 3.JpaRepository findAll save(entries) deleteInBatch findAll(sort) flush 4. JpaSpecificationExecutor这里吧这个接口单独拿出来说主要是因为这个接口实际上不是继承自 Repository 这个接口，他的作用从表面上貌似也是看不出来，实际上我们前面看到我们可以进行简单的分页，但是那些分页并没有一个让我们传入查询条件的地方，我们这个接口就是实现了这个功能也就是有条件的分页查询。\u0013 jpa接口需要继承 JpaSpecificationExecutor 然后这里就包含了五个方法，分别是 findAll(三个重载) 和 findOne 以及 count 。 然后在使用的时候只调用对应的方法即可，Page findAll(@Nullable Specification var1, Pageable var2); 这个算是里面最复杂的方法了主要是需要传递一个 Specification 对象，这个一般我们直接传递一个匿名的对象即可，实现后的代码如下： 12345new Specification&lt;User&gt;() &#123; public Predicate toPredicate(Root&lt;User&gt; root, CriteriaQuery&lt;?&gt; criteriaQuery, CriteriaBuilder criteriaBuilder) &#123; return criteriaBuilder.gt(root.&lt;Number&gt;get(\"id\"),4); &#125;&#125; 可以看到这个函数式接口里面的第一个参数是 root 这个相当于一个导航器，也就是用它可以获取到我们实体类中的属性，也就是我们获取到表的字段，CriteriaQuery 则是可以进行语句的拼装，里面有 where ，groupby 以及having 等方法，进行sql组合的。二最后一个参数就是 CriteriaBuilder 用来创建 Predicate 对象的，也就是生成查询条件对象。 上面的程序生成的最后的条件就是获取id大于4 的所有信息，然后分页展示。 5. 表的映射关系1.一对一一对一关系这里定义了一个Person对象以及一个IDCard对象 Person类： 12345678910111213141516171819202122232425262728293031323334353637@Entity@Table(name=\"t_person\")public class Person&#123; private int id; private String name; private IDCard card; @OneToOne(mappedBy=\"person\") ---&gt; 指定了OneToOne的关联关系，mappedBy同样指定由对方来进行维护关联关系 public IDCard getCard() &#123; return card; &#125; public void setCard(IDCard card) &#123; this.card = card; &#125; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; IDCard类： 12345678910111213141516171819202122232425262728293031323334353637@Entity@Table(name=\"t_id_card\")public class IDCard&#123; private int id; private String no; private Person person; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getNo() &#123; return no; &#125; public void setNo(String no) &#123; this.no = no; &#125; @OneToOne ---&gt; OnetoOne指定了一对一的关联关系，一对一中随便指定一方来维护映射关系，这里选择IDCard来进行维护 @JoinColumn(name=\"pid\") ---&gt; 指定外键的名字 pid public Person getPerson() &#123; return person; &#125; public void setPerson(Person person) &#123; this.person = person; &#125;&#125; 注意:在判断到底是谁维护关联关系时，可以通过查看外键，哪个实体类定义了外键，哪个类就负责维护关联关系。 2.多对一这里我们定义了两个实体类，一个是ClassRoom，一个是Student，这两者是一对多的关联关系。 ClassRoom类： 1234567891011121314151617181920212223242526272829@Entity@Table(name=\"t_classroom\")public class ClassRoom&#123; private Set&lt;Student&gt; students; public ClassRoom() &#123; students = new HashSet&lt;Student&gt;(); &#125; public void addStudent(Student student) &#123; students.add(student); &#125; @OneToMany(mappedBy=\"room\") ---&gt; OneToMany指定了一对多的关系，mappedBy=\"room\"指定了由多的那一方来维护关联关系，mappedBy指的是多的一方对1的这一方的依赖的属性，(注意：如果没有指定由谁来维护关联关系，则系统会给我们创建一张中间表) @LazyCollection(LazyCollectionOption.EXTRA) ---&gt; LazyCollection属性设置成EXTRA指定了当如果查询数据的个数时候，只会发出一条 count(*)的语句，提高性能 public Set&lt;Student&gt; getStudents() &#123; return students; &#125; public void setStudents(Set&lt;Student&gt; students) &#123; this.students = students; &#125; &#125; Student类： 1234567891011121314151617@Entity@Table(name=\"t_student\")public class Student&#123; private ClassRoom room; @ManyToOne(fetch=FetchType.LAZY) ---&gt; ManyToOne指定了多对一的关系，fetch=FetchType.LAZY属性表示在多的那一方通过延迟加载的方式加载对象(默认不是延迟加载) @JoinColumn(name=\"rid\") ---&gt; 通过 JoinColumn 的name属性指定了外键的名称 rid (注意：如果我们不通过JoinColum来指定外键的名称，系统会给我们声明一个名称) public ClassRoom getRoom() &#123; return room; &#125; public void setRoom(ClassRoom room) &#123; this.room = room; &#125;&#125; 3.多对多多对多这里通常有两种处理方式，一种是通过建立一张中间表，然后由任一一个多的一方来维护关联关系，另一种就是将多对多拆分成两个一对多的关联关系 1. 不使用中间表的实体类采用中间表的时候由任一一个多的一方来维护关联关系 Teacher类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Entity@Table(name=\"t_teacher\")public class Teacher&#123; private int id; private String name; private Set&lt;Course&gt; courses; public Teacher() &#123; courses = new HashSet&lt;Course&gt;(); &#125; public void addCourse(Course course) &#123; courses.add(course); &#125; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @ManyToMany(mappedBy=\"teachers\") ---&gt; 表示由Course那一方来进行维护 public Set&lt;Course&gt; getCourses() &#123; return courses; &#125; public void setCourses(Set&lt;Course&gt; courses) &#123; this.courses = courses; &#125; &#125; Course类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Entity@Table(name=\"t_course\")public class Course&#123; private int id; private String name; private Set&lt;Teacher&gt; teachers; public Course() &#123; teachers = new HashSet&lt;Teacher&gt;(); &#125; public void addTeacher(Teacher teacher) &#123; teachers.add(teacher); &#125; @ManyToMany ---&gt; ManyToMany指定多对多的关联关系 @JoinTable(name=\"t_teacher_course\", joinColumns=&#123; @JoinColumn(name=\"cid\")&#125;, inverseJoinColumns=&#123; @JoinColumn(name = \"tid\") &#125;) ---&gt; 因为多对多之间会通过一张中间表来维护两表直接的关系，所以通过 JoinTable 这个注解来声明，name就是指定了中间表的名字，JoinColumns是一个 @JoinColumn类型的数组，表示的是我这方在对方中的外键名称，我方是Course，所以在对方外键的名称就是 rid，inverseJoinColumns也是一个 @JoinColumn类型的数组，表示的是对方在我这放中的外键名称，对方是Teacher，所以在我方外键的名称就是 tid public Set&lt;Teacher&gt; getTeachers() &#123; return teachers; &#125; public void setTeachers(Set&lt;Teacher&gt; teachers) &#123; this.teachers = teachers; &#125; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 2. 采用中间表实体类把之前的ManyToMany拆分成两个One-to-Many的映射 Admin类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Entity@Table(name=\"t_admin\")public class Admin&#123; private int id; private String name; private Set&lt;AdminRole&gt; ars; public Admin() &#123; ars = new HashSet&lt;AdminRole&gt;(); &#125; public void add(AdminRole ar) &#123; ars.add(ar); &#125; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @OneToMany(mappedBy=\"admin\") ---&gt; OneToMany关联到了AdminRole这个类，由AdminRole这个类来维护多对一的关系，mappedBy=\"admin\" @LazyCollection(LazyCollectionOption.EXTRA) public Set&lt;AdminRole&gt; getArs() &#123; return ars; &#125; public void setArs(Set&lt;AdminRole&gt; ars) &#123; this.ars = ars; &#125;&#125; Role类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Entity@Table(name=\"t_role\")public class Role&#123; private int id; private String name; private Set&lt;AdminRole&gt; ars; public Role() &#123; ars = new HashSet&lt;AdminRole&gt;(); &#125; public void add(AdminRole ar) &#123; ars.add(ar); &#125; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @OneToMany(mappedBy=\"role\") ---&gt; OneToMany指定了由AdminRole这个类来维护多对一的关联关系，mappedBy=\"role\" @LazyCollection(LazyCollectionOption.EXTRA) public Set&lt;AdminRole&gt; getArs() &#123; return ars; &#125; public void setArs(Set&lt;AdminRole&gt; ars) &#123; this.ars = ars; &#125;&#125; AdminRole类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Entity@Table(name=\"t_admin_role\")public class AdminRole&#123; private int id; private String name; private Admin admin; private Role role; @Id @GeneratedValue public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @ManyToOne ---&gt; ManyToOne关联到Admin @JoinColumn(name=\"aid\") public Admin getAdmin() &#123; return admin; &#125; public void setAdmin(Admin admin) &#123; this.admin = admin; &#125; @ManyToOne ---&gt; @JoinColumn(name=\"rid\") public Role getRole() &#123; return role; &#125; public void setRole(Role role) &#123; this.role = role; &#125;&#125; 小技巧:通过hibernate来进行插入操作的时候，不管是一对多、一对一还是多对多，都只需要记住一点，在哪个实体类声明了外键，就由哪个类来维护关系，在保存数据时，总是先保存的是没有维护关联关系的那一方的数据，后保存维护了关联关系的那一方的数据 4.中间表两个实体tb_user,tb_role现在我们再tb_user或者tb_role中任意一个里面进行维护关系，多对对的情况下我们需要创建一个中间表来完成这个关系的映射，我们再tb_user中添加注解@ManyToMany然后再添加一个注解@JoinTable因为我们是要创建中间表所以要使用这个注解。JoinTable注解中我们添加如下例子中的内容，joinColumns当前表中的字段在中间表中的字段名称，inverseJoinColumns关联的外键表在中间表中的字段名称 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273@Entity@Table(name = \"tb_user\")@SequenceGenerator(name = \"tb_user_sq\",sequenceName = \"tb_user_sqe\")public class TbUser extends BaseEntity&#123;/** * 用户名 */private String userName;/** * 登录名 */private String loginName;/** * 登陆密码 */private String passWord;/** * 手机号 */private String telPhone;/** * 一个用户可以有多个角色 */private List&lt;TbRole&gt; tbRoleList=new ArrayList&lt;&gt;();public String getUserName() &#123; return userName;&#125;public void setUserName(String userName) &#123; this.userName = userName;&#125;public String getLoginName() &#123; return loginName;&#125;public void setLoginName(String loginName) &#123; this.loginName = loginName;&#125;public String getPassWord() &#123; return passWord;&#125;public void setPassWord(String passWord) &#123; this.passWord = passWord;&#125;public String getTelPhone() &#123; return telPhone;&#125;public void setTelPhone(String telPhone) &#123; this.telPhone = telPhone;&#125;@Id@Override@GeneratedValue(generator = \"tb_user_sq\",strategy = GenerationType.SEQUENCE)public Long getId() &#123; return this.id;&#125;@ManyToMany(cascade = CascadeType.REMOVE,fetch = FetchType.LAZY)@JoinTable(name = \"tb_user_role\",joinColumns = @JoinColumn(name=\"tb_user_id\",referencedColumnName = \"id\"),inverseJoinColumns = @JoinColumn(name = \"tb_role_id\",referencedColumnName = \"id\"))public List&lt;TbRole&gt; getTbRoleList() &#123; return tbRoleList;&#125;public void setTbRoleList(List&lt;TbRole&gt; tbRoleList) &#123; this.tbRoleList = tbRoleList;&#125;&#125; 因为在tb_user中我们维护了两个表的关系，所以如果我们在tb_role中如果不想创建关联字段的话就不用添加tbUser的关系字段 1234567891011121314151617181920@Entity@Table(name = \"tb_role\")@SequenceGenerator(name = \"tb_role_sq\",sequenceName = \"tb_role_sqe\")public class TbRole extends BaseEntity&#123;@Override@Id@GeneratedValue(generator = \"tb_role_sq\",strategy = GenerationType.SEQUENCE)public Long getId() &#123; return this.id;&#125;private String roleName;@ManyToMany(mappedBy = \"tbRoleList\")public String getRoleName() &#123; return roleName;&#125;public void setRoleName(String roleName) &#123; this.roleName = roleName;&#125; 如果想要在tb_role中进行维护关联字段的话如下，我们在字段中添加注解 @ManyToMany然后使用直接属性mappedBy值是当前表在关联表中的字段名称 123456789101112131415161718192021222324252627282930@Entity@Table(name = \"tb_role\")@SequenceGenerator(name = \"tb_role_sq\",sequenceName = \"tb_role_sqe\")public class TbRole extends BaseEntity&#123;@Override@Id@GeneratedValue(generator = \"tb_role_sq\",strategy = GenerationType.SEQUENCE)public Long getId() &#123; return this.id;&#125;private String roleName;private List&lt;TbUser&gt; tbUserList=new ArrayList&lt;&gt;();public String getRoleName() &#123; return roleName;&#125;public void setRoleName(String roleName) &#123; this.roleName = roleName;&#125;@ManyToMany(mappedBy = \"tbRoleList\")public List&lt;TbUser&gt; getTbUserList() &#123; return tbUserList;&#125;public void setTbUserList(List&lt;TbUser&gt; tbUserList) &#123; this.tbUserList = tbUserList;&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"GOF23 常用设计模式","slug":"Java SE/Java设计模式","date":"2018-08-06T00:25:29.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/08/06/Java SE/Java设计模式/","link":"","permalink":"http://lwenxu.coding.me/2018/08/06/Java SE/Java设计模式/","excerpt":"","text":"GOF23 常用设计模式一、单例设计模式1.饿汉式12345678public class GOF23 &#123; // 饿汉式 private static final List list = new ArrayList(); public static List getInstance() &#123; return list; &#125;&#125; 2.懒汉式1234567891011121314151617 // 懒汉式 // 使用双检锁，并且由于 jvm 指令重排序我们需要使用 volatile 关键字抑制指令重排序public class GOF&#123; private static volatile List list1; public static List getInstanceLazy() &#123; synchronized (Object.class) &#123; if (list1 == null) &#123; synchronized (Object.class)&#123; list1 = new ArrayList(); return list; &#125; &#125;else &#123; return list; &#125; &#125; &#125;&#125; 3.静态内部类12345678910public class GOF&#123; // 静态内部类 public static class SingletonClass&#123; private static final List list2 = new ArrayList(); &#125; // 首先要去加载这个静态内部类，然后这个时候会调用 cinit 方法这个是天然的线程安全的，然后返回这个对象即可 可以延时加载 public List getStaticInstance()&#123; return SingletonClass.list2; &#125;&#125; 4.枚举123456public class GOF23 &#123; // 采用枚举的方式 不能延时加载 由 jvm 底层完成的 public enum SingleInstanceEnum&#123; INSTANCE_ENUM &#125;&#125; 二、工厂设计模式工厂设计模式的好处就是把对象的创建和使用分开。在软公众需要遵循的三个原则：开闭原则（对修改关闭，对拓展开放）、依赖翻转（面向接口依赖而不是类的强依赖）、迪米特法则（和朋友通讯而不是陌生人）。 1.简单工厂一般也称之为静态工厂，因为他的方法是一个静态的方法，并且必须要有一个父接口去容纳这些被创建的对象。 123456789101112131415161718192021222324252627282930313233343536public interface Car &#123; public void run();&#125;public class Audi implements Car &#123; @Override public void run() &#123; System.out.println(&quot;audi run&quot;); &#125;&#125;public class Daben implements Car &#123; @Override public void run() &#123; System.out.println(&quot;daben run&quot;); &#125;&#125;public class CarFactory &#123; public static Car createCar(String type) &#123; if (type.equals(&quot;daben&quot;)) &#123; return new Daben(); &#125; else if (type.equals(&quot;audi&quot;)) &#123; return new Audi(); &#125;else &#123; return null; &#125; &#125;&#125;public class CarClient &#123; public static void main(String[] args) &#123; Daben daben = (Daben) CarFactory.createCar(&quot;daben&quot;); daben.run(); &#125;&#125; 2.工厂方法这个比上面好一点的就是我们不用直接修改原来的代码而是可以面向拓展而不是修改就是开闭原则是满足的。其实我们在项目中主要使用的是简单工厂而不是这个，因为这个的类文件剧增。 1234567891011121314151617public interface CarFactory &#123; public Car createFactory();&#125;public class BenChiFactory implements CarFactory &#123; @Override public Car createFactory() &#123; return new Daben(); &#125;&#125;public class AudiFactory implements CarFactory &#123; @Override public Car createFactory() &#123; return new Audi(); &#125;&#125; 3.抽象工厂抽象工厂其实和上面的两个方式区别很大，主要是因为上面两个的维度是创建产品而这个地方的维度是创建一个产品组。也就是比如我们有一个车的工厂，其实这个工厂是创建很多车的零部件而不是一个车，那么我们有多个车的工厂的目的就是为了创建不同层次的车零件。比如下面这个例子，就是他的维度是横向的一个维度。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 座椅类型public interface Seat &#123; public void desc();&#125;class LuxurySeat implements Seat &#123; @Override public void desc() &#123; System.out.println(&quot;high quality seat&quot;); &#125;&#125;class LowSeat implements Seat &#123; @Override public void desc() &#123; System.out.println(&quot;low seat&quot;); &#125;&#125;// 引擎类型public interface Engine &#123; public void run();&#125;class LuxuryEngine implements Engine &#123; @Override public void run() &#123; System.out.println(&quot;high speed engine&quot;); &#125;&#125;class LowEngine implements Engine &#123; @Override public void run() &#123; System.out.println(&quot;low engine&quot;); &#125;&#125;// 车的抽象工厂public interface AbstractCarFactory &#123; public Seat createSeat(); public Engine creaateEngine();&#125;// 两个工厂的实现，分别是高级车工厂，低级车工厂public class LuxuryCarFactory implements AbstractCarFactory &#123; @Override public Seat createSeat() &#123; return new LuxurySeat(); &#125; @Override public Engine creaateEngine() &#123; return new LuxuryEngine(); &#125;&#125;public class LowCarFactory implements AbstractCarFactory&#123; @Override public Seat createSeat() &#123; return new LowSeat(); &#125; @Override public Engine creaateEngine() &#123; return new LowEngine(); &#125;&#125; 三、建造者模式建造者模式分为两部分，第一个部分其实就是工厂模式创建对象，然后另外一部分就是组装创建整个大对象。 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 创建工厂public interface BuilderFactory &#123; Engine createEngine(); Seat createSeat();&#125;public class AirShipBuilderFactory implements BuilderFactory &#123; @Override public Engine createEngine() &#123; return new Engine() &#123; @Override public void run() &#123; &#125; &#125;; &#125; @Override public Seat createSeat() &#123; return new Seat() &#123; @Override public void desc() &#123; &#125; &#125;; &#125;&#125;// 组装工厂public class AirDirectFactory &#123; private BuilderFactory builderFactory; public AirShip buildAirShip() &#123; Engine engine = builderFactory.createEngine(); Seat seat = builderFactory.createSeat(); return new AirShip(engine, seat); &#125; public AirDirectFactory(BuilderFactory builderFactory) &#123; this.builderFactory = builderFactory; &#125;&#125; 四、原型模式可以称之为克隆或者拷贝，然后在拷贝的对象上修改就可以产生新对象，其实js 的原型就是这么干的。 这里需要注意一下这里的一个深拷贝的问题，如果没有作深拷贝而是直接的做了一个 super 的调用可能导致状态关联问题。 12345678910111213141516171819202122232425262728293031@NoArgsConstructor@AllArgsConstructor@Builder(toBuilder = true)@Data@Accessors(chain = true,fluent = true)public class Sheep implements Cloneable&#123; private String name; private Date birthday; /** * 注意在克隆的时候需要进行深拷贝负责就会出现错误结果 * @return * @throws CloneNotSupportedException */ @Override protected Object clone() throws CloneNotSupportedException &#123; Sheep clone = (Sheep) super.clone(); clone.birthday = (Date) this.birthday.clone(); return clone; &#125;&#125;public class PrototypeClient &#123; public static void main(String[] args) throws CloneNotSupportedException &#123; Sheep sheep1 = new Sheep(&quot;A&quot;, new Date()); Sheep sheep2 = (Sheep) sheep1.clone(); sheep2.birthday(new Date()).name(&quot;sss&quot;); System.out.println(sheep2); &#125;&#125; 另外我们除了使用上面的克隆方法我们还可以使用序列化的方式直接生成一个一模一样的对象出来。具体来说就是我们可以用输入输出流来生成对象 五、适配器模式将一个接口转化成另外一个接口，从而使两个原来不能一起工作的组件一起工作。 我们可以想像一下一个 usb 转 hdmi ，那么就有一个目标方和一个被适配方。也就是两个接口再有一个适配器就完成了。 123456789101112131415161718192021222324252627282930313233// 目标方的接口public interface Target &#123; void use();&#125;// 被适配方 其实最好是一个接口这里直接写成了一个类public class BeAdapter &#123; public void hello()&#123; System.out.println(&quot;say hello&quot;); &#125;&#125;// 适配器 实现了目标方，组合了被适配方@Data@AllArgsConstructorpublic class AdapterDemo implements Target &#123; // 其实这里可以进一步抽象 也就是所有的被适配对象另起一个接口即可 BeAdapter beAdapter; public void use() &#123; beAdapter.hello(); &#125;&#125;public class AdapterClient &#123; public static void test(Target target)&#123; target.use(); &#125; public static void main(String[] args) &#123; AdapterDemo adapterDemo = new AdapterDemo(new BeAdapter()); test(adapterDemo); &#125;&#125; 六、代理模式1.静态代理这种代理模式就是在代理对象上保留一个被代理对象的指针，然后有些事情直接调用被代理对象的方法完成，并且可以做一些前置或者后置的操作。 2.动态代理1.JDK 代理其实关键部分就两个：第一个就是一个处理器，所有的对代理的请求的方法都走到了处理器。另外一个就是生成代理对象过程。 处理器 12345678@AllArgsConstructorpublic class SimpleHandler implements InvocationHandler &#123; RealObject real; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;heihei&quot;); return (Object) method.invoke(real, args); &#125;&#125; 被代理对象 123456789public interface ObjectInterface &#123; public void hello();&#125;public class RealObject implements ObjectInterface &#123; public void hello()&#123; System.out.println(&quot;hello&quot;); &#125;&#125; 生成代理对象的过程 12345678public class JdkClient &#123; public static void main(String[] args) &#123; RealObject realObject = new RealObject(); SimpleHandler simpleHandler = new SimpleHandler(realObject); ObjectInterface proxyInstance = (ObjectInterface) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]&#123;ObjectInterface.class&#125;, simpleHandler); proxyInstance.hello(); &#125;&#125; 七、桥接模式桥接模式就是为了处理两个维度的事情，比如说我们定义一个电脑类，那么我们如果需要售卖笔记本、平板、台式机而这些东西又有不同的品牌那么我们就需要建立很多的类在电脑这个类下面。但是我们采用桥接的话我们抽出一个接口这个接口代表了品牌，然后有一个抽象类（电脑类型）包含了品牌的引用，我们只需要在不同的电脑类型下面建立各个类型，在创建一个品牌类型的电脑的时候直接 new 出来就行了。 12345678910111213141516171819202122232425262728293031323334353637// 品牌public interface Brand &#123;&#125;class Dell implements Brand &#123;&#125;class Levon implements Brand &#123;&#125;// 电脑的类型@AllArgsConstructorpublic abstract class AbstractComputer &#123; private Brand brand; public void sell()&#123; System.out.println(&quot;sell...&quot;); &#125;&#125;class DesktopComp extends AbstractComputer &#123; public DesktopComp(Brand brand) &#123; super(brand); &#125;&#125;class PadComp extends AbstractComputer &#123; public PadComp(Brand brand) &#123; super(brand); &#125;&#125;//使用public class BridgeClient &#123; public static void main(String[] args) &#123; DesktopComp levonDesktopComp = new DesktopComp(new Levon()); &#125;&#125; 八、策略模式策略模式就是将一个方法传入到一个地方，简单点来说就是传入一个回调方法，真实是使用的时候看我们传递进去的那个方法作用。 九、模板设计模式在上层的抽象类中放一些抽象方法先调用上，子类在继承的时候实现这些类就行了。 10、观察者模式在对一些变量修改或者方法调用的时候胡触发观察者的方法调用或者状态的转变，其实就相当于埋点。","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"Lombok 常用功能","slug":"Java Web/Lombok常用功能","date":"2018-08-05T13:23:43.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2018/08/05/Java Web/Lombok常用功能/","link":"","permalink":"http://lwenxu.coding.me/2018/08/05/Java Web/Lombok常用功能/","excerpt":"","text":"Lombok 常用功能1.导入123456&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 2.@Getter/@Setter这两个注解可以在类上也可以在字段上，看需要的粒度而定。 3.@ToString生成一个 json 类型的字符串 4.@EqualsAndHashCode生成 equals 和 hashcode 5.@NoArgsConstructor生成午无参构造器 6.@RequiredArgsConstructor只对标有 @NonNull 的字段生成构造器，并且初始化的时候会检查NonNull 的字段如果为空则抛出异常。 7.@AllArgsConstructor所有字段的构造器 8.@Data1@Data`是一个集合体。包含`Getter`,`Setter`,`RequiredArgsConstructor`,`ToString`,`EqualsAndHashCode 9.@Value可以帮忙生成一个不可变对象。对于所有的字段都将生成final的。同@Data， @Value是一个集合体。包含Getter,AllArgsConstructor,ToString,EqualsAndHashCode。 10.@Builder1Room room = builder().name(&quot;name&quot;).id(&quot;id&quot;).createTime(new Date()).occupation(&quot;1&quot;).occupation(&quot;2&quot;).build(); 11.@Log一个日志属性，可以直接使用的。 12.@UtilityClass工具类 12345678910111213@UtilityClasspublic class Utility &#123; public String getName() &#123; return &quot;name&quot;; &#125;&#125;public static void main(String[] args) &#123; // Utility utility = new Utility(); 构造函数为私有的, System.out.println(Utility.getName());&#125; 13.@Cleanup用于流等可以不需要关闭使用流对象. 12345678910@CleanupOutputStream outStream = new FileOutputStream(new File(&quot;text.txt&quot;));@CleanupInputStream inStream = new FileInputStream(new File(&quot;text2.txt&quot;));byte[] b = new byte[65536];while (true) &#123; int r = inStream.read(b); if (r == -1) break; outStream.write(b, 0, r); &#125;","categories":[],"tags":[{"name":"Java工具","slug":"Java工具","permalink":"http://lwenxu.coding.me/tags/Java工具/"}]},{"title":"Java Class对象与反射机制","slug":"JVM/Java Class对象和反射","date":"2018-08-04T13:38:50.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2018/08/04/JVM/Java Class对象和反射/","link":"","permalink":"http://lwenxu.coding.me/2018/08/04/JVM/Java Class对象和反射/","excerpt":"","text":"Java Class对象与反射机制一、关于Class对象1.基本介绍其实我们在任何一个 Java 应用程序中都会存在 class 对象，这个 class 对象其实就是每一个类、类型、数组、接口 等等被加载的时候在 jvm 中创建的。也就是这些类型的一个映射，这些类型在虚拟机中的实体。正是由于存在这个对象在 Jvm 中我们可以通过一定的方式获取这个对象然后去用这个对象去对我们的各种类型做一些加载获取属性等等操作，当然主要是对类进行操作并能够执行他的方法，探知未知的类的各种信息。 2.官方文档解释这是我摘录的 Class 类的 javadoc 内容： Instances of the class Class represent classes and interfaces in a running Java application. An enum is a kind of class and an annotation is a kind of interface. Every array also belongs to a class that is reflected as a Class object that is shared by all arrays with the same element type and number of dimensions. The primitive Java types (boolean, byte, char, short, int, long, float, and double), and the keyword void are also represented as Class objects. Class has no public constructor.Instead Class objects are constructed automatically by the Java Virtual Machine as classes are loaded and by calls to the defineClass method in the class loader. 其实里面主要说了这么几件事： 1.class 对象代表类和接口这个比较好理解其实我们可以看一个例子就能明白： 1Class clazz = Long.class; 前面是 Class 类型后面就是一个具体的变量，那么为什么我们没有 new 这个对象就能获取到呢？ 其实在这里我们使用了 Long 这个类，那么这个类就会被 jvm 加载之后在 jvm 中形成了他所对应的 class 对象，我们在赋值的时候直接从 jvm 取到即可，这里我们也比较好理解这个类的对象其实在内存中只有一份，也就是单例的，这是因为没必要存在多份，他只是一个类的一个内存映射。 2.枚举是类注解是接口注解是接口是头一回听说，但是他的定义方式比较能说明问题，应该是在编译期做了转换吧。 3.同维同类型数组class 对象相同这个也就是说他们的类型和维数一致才可以，具体看一个例子： 123int[] arr1=new int[1];int[] arr2=new int[2];Assert.check(arr1.getClass()==arr2.getClass()); 4.基本类型也有 class 对象5.class 对象不用创建class 对象是没有公共的构造方法，也没有静态的 getInsteance() 所以说没办法从外部构造方法，是直接的由 jvm 在加载类的时候调用了类加载的 defineClass() 方法完成 class 对象的创建的。 3.class 对象获取对于 class 对象的获取方式有三种： 使用类型属性 1Class clazz = Long.class 调用对象的 getClass() 方法 12List list = new ArrayList();Class clazz = list.getClass(); 使用forName()静态方法 12345try &#123; Class.forName(&quot;com.apple.concurrent.Dispatch&quot;);&#125; catch (ClassNotFoundException e) &#123; e.printStackTrace();&#125; 二、关于反射先写一个简单的 javaBean 然后对这个 bean 就进行一些操作： 123456789101112131415161718192021222324package grammer;public class User &#123; private String name; private int age; public User() &#123; &#125; public User(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public void setAge(int age) &#123; this.age = age; &#125; public int getAge() &#123; return age; &#125;&#125; 然后我们主要讨论关于对于属性、方法、构造器的获取以及使用。 1.通过 class 对象创建对象12Class&lt;User&gt; userClass = User.class;User userInstance = userClass.newInstance(); 2. 获取所有的构造方法注意以下两个都是获取构造器列表，但是前面的是可以获取到私有的构造器，而后者并不可以，其他的都是同理的对于方法和字段来说 12Constructor&lt;?&gt;[] constructors = userClass.getDeclaredConstructors();Constructor&lt;?&gt;[] constructors1 = userClass.getConstructors(); 3. 获取所有的属性1Field[] fields = userClass.getDeclaredFields(); 4.获取所有的方法1Method[] methods = userClass.getDeclaredMethods(); 5.获取某个私有属性这个要注意对于私有属性，只有用 fieldName.setAccessible(true); 设置访问权限后 jvm 再运行的时候不会做权限验证 也就不会报错了 12345Field fieldName = userClass.getDeclaredField(\"name\");fieldName.setAccessible(true);System.out.println(fieldName.getName());// 设置值需要调用那个对应的对象 需要指明对象才可以fieldName.set(userInstance,\"lwen\"); 6.获取某个方法并调用这个地方需要指明我们调用的参数的具体类型，否则会由于我们的 java 重载机制而出现模糊不清的情况。当然如果是私有方法我们在调用之前必须要指定他们的访问权限，否则也会调用失败，对于构造方法也是这样的。 123Method setNameMethod = userClass.getDeclaredMethod(\"setName\", String.class);//调用方法也是需要指明对象setNameMethod.invoke(userInstance,\"lwen\"); 7.反射性能问题反射的性能一般比普通调用的性能要低很多，一般一个方法的执行时间应该是 30 倍的关系，我们希望能够加快反射的速度可以使用跳过安全检查 setAccessible(true) 来提升效率，一般相对使用反射来说的话是提升 4 倍效率。另外我们为了操作 class 我们还可以使用一些第三方的操作字节码的类库比如操作底层字节码的 ASM ，以及基于代码的 javassist 和 GCLIB 等等。 这里说一下关于 javassist 的使用，如何使用它来生成一个 class 文件。 1234567891011121314151617181920212223242526package grammer;import javassist.*;import java.io.IOException;public class JavassistDemo &#123; public static void main(String[] args) throws CannotCompileException, NotFoundException, IOException &#123; ClassPool pool = ClassPool.getDefault(); CtClass ctClass = pool.makeClass(\"out.Empl\"); // 创建属性 CtField int_age = CtField.make(\"private int age;\", ctClass); ctClass.addField(int_age); // 创建方法 CtMethod method = (CtMethod) CtMethod.make(\"public int getAge()&#123;return this.age;&#125;\", ctClass); ctClass.addMethod(method); // 创建构造器 CtConstructor constructor = new CtConstructor(new CtClass[]&#123;CtClass.intType&#125;, ctClass); constructor.setBody(\"&#123;this.age=age;&#125;\"); ctClass.addConstructor(constructor); // 生成 ctClass.writeFile(); &#125;&#125;","categories":[{"name":"-Java -虚拟机","slug":"Java-虚拟机","permalink":"http://lwenxu.coding.me/categories/Java-虚拟机/"}],"tags":[{"name":"Java 虚拟机","slug":"Java-虚拟机","permalink":"http://lwenxu.coding.me/tags/Java-虚拟机/"}]},{"title":"MyBatis笔记六：整合Spring","slug":"DataBase/MyBatis笔记六：整合Spring","date":"2018-06-06T14:01:49.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/06/06/DataBase/MyBatis笔记六：整合Spring/","link":"","permalink":"http://lwenxu.coding.me/2018/06/06/DataBase/MyBatis笔记六：整合Spring/","excerpt":"","text":"MyBatis笔记六：整合Spring","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/tags/MyBatis/"},{"name":"数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/tags/数据库/"},{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"MyBatis笔记五：缓存","slug":"DataBase/MyBatis笔记五：缓存","date":"2018-06-05T10:01:49.000Z","updated":"2020-01-09T15:27:46.627Z","comments":true,"path":"2018/06/05/DataBase/MyBatis笔记五：缓存/","link":"","permalink":"http://lwenxu.coding.me/2018/06/05/DataBase/MyBatis笔记五：缓存/","excerpt":"","text":"MyBatis笔记五：缓存Mybatis 的缓存是分为两级缓存的，一个是本地缓存，也就是默认的缓存，这一个缓存是默认开启的。这个缓存是 sqlSession 级别的缓存也就是一个数据库会话的缓存，这个缓存其实说白了就是 sqlSession 级别的一个 Map 。 1.一级缓存一级缓存底层是一个 map 。虽然缓存默认开启的但是我们也会遇到缓存失效的情况： sqlSession 不同 查询条件不同，导致返回的数据都不同 在两次查询之间进行了插删改操作 手动使用了 sqlSession.clearCache 方法清除了缓存。 2.二级缓存 二级缓存是在一级缓存的基础之上的，因为我们的一级缓存是在会话关闭之后这个缓存数据就失效了，那么我们的二级缓存的做的事情就是在会话关闭的时候我们的一级缓存的数据会被转移到一级缓存中，然后新的会话就可以参照二级缓存中的数据。 二级缓存是基于 namespace 的缓存，也就是每一个mapper就是一个二级缓存的空间，他们之间是互相不干扰的。不同的 namespace 查出的数据放到自己的缓存中，也就是 map 中。 1.开启二级缓存默认的情况是开启的，我们也应该显示的配置，就是在settings标签中配置。 2.使用缓存在 mapper 的 xml 中，使用cache标签，配置当前的 namespace 的缓存策略。 1&lt;cache eviction=\"FIFO\" flushInterval=\"60000\" readOnly=\"true\" size=\"12\" type=\"\"/&gt; eviction：缓存的回收策略： LRU - 最近最少使用的：移除最长时间不被使用的对象。 FIFO -先进先出：按对象进入缓存的顺序来移除它们。 SOFT - 软引用：移除基于垃圾回收器状态和软引用规则的对象。 WEAK - 弱引用：更积极地移除基于垃圾收集器状态和弱引用规则的对象。 默认的是LRU. flushInterval：缓存刷新间隔。缓存多长时间清空一次，默认不清空，设置一个毫秒值 readonly：是否只读： true：只读； mybatis认为所有从缓存中获取数据的操作都是只读操作，不会修改数据。 mybatis为了加快获取速度，直接就会将数据在缓存中的引用交给用户。不安全，速度快 false：非只读： mybatis觉得获取的数据可能会被修改。mybatis会利用序列化&amp;反序列的技术克隆一份新的数据给你。 安全，速度慢 size：缓存存放多少元素； type=”” 指定自定义缓存的全类名，但是这个类要实现Cache接口即可； 当然如果我们什么东西都不写的话，也就是只写了一个cache标签，他么上述的属性会自动的被应用。 然后就是我们的Cache的自定义，其实Cache的自定义比较简单也就是我们直接实现它的Cache 接口然后实现一些东西就好，但是更好的就是我们其实不用自己写这些东西，在Mybatis的Github上有很多已经写好的cache适配包不用我们自己写、然后再缓存标签中表明type为我们的适配包的类就好了。 3.POJO实现序列化接口我们的每一个POJO都需要实现序列化接口，否则就会报错，因为我们如果没有开启 readonly 的话我们就必须采用序列化的方式来获取缓存下来的POJO对象。 4.注意只有当我们的 sqlSession 关闭以后我们的一级缓存内容才会放到二级缓存中去，否则一直是一级缓存在起作用的。 cacheEnabled=true: false：关闭缓存(二级缓存关闭) (一级缓存一直可用） 每个select标签都有useCache=”true”. 如果为false：不使用缓存(一级缓存依然使用，二级缓存不使用) 每个增删改标签的： flushCache=”true”: 增册改执行完成后就会清除缓存。他是清除一级二级缓存。 sqlSession. clearCache( )；只是清除当前session的一级缓存，因为我们都是用的 sqlSession 的方法，自然清除的一级缓存。 localCacheScope：本地缓存作用域：(默认的一级缓存是SESSION) ；如果当前会话缓存为 STATEMENT：可以禁用一级缓存。】、 3.缓存原理","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/tags/MyBatis/"},{"name":"数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/tags/数据库/"},{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"MyBatis笔记四：动态SQL","slug":"DataBase/MyBatis笔记四：动态SQL","date":"2018-06-02T14:01:49.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/06/02/DataBase/MyBatis笔记四：动态SQL/","link":"","permalink":"http://lwenxu.coding.me/2018/06/02/DataBase/MyBatis笔记四：动态SQL/","excerpt":"","text":"MyBatis笔记四：动态SQL什么是动态SQL？ 简单来说就是类似于OGNL 表达式的这种 SQL 标签的嵌套然后帮助我们生成SQL语句而避免另外我们的拼字符串的操作。 1.if标签if 标签中的 test 属性就是用来测试条件的，然后里面的条件之间可以采用 and or来连接，当然我们也可以使用 &amp;&amp; 这种，但是注意我们只能使用它们的实体符号而不能直接使用 &amp;&amp; 这种。 12345678910111213141516@Testpublic void DynamicSelectIf() throws IOException &#123; SqlSessionFactory sessionFactory = GettingStart.getSessionFactory(\"mybatis.xml\"); SqlSession sqlSession = null; try &#123; sqlSession = sessionFactory.openSession(true); EmployeeDynamicMapper mapper = sqlSession.getMapper(EmployeeDynamicMapper.class); Employee emp = mapper.getEmp(new Employee(13, \"lwen\", 12)); System.out.println(emp); &#125;finally &#123; if (sqlSession != null) &#123; sqlSession.close(); &#125; &#125;&#125; 12345678910&lt;select id=\"getEmp\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where &lt;if test=\"id!=null\"&gt; id=#&#123;id&#125; &lt;/if&gt; &lt;if test=\"name!=null\"&gt; and name=#&#123;name&#125; &lt;/if&gt;&lt;/select&gt; 但是注意的一点就是假如我们没有传入我们的 id 字段的话，我们的sql就会报错，因为拼接会出问题啊。那么出来的 sql 就会是： 1select * from employee where and name=#&#123;name&#125; 显然会报错！ 解决方案1： 12345678910111213&lt;select id=\"getEmp\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where &lt;if test=\"1=1\"&gt; 1=1 &lt;/if&gt; &lt;if test=\"id!=null\"&gt; and id=#&#123;id&#125; &lt;/if&gt; &lt;if test=\"name!=null\"&gt; and name=#&#123;name&#125; &lt;/if&gt;&lt;/select&gt; 解决方案2： 2.where标签123456789101112&lt;select id=\"getEmpWhere\" resultType=\"lwen.entries.Employee\"&gt; select * from employee &lt;where&gt; &lt;if test=\"id!=null\"&gt; id=#&#123;id&#125; &lt;/if&gt; &lt;if test=\"name!=null\"&gt; and name=#&#123;name&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 可以看到我们删除了 where 关键字而是加上了 where标签这样的话虽然我们不传 id 我们的 sql 也是拼装正常的，不会报错。注意的一点就是我们的 where 标签只能解决当我们的 条件前面多出来的 and 或者 or 而不能解决后面的 and 比如说我们的 sql写成了： 123456789101112&lt;select id=\"getEmpWhere\" resultType=\"lwen.entries.Employee\"&gt; select * from employee &lt;where&gt; &lt;if test=\"id!=null\"&gt; id=#&#123;id&#125; and &lt;/if&gt; &lt;if test=\"name!=null\"&gt; name=#&#123;name&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 如果不传 name 的话就会报错。 可以看到我们的sql 语句是这样的： 1EmployeeDynamicMapper.getEmpWhere1 - ==&gt; Preparing: select * from employee where id=? and ; 3.trim标签trim标签就是可以给一个语句加上一个前缀一个后缀，删除某个前缀删除某个后缀。 prefix：加前缀 prefixOverrides：删前缀 suffix：加后缀 suffixOverrides：删后缀 123456789101112&lt;select id=\"getEmpWhere1\" resultType=\"lwen.entries.Employee\"&gt; select * from employee &lt;trim prefix=\"where\" suffixOverrides=\"and\"&gt; &lt;if test=\"id!=null\"&gt; id=#&#123;id&#125; and &lt;/if&gt; &lt;if test=\"name!=null\"&gt; name=#&#123;name&#125; &lt;/if&gt; &lt;/trim&gt;;&lt;/select&gt; 解决上述问题呢。 4.choose标签这个标签的功能就类似于带有 break 的 switch-case 语句，就是只会进入一个分支。 1234567891011121314151617&lt;select id=\"getEmpWhere2\" resultType=\"lwen.entries.Employee\"&gt; select * from employee &lt;where&gt; &lt;choose&gt; &lt;when test=\"id!=null\"&gt; id=#&#123;id&#125; &lt;/when&gt; &lt;when test=\"name!=null\"&gt; name like #&#123;name&#125; &lt;/when&gt; &lt;otherwise&gt; age=1 &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt;&lt;/select&gt; 可以看到这里的功能说白了就是根据我们传入了哪个属性就用哪个属性查询，如果啥都没有的话就使用我们默认的就好。 5.set标签我们上面都是在讨论关于选择的 条件判断问题，但是如果我们希望是更新也是条件进行的呢？我们这里就有与 where 对应的标签来保证我们的逗号不会多出来。 1234567891011&lt;update id=\"updateEmp\"&gt; update employee &lt;set&gt; &lt;if test=\"name!=null\"&gt; name=#&#123;name&#125;, &lt;/if&gt; &lt;if test=\"age!=null\"&gt; age=#&#123;age&#125; &lt;/if&gt; &lt;/set&gt;&lt;/update&gt; 同样的既然我们上面可以使用 trim 做一个通用的查询，那我们肯定可以使用 trim 做一个更通用的更新 6.foreach标签1234567&lt;select id=\"getEmpIn\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where id in &lt;foreach collection=\"ids\" item=\"id\" separator=\",\" open=\"(\" close=\")\" index=\"index\"&gt; #&#123;id&#125; &lt;/foreach&gt;&lt;/select&gt; 主要用于 in 这种枚举类型的。自然的我们也是可以批量保存的 就是采用这种方式，也就是 values 的位置数据很多。 7.内置参数 _databaseId 这个表示的就是 databaseProvider 也就是我们配置的数据源厂商的名字了 _parameter 这个表示的就是我们的方法的入参，如果单个参数就是它本身，如果是一个对象什么的就是一个 map 8.变量声明，绑定我们的某一个参数过来的值我们没办法修改，或者说给他加一些修饰，修改。比如我们的某个like查询我们希望给传过来的东西加上 % 那么我们没办法直接在 sql 中添加，这时候我们就可以使用一个新变量，然后再新变量里修饰原来的变量。 1&lt;bind name=\"_new\" value=\"'%'+name\"/&gt; 9.sql抽取1234567891011&lt;sql id=\"select\"&gt; select name,id,$&#123;other&#125; from employee;&lt;/sql&gt;&lt;select id=\"ha\"&gt; &lt;include refid=\"select\"&gt; &lt;property name=\"other\" value=\"age\"/&gt; &lt;/include&gt; where id=#&#123;id&#125;&lt;/select&gt; 我们可以使用 sql 标签抽取 sql模板，然后使用 include 标签应用模板，之所以称为模板说的是他们是可以被重用的并且里面的内容是可变的。我们可以在 include 中使用 property 标签向模板中注入我们的定义的变量，只不过要注意的是变量的名字必须是采用 ${} 不能是 #{}","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/tags/MyBatis/"},{"name":"数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/tags/数据库/"},{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"MyBatis笔记三：SQL映射文件","slug":"DataBase/MyBatis笔记三：SQL映射文件","date":"2018-05-31T11:56:49.000Z","updated":"2019-03-14T16:50:18.000Z","comments":true,"path":"2018/05/31/DataBase/MyBatis笔记三：SQL映射文件/","link":"","permalink":"http://lwenxu.coding.me/2018/05/31/DataBase/MyBatis笔记三：SQL映射文件/","excerpt":"","text":"MyBatis笔记三：SQL映射文件1.简单的CRUD1.绑定首先呢我们还是需要把我们的 Mapper 接口和我们的 mapper xml 进行绑定，绑定的方式就是采用 namespace 了。不具体多说了。 2.接口接着就是写我们的 Mapper 接口了，写Mapper接口的时候有一些注意事项，就是我们的 插删改 操作是可以有返回值的，默认情况下这些都是返回我们影响的行数，但是这里我们可以返回 Integer , Long , Boolean 类型，前两个好理解，就是我们常见的那种行数。然后后面具体就是布尔值是我们的行数大于0 就返回真。当然我们也可以不返回： 12345678910111213package lwen.dao;import lwen.entries.Employee;public interface EmployeeMapper &#123; Employee getEmployeeById(Integer id); boolean addEmpl(Employee employee); boolean updateEmpl(Employee employee); boolean deleteEmpl(Integer id);&#125; 3.mapper xml然后就是在 mapper 的 xml文件中写 sql 语句了，具体就是几个 动作标签 ，然后里面配置上我们的 sql ，至于我们的 sql 的参数我们采用了 #{..} 的方式，然后就是我们需要注意的一点就是我们的 sql 标签的 select 标签是含有一个返回值类型的，但是其他的标签是没有的，需要注意一下。 1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \" -//mybatis.org//DTD Mapper 3.e//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"lwen.dao.EmployeeMapper\"&gt; &lt;select id=\"selectOneEmployee\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where id=#&#123;id&#125; &lt;/select&gt; &lt;!--添加--&gt; &lt;insert id=\"addEmpl\"&gt; insert into employee (name, age) values (#&#123;name&#125;, #&#123;age&#125;) &lt;/insert&gt; &lt;!--修改--&gt; &lt;update id=\"updateEmpl\"&gt; update employee set name = #&#123;name&#125;, age = #&#123;age&#125; &lt;/update&gt; &lt;!--删除--&gt; &lt;delete id=\"deleteEmpl\"&gt; delete from employee where id=#&#123;id&#125; &lt;/delete&gt;&lt;/mapper&gt; 4.测试类1234567891011121314@Testpublic void CURDTest() throws IOException &#123; SqlSessionFactory sessionFactory = GettingStart.getSessionFactory(\"mybatis.xml\"); SqlSession sqlSession = null; try &#123; sqlSession = sessionFactory.openSession(true); EmployeeMapper mapper = sqlSession.getMapper(EmployeeMapper.class); System.out.println(mapper.addEmpl(new Employee(1,\"lwen\",18))); &#125;finally &#123; if (sqlSession != null) &#123; sqlSession.close(); &#125; &#125;&#125; 测试类的地方我们也看到了一个比较奇怪的地方就是 sqlSession = sessionFactory.openSession(true); 我们在获取 session 的时候加了一个参数，其实这个参数就是说我们的每一条sql是否为一个事物，或者说是不是一个自动提交的 sql 。如果我们不开启这个自动提交的话我们在执行完若干条sql以后我们需要手动的调用 sql 的 sqlSession.commit(); 方法了。 2.获取自增主键我们在 Mybatis 中需要将我们插入的值获取到，然后返回给我们传入的 JavaBean 的话我们就可以才用这个方式把自动增长的主键的值封装获取我们在 Service 层就可以获取到我们插入的数据的 id 。 123&lt;insert id=\"addEmpl\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into employee (name, age) values (#&#123;name&#125;, #&#123;age&#125;)&lt;/insert&gt; useGeneratedKeys 这个属性说我们需要开启自动增长的策略并获取增长的值，然后我们需要把这个值封装进我们的 Java bean 的哪个属性就是我们的 keyProperty 来确定了。 123Employee employee = new Employee(1, \"lwen\", 18);System.out.println(mapper.addEmpl(employee));System.out.println(employee); Employee(id=13, name=lwen, age=18) 虽然我们传入了 id=1 但是 bean 被修改成了 13。 3.参数处理1.单个参数这个时候我们直接采用 #{} 取出值，不做特殊处理，我们的 #{} 里面写什么都可以，不用和我们的方法参数对应。 2.多个参数多个参数就设计到绑定的问题了，也就是要么我们进行参数的绑定，要么我们就进行参数的顺序处理。 1.param顺序处理123&lt;select id=\"getEmplByIdAndName\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where id=#&#123;param1&#125; and name=#&#123;param2&#125;&lt;/select&gt; 这里我们的 Java 代码是有两个参数的，所以注意我们的这个地方参数是从 1 开始的不是 0. 2.args顺序处理123&lt;select id=\"getEmplByIdAndName2\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where id=#&#123;arg0&#125; and name=#&#123;arg1&#125;&lt;/select&gt; 这里的参数有是从 0 开始的。 注意： 以上两种代码我们的 Mapper 接口不需要做任何的额外的配置，就可以直接可以工作了如下： 1Employee getEmplByIdAndName(Integer id, String name); 3.命名参数上面的代码虽然可以工作但是我们需要注意的就是这个地方我们的代码是没有任何的具体的意义的，因为就是我们看不出来这个变量的具体意义。我们就可以和我们的接口的参数绑定，那么就是用命名参数。 首先我们需要在Mapper接口中写相关的注解，确定参数： 1Employee getEmplByIdAndName1(@Param(\"id\") Integer id,@Param(\"name\") String name); 然后我们在 xml 中就可以应用这些参数了： 123&lt;select id=\"getEmplByIdAndName1\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where id=#&#123;id&#125; and name=#&#123;name&#125;&lt;/select&gt; 当然采用命名参数肯定是最好的方式了。 3.传递pojo如果我们的参数太多了我们使用命名参数就很麻烦，我们就可以自己构建 pojo 。但是如果这些属性之间没什么关系，然后我们不用自己创建一个没什么用的封装类，我们直接使用 map 就好了。然后我们在 sql 就可以直接使用 #{key} 就可以获取对应的 value 。但是如果这个参数经常被使用的话我们就可以自己封装一个类数据传输类 TO。 其实真正在 Mybatis 中他自动把我们的参数封装到了 map中所以我们这么写也是很自然的。 1Employee getEmplByIdAndName3(Map&lt;String, Object&gt; map); 我们的xml 可以直接取出我们的map中的key 123&lt;select id=\"getEmplByIdAndName3\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where id=#&#123;id&#125; and name=#&#123;name&#125;&lt;/select&gt; 1234Map&lt;String, Object&gt; map = new HashMap();map.put(\"id\", 12);map.put(\"name\", \"lwen\");Employee employee4 = mapper.getEmplByIdAndName3(map); 4.List/Array 特殊情况 public Employee getEmp(@Param(“id”)Integer id,String lastName)； 取值：id ： #{id/param1} lastName ：#{param2} public Employee getEmp(Integer id,@Param(“e”)Employee emp)； 取值：id： #{param1} lastName：#{param2.lastName/e.lastName} 特别注意： 如果是Collection(List、Set)类型或者是数组，也会特殊处理。也是把传入的list或者数组封装在map中。 比如：public Employee getEmpById(Listids)； 取值：取出第一个id的值：#{list[e]} 4.参数处理原理我们从源码的角度来看看我们的 Mybatis 框架是如何处理我们的传入的参数，以及绑定的参数的。 1.代理对象首先我们在获取到的 mapper 上打断点，然后 step into： 接着我们就能来到代理类了：org.apache.ibatis.binding.MapperProxy 12345678910111213141516@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; try &#123; //放行Object对象的方法，不做代理 if (Object.class.equals(method.getDeclaringClass())) &#123; return method.invoke(this, args); &#125; else if (isDefaultMethod(method)) &#123; return invokeDefaultMethod(proxy, method, args); &#125; &#125; catch (Throwable t) &#123; throw ExceptionUtil.unwrapThrowable(t); &#125; final MapperMethod mapperMethod = cachedMapperMethod(method); //真正执行的 sqlSession return mapperMethod.execute(sqlSession, args);&#125; 可以看到我们在这里生成了对应方法的代理对象，也就是给我们的 Mapper 接口生成了代理对象，接着就用代理对象 mapperMethod 来调用我们的接口方法。 2.execute核心逻辑我们单步进入 execute 方法可以看到主要的逻辑如下： 12345678910111213141516171819202122232425262728293031323334353637switch (command.getType()) &#123; case INSERT: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; case DELETE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &#125; case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(\"Unknown execution method for: \" + command.getName());&#125; 也就是我们所有的采用Mapper 接口的方法开发的最后采用的代理生成代理对象以后我们的插删改操作还是调用了我们 sqlSession 底层的 Select、Delete 方法等等。 里面的套路就是先对我们的方法的参数进行转换，然后执行对应的动作方法，传入我们的参数。 3.参数转换convertArgsToSqlCommandParam（） 主要完成了这个功能，这里我们就着重看看这个方法。 最后追溯到下面这个方法，代码补偿我就全部贴上来了： 12345678910111213141516171819202122public Object getNamedParams(Object[] args) &#123; final int paramCount = names.size(); if (args == null || paramCount == 0) &#123; return null; &#125; else if (!hasParamAnnotation &amp;&amp; paramCount == 1) &#123; return args[names.firstKey()]; &#125; else &#123; final Map&lt;String, Object&gt; param = new ParamMap&lt;Object&gt;(); int i = 0; for (Map.Entry&lt;Integer, String&gt; entry : names.entrySet()) &#123; param.put(entry.getValue(), args[entry.getKey()]); // add generic param names (param1, param2, ...) final String genericParamName = GENERIC_NAME_PREFIX + String.valueOf(i + 1); // ensure not to overwrite parameter named with @Param if (!names.containsValue(genericParamName)) &#123; param.put(genericParamName, args[entry.getKey()]); &#125; i++; &#125; return param; &#125;&#125; 我们看看这个方法的执行逻辑： 1.names获取首先就是一堆names的获取，这个names又是什么？其实这是当前类的一个属性，记录的东西是Mapper 接口的参数的名字他是在这个类的构造方法中初始化的，也就是在我们调用方法之前 names 就已经确定好了。 123456789101112131415161718192021222324252627// get names from @Param annotationsfor (int paramIndex = 0; paramIndex &lt; paramCount; paramIndex++) &#123; if (isSpecialParameter(paramTypes[paramIndex])) &#123; // skip special parameters continue; &#125; String name = null; for (Annotation annotation : paramAnnotations[paramIndex]) &#123; if (annotation instanceof Param) &#123; hasParamAnnotation = true; name = ((Param) annotation).value(); break; &#125; &#125; if (name == null) &#123; // @Param was not specified. if (config.isUseActualParamName()) &#123; name = getActualParamName(method, paramIndex); &#125; if (name == null) &#123; // use the parameter index as the name (\"0\", \"1\", ...) // gcode issue #71 name = String.valueOf(map.size()); &#125; &#125; map.put(paramIndex, name);&#125; 这就是 ParamNameResolver 的构造函数，里面最重要的逻辑就是确定我们的 names ： 1.获取 @param 注解标注的参数名，然后把这个注解的value值作为 names 的value，然后把参数的位置作为 key 。比如我们的方法是 findAll(@Parma(&quot;name&quot;) String name,Integer age) 最后生成的names这个map里面就是 {0-&gt;name,1-&gt;1} 至于为什么是 1-&gt;1 我们接下来再说 2.如果我们的 @param 不存在的话并且我们配置了 isUseActualParamName 我们会尝试采用 JDK1.8 的新特性也就是使用 -paramters 编译参数，通过反射直接获取到我们方法的参数名。 3.如果还是不行的话我们就使用参数的索引值，也就是 0,1 上面的注释也是特别清楚。 2.方法没有参数没有参数的时候就会直接返回null 3.单参数只有一个参数并且没有 @param 注解的时候，我们就直接获取names的第一个key也就是0 4.多参数这个地方有两部分，当有 @Param 注解的时候就是把 names 的 value 作为 key ，然后我们的真正的参数作为 value 。然后当然为了保险起见 Mybatis 还未每一个参数生成了一个 以 paramIndex 作为key 以值作为 value 的 也就是我们用的 param0 .. paramN .可是我们会说为啥我们还可以用 args0 和 args1 来取值呢？ 这个就看上面的 names 获取值的时候我们可以采用编译器的反射机制获取，因为如果我们编译器不支持这个特性的话我们的参数就会被抹掉，用args0 args1 来代替。 5.取值规则1.#{}与${}区别#{}：是以预编译的形式，将参数设置到sq1语句中；PreparedStatement；防止sq1注入 ${}：取出的值直接拼装在sq1语句中；会有安全问题；大多情况下，我们去参数的值都应该去使用#{}；原生jdbc不支持占位符的地方我们就可以使用${}进行取值,比如分表；按照年份分表拆分select * from ${year}_salary where xxx； 2.#{}注意事项在#{} 中我们可以放入 javaType、jdbcType、mode(存储过程）、numericScale、resultMap、typeHandler、jdbcTypeName、expression(未来准备支持的功能）； 比较重要的就是：jdbcType通常需要在某种特定的条件下被设置：在我们数据为null的时候，有些数据库可能不能识别mybatis对nu11的默认处理。比如Oracle（报错），因为他们对null的映射是到了 Other 类型，然后就会导致JdbcType OTHER：无效的类型；因为mybatis对所有的nu11都映射的是原生Jdbc的OTHER类型，由于全局配置中：jdbcTypeForNull=OTHER；oracle不支持；两种办法1、#{email,jdbcType=OTHER}；2、&lt;setting name=&quot;jdbcTypeForNull&quot; value=&quot;NULL&quot;/&gt; 6.查询1.返回集合结果返回集合结果的时候我们的 resultType 不能写成 list 、set 类型而是要写做我们的集合里面的元素的类型。 12345&lt;select id=\"getLikeByName\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where name like #&#123;name&#125;;&lt;/select&gt; 2.返回map也就是将我们的 bean 的属性作为 key 然后 值作为 value 来存储到一个 map 中，其实这个只存一条数据，那么我们的语句的返回类型就是我们的 map 他会自动的做封装。 123&lt;select id=\"getEmplReturenMap\" resultType=\"map\"&gt; select * from employee where id=#&#123;id&#125;;&lt;/select&gt; 1Map&lt;String, Object&gt; getEmplReturenMap(Integer id); 3.返回多条记录的map如果我们想让map的key是我们的某一条属性，然后value是我们的实体对象，那么我们的封装结果就必须是元素的类型，也就是我们的实体类的类型，但是我们的key则需要我们另行指定我们采用的方式就是使用一个注解在方法上。 12@MapKey(\"name\")Map&lt;String, Employee&gt; getEmplReturnMaps(String name); 1234&lt;select id=\"getEmplReturnMaps\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where name like #&#123;name&#125;;&lt;/select&gt; 4.返回自定义结果集有时候对于Mybatis自带的一些默认封装的规则不能满足我们的需求的时候，我们可以采用 resultMap 自定义结果集。这里就演示一些自定义结果集，但是注意 resultMap 与 resultType 只能存在一个。 1234567891011&lt;resultMap id=\"MyEmp\" type=\"lwen.entries.Employee\"&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;result column=\"age\" property=\"age\"/&gt;&lt;/resultMap&gt;&lt;select id=\"getEmplByResultMap\" resultMap=\"MyEmp\"&gt; select * from employee where id = #&#123;id&#125;;&lt;/select&gt; 可以看到重点就是写我们的 resultMap 标签，然后再标签中我们自己封装规则。注意的一点就是如果说我们在 result 中没有封装 bean 中的其他属性他会自动帮我们封装，也就是我们可以把一些特殊的字段和我们的 bean 结合起来。其他的正常的自动封装。然后就是 id 字段我们在 resultMap 中指明以后Mybatis就会帮我们自动封装，并且做一些查询优化。 5.关联查询1.union1234&lt;select id=\"getById\" resultMap=\"EmpNew\"&gt; select employee.id id,employee.name name,age,d_id did,department.name dname from employee,department where employee.id=#&#123;id&#125; and employee.d_id=department.id;&lt;/select&gt; 我们采用的联合查询，得到了关联查询的结果，这也是常用的套路，但是注意的一点就是我们的 result 的封装并不是使用的自带的封装规则而是采用了 我们自定义的 resultMap 因为我们的 employee 中有一个 department 的对象，我们无法直接封装，至少列名都没办法对应。 1234567&lt;resultMap id=\"EmpNew\" type=\"lwen.entries.EmployeeNew\"&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;result column=\"age\" property=\"age\"/&gt; &lt;result column=\"did\" property=\"department.id\"/&gt; &lt;result column=\"dname\" property=\"department.name\"/&gt;&lt;/resultMap&gt; 2.association关联使用 association 标签可以给一个 javaBean 的内部引用创建关联关系，与上面的效果类似，但是方法不同。 123456789&lt;resultMap id=\"EmpNew1\" type=\"lwen.entries.EmployeeNew\"&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;result column=\"age\" property=\"age\"/&gt; &lt;association property=\"department\" javaType=\"lwen.entries.Department\"&gt; &lt;id column=\"did\" property=\"id\"/&gt; &lt;result column=\"dname\" property=\"name\"/&gt; &lt;/association&gt;&lt;/resultMap&gt; 1234&lt;select id=\"getByIdAssociation\" resultMap=\"EmpNew1\"&gt; select employee.id id,employee.name name,age,d_id did,department.name dname from employee,department where employee.id=#&#123;id&#125; and employee.d_id=department.id;&lt;/select&gt; 3.association多步查询当我们需要 department 的 id 然后作为我们封装 Employee 的条件的时候我们就需要用 id 查询这个 Department 123456789101112131415&lt;resultMap id=\"EmpNew2\" type=\"EmployeeNew\"&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;result column=\"age\" property=\"age\"/&gt; &lt;association property=\"department\" select=\"lwen.dao.DepartmentMapper.getDepById\" column=\"d_id\"&gt; &lt;/association&gt;&lt;/resultMap&gt;&lt;select id=\"getEmplStepByStep\" resultMap=\"EmpNew2\"&gt; select * from employee where id=#&#123;id&#125;&lt;/select&gt;&lt;select id=\"getDepById\" resultType=\"lwen.entries.Department\"&gt; select * from department where id=#&#123;id&#125;&lt;/select&gt; 可以看到我们在 association 中调用了 lwen.dao.DepartmentMapper.getDepById 这个方法其实就是只进行了一个简单的 按照 id 查询，然后我们传入的 column 就是作为我们查询 department 的参数。最后做关联。 4.懒加载需要我们在以前的分布查询的基础之上添加上一个配置项，这个配置项是在我们的全局配置文件中的。 12&lt;setting name=\"lazyloadingEnabled\" value=\"true\"/&gt;&lt;setting name=\"aggressivelazyLoading\" value=\"false\"/&gt; 配置这两项的时候我们在查询获取一个对象的时候我们只有在引用他们的值得时候才真的去加载这些东西，否则不会加载。 5.一对多映射1234567891011121314&lt;resultMap id=\"EmpNew3\" type=\"Department\"&gt; &lt;id column=\"id\" property=\"id\"/&gt; &lt;result column=\"name\" property=\"name\"/&gt; &lt;association property=\"employees\" select=\"lwen.dao.EmployeeNewMapper.getEmplsByDeptId\" column=\"id\"/&gt;&lt;/resultMap&gt;&lt;select id=\"getEmplStepByDepIdStep\" resultMap=\"EmpNew3\"&gt; select * from department where id=#&#123;id&#125;;&lt;/select&gt;&lt;select id=\"getEmplsByDeptId\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where d_id=#&#123;did&#125;&lt;/select&gt;","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/tags/MyBatis/"},{"name":"数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/tags/数据库/"},{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"MyBatis笔记二：配置","slug":"DataBase/MyBatis笔记二：配置","date":"2018-05-30T13:02:49.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/05/30/DataBase/MyBatis笔记二：配置/","link":"","permalink":"http://lwenxu.coding.me/2018/05/30/DataBase/MyBatis笔记二：配置/","excerpt":"MyBatis笔记二：配置1.全局配置1.properites这个配置主要是引入我们的 properites 配置文件的： 12345678910111213&lt;properties resource=\"db.properties\"/&gt;&lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt; 可以看到我们使用 &lt;properties resource=&quot;db.properties&quot;/&gt; 引入了我们的数据据库的配置文件，然后这个标签有两个属性 ： resource 和 uri 第一种直接是引用项目下的文件。第二个就是引用网络路径的和我们本地文件系统的资源。","text":"MyBatis笔记二：配置1.全局配置1.properites这个配置主要是引入我们的 properites 配置文件的： 12345678910111213&lt;properties resource=\"db.properties\"/&gt;&lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;driver&#125;\"/&gt; &lt;property name=\"url\" value=\"$&#123;url&#125;\"/&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt; 可以看到我们使用 &lt;properties resource=&quot;db.properties&quot;/&gt; 引入了我们的数据据库的配置文件，然后这个标签有两个属性 ： resource 和 uri 第一种直接是引用项目下的文件。第二个就是引用网络路径的和我们本地文件系统的资源。 2.settings非常重要！！！ 1234&lt;!--全局配置--&gt;&lt;settings&gt; &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/&gt;&lt;/settings&gt; 装了Mybatis 插件的话我们会看到我们的设置的代码提示，都不用自己去记的。 3.typeAliases可以为我们的 Java 类型取别名。避免我们去写很长的类包名，等等。并且这里提供了三种取别名的方式： 1. typeAlias123&lt;typeAliases&gt; &lt;typeAlias type=\"lwen.entries.Employee\" alias=\"emp\"/&gt;&lt;/typeAliases&gt; 这就是给我们的 Java 类取的别名，我们在 xml 中配置返回值，参数，命名空间的时候就不用写那么长了。我们直接写 emp 即可，但是注意的是我们如果不写 alias 属性他就会配置默认的别名，也就是我们的类名首字母小写。在这里就是employee 2.package批量取别名，有时候我们的一个包下面的类太多了我们希望给他们都取上默认别名，我们就可以使用这个标签，但是注意这个标签不能和 typeAlias标签共存 ，这个标签指定的包其实是对我们的这个包以及他的子包进行别名操作，并且都是默认别名 123&lt;typeAliases&gt; &lt;package name=\"lwen.entries\"/&gt;&lt;/typeAliases&gt; 3.@Alias因为上面的两个标签不能同时存在，所以我们没办法给某一个包下的特定的类取别名，这里我们就需要使用 @Alias 来做注解别名了，这样可以解决上面的问题。 1@Alias(\"emps\") 其实除了这些我们需要自定义的一些别名，系统帮我们预先设定好了很多常用的别名： 别名 映射的类型 _byte byte _long long _short short _int int _integer int _double double _float float _boolean boolean string String byte Byte long Long short Short int Integer integer Integer double Double float Float boolean Boolean date Date decimal BigDecimal bigdecimal BigDecimal object Object map Map hashmap HashMap list List arraylist ArrayList collection Collection iterator Iterator 可以看到规律就是类名小写，然后基本类型就是下划线。 4.typeHandler这个东西其实就是把我们的Java类型和数据库的类型相对应，这里暂时不具体说。 5.plugins插件功能，对下面对象的方法进行拦截，他的原理就是动态代理。 Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query) 6.environments12345678910&lt;environments default=\"dev\"&gt; &lt;environment id=\"dev\"&gt; &lt;transactionManager type=\"JDBC\"&gt; &lt;property name=\"hah\" value=\"heh\"/&gt; &lt;/transactionManager&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt; 最外层就是我们的 environments 这个就是配置各种环境（比如：开发，测试，线上…），所以说我们的这个标签有一个 default 属性，就是用来制定我们的具体激活哪个环境的，这里用的是 dev 。然后下面就是具体的环境了，环境的 id 就是我们配置的环境的名称，每一个环境里有且只有两个属性，就是 transactionManager 和 dataSource 他们必须配置否则会报错。 可以看到 transactionManager 有一个 Type 就是用来指定使用哪个食物管理器，这里它使用了 JDBC 的，其实在Mybatis中只有两种：type=”[JDBC|MANAGED]” JDBC – 这个配置就是直接使用了 JDBC 的提交和回滚设置，它依赖于从数据源得到的连接来管理事务作用域。 MANAGED – 这个配置几乎没做什么。它从来不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接，然而一些容器并不希望这样，因此需要将 closeConnection 属性设置为 false 来阻止它默认的关闭行为。例如: 123&lt;transactionManager type=\"MANAGED\"&gt; &lt;property name=\"closeConnection\" value=\"false\"/&gt;&lt;/transactionManager&gt; 然后我们就很好奇这些 MANAGED 之类的东西在哪有定义，我们是否可以配置自己的书屋管理器比如强大的 Spring的事务管理。 org.apache.ibatis.session.Configuration 在这个类里我们发现了 123456typeAliasRegistry.registerAlias(\"JDBC\", JdbcTransactionFactory.class);typeAliasRegistry.registerAlias(\"MANAGED\", ManagedTransactionFactory.class);typeAliasRegistry.registerAlias(\"JNDI\", JndiDataSourceFactory.class);typeAliasRegistry.registerAlias(\"POOLED\", PooledDataSourceFactory.class);typeAliasRegistry.registerAlias(\"UNPOOLED\", UnpooledDataSourceFactory.class); 也就是说他们都是别名而已。那么我们就可以配置自己的类了，我们直接在 type 位置写上我们的事务管理器全类名，或者使用别名机制也可以。具体的对应的类需要什么特性我们直接看看他本来自带的两个类就明白了。 显然下面的配置数据源也是如此，默认的采用了连接池，也就是我们的 sqlSession 对象会被缓存起来不用每次去数据库里获取。 7.databaseIdProviderMyBatis 可以根据不同的数据库厂商执行不同的语句，这种多厂商的支持是基于映射语句中的 databaseId 属性。 MyBatis 会加载不带 databaseId 属性和带有匹配当前数据库 databaseId 属性的所有语句。 如果同时找到带有 databaseId 和不带 databaseId 的相同语句，则后者会被舍弃。 我们通过设置属性别名来使其变短 ： 123456&lt;databaseIdProvider type=\"DB_VENDOR\"&gt; &lt;property name=\"SQL Server\" value=\"sqlserver\"/&gt; &lt;property name=\"DB2\" value=\"db2\"/&gt; &lt;property name=\"Oracle\" value=\"oracle\" /&gt; &lt;property name=\"MySQL\" value=\"mysql\" /&gt;&lt;/databaseIdProvider&gt; 然后我们在 mapper 的xml文件中就可以匹配这些数据提供商： 123456&lt;select id=\"getEmployeeById\" resultType=\"lwen.entries.Employee\" databaseId=\"mysql\"&gt; select * from employee where id=#&#123;id&#125;&lt;/select&gt;&lt;select id=\"getEmployeeById\" resultType=\"lwen.entries.Employee\" databaseId=\"oracle\"&gt; select * from employee where id=#&#123;id&#125;&lt;/select&gt; 那么他会按照数据源来确定当前是哪个数据源，我们需要使用哪个sql语句。这些都是自动进行的，无需我们的干预。 8.mappers这个就是用来配置我们的 mapper 的 xml 标签了。我们在里面配置 xml 有以下三种方式： 1.使用 mapper 标签12345&lt;!--我们的mapper文件的位置--&gt;&lt;mappers&gt; &lt;mapper resource=\"EmployeeMapper.xml\"/&gt; &lt;mapper resource=\"EmployeeMapperInterface.xml\"/&gt;&lt;/mappers&gt; 显然这个地方的 mapper 标签还有两个属性 分别就是 resource 和 uri 就是和上面是一样的。 2.使用包扫描的方式1&lt;package name=\"lwen\"/&gt; lwen 包下面的xml 映射文件都被加载进去。 3.注解我们可以使用对应的注解 注解名 就是我们的 sql 语句的动作。 @Select Update 等等 注意以上的标签都是有顺序的，顺序不能随便配置","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/tags/MyBatis/"},{"name":"数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/tags/数据库/"},{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"MyBatis笔记一：GettingStart","slug":"DataBase/MyBatis笔记一：GettingStart","date":"2018-05-30T10:56:49.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/05/30/DataBase/MyBatis笔记一：GettingStart/","link":"","permalink":"http://lwenxu.coding.me/2018/05/30/DataBase/MyBatis笔记一：GettingStart/","excerpt":"MyBatis笔记一：GettingStart1.MyBatis优点 我们的工具和各种框架的作用就是为了我们操作数据库简洁，对于一些数据库的工具能帮我们少写一些处理异常等等的代码，但是他们并不是自动化的，很多的操作还是需要我们自己进行，所以我们的框架就帮我们把中间黑色的部分封装起来了，减少我们的负担，但是SQL也是重中之重，我们需要把这些东西自己来控制就有 MyBatis 这个半自动框架，以及我们需要学习更多的关于 HQL 的内容。","text":"MyBatis笔记一：GettingStart1.MyBatis优点 我们的工具和各种框架的作用就是为了我们操作数据库简洁，对于一些数据库的工具能帮我们少写一些处理异常等等的代码，但是他们并不是自动化的，很多的操作还是需要我们自己进行，所以我们的框架就帮我们把中间黑色的部分封装起来了，减少我们的负担，但是SQL也是重中之重，我们需要把这些东西自己来控制就有 MyBatis 这个半自动框架，以及我们需要学习更多的关于 HQL 的内容。 相对于Hibernate 他的优点就是可以进行SQL 的定制化，能让我们的SQL更加优化，虽然 Hibernate 也可以这么做但是有一点就是我们需要在原来的框架的基础上学习更多的 HQL 相关的东西，加重学习负担。 2.Getting Start1.引入依赖首先我们需要建立一个新的工程，第一步就是进入 MyBatis 的依赖，当然也少不了数据库的依赖，这里我们为了方便实体类的编写我们还加上了 Lombok ，以及log4j ： 12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.35&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.编写配置文件需要在类路径下编写配置文件： 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///spring_data\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;&lt;/configuration&gt; 2.log4j配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"&gt;&lt;log4j:configuration&gt; &lt;appender name=\"myConsole\" class=\"org.apache.log4j.ConsoleAppender\"&gt; &lt;layout class=\"org.apache.log4j.PatternLayout\"&gt; &lt;param name=\"ConversionPattern\" value=\"[%d&#123;dd HH:mm:ss,SSS\\&#125; %-5p] [%t] %c&#123;2\\&#125; - %m%n\" /&gt; &lt;/layout&gt; &lt;!--过滤器设置输出的级别--&gt; &lt;filter class=\"org.apache.log4j.varia.LevelRangeFilter\"&gt; &lt;param name=\"levelMin\" value=\"debug\" /&gt; &lt;param name=\"levelMax\" value=\"warn\" /&gt; &lt;param name=\"AcceptOnMatch\" value=\"true\" /&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name=\"myFile\" class=\"org.apache.log4j.RollingFileAppender\"&gt; &lt;param name=\"File\" value=\"D:/output.log\" /&gt;&lt;!-- 设置日志输出文件名 --&gt; &lt;!-- 设置是否在重新启动服务时，在原有日志的基础添加新日志 --&gt; &lt;param name=\"Append\" value=\"true\" /&gt; &lt;param name=\"MaxBackupIndex\" value=\"10\" /&gt; &lt;layout class=\"org.apache.log4j.PatternLayout\"&gt; &lt;param name=\"ConversionPattern\" value=\"%p (%c:%L)- %m%n\" /&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;appender name=\"activexAppender\" class=\"org.apache.log4j.DailyRollingFileAppender\"&gt; &lt;param name=\"File\" value=\"E:/activex.log\" /&gt; &lt;param name=\"DatePattern\" value=\"'.'yyyy-MM-dd'.log'\" /&gt; &lt;layout class=\"org.apache.log4j.PatternLayout\"&gt; &lt;param name=\"ConversionPattern\" value=\"[%d&#123;MMdd HH:mm:ss SSS\\&#125; %-5p] [%t] %c&#123;3\\&#125; - %m%n\" /&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- 指定logger的设置，additivity指示是否遵循缺省的继承机制--&gt; &lt;logger name=\"com.runway.bssp.activeXdemo\" additivity=\"false\"&gt; &lt;appender-ref ref=\"activexAppender\" /&gt; &lt;/logger&gt; &lt;!-- 根logger的设置--&gt; &lt;root&gt; &lt;priority value =\"debug\"/&gt; &lt;appender-ref ref=\"myConsole\"/&gt; &lt;appender-ref ref=\"myFile\"/&gt; &lt;/root&gt;&lt;/log4j:configuration&gt; 3.编写实体类12345678910111213141516package lwen.entries;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import lombok.experimental.Accessors;@Data@NoArgsConstructor@AllArgsConstructor@Accessors(chain = true)public class Employee &#123; private int id; private String name; private int age;&#125; 4.编写测试类1234567891011121314151617181920212223242526272829303132import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.junit.Test;import java.io.IOException;import java.io.InputStream;public class GettingStart &#123; @Test public void sessionFactoryTest() throws IOException &#123; String resource = \"mybatis.xml\"; InputStream stream = Resources.getResourceAsStream(resource); SqlSession sqlSession = null; try &#123; //获取sql工厂 SqlSessionFactory sessionFactory = new SqlSessionFactoryBuilder().build(stream); //获取sql session sqlSession = sessionFactory.openSession(); // 1.sql标识 2.绑定的参数 Object employee = sqlSession.selectOne(\"selectOneEmployee\", 3); System.out.println(employee); &#125;finally &#123; if (sqlSession != null) &#123; sqlSession.close(); &#125; &#125; &#125;&#125; 5.编写mapper文件12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \" -//mybatis.org//DTD Mapper 3.e//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"org.mybatis.example.BlogMapper\"&gt; &lt;select id=\"selectOneEmployee\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where id=#&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 注意这里其实我们的mapper和测试类里的参数必须是需要匹配的才行。比如我们的 id 就是我们的测试类中的 select 方法需要传的参数，然后我们的 resultType 就是一个实体类的具体路径。 6.总结基本套路 根据xml配置文件（全局配置文件）创建一个Sq1SessionFactory对象，xml是用来配置数据源一些运行环境信息 sql映射文件：配置了每一个sql，以及sql的封装规则等。 将sq1映射文件注册在全局配置文件中 写Java代码： 1）、根据全局置文件得到Sq1SessionFactory；2）、使用sqlSession工厂，获取到sqlSession对象使用他来执行增改查，一个sqlSession就是代表和数据库的一次会话，用完关闭3）、使用sql的唯一标志来告诉MyBatis执行哪个sql，语句都是保存在Sql映射文件中的。 上面我们使用的方式是以前比较老的方式，现在不再使用那种方式了，我们现在都是面向的接口编程的，所以我们使用Mapper 类来完成数据库访问。 3.面向接口编程1.编写接口Mapper创建一个mapper接口，然后里面写方法即可： 1234567package lwen.dao;import lwen.entries.Employee;public interface EmployeeMapper &#123; public Employee getEmployeeById(Integer id);&#125; 可以看到就是这么简单，但是我们一开始是通过方法的参数和我们的 xml 的查询语句链接起来的，这里我们又怎么做这个映射关系呢？其实就是需要在我们的 xml 中配置我们的 这个Mapper 的路径，以及我们的方法作为查询语句的 id 属性，还有返回值类型，等等。接下来就来看这些配置。 2.配置Mapper.xml接下来就是配置我们的 mapper 的xml了，让他和我们的接口挂钩。 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \" -//mybatis.org//DTD Mapper 3.e//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"lwen.dao.EmployeeMapper\"&gt; &lt;select id=\"getEmployeeById\" resultType=\"lwen.entries.Employee\"&gt; select * from employee where id=#&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 注意事项： 第一点就是我们的 namespace 以前事随便写，但是这个地方就是需要我们和Mapper 接口绑定，也就是我们的接口的全类名。 然后就是我们的id属性，就是我们的Mapper的方法名。 还有一点疑问就是我们的参数，我们都没传，其实这里他做了默认绑定，参数名和这里的sql模板参数名一致就行。 3.测试类1234567891011121314151617181920212223@Testpublic void InterfaceMapperTest() throws IOException &#123; String resource = \"mybatis.xml\"; InputStream stream = Resources.getResourceAsStream(resource); SqlSession sqlSession = null; try &#123; //获取sql工厂 SqlSessionFactory sessionFactory = getSessionFactory(\"mybatis.xml\"); //获取sql session sqlSession = sessionFactory.openSession(); // 获取 mapper 接口的实例对象 EmployeeMapper employeeMapper = sqlSession.getMapper(EmployeeMapper.class); //直接调用的 mapper 里的方法 System.out.println(employeeMapper.getEmployeeById(3)); &#125;finally &#123; if (sqlSession != null) &#123; sqlSession.close(); &#125; &#125;&#125; 4.一个神奇的点这里我们会发现我们根本没有写接口的实现类，我们怎么获取到我们的 Mapper 的对象，并且还可以调用他的方法呢？实际上我们去打印一下我们使用 sqlSession.getMapper(EmployeeMapper.class) 这句话获取到我们的对象，并且能执行相应的操作呢？ 我们打印出来这个对象我们就会发现，获取到的对象实际上是一个代理对象，那么也就是说我们 Mybatis 底层采用的代理方式做的具体的功能。 其实我们通过SqlSession.getMapper(XXXMapper.class) 方法，MyBatis 会根据相应的接口声明的方法信息，通过动态代理机制生成一个Mapper 实例，我们使用Mapper 接口的某一个方法时，MyBatis 会根据这个方法的方法名和参数类型，确定Statement Id，底层还是通过SqlSession.select(&quot;statementId&quot;,parameterObject);或者SqlSession.update(&quot;statementId&quot;,parameterObject); 等等来实现对数据库的操作，（至于这里的动态机制是怎样实现的，我想专门用一篇文章来讨论） MyBatis 引用 Mapper 接口这种调用方式，纯粹是为了满足面向接口编程的需要。（其实还有一个原因是在于，面向接口的编程，使得用户在接口上可以使用注解来配置SQL语句，这样就可以脱离XML配置文件，实现“0配置”）。 因为面向接口编程其实有非常多的好处。因为现在我们的 dao 代码就是我们的 mapper 接口了，但是如果有一天我们希望不采用 MyBatis 来做数据访问了，我们在底层就可以直接写对应的实现类使用 Hibernate 等等其他框架来顶替，也是一件很容易的事。 4.总结 SqlSession代表和数据库的一次会话：用完必须关闭，这也是一个资源，所以我们用完了必须进行关闭操作，避免数据库不必要的问题。 SqlSession和connection一样都是非线程安全，每次使用都应该去获取新的对象，不可以当作一个成员变量 ，不然自然会导致紊乱，也就是我们需要把他放在一个局部方法中，用完关闭。其实说清楚点他的底层就是 connection。 mapper接口没有实现类，但是mybatis会为这个接口生成一个代理对象。（将接口和xml进行绑定） 两个重要的配置文件： mybatis的全局配置文件：包含数据库连接池信息，事务管理器信息等。。。系统运行环境信息 sql映射文件：保存了每一个sq1语句的映射信息：将sql抽取出来。","categories":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/categories/MyBatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://lwenxu.coding.me/tags/MyBatis/"},{"name":"数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/tags/数据库/"},{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"SpringCloud：Eureka服务注册与发现","slug":"SpringCloud/SpringCloud：Eureka服务注册与发现","date":"2018-05-26T02:51:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/26/SpringCloud/SpringCloud：Eureka服务注册与发现/","link":"","permalink":"http://lwenxu.coding.me/2018/05/26/SpringCloud/SpringCloud：Eureka服务注册与发现/","excerpt":"SpringCloud：Eureka服务注册与发现Eureka 其实就是一个 服务注册与发现的中心，也就是相当于我们前面做的一些生产者的服务需要注册到我们的注册中心，那么我们的消费者就不用把代码写死，而是可以去服务中心订阅对应的服务，获取服务的最新地址，并且进行逻辑解耦。 说的更简单一点它就相当于我们的 Dubbo 中的zookeeper 的功能就是用来服务发现的和注册的。他是一个CS架构的一个应用，也就是我们会有客户端和服务端，接下来就准备使用这个服务注册中心。 那么现在我们就只需要在我们以前的那个项目上在进行进一步的操作，也就是加上注册中心就好，那么现在就开始搭建！","text":"SpringCloud：Eureka服务注册与发现Eureka 其实就是一个 服务注册与发现的中心，也就是相当于我们前面做的一些生产者的服务需要注册到我们的注册中心，那么我们的消费者就不用把代码写死，而是可以去服务中心订阅对应的服务，获取服务的最新地址，并且进行逻辑解耦。 说的更简单一点它就相当于我们的 Dubbo 中的zookeeper 的功能就是用来服务发现的和注册的。他是一个CS架构的一个应用，也就是我们会有客户端和服务端，接下来就准备使用这个服务注册中心。 那么现在我们就只需要在我们以前的那个项目上在进行进一步的操作，也就是加上注册中心就好，那么现在就开始搭建！ 1.配置Eureka服务端前面也提到了Eureka是一个CS架构的应用，所以说我们的服务器端说白了就是一个新的SpringBoot的应用，所以我们可以直接开一个Eureka 的服务端并且它带有一个Dashboard 。接着我们就需要整合我们的客户端，客户端说白了就是我们的服务提供者，我们的服务消费者，我们的服务提供者以及消费者需要去Eureka上面看哪些服务注册了能够消费哪些服务。 ok，还是先建一个module，然后再这个module中创建我们的服务端。 1.pom文件12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud&lt;/artifactId&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;eureka-server-7001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-server服务端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.配置文件123456789101112server: port: 7001eureka: instance: hostname: eureka7001.com #eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己。 fetch-registry: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: #单机 defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址（单机）。 defaultZone: http://eureka7003.com:7003,http://eureka7003.com:7002 注意一下这个地方我们使用了 http://eureka7003.com url 这个东西其实就是我们在 host 中配置了 127.0.0.1 形成的。 3.启动类1234567@EnableEurekaServer@SpringBootApplicationpublic class EurekaServer7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer7001.class, args); &#125;&#125; 这里唯一需要注意的就是我们这是一个Eureka的服务端，所以我们需要配置这个注解 @EnableEurekaServer 。然后同样的方法我们在建一个 Eureka的server端，就形成一个集群。 最后启动的时候我们就能发现我们的Eureka集群是有备份的。 2.配置Eureka客户端1.配置生产者1.配置pom12345678910&lt;!-- actuator监控信息完善 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 将微服务provider侧注册进eureka --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; 2.配置启动类12345678@EnableEurekaClient@SpringBootApplication@MapperScan(\"lwen.dao\")public class DeptApp8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptApp8001.class, args); &#125;&#125; 主要就是添加 @EnableEurekaClient 注解。 3.配置yml12345678eureka: client: #客户端注册进eureka服务列表内 service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ instance: instance-id: cloud-dept8001 prefer-ip-address: true #访问路径可以显示IP地址 3.配置消费者1.配置pom同上 2.配置启动类需要加上Ribbon 的配置，因为我们需要使用为服务名去调用对应的服务，而不再采用以前的url地址了。@RibbonClient(name = &quot;CLOUD-DEPT&quot;) 3.配置RestTemplate123456789@Configurationpublic class RestConfig &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 进行负载均衡 4.配置yml12345eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 这里就是相对于上面我们没有配置 instance 这是因为我们的消费者只是在上面寻找服务提供者消费这些提供者，而不用去注册这些消费者。 3.配置负载均衡Ribbon 就是用来做负载均衡的。只是和一般的负载均衡的处理方式不同的是这个东西是客户端的负载均衡，所谓的客户端负载均衡就是我们的服务消费者会过来消费服务的时候对当前的生产者的状态进行判断，然后消费者主动去找负载比较轻的服务端去做消费。 所以说我们的客户端（消费者）就自带了负载均衡的策略，而不是说我们的客户端来了以后我们有一个中间的件，例如我们常用的 Nginx ，来判断我们采用什么策略来完成这个客户端的访问请求。 那么很明显，我们的代码必须是写在客户端这一方，其实真正的负载均衡在 SpringCloud 中非常简单，就是开启负载均衡，然后在我们的 rest 客户端添加一个负载均衡的标志，也就是我们的 rest 客户端是最后真正去访问我们的客户端的，所以说配置起来就两步，最后我们可以对他们的负载均衡的策略进行调整。 1.开启负载均衡@RibbonClient(name = &quot;CLOUD-DEPT&quot;) 我们只需要在主类上加上这个我们就算是开启了负载均衡的功能，需要注意的一点就是我们需要在上面说明对哪个服务访问的时候采用负载均衡，因为有的服务可以负债均衡有的根本不需要，接下来我们只需要对 rest 客户端修改修改即可。 12345678@RibbonClient(name = \"CLOUD-DEPT\")@EnableEurekaClient@SpringBootApplicationpublic class DeptConsumerApp81 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumerApp81.class, args); &#125;&#125; 2.rest 客户端启用负载均衡可以看到下面的代码我们只需要在这个rest客户端的获取的时候添加一个注解我们的rest客户端就拥有了负载均衡的功能。 12345678@Configurationpublic class RestConfig &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 3.自定义负载均衡算法对于Nginx我们肯定熟悉的就是他有很多的自定义算法，也就是用来做负载均衡的。当然这个地方默认的负载均衡的算法就是轮询，然后我们还可以自定义一些： 可以看到这里有很多的负载均衡的算法，那些具体的类其实都是算法，然后可以看到有一个 MyLBRule1 这个是我自定义的一个负载均衡算法，其实很简单就是拷贝一个类然后照着他的样子重写 choose 方法即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package rules;import com.netflix.client.config.IClientConfig;import com.netflix.loadbalancer.AbstractLoadBalancerRule;import com.netflix.loadbalancer.ILoadBalancer;import com.netflix.loadbalancer.Server;import java.util.List;public class RandomRule_ZY extends AbstractLoadBalancerRule&#123; // total = 0 // 当total==5以后，我们指针才能往下走， // index = 0 // 当前对外提供服务的服务器地址， // total需要重新置为零，但是已经达到过一个5次，我们的index = 1 // 分析：我们5次，但是微服务只有8001 8002 8003 三台，OK？ // private int total = 0; // 总共被调用的次数，目前要求每台被调用5次 private int currentIndex = 0; // 当前提供服务的机器号 public Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; return null; &#125; Server server = null; while (server == null) &#123; if (Thread.interrupted()) &#123; return null; &#125; List&lt;Server&gt; upList = lb.getReachableServers(); List&lt;Server&gt; allList = lb.getAllServers(); int serverCount = allList.size(); if (serverCount == 0) &#123; /* * No servers. End regardless of pass, because subsequent passes only get more * restrictive. */ return null; &#125;// int index = rand.nextInt(serverCount);// java.util.Random().nextInt(3);// server = upList.get(index); // private int total = 0; // 总共被调用的次数，目前要求每台被调用5次// private int currentIndex = 0; // 当前提供服务的机器号 if(total &lt; 5) &#123; server = upList.get(currentIndex); total++; &#125;else &#123; total = 0; currentIndex++; if(currentIndex &gt;= upList.size()) &#123; currentIndex = 0; &#125; &#125; if (server == null) &#123; /* * The only time this should happen is if the server list were somehow trimmed. * This is a transient condition. Retry after yielding. */ Thread.yield(); continue; &#125; if (server.isAlive()) &#123; return (server); &#125; // Shouldn't actually happen.. but must be transient or a bug. server = null; Thread.yield(); &#125; return server; &#125; @Override public Server choose(Object key) &#123; return choose(getLoadBalancer(), key); &#125; @Override public void initWithNiwsConfig(IClientConfig clientConfig) &#123; // TODO Auto-generated method stub &#125;&#125; 这是一个简单的算法，也就是用来每个服务器轮询5次的算法。 4.面向接口的服务调用前面我们都看到了关于我们的微服务的调用其实就是使用我们的 rest 客户端去请求我们的生产者的 controller ，那么我们是不是能够使用更简洁的方式去调用我们的生产者的服务呢？也就是我们不再用手动的注入我们的 restTemplate 而是直接类似于我们以前那样直接调用我们的服务端的controller。 并且当我们可以使用这个面向接口的服务以后我们又如何进行负载均衡呢，因为我们以前的负载均衡的方式就是采用的对 rest 客户端添加注解，这里我们因为采用了接口的调用方式又如何使用负载均衡，这里 Feign 就帮助我们解决了这一系列的问题。 首先可以知道的是： Feign 也是一个基于客户端的面向接口的服务，所以我们需要在客户端进行配置，由于他是一个发布的controller 服务我们直接把他定义到 api 层面即可。然后我们在需要调用这个服务的地方也需要进行 Feign 的配置，也就是需要配置消费者。这样我们才能识别到 Feign 才对。 1.配置 API我们建立一个 service 包，然后我们在这个包里写一个接口 注意是一个接口，因为我们是面向接口编程 的，这里主要要注意的就是我们的 url 就是我们以前的 rest 客户端的请求的 url 说啊比了就是我们服务提供者的方法的 url 。 那么另外一个非常重要的地方就是我们的 @FeignClient 这个说明了我们的接口就是一个 Feign 的 rest 调用接口 . 12345678910111213141516package lwen.service;import lwen.entries.Dept;import org.springframework.cloud.netflix.feign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PostMapping;import java.util.List;@FeignClient(&quot;CLOUD-DEPT&quot;)public interface DeptClientService &#123; @GetMapping(&quot;/dept/list&quot;) List&lt;Dept&gt; findAll(); @PostMapping(&quot;/dept&quot;) Boolean insertDept(Dept dept);&#125; 2.配置消费者我们配置好了客户端其实我们就可以进行服务访问了,这里我们为了可以直接访问接口服务我们创建一个新的服务端的服务。 首先我们需要在主类上开启我们的 Feign 也就是使用注解 @EnableFeignClients 12345678@EnableFeignClients(\"lwen.service\")@EnableEurekaClient@SpringBootApplicationpublic class DeptConsumerFeignApp82 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumerFeignApp82.class, args); &#125;&#125; 然后就是我们的，controller了这里就是去请求我们的后台的的服务提供者的 controller 层。 123456789101112131415161718192021222324252627package lwen.controller;import lwen.entries.Dept;import lwen.service.DeptClientService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import java.util.List;@RestControllerpublic class DeptController &#123; @Autowired private DeptClientService deptClientService; @GetMapping(\"/dept/list\") public List findAll() &#123; return deptClientService.findAll(); &#125; @PostMapping(\"/dept\") public Boolean insertDept(Dept dept) &#123; return deptClientService.insertDept(dept); &#125;&#125; 其实当我们写完这些东西配置都正确了以后我们就会发现我们的 ide 会有非常智能的提示，也就是把我们暴露的服务的controller 的方法显示成可运行的状态。 很神奇，接着我们就可以准备解决负载均衡的问题了。 3.负载均衡好的，我们的 rest 客户端被省略了，那么我们如何进行负载均衡这是一个问题。但是事实上我们完全不用担心如何进行负载均衡，这是因为我们的 Feign 已经帮我们整合好了这些东西。 是的，也就是我们在标注 @FeignClient 这个注解的时候我们已经配置了负载均衡，在我们的每一个方法之上，并且他的默认的负载均衡的策略就是轮训方式，现在我们就可以启动我们的服务然后测试一下。的确是这样。 可是我们以前还可以对服务是可以进行负载均衡的策略进行定制的，其实这个也很简单，我们只需要在我们的API端写好我们的配置类即可。 123456789@FeignClient(value = \"CLOUD-DEPT\",configuration = MyRuleConfig.class)public interface DeptClientService &#123; @GetMapping(\"/dept/list\") List&lt;Dept&gt; findAll(); @PostMapping(\"/dept\") Boolean insertDept(Dept dept);&#125; 可以看到我们的注解上加了新的属性，就是用来配置负载均衡的，并且值得注意的是他和 Ribbon 的负载均衡的属性一模一样。 5.服务熔断与服务降级1.基本概念其实在我们的应用中很有可能会出现服务压力太大的情况，这时候为了避免我们服务发生雪崩我们需要对他们进行必要的处理，比如这里提到的服务熔断和服务降级。 服务熔断：服务熔断一般是指软件系统中，由于某些原因使得服务出现了过载现象，为防止造成整个系统故障，从而采用的一种保护措施，所以很多地方把熔断亦称为过载保护。 这个其实就是在我们服务被熔断的时候还需要给客户端返回一个符合预期的友好的结果。 服务降级 ：旅行箱是必备物，平常走走近处绰绰有余，但一旦出个远门，再大的箱子都白搭了，怎么办呢？常见的情景就是把物品拿出来分分堆，比了又比，最后一些非必需品的就忍痛放下了，等到下次箱子够用了，再带上用一用。而服务降级，就是这么回事，整体资源快不够了，忍痛将某些服务先关掉，待渡过难关，再开启回来。 但是这个过程中我们的关闭的服务也必须要返回一些友好的提示，不能让客户端调用抛出异常或者长时间等待。 2.熔断降级的异同所以从上述分析来看，两者其实从有些角度看是有一定的类似性的： 目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段； 最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用； 粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改）； 自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段； 而两者的区别也是明显的： 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑； 管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 实现方式不太一样，这个区别后面会单独来说 3.服务熔断配置服务熔断的话一般来说我们只需要对于我们的生产者的某个方法进行熔断处理，说的简单点就是但我们的服务出现问题，需要被熔断的的时候我们需要有一个保险机制然后给客户端符合预期的结果，也就是我们的熔断以后的句柄（Handler）。 首先创建一个新的 Module ，然后我们需要在主启动类上面加上对熔断的支持。@EnableCircuitBreaker 1234567891011121314151617181920212223242526package lwen.controller;import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import lwen.entries.Dept;import lwen.service.DeptService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import java.util.List;@RestControllerpublic class DeptController &#123; @Autowired DeptService deptService; @HystrixCommand(fallbackMethod = \"findAllFallBack\") @GetMapping(\"/dept/list\") public List&lt;Dept&gt; findAll() &#123; return deptService.findAll(); &#125; @PostMapping(\"/dept\") public Boolean insertDept(Dept dept) &#123; return deptService.insertDept(dept); &#125; public Dept findAllFallBack() &#123; return new Dept().setName(\"No such data ...\"); &#125;&#125; 可以看到上面的这个controller 就是我们对 findAll 这个方法进行了服务熔断的处理，也就是当我们服务出现问题的时候我们的熔断句柄就会被调用。这里就是我们设置的 fallback 。 因为这个方法肯定会抛出异常，所以我们也自然会调用我们的 fallback 4.服务降级配置服务降级一般是对于整个的一个服务来说的，所以我们的降级配置直接就配置在API中就好。 首先就是添加一个 FallbackFactory 主要就是对我们的服务每一个方法进行降级的句柄。 123456789101112131415161718192021222324252627282930package lwen.service;import feign.hystrix.FallbackFactory;import lwen.entries.Dept;import org.springframework.stereotype.Component;import java.util.ArrayList;import java.util.List;@Component // 不要忘记添加，不要忘记添加public class DeptClientServiceFallbackFactory implements FallbackFactory&lt;DeptClientService&gt;&#123; @Override public DeptClientService create(Throwable throwable) &#123; return new DeptClientService() &#123; @Override public List&lt;Dept&gt; findAll() &#123; ArrayList&lt;Dept&gt; list = new ArrayList&lt;&gt;(); list.add(new Dept().setName(\"No such data\")); return list; &#125; @Override public Boolean insertDept(Dept dept) &#123; return null; &#125; &#125;; &#125;&#125; 在我们的 API 中添加 @FeignClient(value = &quot;CLOUD-DEPT&quot;, configuration = MyRuleConfig.class, fallbackFactory = DeptClientServiceFallbackFactory.class) 也就是我们的 fallbackFactory 6.服务网关服务网关就相当于我们网络中的网关一样，住哟啊就用着请求的转发代理作用。然后这里我们的目的就是把所有的微服务都放在内网，然后我们只对外暴露网关即可，这样我们的微服务才会更加的安全。 在 SpringCloud 中我们使用的网关是 Zuul ，他是一个独立的微服务，所以我们自己建立一个新的服务。这个服务其实只需要一个启动类和一个配置文件即可。 1.配置主类12345678910111213package lwen;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@EnableZuulProxy@SpringBootApplicationpublic class DeptZuul9527 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptZuul9527.class, args); &#125;&#125; 2.配置文件1234567891011121314151617181920212223server: port: 9527spring: application: name: microservicecloud-zuul-gatewayeureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka instance: instance-id: gateway-9527.com prefer-ip-address: truezuul: #ignored-services: microservicecloud-dept prefix: /lwen #服务前缀 ignored-services: \"*\" routes: mydept.serviceId: cloud-dept mydept.path: /mydept/** #服务路径 后面接的就是我们的controller 的地址 之后我们就可以访问对应的地址 http://localhost:8080/lwen/mydept/controller_url 7.统一配置服务我们的开发过程中有时候为了更方便的股那里我们所有的微服务的配置文件我们可以单独启动一个微服务专门用来管理我们其他的微服务的配置文件，这里我们要做的就是这么一件事，采用的东西就叫做 Config 组件。 1.创建服务首先还是创建一个新的服务，因为我们是使用一个独立的微服务来管理其他的微服务。这个微服务基本和我们一个普通的SpringBoot 应用没区别，但是我们还是需要加入我们的配置模块。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;spring-cloud&lt;/artifactId&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;dept-config-3344&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- springCloud Config --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 避免Config的Git插件报错：org/eclipse/jgit/api/TransportConfigCallback --&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jgit&lt;/groupId&gt; &lt;artifactId&gt;org.eclipse.jgit&lt;/artifactId&gt; &lt;version&gt;4.10.0.201712302008-r&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 图形化监控 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 熔断 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 热部署插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.主类1234567891011package lwen;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class DeptConfigApp3344 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConfigApp3344.class, args); &#125;&#125; 3.配置文件1234567891011server: port: 3344spring: application: name: cloud-config cloud: config: server: git: uri: https://github.com/lwenxu/springcloudconfig.git #GitHub上面的git仓库名字 其实我们的主类基本没有任何的特别的地方，最主要的就是我们的配置文件，这里我们配置了我们 config 的server 也就是我们仓库的地址。这个东西并不需要我们配置 ssh ，这是因为我们的仓库主要是公开的我们的服务就可以访问到。 4.配置客户端客户端我们需要一个新的配置文件，做一些通用的不可变的配置，这是 boostrap.yml 配置文件 1234567spring: cloud: config: name: application #需要从github上读取的资源名称，注意没有yml后缀名# profile: test #本次访问的配置项 label: master uri: http://config-3344.com:3344 #本微服务启动后先去找3344号服务，通过SpringCloudConfig获取GitHub的服务地址 下面是我们的 springboot 的配置文件： 123spring: application: name: microservicecloud-config-client","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://lwenxu.coding.me/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://lwenxu.coding.me/tags/SpringCloud/"}]},{"title":"SpringCloud：基础","slug":"SpringCloud/SpringCloud：SpringCloud基础","date":"2018-05-25T12:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/25/SpringCloud/SpringCloud：SpringCloud基础/","link":"","permalink":"http://lwenxu.coding.me/2018/05/25/SpringCloud/SpringCloud：SpringCloud基础/","excerpt":"","text":"SpringCloud：基础SpringCloud 是微服务架构的一个实现框架，说他是一个框架更不如说他是一个生态，他包含了很多个技术，将这些技术组合起来形成我们的微服务架构应用。 1.SpringCloud vs Dubbo 最大区别：SpringCloud抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式。 严格来说，这两种方式各有优劣。虽然从一定程度上来说，后者牺牲了服务调用的性能，但也避免了上面提到的原生RPC带来的问题。而且REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更加合适。 很明显，Spring Cloud的功能比DUBBO更加强大，涵盖面更广，而且作为Spring的拳头项目，它也能够与Spring Framework、Spring Boot、Spring Data、Spring Batch等其他Spring项目完美融合，这些对于微服务而言是至关重要的。使用Dubbo构建的微服务架构就像组装电脑，各环节我们的选择自由度很高，但是最终结果很有可能因为一条内存质量不行就点不亮了，总是让人不怎么放心，但是如果你是一名高手，那这些都不是问题；而Spring Cloud就像品牌机，在Spring Source的整合下，做了大量的兼容性测试，保证了机器拥有更高的稳定性，但是如果要在使用非原装组件外的东西，就需要对其基础有足够的了解。 2.微服务搭建实例我们准备了四个模块，然后这四个模块分别就是用来做统一项目管理的 parent 、一个公共的 api 比如通用的实体类 、一个服务提供者和一个服务消费者。 这样我们形成了一个简单的微服务架构的程序了，接下来就是一步一步的搭建这个框架，这里采用的是 Idea 来搭建项目。 1.创建parent工程首先我们创建一个Maven项目，注意一点的就是再生成这个项目的时候我们的打包方式要选择 pom 而不是 jar 或者 war，然后这个项目会自动生成一堆的文件夹，其实我们只需要这个 pom 文件，因为只需要做版本控制，而不用写代码的地方。那么我们就删除那些 java 、test 文件夹。 那么现在我们的 parent 工程就创建好了，接着就是做一些版本依赖的处理了，我们就需要在pom文件中添加如下的内容。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--我们的子模块--&gt; &lt;modules&gt; &lt;module&gt;cloud-api&lt;/module&gt; &lt;module&gt;provider-dept-8001&lt;/module&gt; &lt;module&gt;consumer-dept-80&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.0.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.31&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;finalName&gt;microservicecloud&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;delimit&gt;$&lt;/delimit&gt; &lt;/delimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 注意一点的就是因为我这个pom文件是所有工程都创建好的工程的 pom 所以说这里我的 子模块 是后来加上去的，可以直接删了后面真的在创建子模块的时候会自动生成这些东西。 2.创建公共的api接着我们在我们创建好的 parent 工程上 右键创建一个新的 module 然后我们项目结构还是选择 Maven 注意一点的就是我们在创建项目的时候可以选择父工程，我们在这里就选择我们创建好的 parent 工程。 那么生成好的项目就会有这么一段文字： 12345&lt;parent&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt; 然后我们在里面加一些我们常用的依赖以后，我们的pom就会长成这个样子： 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-api&lt;/artifactId&gt; &lt;dependencies&gt;&lt;!-- 当前Module需要用到的jar包，按自己需求添加，如果父类已经包含了，可以不用写版本号 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 好的，现在我们的基础配置已经配置好了，就可以在 api 中写代码了。我们这里需要共享的 api 其实就是我们的实体类，实际上还有很多，这里我们就仅仅拿实体类做例子。 创建一个 entries 包 然后创建一个实体类： 1234567891011121314151617181920package entries;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import lombok.experimental.Accessors;import java.io.Serializable;@NoArgsConstructor@AllArgsConstructor@Data@Accessors(chain = true)//必须实现序列化接口public class Dept implements Serializable &#123; private Long deptno; private String dname; private String db_source;&#125; 由于我们上面添加了 小辣椒 的依赖，这里的实体类非常简单。 这步完成了就应该是这样的一个结构，然后我们就可以开始生产者的创建了。 3.生产者生产者里面其实我们应该包含一个完整的 web 层，也就是说我们需要有完整的 Controller 、Service、Dao 然后我们的Controller是用来给后面的消费者调用的，因为我们的SpringCloud是基于Rest请求的嘛。 同理我们创建一个Maven项目，然后导入父工程，接着就是导入依赖： 1.导入依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;artifactId&gt;provider-dept-8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- 引入自己定义的api通用包，可以使用Dept部门Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;artifactId&gt;cloud-api&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.配置springboot配置文件123456789101112131415161718192021server: port: 8001spring: application: name: cloud-dept datasource: type: com.alibaba.druid.pool.DruidDataSource # 当前数据源操作类型 driver-class-name: org.gjt.mm.mysql.Driver # mysql驱动包 url: jdbc:mysql://localhost:3306/cloudDB01 # 数据库名称 username: root password: dbcp2: min-idle: 5 # 数据库连接池的最小维持连接数 initial-size: 5 # 初始化连接数 max-total: 5 # 最大连接数 max-wait-millis: 200 # 等待连接获取的最大超时时间 mybatis: configuration: map-underscore-to-camel-case: true 3.dao12345678910111213141516package lwen.dao;import lwen.entries.Dept;import org.apache.ibatis.annotations.Insert;import org.apache.ibatis.annotations.Select;import java.util.List;public interface DeptDao &#123; @Select(\"select * from clouddb01.dept\") public List&lt;Dept&gt; findAll(); @Insert(\"insert into clouddb01.dept(name, db_name) values (#&#123;name&#125;,database())\") boolean insertDept(Dept dept);&#125; 4.Service12345678910111213141516171819202122package lwen.service;import lwen.dao.DeptDao;import lwen.entries.Dept;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class DeptService &#123; @Autowired DeptDao deptDao; public List&lt;Dept&gt; findAll() &#123; return deptDao.findAll(); &#125; public Boolean insertDept(Dept dept) &#123; return deptDao.insertDept(dept); &#125;&#125; 5.controller1234567891011121314151617181920212223242526package com.lwen.controller;import entries.Dept;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import com.lwen.service.DeptService;import java.util.List;@RestControllerpublic class DeptController &#123; @Autowired DeptService deptService; @GetMapping(\"/dep\") public List&lt;Dept&gt; list() &#123; return deptService.list(); &#125; @GetMapping(\"/dep/add\") public Integer insert(Dept dept) &#123; return deptService.add(dept); &#125;&#125; 4.消费者同上创建一个module，完成消费者的编写。 消费者其实只有一个Controller，这是因为我们的真正的业务逻辑都被封装到我们的微服务中去了，所以说不存在后面的Service以及Dao。 1.导入依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;parent&lt;/artifactId&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;artifactId&gt;consumer-dept-80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt;&lt;!-- 自己定义的api --&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;artifactId&gt;cloud-api&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Ribbon相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 修改后立即生效，热部署 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.配置文件12server: port: 81 3.config1234567891011121314package com.lwen.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class BeanConfig &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 这个地方我使用了 JavaConfig 配置了一个 RestTemplate 的Bean，然后这个东西其实就是和我们以前接触的 redisTemplate 以及 jdbc的一样，就是一个工具，用来简化操作的。这里就是简化我们的 rest 请求操作，相当于一个 Http 的客户端。 4.Controller123456789101112131415161718192021222324252627282930package com.lwen.controller;import entries.Dept;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;import java.util.List;@RestControllerpublic class DeptController &#123; public static final String PREFIX_URL = \"http://localhost:8001/\"; @Autowired RestTemplate restTemplate; @GetMapping(\"/list\") public List list() &#123; return restTemplate.getForObject(PREFIX_URL + \"dep\", List.class); &#125; @GetMapping(\"/dep/add\") public Integer add(Dept dept) &#123; return restTemplate.getForObject(PREFIX_URL + \"dep/add\",Integer.class); &#125;&#125; 好，现在我们的项目搭建完毕，目前的目录架构应该是这样的：","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://lwenxu.coding.me/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://lwenxu.coding.me/tags/SpringCloud/"}]},{"title":"SpringCloud：微服务","slug":"SpringCloud/SpringCloud：微服务","date":"2018-05-25T12:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/25/SpringCloud/SpringCloud：微服务/","link":"","permalink":"http://lwenxu.coding.me/2018/05/25/SpringCloud/SpringCloud：微服务/","excerpt":"","text":"1.微服务微服务其实就是我们的以前的整个应用拆分的一个个小的应用服务，也就是我们的一个个模块。每一个微服务就是一个进程，运行在一个独立的进程之上，然后通过网络进行通讯互联。 2.微服务架构微服务架构是一种架构模式，他是把传统的单体应用(All in one)，拆分成多个项目独立的微服务，然后每一个为服务都是一个独立进程，拥有自己的独立的数据库。然后各个微服务的整合形成整个的微服务架构。 3.微服务的优缺点1.优点： 每一个服务就是一个聚焦一个功能 单个服务开发简单 服务解耦 小而精 2.缺点： 部署困难，部署依赖 排查困难 服务通讯的成本 数据的一致性 集成测试 性能监控 4.微服务技术栈 微服务条目 技术 服务开发 Springboot、Spring、SpringMVC 服务配置与管理 Netflix公司的Archaius、阿里的Diamond等 服务注册与发现 Eureka、Consul、Zookeeper等 服务调用 Rest、RPC、gRPC 服务熔断器 Hystrix、Envoy等 负载均衡 Ribbon、Nginx等 服务接口调用（客户端调用服务的简化工具） Feign等 消息队列 Kafka、RabbitMQ、ActiveMQ等 服务配置中心管理 SpringCloudConfig、Che等 服务路由（API网关) Zuul 服务监控 Zabbix、Nagios、Metrics、Spectator等 全链路追踪 Zipkin,Brave、Dapper等 服务部署 Docker、OpenStack、Kubernetes等 数据流操作开发包 SpringCloud Stream（封装与Redis,Rabbit、Kafka等发送接收消息） 事件消息总线 Spring Cloud Bus 5.SpringCloud这里我们的SpringCloud就是一个微服务架构的框架的具体实现了。同样的还有很多其他的微服务架构，比如现在非常出名的Dubbo 以及京东的 JSF 新浪的 Motai","categories":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://lwenxu.coding.me/categories/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://lwenxu.coding.me/tags/SpringCloud/"}]},{"title":"SpringBoot 笔记(十)：错误处理","slug":"SpringBoot/SpringBoot 笔记 ( 十 )：错误处理","date":"2018-05-24T02:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/24/SpringBoot/SpringBoot 笔记 ( 十 )：错误处理/","link":"","permalink":"http://lwenxu.coding.me/2018/05/24/SpringBoot/SpringBoot 笔记 ( 十 )：错误处理/","excerpt":"SpringBoot 笔记 ( 十 )：错误处理1）、SpringBoot默认的错误处理机制默认效果： ​ 1）、浏览器，返回一个默认的错误页面 2）、如果是其他客户端，默认响应一个json数据","text":"SpringBoot 笔记 ( 十 )：错误处理1）、SpringBoot默认的错误处理机制默认效果： ​ 1）、浏览器，返回一个默认的错误页面 2）、如果是其他客户端，默认响应一个json数据 2）、自动配置原理​ 具体就是在 ErrorMvcAutoConfiguration，错误处理的自动配置。 给容器中添加了以下组件1、ErrorPageCustomizer：规定错误页面 /error12@Value(\"$&#123;error.path:/error&#125;\")private String path = \"/error\"; //系统出现错误以后来到error请求进行处理,（类似与我们在web.xml注册的错误页面规则） 2、BasicErrorController：处理默认 /error 请求12345678910111213141516171819202122232425@Controller@RequestMapping(\"$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;\")public class BasicErrorController extends AbstractErrorController &#123; //处理产生html类型的数据；浏览器发送的请求来到这个方法处理 @RequestMapping(produces = \"text/html\") public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) &#123; HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //去哪个页面作为错误页面；包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView == null ? new ModelAndView(\"error\", model) : modelAndView); &#125; //处理非Html的类型的数据。产生json数据，其他客户端来到这个方法处理； @RequestMapping @ResponseBody public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123; Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity&lt;Map&lt;String, Object&gt;&gt;(body, status); &#125; 其实这里就解释了为什么我们不同的客户端会返回的数据不一样，我们采用浏览器和程序请求会不同，就是因为他们的header不一样导致的。 但是注意上面的ModelAndView对象我们是通过 resolveErrorView 来获取的，也就是下面的逻辑： 1234567891011protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map&lt;String, Object&gt; model) &#123; // 所有的 ErrorViewResolver 得到 ModelAndView for (ErrorViewResolver resolver : this.errorViewResolvers) &#123; ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) &#123; return modelAndView; &#125; &#125; return null;&#125; 然后上面在解析错误视图，调用了 resolver 的方法，这个方法其实是 DefaultErrorViewResolver 的方法。也就是下面的这个类的方法。 3、DefaultErrorViewResolver：123456789101112131415161718192021222324@Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) &#123; ModelAndView modelAndView = resolve(String.valueOf(status), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) &#123; modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); &#125; return modelAndView; &#125; private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123; //默认SpringBoot可以去找到一个页面？ error/404 String errorViewName = \"error/\" + viewName; //模板引擎可以解析这个页面地址就用模板引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); if (provider != null) &#123; //模板引擎可用的情况下返回到errorViewName指定的视图地址 return new ModelAndView(errorViewName, model); &#125; //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面 error/404.html return resolveResource(errorViewName, model); &#125; 这里主要做的事情就是，根据状态码得到模板的页面地址，然后让我们的模板引擎解析一下，如果能解析到就是返回对应的ModelAndView 否则的话就直接去静态资源的static目录找对应的状态码对应的页面404.html 4xx.html …。然后这里的model也就是我们的异常错误数据，是通过下面的组件完成的。 4、DefaultErrorAttributes12345678910 @Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); errorAttributes.put(\"timestamp\", new Date()); addStatus(errorAttributes, requestAttributes); addErrorDetails(errorAttributes, requestAttributes, includeStackTrace); addPath(errorAttributes, requestAttributes); return errorAttributes;&#125; 这个方法就是在容器里注册了一个 Map 帮我们在页面共享信息。 ​ 步骤： 一但系统出现4xx或者5xx之类的错误，ErrorPageCustomizer就会生效（定制错误的响应规则），来到/error请求 就会被BasicErrorController处理 响应页面：去哪个页面，错误信息是由DefaultErrorViewResolver解析得到的，错误信息由 getErrorAttributes 获取。 3）、定制错误响应1）、定制错误的 Html 页面1）、有模板引擎error/状态码【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到 对应的页面； 我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）。 页面能获取的信息，是由Model来确定的，也就是我们的 getErrorAttributes 方法来确定的。具体的有： timestamp：时间戳 status：状态码 error：错误提示 exception：异常对象 message：异常消息 errors：JSR303数据校验的错误都在这里 2）、没有模板引擎没有模板引擎或者说模板引擎找不到这个错误页面，那就去静态资源文件夹static下找，规则同模板引擎的规则。 3）、没有任何错误页面就是默认来到SpringBoot默认的错误提示页面 2）、如何定制错误的json数据；1）、自定义异常处理&amp;返回定制json数据这里其实就是用了 Spring 的统一异常处理，但是这样的话我们就是对所有的页面都会出现json了，没有针对不同的客户端有自适应效果。 1234567891011@ControllerAdvicepublic class MyExceptionHandler &#123; @ResponseBody @ExceptionHandler(UserNotExistException.class) public Map&lt;String,Object&gt; handleException(Exception e)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put(\"code\",\"user.notexist\"); map.put(\"message\",e.getMessage()); return map; &#125;&#125; 2）、转发到/error进行自适应响应效果处理1234567891011121314@ExceptionHandler(UserNotExistException.class) public String handleException(Exception e, HttpServletRequest request)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //传入我们自己的错误状态码 4xx 5xx，否则就不会进入定制错误页面的解析流程 /** * Integer statusCode = (Integer) request .getAttribute(\"javax.servlet.error.status_code\"); */ request.setAttribute(\"javax.servlet.error.status_code\",500); map.put(\"code\",\"user.notexist\"); map.put(\"message\",e.getMessage()); //转发到 /error return \"forward:/error\"; &#125; 这里就是通过我们自动配置的默认错误页面的控制器来处理错误页面的请求，让我们吧一些特殊的错误数据发送过去，然后直接转发到我们的错误页面即可，接下来就是SpringBoot帮助我们处理自适应问题了。 又一点要注意，就是我们这里自己设置了状态码，为什么需要这样，这是由于我们这里拦截到了错误，然后我们并没有走默认的错误处理的逻辑也就是我们的默认的错误处理的Controller没有执行，导致一些错误的状态码没有设置，但是我们最终需要渲染视图，以及寻找错误页面都是通过我们的的错误状态码的，这里找不到状态码，我们必须手动的添加上才行。否则不是去往我们的错误页面。 还有一点需要注意的就是我们虽然已经设置了一个map，但是这个map并没有被我们的模板获取到，因为根本没用我们的数据，这里我们需要 定制一下 getErrorAttributes（） 方法才行。 3）、将我们的定制数据携带出去；出现错误以后，会来到/error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）； 我们有两种方式来自定义数据： ​ 1、完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中； ​ 2、页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到，容器中DefaultErrorAttributes.getErrorAttributes()，默认进行数据处理的； 自定义ErrorAttributes 1234567891011//给容器中加入我们自己定义的ErrorAttributes@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes &#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; map = super.getErrorAttributes(requestAttributes, includeStackTrace); map.put(\"company\",\"atguigu\"); return map; &#125;&#125; 最终的效果：响应是自适应的，可以通过定制ErrorAttributes改变需要返回的内容，","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记(十一):Servlet容器","slug":"SpringBoot/SpringBoot 笔记 ( 十一 )Servlet容器","date":"2018-05-24T02:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/24/SpringBoot/SpringBoot 笔记 ( 十一 )Servlet容器/","link":"","permalink":"http://lwenxu.coding.me/2018/05/24/SpringBoot/SpringBoot 笔记 ( 十一 )Servlet容器/","excerpt":"SpringBoot 笔记 ( 十一 ):Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器 1）、定制和修改Servlet容器的相关配置1、修改配置文件中的和 server 有关的配置ServerProperties【也是EmbeddedServletContainerCustomizer】","text":"SpringBoot 笔记 ( 十一 ):Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器 1）、定制和修改Servlet容器的相关配置1、修改配置文件中的和 server 有关的配置ServerProperties【也是EmbeddedServletContainerCustomizer】 1234567server.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx 2、编写一个 EmbeddedServletContainerCustomizer嵌入式的Servlet容器的定制器，来修改Servlet容器的配置 12345678910@Bean //将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123; return new EmbeddedServletContainerCustomizer() &#123; //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8083); &#125; &#125;;&#125; 2）、注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。 注册三大组件用以下方式： 1.ServletRegistrationBean123456//注册三大组件@Beanpublic ServletRegistrationBean myServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),\"/myServlet\"); return registrationBean;&#125; 2.FilterRegistrationBean1234567@Beanpublic FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); registrationBean.setUrlPatterns(Arrays.asList(\"/hello\",\"/myServlet\")); return registrationBean;&#125; 3.ServletListenerRegistrationBean12345@Beanpublic ServletListenerRegistrationBean myListener()&#123; ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;&#125; 4、DIspatcherServlet 配置SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器，DIspatcherServlet DispatcherServletAutoConfiguration中： 1234567891011121314151617@Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration( DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean registration = new ServletRegistrationBean( dispatcherServlet, this.serverProperties.getServletMapping()); //默认拦截： / 所有请求，包静态资源，但是不拦截jsp请求； /*会拦截jsp //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径 registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME); registration.setLoadOnStartup( this.webMvcProperties.getServlet().getLoadOnStartup()); if (this.multipartConfig != null) &#123; registration.setMultipartConfig(this.multipartConfig); &#125; return registration;&#125; 3）、替换为其他嵌入式Servlet容器默认支持： 1.Tomcat（默认使用）12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; 引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器；&lt;/dependency&gt; 2.Jetty（长链接类的服务）1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 3.Undertow（高并发的不支持JSP）1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 4）、嵌入式Servlet容器自动配置原理EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration &#123; @Configuration @ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;)//判断当前是否引入了Tomcat依赖； @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器 public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123; return new JettyEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123; return new UndertowEmbeddedServletContainerFactory(); &#125; &#125; EmbeddedServletContainerFactory（嵌入式Servlet容器工厂）,主要是用来创建 EmbeddedServletContainer 也就是嵌入式的Servlet容器。这个是一个接口，也就是我们有对应的实现类，就是上面的三种嵌入式的容器。 1234567public interface EmbeddedServletContainerFactory &#123; //获取嵌入式的Servlet容器 EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers);&#125; 下面我们以 TomcatEmbeddedServletContainerFactory 分析 123456789101112131415161718192021222324@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; //创建一个Tomcat Tomcat tomcat = new Tomcat(); //配置Tomcat的基本环节 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(\"tomcat\")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer //并且启动Tomcat服务器 return getTomcatEmbeddedServletContainer(tomcat);&#125; 但是我们对嵌入式容器的配置修改是怎么生效？实际上是 ServerProperties、EmbeddedServletContainerCustomizer ：定制器帮我们修改了Servlet容器的配置，也就是我们在上面导入的 @Import(BeanPostProcessorsRegistrar.class) 然后导入了EmbeddedServletContainerCustomizerBeanPostProcessor（后置处理器）：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作。 容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor，他的配置原理 12345678910111213141516171819202122232425262728293031323334353637//初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) &#123; // postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); &#125; return bean;&#125;private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) &#123; //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值； for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) &#123; customizer.customize(bean); &#125;&#125;private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() &#123; if (this.customizers == null) &#123; // Look up does not include the parent context this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;( this.beanFactory //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); &#125; return this.customizers;&#125;ServerProperties也是定制器 步骤： 1）、SpringBoot根据导入的依赖情况，给容器中添加相应的 EmbeddedServletContainerFactory 比如这里就是TomcatEmbeddedServletContainerFactory 2）、容器中某个组件要创建对象就会调用后置处理器：EmbeddedServletContainerCustomizerBeanPostProcessor。 只要是嵌入式的容器工厂，后置处理器就工作。 3）、后置处理器，从容器中获取所有的 EmbeddedServletContainerCustomizer，调用定制器的定制方法，而我们的ServerProperties 就是我们要的定制器。 5）、嵌入式Servlet容器启动原理什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat； 获取嵌入式的Servlet容器工厂： 1）、SpringBoot应用启动运行run方法2）、refreshContext(context)SpringBoot刷新IOC容器，也就是创建IOC容器对象，并初始化容器，创建容器中的每一个组件，这里需要判断如果是web应用创建 AnnotationConfigEmbeddedWebApplicationContext，否则创建AnnotationConfigApplicationContext 3）、refresh(context)刷新刚才创建好的ioc容器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 4）、 onRefresh() web的ioc容器重写了onRefresh方法，web 的 ioc容器会创建嵌入式的Servlet容器，createEmbeddedServletContainer()。 5）、获取嵌入式的Servlet容器工厂createEmbeddedServletContainer() 这个方法的第一步就是去创建这个工厂，getEmbeddedServletContainerFactory。 EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); 从ioc容器中获取EmbeddedServletContainerFactory 组件，TomcatEmbeddedServletContainerFactory 创建对象，后置处理器就获取所有的定制器来先定制Servlet容器的相关配置。完成配置和启动。 6）、使用容器工厂获取嵌入式的Servlet容器this.embeddedServletContainer = containerFactory.getEbeddedServletContainer(getSelfInitializer()); 7）、嵌入式的Servlet容器创建对象并启动Servlet容器先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来，这个时候我们自己写的Controller Service 以及各种配置类才会生效。 6）、使用外置的Servlet容器我们采用嵌入式Servlet容器，这样我们的应用打成可执行的jar 优点：简单、便携 缺点：默认不支持JSP、优化定制比较复杂（使用定制器ServerProperties、自定义EmbeddedServletContainerCustomizer，自己编写嵌入式Servlet容器的创建工厂EmbeddedServletContainerFactory） 所以我们可以使用外置的Servlet容器：外面安装Tomcat—应用war包的方式打包； 1.步骤1）、必须创建一个war项目，我们还是使用 SpringBootInitlizer 这个工具创建项目，但是注意我们在创建项目的时候我们选择部署的方式为 war 就可以生成 war的形式。 然后我们需要去项目的结构地方的web模块点击我们的目录结构让他自动生成webapp 目录。生成在 src/main 下面。然后就是生成 web 应用描述符，也就是生成 web.xml 接着我们需要修改应用的启动配置，自己添加一个tomcat的服务器。然后在 deploy 这个地方加入我们的 war包。 2）、将嵌入式的Tomcat指定为provided； 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3）、必须编写一个SpringBootServletInitializer的子类类名随意但是必须继承，并调用configure方法 123456789public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //传入SpringBoot应用的主程序 return application.sources(SpringBoot04WebJspApplication.class); &#125;&#125; 4）、启动服务器就可以使用； 2.启动原理1. 打包方式 jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器。 war包：启动服务器，然后服务器启动SpringBoot应用，使用的是 SpringBootServletInitializer，启动ioc容器。 servlet3.0一个规范： ​ 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面 ServletContainerInitializer 实例 ​ 2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名 ​ 3）、还可以使用 @HandlesTypes，在应用启动的时候加载我们感兴趣的类 2.启动流程：1）、启动Tomcat2）、SpringServletContainerInitializer 的调用org\\springframework\\spring-web\\4.3.14.RELEASE\\spring-web-4.3.14.RELEASE.jar!\\META-INF\\services\\javax.servlet.ServletContainerInitializer：Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer 也就是我们应用启动的时候会创建这个对象。 3）、创建 @HandlesTypes 的对象SpringServletContainerInitializer 将 @HandlesTypes(WebApplicationInitializer.class) 标注的所有这个类型的类都传入到 onStartup 方法的 Set&lt;Class&lt;?&gt;&gt;，为这些 WebApplicationInitializer 类型的类创建实例 4）、调用 onStartup 方法每一个 WebApplicationInitializer 都调用自己的onStartup； 5）、SpringBootServletInitializer 的 onStartup我们的 SpringBootServletInitializer 的类是继承自 WebApplicationInitializer 并且被放到了@HandlesTypes里，所以会被创建对象，并执行onStartup方法，也就是我们采用 war 包工程生成的这个类。 6）、创建 ICO 容器SpringBootServletInitializer实例执行onStartup的时候会 createRootApplicationContext 创建容器 1234567891011121314151617181920212223242526272829303132333435363738protected WebApplicationContext createRootApplicationContext( ServletContext servletContext) &#123; //1、创建SpringApplicationBuilder SpringApplicationBuilder builder = createSpringApplicationBuilder(); StandardServletEnvironment environment = new StandardServletEnvironment(); environment.initPropertySources(servletContext, null); builder.environment(environment); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; this.logger.info(\"Root context already created (using as parent).\"); servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers( new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class); //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来 builder = configure(builder); //使用builder创建一个Spring应用 SpringApplication application = builder.build(); if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils .findAnnotation(getClass(), Configuration.class) != null) &#123; application.getSources().add(getClass()); &#125; Assert.state(!application.getSources().isEmpty(), \"No SpringApplication sources have been defined. Either override the \" + \"configure method or add an @Configuration annotation\"); // Ensure error pages are registered if (this.registerErrorPageFilter) &#123; application.getSources().add(ErrorPageFilterConfiguration.class); &#125; //启动Spring应用 return run(application);&#125; 7）、Spring的应用就启动并且创建IOC容器1234567891011121314151617181920212223242526272829303132333435public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新IOC容器 refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 先启动Servlet容器，然后容器根据我们的Servlet的3.0 的标准，去启动我们SpringBoot 下生成的一个类，这个类再启动SpringBoot应用。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记(十一):Servlet容器","slug":"SpringBoot/SpringBoot 笔记 ( 十一 )：Servlet容器","date":"2018-05-24T02:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/24/SpringBoot/SpringBoot 笔记 ( 十一 )：Servlet容器/","link":"","permalink":"http://lwenxu.coding.me/2018/05/24/SpringBoot/SpringBoot 笔记 ( 十一 )：Servlet容器/","excerpt":"SpringBoot 笔记 ( 十一 ):Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器 1）、定制和修改Servlet容器的相关配置1、修改配置文件中的和 server 有关的配置ServerProperties【也是EmbeddedServletContainerCustomizer】","text":"SpringBoot 笔记 ( 十一 ):Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器 1）、定制和修改Servlet容器的相关配置1、修改配置文件中的和 server 有关的配置ServerProperties【也是EmbeddedServletContainerCustomizer】 1234567server.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx 2、编写一个 EmbeddedServletContainerCustomizer嵌入式的Servlet容器的定制器，来修改Servlet容器的配置 12345678910@Bean //将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123; return new EmbeddedServletContainerCustomizer() &#123; //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8083); &#125; &#125;;&#125; 2）、注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。 注册三大组件用以下方式： 1.ServletRegistrationBean123456//注册三大组件@Beanpublic ServletRegistrationBean myServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),\"/myServlet\"); return registrationBean;&#125; 2.FilterRegistrationBean1234567@Beanpublic FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); registrationBean.setUrlPatterns(Arrays.asList(\"/hello\",\"/myServlet\")); return registrationBean;&#125; 3.ServletListenerRegistrationBean12345@Beanpublic ServletListenerRegistrationBean myListener()&#123; ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;&#125; 4、DIspatcherServlet 配置SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器，DIspatcherServlet DispatcherServletAutoConfiguration中： 1234567891011121314151617@Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration( DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean registration = new ServletRegistrationBean( dispatcherServlet, this.serverProperties.getServletMapping()); //默认拦截： / 所有请求，包静态资源，但是不拦截jsp请求； /*会拦截jsp //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径 registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME); registration.setLoadOnStartup( this.webMvcProperties.getServlet().getLoadOnStartup()); if (this.multipartConfig != null) &#123; registration.setMultipartConfig(this.multipartConfig); &#125; return registration;&#125; 3）、替换为其他嵌入式Servlet容器默认支持： 1.Tomcat（默认使用）12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; 引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器；&lt;/dependency&gt; 2.Jetty（长链接类的服务）1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 3.Undertow（高并发的不支持JSP）1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 4）、嵌入式Servlet容器自动配置原理EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration &#123; @Configuration @ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;)//判断当前是否引入了Tomcat依赖； @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器 public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123; return new JettyEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123; return new UndertowEmbeddedServletContainerFactory(); &#125; &#125; EmbeddedServletContainerFactory（嵌入式Servlet容器工厂）,主要是用来创建 EmbeddedServletContainer 也就是嵌入式的Servlet容器。这个是一个接口，也就是我们有对应的实现类，就是上面的三种嵌入式的容器。 1234567public interface EmbeddedServletContainerFactory &#123; //获取嵌入式的Servlet容器 EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers);&#125; 下面我们以 TomcatEmbeddedServletContainerFactory 分析 123456789101112131415161718192021222324@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; //创建一个Tomcat Tomcat tomcat = new Tomcat(); //配置Tomcat的基本环节 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(\"tomcat\")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer //并且启动Tomcat服务器 return getTomcatEmbeddedServletContainer(tomcat);&#125; 但是我们对嵌入式容器的配置修改是怎么生效？实际上是 ServerProperties、EmbeddedServletContainerCustomizer ：定制器帮我们修改了Servlet容器的配置，也就是我们在上面导入的 @Import(BeanPostProcessorsRegistrar.class) 然后导入了EmbeddedServletContainerCustomizerBeanPostProcessor（后置处理器）：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作。 容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor，他的配置原理 12345678910111213141516171819202122232425262728293031323334353637//初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) &#123; // postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); &#125; return bean;&#125;private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) &#123; //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值； for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) &#123; customizer.customize(bean); &#125;&#125;private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() &#123; if (this.customizers == null) &#123; // Look up does not include the parent context this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;( this.beanFactory //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); &#125; return this.customizers;&#125;ServerProperties也是定制器 步骤： 1）、SpringBoot根据导入的依赖情况，给容器中添加相应的 EmbeddedServletContainerFactory 比如这里就是TomcatEmbeddedServletContainerFactory 2）、容器中某个组件要创建对象就会调用后置处理器：EmbeddedServletContainerCustomizerBeanPostProcessor。 只要是嵌入式的容器工厂，后置处理器就工作。 3）、后置处理器，从容器中获取所有的 EmbeddedServletContainerCustomizer，调用定制器的定制方法，而我们的ServerProperties 就是我们要的定制器。 5）、嵌入式Servlet容器启动原理什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat； 获取嵌入式的Servlet容器工厂： 1）、SpringBoot应用启动运行run方法2）、refreshContext(context)SpringBoot刷新IOC容器，也就是创建IOC容器对象，并初始化容器，创建容器中的每一个组件，这里需要判断如果是web应用创建 AnnotationConfigEmbeddedWebApplicationContext，否则创建AnnotationConfigApplicationContext 3）、refresh(context)刷新刚才创建好的ioc容器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 4）、 onRefresh() web的ioc容器重写了onRefresh方法，web 的 ioc容器会创建嵌入式的Servlet容器，createEmbeddedServletContainer()。 5）、获取嵌入式的Servlet容器工厂createEmbeddedServletContainer() 这个方法的第一步就是去创建这个工厂，getEmbeddedServletContainerFactory。 EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); 从ioc容器中获取EmbeddedServletContainerFactory 组件，TomcatEmbeddedServletContainerFactory 创建对象，后置处理器就获取所有的定制器来先定制Servlet容器的相关配置。完成配置和启动。 6）、使用容器工厂获取嵌入式的Servlet容器this.embeddedServletContainer = containerFactory.getEbeddedServletContainer(getSelfInitializer()); 7）、嵌入式的Servlet容器创建对象并启动Servlet容器先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来，这个时候我们自己写的Controller Service 以及各种配置类才会生效。 6）、使用外置的Servlet容器我们采用嵌入式Servlet容器，这样我们的应用打成可执行的jar 优点：简单、便携 缺点：默认不支持JSP、优化定制比较复杂（使用定制器ServerProperties、自定义EmbeddedServletContainerCustomizer，自己编写嵌入式Servlet容器的创建工厂EmbeddedServletContainerFactory） 所以我们可以使用外置的Servlet容器：外面安装Tomcat—应用war包的方式打包； 1.步骤1）、必须创建一个war项目，我们还是使用 SpringBootInitlizer 这个工具创建项目，但是注意我们在创建项目的时候我们选择部署的方式为 war 就可以生成 war的形式。 然后我们需要去项目的结构地方的web模块点击我们的目录结构让他自动生成webapp 目录。生成在 src/main 下面。然后就是生成 web 应用描述符，也就是生成 web.xml 接着我们需要修改应用的启动配置，自己添加一个tomcat的服务器。然后在 deploy 这个地方加入我们的 war包。 2）、将嵌入式的Tomcat指定为provided； 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3）、必须编写一个SpringBootServletInitializer的子类类名随意但是必须继承，并调用configure方法 123456789public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //传入SpringBoot应用的主程序 return application.sources(SpringBoot04WebJspApplication.class); &#125;&#125; 4）、启动服务器就可以使用； 2.启动原理1. 打包方式 jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器。 war包：启动服务器，然后服务器启动SpringBoot应用，使用的是 SpringBootServletInitializer，启动ioc容器。 servlet3.0一个规范： ​ 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面 ServletContainerInitializer 实例 ​ 2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名 ​ 3）、还可以使用 @HandlesTypes，在应用启动的时候加载我们感兴趣的类 2.启动流程：1）、启动Tomcat2）、SpringServletContainerInitializer 的调用org\\springframework\\spring-web\\4.3.14.RELEASE\\spring-web-4.3.14.RELEASE.jar!\\META-INF\\services\\javax.servlet.ServletContainerInitializer：Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer 也就是我们应用启动的时候会创建这个对象。 3）、创建 @HandlesTypes 的对象SpringServletContainerInitializer 将 @HandlesTypes(WebApplicationInitializer.class) 标注的所有这个类型的类都传入到 onStartup 方法的 Set&lt;Class&lt;?&gt;&gt;，为这些 WebApplicationInitializer 类型的类创建实例 4）、调用 onStartup 方法每一个 WebApplicationInitializer 都调用自己的onStartup； 5）、SpringBootServletInitializer 的 onStartup我们的 SpringBootServletInitializer 的类是继承自 WebApplicationInitializer 并且被放到了@HandlesTypes里，所以会被创建对象，并执行onStartup方法，也就是我们采用 war 包工程生成的这个类。 6）、创建 ICO 容器SpringBootServletInitializer实例执行onStartup的时候会 createRootApplicationContext 创建容器 1234567891011121314151617181920212223242526272829303132333435363738protected WebApplicationContext createRootApplicationContext( ServletContext servletContext) &#123; //1、创建SpringApplicationBuilder SpringApplicationBuilder builder = createSpringApplicationBuilder(); StandardServletEnvironment environment = new StandardServletEnvironment(); environment.initPropertySources(servletContext, null); builder.environment(environment); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; this.logger.info(\"Root context already created (using as parent).\"); servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers( new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class); //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来 builder = configure(builder); //使用builder创建一个Spring应用 SpringApplication application = builder.build(); if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils .findAnnotation(getClass(), Configuration.class) != null) &#123; application.getSources().add(getClass()); &#125; Assert.state(!application.getSources().isEmpty(), \"No SpringApplication sources have been defined. Either override the \" + \"configure method or add an @Configuration annotation\"); // Ensure error pages are registered if (this.registerErrorPageFilter) &#123; application.getSources().add(ErrorPageFilterConfiguration.class); &#125; //启动Spring应用 return run(application);&#125; 7）、Spring的应用就启动并且创建IOC容器1234567891011121314151617181920212223242526272829303132333435public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新IOC容器 refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 先启动Servlet容器，然后容器根据我们的Servlet的3.0 的标准，去启动我们SpringBoot 下生成的一个类，这个类再启动SpringBoot应用。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记(十二):数据访问","slug":"SpringBoot/SpringBoot 笔记 ( 十二 )数据访问","date":"2018-05-24T02:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/24/SpringBoot/SpringBoot 笔记 ( 十二 )数据访问/","link":"","permalink":"http://lwenxu.coding.me/2018/05/24/SpringBoot/SpringBoot 笔记 ( 十二 )数据访问/","excerpt":"","text":"SpringBoot 笔记(十二):数据访问1、JDBC123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; 123456spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.15.22:3306/jdbc driver-class-name: com.mysql.jdbc.Driver 1.默认情况下：​ 1. 用org.apache.tomcat.jdbc.pool.DataSource作为数据源； ​ 2. 数据源的相关配置都在DataSourceProperties里面； 2.自动配置原理：org.springframework.boot.autoconfigure.jdbc包下就是进行自动配置的包： 1、数据库连接池参考 DataSourceConfiguration，根据配置创建数据源，默认使用Tomcat连接池，可以使用spring.datasource.type指定自定义的数据源类型 2、创建数据源SpringBoot默认可以支持：org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource 1234567891011121314/** * Generic DataSource configuration. */@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = \"spring.datasource.type\")static class Generic &#123; @Bean public DataSource dataSource(DataSourceProperties properties) &#123; //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); &#125;&#125; 3、DataSourceInitializer：ApplicationListener一个监听器，主要用于sql脚本的运行 ​ 作用： ​ 1）、runSchemaScripts();运行建表语句； ​ 2）、runDataScripts();运行插入数据的sql语句； 默认只需要将文件命名为： schema-*.sql 或者 data-*.sql 默认规则：schema.sql，schema-all.sql 当然我们也可以在配置文件中指定，然后就加载指定的sql 脚本，这里是一个 list 也就是脚本可以指定多个。 12schema: - classpath:department.sql 2、整合Druid数据源1.配置 yml12345678910111213141516spring.datasource.initialSize:5spring.datasource.minIdle:5spring.datasource.maxActive:20spring.datasource.maxlait:60800spring.datasource.timeBetweenEvictionRunsMillis:60000spring.datasource.minEvictableIdleTimeMillis:300000spring.datasource.validationQuery:SELECT 1 FROM DUALspring.datasource.testWhileIdle:truespring.datasource.testOnBorrow:falsespring.datasource.testOnReturn:falsespring.datasource.poolPreparedStatements:true#配置监控统计拦截的filters，去掉后监控界面sql无法统计，‘walL“用于防火墙spring.datasource.filters:stat,wall,log4jspring.datasource.maxPoolPreparedStatementPerConnectionSize:20spring.datasource.useGTobalDataSourceStat:truespring.datasource.connectionProperties:druid.stat.mergeSql=true；druid.stat.slowsqlMillis=5e0 上面的配置文件中的数据实际上我们没用上，这里我们需要创建一个 DruidConfig 然后和当前的配置文件绑定。 2.JavaConfig123456789101112131415161718192021222324252627282930313233343536373839404142@Configurationpublic class DruidConfig &#123; @ConfigurationProperties(prefix = \"spring.datasource\") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), \"/druid/*\"); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"loginUsername\",\"admin\"); initParams.put(\"loginPassword\",\"123456\"); initParams.put(\"allow\",\"\");//默认就是允许所有访问 initParams.put(\"deny\",\"192.168.15.21\"); bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"exclusions\",\"*.js,*.css,/druid/*\"); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList(\"/*\")); return bean; &#125;&#125; 3、整合MyBatis12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; 1、注解版1234567891011121314151617//指定这是一个操作数据库的mapper@Mapperpublic interface DepartmentMapper &#123; @Select(\"select * from department where id=#&#123;id&#125;\") public Department getDeptById(Integer id); @Delete(\"delete from department where id=#&#123;id&#125;\") public int deleteDeptById(Integer id); @Options(useGeneratedKeys = true,keyProperty = \"id\") //这是为了获取自动增长的id @Insert(\"insert into department(departmentName) values(#&#123;departmentName&#125;)\") public int insertDept(Department department); @Update(\"update department set departmentName=#&#123;departmentName&#125; where id=#&#123;id&#125;\") public int updateDept(Department department);&#125; 2.自定义配置自定义MyBatis的配置规则，给容器中添加一个ConfigurationCustomizer； 12345678910111213@org.springframework.context.annotation.Configurationpublic class MyBatisConfig &#123; @Bean public ConfigurationCustomizer configurationCustomizer()&#123; return new ConfigurationCustomizer()&#123; @Override public void customize(Configuration configuration) &#123; configuration.setMapUnderscoreToCamelCase(true); &#125; &#125;; &#125;&#125; 使用MapperScan批量扫描所有的Mapper接口，这样的话我们就不用在Mapper接口上写 @Mapper 注解了。就属于批量的注解了这些注解。 1234567@MapperScan(value = \"com.springboot.mapper\")@SpringBootApplicationpublic class SpringBootMybatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootMybatisApplication.class, args); &#125;&#125; 3、配置文件版123mybatis: config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置 mapper-locations: classpath:mybatis/mapper/*.xml 指定sql映射文件的位置 更多使用参照 http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/ 4、整合SpringData JPA1）、SpringData简介 2）、整合SpringData JPAJPA:ORM（Object Relational Mapping）； 1）、编写一个实体类（bean）和数据表进行映射，并且配置好映射关系； 12345678910111213//使用JPA注解配置映射关系@Entity //告诉JPA这是一个实体类（和数据表映射的类）@Table(name = \"tbl_user\") //@Table来指定和哪个数据表对应;如果省略默认表名就是user；public class User &#123; @Id //这是一个主键 @GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键 private Integer id; @Column(name = \"last_name\",length = 50) //这是和数据表对应的一个列 private String lastName; @Column //省略默认列名就是属性名 private String email; 2）、编写一个Dao接口来操作实体类对应的数据表（Repository） 123//继承JpaRepository来完成对数据库的操作public interface UserRepository extends JpaRepository&lt;User,Integer&gt; &#123;&#125; 3）、基本的配置JpaProperties 1234567spring: jpa: hibernate:# 更新或者创建数据表结构 ddl-auto: update# 控制台显示SQL show-sql: true","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记(十三):运行流程","slug":"SpringBoot/SpringBoot 笔记 ( 十三 )：运行流程","date":"2018-05-24T02:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/24/SpringBoot/SpringBoot 笔记 ( 十三 )：运行流程/","link":"","permalink":"http://lwenxu.coding.me/2018/05/24/SpringBoot/SpringBoot 笔记 ( 十三 )：运行流程/","excerpt":"","text":"SpringBoot 笔记(十三):运行流程几个重要的事件回调机制 配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner CommandLineRunner 1.启动流程：1、创建SpringApplication对象先 new 了这个对象，然后调用了他的 run 方法。 1. 创建对象调用了initialize(sources) 123456789101112131415private void initialize(Object[] sources) &#123; //保存主配置类 if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判断当前是否一个web应用 this.webEnvironment = deduceWebEnvironment(); //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类，也就是我们的主类。 this.mainApplicationClass = deduceMainApplicationClass();&#125; 2、运行run方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META-INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 Banner printedBanner = printBanner(environment); //创建ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //准备上下文环境;将environment保存到ioc中；而且applyInitializers()； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； // prepareContext(context, environment, listeners, applicationArguments, printedBanner); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； //刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat） //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 afterRefresh(context, applicationArguments); //所有的SpringApplicationRunListener回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 2、事件监听机制配置在META-INF/spring.factories ApplicationContextInitializer 123456public class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println(\"ApplicationContextInitializer...initialize...\"+applicationContext); &#125;&#125; SpringApplicationRunListener 123456789101112131415161718192021222324252627282930313233public class HelloSpringApplicationRunListener implements SpringApplicationRunListener &#123; //必须有的构造器 public HelloSpringApplicationRunListener(SpringApplication application, String[] args)&#123; &#125; @Override public void starting() &#123; System.out.println(\"SpringApplicationRunListener...starting...\"); &#125; @Override public void environmentPrepared(ConfigurableEnvironment environment) &#123; Object o = environment.getSystemProperties().get(\"os.name\"); System.out.println(\"SpringApplicationRunListener...environmentPrepared..\"+o); &#125; @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; System.out.println(\"SpringApplicationRunListener...contextPrepared...\"); &#125; @Override public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println(\"SpringApplicationRunListener...contextLoaded...\"); &#125; @Override public void finished(ConfigurableApplicationContext context, Throwable exception) &#123; System.out.println(\"SpringApplicationRunListener...finished...\"); &#125;&#125; 配置（META-INF/spring.factories） 12345org.springframework.context.ApplicationContextInitializer=\\com.atguigu.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\\com.atguigu.springboot.listener.HelloSpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner 1234567@Componentpublic class HelloApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println(\"ApplicationRunner...run....\"); &#125;&#125; CommandLineRunner 1234567@Componentpublic class HelloCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(\"CommandLineRunner...run...\"+ Arrays.asList(args)); &#125;&#125; 3.自定义starterstarter： 1、这个场景需要使用到的依赖2、如何编写自动配置12345678910111213@Configuration //指定这个类是一个配置类@ConditionalOnXXX //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter //指定自动配置类的顺序@Bean //给容器中添加组件@ConfigurationPropertie //结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ 3、模式：启动器只用来做依赖导入；专门来写一个自动配置模块； 启动器依赖自动配置；别人只需要引入启动器（starter） mybatis-spring-boot-starter；自定义启动器名-spring-boot-starter 步骤： 1）、启动器模块 12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--启动器--&gt; &lt;dependencies&gt; &lt;!--引入自动配置模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）、自动配置模块 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.10.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--引入spring-boot-starter；所有starter的基本配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 1234567891011121314151617181920212223242526package com.atguigu.starter;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = \"atguigu.hello\")public class HelloProperties &#123; private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 123456789101112131415161718package com.atguigu.starter;public class HelloService &#123; HelloProperties helloProperties; public HelloProperties getHelloProperties() &#123; return helloProperties; &#125; public void setHelloProperties(HelloProperties helloProperties) &#123; this.helloProperties = helloProperties; &#125; public String sayHellAtguigu(String name)&#123; return helloProperties.getPrefix()+\"-\" +name + helloProperties.getSuffix(); &#125;&#125; 12345678910111213141516171819202122package com.atguigu.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //web应用才生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration &#123; @Autowired HelloProperties helloProperties; @Bean public HelloService helloService()&#123; HelloService service = new HelloService(); service.setHelloProperties(helloProperties); return service; &#125;&#125; 更多SpringBoot整合示例https://github.com/spring-projects/spring-boot/tree/master/spring-boot-samples","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记(十二):数据访问","slug":"SpringBoot/SpringBoot 笔记 ( 十二 )：数据访问","date":"2018-05-24T02:01:28.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/05/24/SpringBoot/SpringBoot 笔记 ( 十二 )：数据访问/","link":"","permalink":"http://lwenxu.coding.me/2018/05/24/SpringBoot/SpringBoot 笔记 ( 十二 )：数据访问/","excerpt":"","text":"SpringBoot 笔记(十二):数据访问1、JDBC123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; 123456spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.15.22:3306/jdbc driver-class-name: com.mysql.jdbc.Driver 1.默认情况下：​ 1. 用org.apache.tomcat.jdbc.pool.DataSource作为数据源； ​ 2. 数据源的相关配置都在DataSourceProperties里面； 2.自动配置原理：org.springframework.boot.autoconfigure.jdbc包下就是进行自动配置的包： 1、数据库连接池参考 DataSourceConfiguration，根据配置创建数据源，默认使用Tomcat连接池，可以使用spring.datasource.type指定自定义的数据源类型 2、创建数据源SpringBoot默认可以支持：org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource 1234567891011121314/** * Generic DataSource configuration. */@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = \"spring.datasource.type\")static class Generic &#123; @Bean public DataSource dataSource(DataSourceProperties properties) &#123; //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); &#125;&#125; 3、DataSourceInitializer：ApplicationListener一个监听器，主要用于sql脚本的运行 ​ 作用： ​ 1）、runSchemaScripts();运行建表语句； ​ 2）、runDataScripts();运行插入数据的sql语句； 默认只需要将文件命名为： schema-*.sql 或者 data-*.sql 默认规则：schema.sql，schema-all.sql 当然我们也可以在配置文件中指定，然后就加载指定的sql 脚本，这里是一个 list 也就是脚本可以指定多个。 12schema: - classpath:department.sql 2、整合Druid数据源1.配置 yml12345678910111213141516spring.datasource.initialSize:5spring.datasource.minIdle:5spring.datasource.maxActive:20spring.datasource.maxlait:60800spring.datasource.timeBetweenEvictionRunsMillis:60000spring.datasource.minEvictableIdleTimeMillis:300000spring.datasource.validationQuery:SELECT 1 FROM DUALspring.datasource.testWhileIdle:truespring.datasource.testOnBorrow:falsespring.datasource.testOnReturn:falsespring.datasource.poolPreparedStatements:true#配置监控统计拦截的filters，去掉后监控界面sql无法统计，‘walL“用于防火墙spring.datasource.filters:stat,wall,log4jspring.datasource.maxPoolPreparedStatementPerConnectionSize:20spring.datasource.useGTobalDataSourceStat:truespring.datasource.connectionProperties:druid.stat.mergeSql=true；druid.stat.slowsqlMillis=5e0 上面的配置文件中的数据实际上我们没用上，这里我们需要创建一个 DruidConfig 然后和当前的配置文件绑定。 2.JavaConfig123456789101112131415161718192021222324252627282930313233343536373839404142@Configurationpublic class DruidConfig &#123; @ConfigurationProperties(prefix = \"spring.datasource\") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), \"/druid/*\"); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"loginUsername\",\"admin\"); initParams.put(\"loginPassword\",\"123456\"); initParams.put(\"allow\",\"\");//默认就是允许所有访问 initParams.put(\"deny\",\"192.168.15.21\"); bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put(\"exclusions\",\"*.js,*.css,/druid/*\"); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList(\"/*\")); return bean; &#125;&#125; 3、整合MyBatis12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; 1、注解版1234567891011121314151617//指定这是一个操作数据库的mapper@Mapperpublic interface DepartmentMapper &#123; @Select(\"select * from department where id=#&#123;id&#125;\") public Department getDeptById(Integer id); @Delete(\"delete from department where id=#&#123;id&#125;\") public int deleteDeptById(Integer id); @Options(useGeneratedKeys = true,keyProperty = \"id\") //这是为了获取自动增长的id @Insert(\"insert into department(departmentName) values(#&#123;departmentName&#125;)\") public int insertDept(Department department); @Update(\"update department set departmentName=#&#123;departmentName&#125; where id=#&#123;id&#125;\") public int updateDept(Department department);&#125; 2.自定义配置自定义MyBatis的配置规则，给容器中添加一个ConfigurationCustomizer； 12345678910111213@org.springframework.context.annotation.Configurationpublic class MyBatisConfig &#123; @Bean public ConfigurationCustomizer configurationCustomizer()&#123; return new ConfigurationCustomizer()&#123; @Override public void customize(Configuration configuration) &#123; configuration.setMapUnderscoreToCamelCase(true); &#125; &#125;; &#125;&#125; 使用MapperScan批量扫描所有的Mapper接口，这样的话我们就不用在Mapper接口上写 @Mapper 注解了。就属于批量的注解了这些注解。 1234567@MapperScan(value = \"com.springboot.mapper\")@SpringBootApplicationpublic class SpringBootMybatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootMybatisApplication.class, args); &#125;&#125; 3、配置文件版123mybatis: config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置 mapper-locations: classpath:mybatis/mapper/*.xml 指定sql映射文件的位置 更多使用参照 http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/ 4、整合SpringData JPA1）、SpringData简介 2）、整合SpringData JPAJPA:ORM（Object Relational Mapping）； 1）、编写一个实体类（bean）和数据表进行映射，并且配置好映射关系； 12345678910111213//使用JPA注解配置映射关系@Entity //告诉JPA这是一个实体类（和数据表映射的类）@Table(name = \"tbl_user\") //@Table来指定和哪个数据表对应;如果省略默认表名就是user；public class User &#123; @Id //这是一个主键 @GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键 private Integer id; @Column(name = \"last_name\",length = 50) //这是和数据表对应的一个列 private String lastName; @Column //省略默认列名就是属性名 private String email; 2）、编写一个Dao接口来操作实体类对应的数据表（Repository） 123//继承JpaRepository来完成对数据库的操作public interface UserRepository extends JpaRepository&lt;User,Integer&gt; &#123;&#125; 3）、基本的配置JpaProperties 1234567spring: jpa: hibernate:# 更新或者创建数据表结构 ddl-auto: update# 控制台显示SQL show-sql: true","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记(九):分布式","slug":"SpringBoot/SpringBoot 笔记 ( 九 )：分布式","date":"2018-05-23T14:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/23/SpringBoot/SpringBoot 笔记 ( 九 )：分布式/","link":"","permalink":"http://lwenxu.coding.me/2018/05/23/SpringBoot/SpringBoot 笔记 ( 九 )：分布式/","excerpt":"SpringBoot 笔记(九):分布式我们可以使用 SpringBoot构建分布式应用，也就是我们在开发的时候可以进行多个模块的拆分，每一个功能做一个模块，然后我们使用一些分布式的框架，进行远程调用，所谓的远程调用就是RPC调用，而不是以前的WebService这个形式的.。其实这种分布式的RPC框架有很多，除了我们创常见的Doubbo还有就是我们Spring 项目自带的 SpringCloud 也是类似的东西。","text":"SpringBoot 笔记(九):分布式我们可以使用 SpringBoot构建分布式应用，也就是我们在开发的时候可以进行多个模块的拆分，每一个功能做一个模块，然后我们使用一些分布式的框架，进行远程调用，所谓的远程调用就是RPC调用，而不是以前的WebService这个形式的.。其实这种分布式的RPC框架有很多，除了我们创常见的Doubbo还有就是我们Spring 项目自带的 SpringCloud 也是类似的东西。 器基本理念就是：我们一个模块写好我们的业务逻辑然后，把我们写好的逻辑当作服务发布出去，然后发布出去的具体位置我们称之为注册中心，现在注册中心主要是通过 zookeeper 了来完成的。 1.zookeeper的安装12docker pull registry.docker-cn.com/library/zookeeperdocker run -d -p 2181:2181 --name zk-01 bf5cbc9d5cac 2.添加依赖123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.1&lt;/v ersion&gt;&lt;/dependency&gt; 3.配置文件1234567dubbo: application: name: producer registry: address: zookeeper://219.245.18.94:2181 scan: base-packages: com.example.producer.service 4.代码开启分布式注解12345678@EnableDubbo@SpringBootApplicationpublic class ProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProducerApplication.class, args); &#125;&#125; 发布服务12345package com.example.service;public interface TickService &#123; public String sell();&#125; 12345678910111213package com.example.service;import com.alibaba.dubbo.config.annotation.Service;import org.springframework.stereotype.Component;@Component@Servicepublic class TickServiceImpl implements TickService &#123; @Override public String sell() &#123; return \"hello dubbo\"; &#125;&#125; 注意使用的注解，发布服务的时候使用的是阿里的注解。 消费服务12345package com.example.service;public interface TickService &#123; public String sell();&#125; 必须有一样的接口才行。 1234567891011121314package com.example.service;import com.alibaba.dubbo.config.annotation.Reference;import org.springframework.stereotype.Service;@Servicepublic class UserService &#123; @Reference TickService tickService; public void getTick()&#123; System.out.println(tickService.sell()); &#125;&#125; 使用 @Reference 注解注入远程的 服务。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记(八):任务","slug":"SpringBoot/SpringBoot 笔记 ( 八 )：任务","date":"2018-05-22T09:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/22/SpringBoot/SpringBoot 笔记 ( 八 )：任务/","link":"","permalink":"http://lwenxu.coding.me/2018/05/22/SpringBoot/SpringBoot 笔记 ( 八 )：任务/","excerpt":"","text":"SpringBoot 笔记 (八):任务1.异步任务1.开启异步任务注解@EnableAsync 2.对Service层方法开启异步@Async 123456789@Servicepublic class TaskService &#123; @Async public void task() throws InterruptedException &#123; System.out.println(\"start\"); Thread.sleep(3000); System.out.println(\"end\"); &#125;&#125; 12345678@EnableAsync@SpringBootApplicationpublic class TaskApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(TaskApplication.class, args); &#125;&#125; 2.定时任务1.开启调度@EnableScheduling 2.@Scheduled(cron = “”)调度注解，放在Service层即可。 3.cron格式秒(0-59) 分(0-59) 时(0-23) 日(1-31) 月(1-12) 周(0-7 其中0/7表示周日) 这几个位置可写的值不仅仅是上面的数字，还可以是表达式： 枚举：1,2,3,4 范围：2-5 任意： * 步长： /3 每3步 冲突：？ 当日和星期回冲突的时候 一些例子： 1 * * *？ * 2-7 每周的周二到周天的每一分钟的第一秒触发 1-7 * * ？ * 3 每周三的每分钟的1-7秒触发 0 0/5 14,18 ？ * 1-6 每周的1-6 14点和18点 每个五分钟执行一次 0 15 10？* 1-6 每个月的周一至周六10:15分执行一次 0 0 2？* 6 每个月的最后一个周六凌晨2点执行一次 3.邮件发送1.配置原理配置pom文件 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.sun.mail&lt;/groupId&gt; &lt;artifactId&gt;javax.mail&lt;/artifactId&gt; &lt;/dependency&gt; 查看MailSenderAutoConfiguration的自动配置类 1234567891011@Beanpublic JavaMailSenderImpl mailSender() &#123; JavaMailSenderImpl sender = new JavaMailSenderImpl(); if (this.session != null) &#123; sender.setSession(this.session); &#125; else &#123; applyProperties(sender); &#125; return sender;&#125; 可以看到主要就是注入了一个 JavaMailSenderImpl 这个类的实例，然后我们就可以借助这个实例进行发送邮件。 2.配置属性1234567spring: mail: host: username: password: default-encoding: utf-8 protocol: smtp 3.发送邮件1234567891011121314151617181920212223242526272829@AutowiredJavaMailSenderImpl javaMailSender;/** * 简单的文本文件的发送 */@Testpublic void senderSimple()&#123; SimpleMailMessage message = new SimpleMailMessage(); message.setSubject(\"开会\"); message.setText(\"你好开会\"); message.setFrom(\"lwenxu\"); message.setTo(\"xpf199741@outlook.com\"); javaMailSender.send(message);&#125;@Testpublic void senderMulti() throws MessagingException &#123; MimeMessage mimeMessage = javaMailSender.createMimeMessage(); MimeMessageHelper mimeMessageHelper = new MimeMessageHelper(mimeMessage, true); mimeMessageHelper.setSubject(\"开会\"); mimeMessageHelper.setText(\"你好开会\"); mimeMessageHelper.setFrom(\"lwenxu\"); mimeMessageHelper.setTo(\"11@qq.com\"); mimeMessageHelper.addAttachment(\"1.jpg\", new File(\"C:\\\\asd.jpg\")); javaMailSender.send(mimeMessage);&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记(七):搜索","slug":"SpringBoot/SpringBoot 笔记 ( 七 )：搜索","date":"2018-05-21T06:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/21/SpringBoot/SpringBoot 笔记 ( 七 )：搜索/","link":"","permalink":"http://lwenxu.coding.me/2018/05/21/SpringBoot/SpringBoot 笔记 ( 七 )：搜索/","excerpt":"","text":"SpringBoot 笔记 (七):搜索这里我们的搜索就是用 ElasticSearch 这个工具，这个其实是在 Lauce 的基础上构建的一个搜索引擎。 1. ES入门1.docker安装12docker pull registry.docker-cn.com/library/elasticsearchdocker run -e ES_JAVA_OPTS=\"-Xms256m -Xmx256m\" -d -p 9200:9200 -p 9300:9300 --name ES_dev 这里指定了es的初始的java堆大小和最大堆大小，否则就是默认的 2G 。 2.基本概念ES 是一个面向文档的数据库，他的文档的格式就是JSON的格式。 1.索引这个索引指的是动词，也就是我们把数据存放到ES中的一个过程。 2.索引这个索引是名词，指的是我们的ES中的一个数据库。 3.类型这个就相当与我们的一个表 4.文档就是我们的数据记录。 简单的可以用一张表来表示：","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记 ( 六)：消息","slug":"SpringBoot/SpringBoot 笔记 ( 六 )：消息","date":"2018-05-20T07:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/20/SpringBoot/SpringBoot 笔记 ( 六 )：消息/","link":"","permalink":"http://lwenxu.coding.me/2018/05/20/SpringBoot/SpringBoot 笔记 ( 六 )：消息/","excerpt":"SpringBoot 笔记 (六): 消息1.基本概念1.应用场景","text":"SpringBoot 笔记 (六): 消息1.基本概念1.应用场景 2.重要概念 消息代理（broker）：消息队列服务器 目的地：消息消费者 1.消息队列的两种目的地： 队列：点对点的通讯，这种就是消息生产者把消息发送到消息队列中，然后消息接受者去获取消息，获取后这个消息就被移除，消息的接受者可以有多个也就是可以有多个消费者，但是注意一个消息只能被其中的一个消费者消费。 主题：发布订阅通讯，广播形式。所有的接受者都可以收到消息。 2.JMS这是一个基于JVM的消息代理的规范，但是他只是一个规范真正的实现则是 ActiveMQ和HornetMQ等等 3.AMQP高级消息队列，他也是消息队列的规范但是他是兼容JMS的，他的具体实现就是我们常常听到的RabbitMQ 4.JMS和AMQP对比 5.Spring支持spring-jms提供了对JMS的支持spring-rabbit提供了对AMQP的支持需要ConnectionFactory的实现来连接消息代理提供JmsTemplate、Rabbit Template来发送消息@JmsListener(JMS）、@RabbitListener(AMQP)注解在方法上监听消息代理发布的消息@EnableJms、@EnableRabbit开启支持 6.Spring Boot自动配置JmsAutoConfigurationRabbitAutoConfiguration 7.RabbitMQ基本结构 首先我们产生消息的我们叫做 生产者(Publisher) 然后我们生产者会把消息发送给 我们的消息服务器(Broker) 中的一个虚拟主机(Virtual Host)，虚拟主机中有一个专门用来接受生产者消息的组件就是 交换机Exchange ，在接收到消息以后我们的路由器就和我们真正的某条 消息队列Queue 通过路由键连接起来，这里的消息队列有多个，然后消息队列与路由器的链接也是多对多的。最后就是我们的消费者去消息队列中消费消息，采用的就是建立TCP链接，但是我们为了节省资源开销，采用了一条TCP的多路复用，也就是在一个TCP中开辟了多个信道来传输数据。 8.Exchange类型 direct 直连模式，在我们消息带过来的类型和消息键完全匹配的时候我们直接转发到对应的队列 —- 点对点 fanout 广播模式，对所有的消息都会广播到每一个队列中，这是最快的 —- 广播 topic 模式匹配方式，单词级别的匹配，消息的消费者使用的 ‘# ‘表示匹配0个或者多个单词 ’*‘ 表示匹配一个单词 2.RabbitMQ1.docker安装RabbitMQ12docker pull registry.docker-cn.com/library/rabbitmq:3.7-management #获取具有web管理面板的镜像+使用加速docker run -d -p 5672:5672 -p 8002:15672 --name rabbitmq_dev c51d1c73d028 2.管理界面输入 ip:15672 输入 guest/guest 登录进入管理界面 3.SpringBoot整合RabbitMQ1.添加starter1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 2.自动配置原理1234567891011121314151617181920212223242526272829303132333435363738@Configuration@ConditionalOnClass(&#123; RabbitTemplate.class, Channel.class &#125;)@EnableConfigurationProperties(RabbitProperties.class)@Import(RabbitAnnotationDrivenConfiguration.class)public class RabbitAutoConfiguration &#123; @Configuration @ConditionalOnMissingBean(ConnectionFactory.class) protected static class RabbitConnectionFactoryCreator &#123; @Bean public CachingConnectionFactory rabbitConnectionFactory(RabbitProperties config)&#123;&#125; &#125; @Configuration @Import(RabbitConnectionFactoryCreator.class) protected static class RabbitTemplateConfiguration&#123; @Bean @ConditionalOnSingleCandidate(ConnectionFactory.class) @ConditionalOnMissingBean(RabbitTemplate.class) public RabbitTemplate rabbitTemplate(ConnectionFactory connectionFactory) &#123;&#125; @Bean @ConditionalOnSingleCandidate(ConnectionFactory.class) @ConditionalOnProperty(prefix=\"spring.rabbitmq\", name = \"dynamic\", matchIfMissing = true) @ConditionalOnMissingBean(AmqpAdmin.class) public AmqpAdmin amqpAdmin(ConnectionFactory connectionFactory) &#123;&#125; &#125; @Configuration @ConditionalOnClass(RabbitMessagingTemplate.class) @ConditionalOnMissingBean(RabbitMessagingTemplate.class) @Import(RabbitTemplateConfiguration.class) protected static class MessagingTemplateConfiguration &#123; @Bean @ConditionalOnSingleCandidate(RabbitTemplate.class) public RabbitMessagingTemplate rabbitMessagingTemplate&#123;&#125; &#125;&#125; 可以看到我们整个的自动配置类其实是我们的三个自动配置类的组合，在这个配置类里面我们配置了链接工厂，以及两个供我们便捷操作RabbitMQ的两个Template 这个和 redis 以及 jdbc 的 template 非常的类似。 1.rabbitConnectionFactory这个bean就是配置了他的配置信息，包括地址端口什么的，这些可以看到是从我们的 RabbitProperties 中获取的，也就是 @EnableConfigurationProperties(RabbitProperties.class) 导入的 properties ，我们点进去就可以看到它对应的配置项以及关联的配置文件的前缀。其中前缀就是 “spring.rabbitmq” 下面就是具体的配置了。 1234567@ConfigurationProperties(prefix = \"spring.rabbitmq\")public class RabbitProperties &#123; private String host = \"localhost\"; private int port = 5672; private String username; //....&#125; 那么我们就在配置文件中填写配置项： 1234567spring: rabbitmq: host: 219.245.18.94 username: guest password: guest virtual-host: / port: 5672 2.rabbitTemplate这个就是操作RabbitMQ的接口组件。 3.amqpAdmin而这个是RabbitMQ的系统管理组件 4.rabbitMessagingTemplate消息相关的操作接口。 3.简单的API操作123456789101112131415161718192021222324@Testpublic void rabbitSend()&#123; //自定义消息头和消息体形式 rabbitTemplate.send(\"lwen.direct\", \"lwen.q1\", new Message(\"hello\".getBytes(),new MessageProperties())); //简单一点直接传输消息体，并且自动进行序列化 对象默认使用jdk序列化 HashMap&lt;String, Object&gt; msg = new HashMap&lt;&gt;(); msg.put(\"m1\", \"hello\"); msg.put(\"m2\", Arrays.asList(\"hello\", \"world\")); rabbitTemplate.convertAndSend(\"lwen.direct\", \"lwen.q1\", msg);&#125;@Testpublic void receiveMsg()&#123; //获取消息进行反序列化 Object q1 = rabbitTemplate.receiveAndConvert(\"q1\"); System.out.println(q1.getClass()); System.out.println(q1);&#125; 上面就是简单的读写消息队列的操作。 以上我们看到的是单播的例子，其实广播以及模式匹配我们只是使用了不同的exchange就能达到目的。 4.配置序列化规则可以看到上面的自动序列化出来的东西我们是没办法看的，我们更希望使用json等序列化工具。我们看一下他的序列化的配置。 在 public RabbitTemplate rabbitTemplate() 方法中 可以看到 MessageConverter messageConverter = this.messageConverter.getIfUnique(); 就是获取消息转换的工具。 可以看到有这么多 MessageConverter 的具体实现，我们就是使用json的。 1234567@Configurationpublic class AMQPConfig &#123; @Bean public MessageConverter messageConverter() &#123; return new Jackson2JsonMessageConverter(); &#125;&#125; 之后我们可以在RabbitMQ的管理面板上看到这种格式的数据了，而不是二进制： 1&#123;\"m1\":\"hello\",\"m2\":[\"hello\",\"world\"]&#125; 5.消息监听我们对一些应用解耦的话我们就需要使用消息队列，那么消息队列就需要有通知的功能，这里我们只需要两个注解就能搞定这个问题。 首先我们需要开启RabbitMQ的注解 @EnableRabbit 12345678@SpringBootApplication@EnableRabbitpublic class BootMqApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(BootMqApplication.class, args); &#125;&#125; 然后我们对接受消息的方法加上@RabbitListener注解进行监听 1234567@Servicepublic class BookService &#123; @RabbitListener(queues = \"q1\") public void bookReceive(Book book)&#123; System.out.println(book); &#125;&#125; 6.amqpAdmin前面我们看到在自动配置的时候他们帮我们创建了一个 amqpAdmin 这个组件，然后我们是可以拿这个组件进行创建路由、队列、以及绑定规则，也就是我们在管理面板上能完成的操作。 123456789101112131415@AutowiredAmqpAdmin amqpAdmin@Testpublic void rabbitAdmins()&#123; //创建路由 DirectExchange 是Exchange的实现类 类自己找 有很多 amqpAdmin.declareExchange(new DirectExchange(\"amqpAdmin.exchange\")); //创建队列 amqpAdmin.declareQueue(new Queue(\"amqpAdmin.queue\")); //绑定 amqpAdmin.declareBinding(new Binding(\"amqpAdmin.queue\", Binding.DestinationType.QUEUE, \"amqpAdmin.exchange\", \"amqp.key\", null));&#125;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记 ( 五 )：缓存","slug":"SpringBoot/SpringBoot 笔记 ( 五)：缓存","date":"2018-05-20T02:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/20/SpringBoot/SpringBoot 笔记 ( 五)：缓存/","link":"","permalink":"http://lwenxu.coding.me/2018/05/20/SpringBoot/SpringBoot 笔记 ( 五)：缓存/","excerpt":"SpringBoot 笔记 (五): 缓存1.JSR107介绍1.核心概念JSR107这个规范有五个核心概念分别是： CacheProvider 它用来管理缓存的Manager也就是用来创建，删除，管理，配置CacheManager 的 CacheManager 是用来管理各个缓存，创建，删除，管理，配置Cache的 Cache 是各个具体的缓存组件 Entry 是缓存中具体的一个缓存项 Expire 缓存的过期时间","text":"SpringBoot 笔记 (五): 缓存1.JSR107介绍1.核心概念JSR107这个规范有五个核心概念分别是： CacheProvider 它用来管理缓存的Manager也就是用来创建，删除，管理，配置CacheManager 的 CacheManager 是用来管理各个缓存，创建，删除，管理，配置Cache的 Cache 是各个具体的缓存组件 Entry 是缓存中具体的一个缓存项 Expire 缓存的过期时间 2.导入包 javax.cache.cache-api javax.cache.cache 2.Spring缓存抽象spring保留了两个核心的概念就是 CacheManager 和 Cache 用来支持并简化 JSR107 技术。支持JSR107的注解，以及自带一些注解。 这几个注解其实都是标注在方法上面，主要说一些这几个注解： Cacheable 就是标注该方法在执行查询的结果是被缓存起来的，一般来说就是在dao的select的时候调用。 CacheEvict 这个一般放在删除某些数据的时候我们必须清空缓存让缓存失效 CachePut 这个住哟啊用于更新操作，不然的话缓存无法同步更新。 EnableCache 就是开启注解。 3.搭建项目工程1.给主类加上@CacheEnable2.给方法加上@Cacheable将方法的运行结果进行缓存；以后再要相同的数据，直接从缓存中获取，不用调用方法；CacheManager管理多个cache组件的，对缓存的真正CRUD操作在cache组件中，每一个缓存组件有自己唯一一个名字；几个属性： cacheNames/value：指定缓存组件的名字 key：缓存数据使用的key；可以用它来指定。默认是使用方法参数的值1-方法的返回值 编写SpEL；#id；参数id的值#ae#pe#root.args[e] keyGenerator:key的生成器；可以自己指定key的生成器的组件id 注意：key/keyGenerator：二选一使用 cacheManager：指定缓存管理器；或者cacheResolver指定获取解析器 condition：指定符合条件的情况下才缓存； unLess：否定缓存；当unLess指定的条件为true，方法的返回值就不会被缓存；可以获取到结果进行判断 unless=”#result==null” sync：是否使用用异步 [^针对dao包开启sql调试日志]: logging: level: com: example: bootcache: dao: debug 3.自动配置原理1. CacheAutoConfiguration 自动配置类2.@Import({CacheAutoConfiguration.CacheConfigurationImportSelector.class}) 导入了自动配置选择类3. CacheConfigurationImportSelector.selectImports() 方法导入依赖12345678910\"org.springframework.boot.autoconfigure.cache.GenericCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.JCacheCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.EhCacheCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.HazelcastCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.InfinispanCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.CouchbaseCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.RedisCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.CaffeineCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration\"\"org.springframework.boot.autoconfigure.cache.NoOpCacheConfiguration 4.具体哪一个配置类会生效就看我们这些配置类的condition123@ConditionalOnClass(&#123;Cache.class, EhCacheCacheManager.class&#125;)@ConditionalOnMissingBean(&#123;CacheManager.class&#125;)@Conditional(&#123;CacheCondition.class, EhCacheCacheConfiguration.ConfigAvailableCondition.class&#125;) 5.我们可以打开调试，那么再启动的时候就会打印出我们自动配置的日志 （debug: true） 搜索CacheConfiguration 可以看到 123SimpleCacheConfiguration matched: - Cache org.springframework.boot.autoconfigure.cache.SimpleCacheConfiguration automatic cache type (CacheCondition) - @ConditionalOnMissingBean (types: org.springframework.cache.CacheManager; SearchStrategy: all) did not find any beans (OnBeanCondition) 那么也就是说我们没配置的时候默认是 Simple 的Cache 123456789@Beanpublic ConcurrentMapCacheManager cacheManager() &#123; ConcurrentMapCacheManager cacheManager = new ConcurrentMapCacheManager(); List&lt;String&gt; cacheNames = this.cacheProperties.getCacheNames(); if (!cacheNames.isEmpty()) &#123; cacheManager.setCacheNames(cacheNames); &#125; return (ConcurrentMapCacheManager)this.customizerInvoker.customize(cacheManager);&#125; 默认返回的是 ConcurrentMapCacheManager 这个CacheManager 给容器中注册缓存管理器。 6. ConcurrentMapCacheManager 分析这个缓存管理器的主要作用分析一下，其他的基本都类似： 1234567891011121314151617181920public class ConcurrentMapCacheManager implements CacheManager｛ //所有的缓存管理器都继承了这个CacheManager //里面最重要的方法就是 getCache 方法 这个方法就是创建和获取缓存组件！！组件 @Nullable public Cache getCache(String name) &#123; Cache cache = (Cache)this.cacheMap.get(name); if (cache == null &amp;&amp; this.dynamic) &#123; ConcurrentMap var3 = this.cacheMap; synchronized(this.cacheMap) &#123; cache = (Cache)this.cacheMap.get(name); if (cache == null) &#123; cache = this.createConcurrentMapCache(name); //创建缓存其实就是new ConcurrentHashMap(256) this.cacheMap.put(name, cache); &#125; &#125; &#125; return cache; &#125; &#125; 7.Cache的执行流程1.获取缓存组件在被注解的方法调用之前会去Cache组件按照cacheName获取缓存组件 （注意不是缓存数据而是组件），也就是去 CacheManager 的 getCache() 方法，如果没有Cache组件我们就new一个Cache组件 2.获取key待会说 3.获取缓存数据接着使用ConcurrentMapCache.lookup()`来查找缓存数据，也就是使用 key 来查找，默认就是方法的参数。但是又是怎样生成key的呢？ 我们在 lookup() 上面打上断点，然后我们往上翻一下栈帧就能找到 findCachedItem:491, CacheAspectSupport 接着我们可以在这个方法中看到他生成了 key 也就是 bject key = this.generateKey(context, result); 12345678protected Object generateKey(@Nullable Object result) &#123; if (StringUtils.hasText(this.metadata.operation.getKey())) &#123; //获取到key的值 直接使用 EvaluationContext evaluationContext = this.createEvaluationContext(result); return CacheAspectSupport.this.evaluator.key(this.metadata.operation.getKey(), this.metadata.methodKey, evaluationContext); &#125; else &#123; //没有key的值需要生成 return this.metadata.keyGenerator.generate(this.target, this.metadata.method, this.args); &#125;&#125; 上面的逻辑就是 获取到key的值 ，直接使用，没有key的值需要生成。好那么这个生成的 generate() 最后是在 一个 public interface KeyGenerator 接口中定义的，那么接下来这个实现类其实就是 SimpleKeyGenerator 在栈帧中是可以看出来的。 1234567891011121314public static Object generateKey(Object... params) &#123; if (params.length == 0) &#123; return SimpleKey.EMPTY; &#125; else &#123; if (params.length == 1) &#123; Object param = params[0]; if (param != null &amp;&amp; !param.getClass().isArray()) &#123; return param; &#125; &#125; return new SimpleKey(params); &#125;&#125; 最后生成了 key 值：生成策略 ： 如果没有参数就是 Simple对象 有一个参数就是这个东西 多个参数就是参数传入Simple的封装 如果我们在缓存中获取到了数据那么我们就不需要运行方法了，如果是没有的话我们必须运行方法执行下面的 put 操作，但是注意一点就是我们通篇使用了 AspectJ 完成的。 4.没有值put进去使用了 ConcurrentMapCache.put() 方法来put新的值。 所以说我们的@Cacheable代码的调用时机有两个：分别是运行之前需要查询一次缓存看有没有，以及在没有时候需要运行方法并把结果放到缓存中。所以我们不能在注解中使用#result el表达式，还有注意一点的就是这些注解都是放在Service层的别放到了Controller中，因为Controller每次都会被访问。 4.自定义key1.使用注解中的key属性我们可以采用 SPEL 表达式，这里举一个简单的例子，我们的可以要用方法名加上参数 Empl[1] 我们就可以用 #root.method.name+’[‘ +#id+’]’ 来完成 2.重写 keyGenerator()12345678910111213@Configurationpublic class KeyGeneratorConfig &#123; @Bean public KeyGenerator keyGenerator()&#123; // 生策略就是 方法名家参数 return new KeyGenerator() &#123; @Override public Object generate(Object target, Method method, Object... params) &#123; return method.getName() + Arrays.asList(params).toString(); &#125; &#125;; &#125;&#125; 然后在 keyGenerator的属性写上 我们的bean的id 5.@CachePut 注解这个注解就是在update数据的时候使用的，在更新数据库的同时同期的更新缓存，这个注解的代码都是在方法运行以后才开始运行的，也就是我们代码之运行一次，然后他的原理就是更新后的数据重新放到缓存里面而不是真的去查那条缓存然后更新。所以说有一个非常值得注意的地方就是如果我们的@Cacheable注解使用了自定义的key的时候我们必须保证他们两个的key一样 不然的话是没有办法同步更新数据库和缓存的。 6.@CacheEvict 缓存清除 这个删除默认的情况就是删除指定的key的缓存而非当前Cache组件中所有的缓存。 我们可以指定 allEntries 属性来指定是否删除所有的缓存 beforeInvocation 指定缓存是在方法之前还是之后运行，这个东西的影响就是我们的方法抛出异常的时候缓存能否被清除，显然后者是不可以的。 7.@Caching 综合注解这个注解其实就是上面三个注解的综合，也就是我们可以定义综合注解。 12345678910111213@Caching( cacheable = &#123; @Cacheable(cacheNames = \"empl\") &#125;, put = &#123; //多key缓存 @CachePut(cacheNames = \"empl\",key = \"#id\"), @CachePut(cacheNames = \"empl\",key = \"#result\") &#125;, evict = &#123; @CacheEvict(cacheNames = \"empl\") &#125;) 8.@CacheConfig类上注解这个注解可以配置一些公共的项目，然后我们下面的方法就可以不用配置一些公共的东西了。这个注解是配置在类上面的。 1@CacheConfig(cacheNames = \"empl\") 4.使用redis缓存中间件1. 配置redis客户端2.配置redis-starter1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;&lt;/dependency&gt; 3.配置redis地址123spring: redis: host: localhost 4.注入两个redis的客户端 redisTemplate 基本的redis客户端 stringRedisTemplate 简化字符串操作的 1234@AutowiredRedisTemplate redisTemplate; //默认k-v为object@AutowiredStringRedisTemplate stringRedisTemplate; //默认k-v为string的 5.Redis常见的五大数据类型String（字符串）、List（列表）、Set（集合）、Hash（散列）、ZSet（有序集合） 12345stringRedis Template.opsForValue()[String(字符串）]stringRedis Template.opsForlist()[List(列表）]stringRedis Template.opsForSet()[Set(集合）]stringRedisTemplate.opsForHash()[Hash(散列）]stringRedis Template.opsForZSet()[ZSet(有序集合）] 6.string以及对象序列化1.string类型的操作：123456 // stringstringRedisTemplate.opsForValue().append(\"name\", \"lwen\");stringRedisTemplate.opsForValue().append(\"age\", \"20\"); //liststringRedisTemplate.opsForList().leftPush(\"mylist\", \"hello\");stringRedisTemplate.opsForList().leftPush(\"mylist\", \"world\"); 2.对象的操作：12Employee employee = new Employee(10, 20, \"lwen\");redisTemplate.opsForValue().set(\"objStr\", employee); 注意一点的就是这个对象必须要实现序列化接口否则会报错的！！！ 测试成功以后会发现我们的数据成了这个样子，value还好说应该是序列化导致的，但是key其实也是序列化，我们的string 类也是可以被序列化的。这不是我们希望的而是采用json的格式。那么我们可以配置序列化的规则，去 RedisAutoConfiguration 找对应的默认序列化配置。 1234567891011121314151617@Bean@ConditionalOnMissingBean(name = \"redisTemplate\")public RedisTemplate&lt;Object, Object&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template;&#125;@Bean@ConditionalOnMissingBeanpublic StringRedisTemplate stringRedisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template;&#125; 可以看到这里就是配置了两个 redisTemplate 我们主要就是让他重新返回新的 redisTemplate 并且在这些模板里面加上我们的序列话规则就好。 我们去 redisTemplate 中看看会发现 afterPropertiesSet 这个方法中有一段逻辑： 123if (this.defaultSerializer == null) &#123; this.defaultSerializer = new JdkSerializationRedisSerializer(this.classLoader != null ? this.classLoader : this.getClass().getClassLoader());&#125; 意思就是说我们没有配置 defaultSerializer 的话默认使用的是jdk的序列化规则。所以我们自己配置一个 redisTemplate 加上我们自己的规则即可。把上面配置 redisTemplate 的代码复制到我们的JavaConfig中。修改一下，首先我们定位到 private RedisSerializer&lt;?&gt; defaultSerializer; 看到这个地方就是redis的序列化器，我们看看他的具体实现就能找到我们需要的序列化器（Ctrl+H）。 123456789@Bean@ConditionalOnMissingBean(name = \"redisTemplate\")public RedisTemplate&lt;Object, Object&gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); template.setDefaultSerializer(new Jackson2JsonRedisSerializer&lt;&gt;(Employee.class)); return template;&#125; 使用jackson序列化之后的，就很正常！！！ 7.自定义CacheManager上面的操作我们都是在test中进行的，我们手动的拿到了 redisTemplate 但是实际上我们在项目中使用的时候我们是不关心我们用的是什么 redisTemplate 也就是我们没办法定义序列化规则了，实际上主要是因为我们的CacheManager被自动配置了。那么去找一下这个自动配置类 RedisCacheConfiguration 里面就是把 CacheManager 放到了容器里。 123456789101112@Beanpublic RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory, ResourceLoader resourceLoader) &#123; RedisCacheManagerBuilder builder = RedisCacheManager .builder(redisConnectionFactory) .cacheDefaults(determineConfiguration(resourceLoader.getClassLoader())); List&lt;String&gt; cacheNames = this.cacheProperties.getCacheNames(); if (!cacheNames.isEmpty()) &#123; builder.initialCacheNames(new LinkedHashSet&lt;&gt;(cacheNames)); &#125; return this.customizerInvoker.customize(builder.build());&#125; 但是注意的一点就是我们的CacheManager是每一个Service很可能不太一样的这是因为我们的泛型不一样，否则的话我们有时候就没办法反序列化回来，所以我们现在必须在每一个Service类上面使用 @CacheConfig 注解中的CacheManager属性来制定使用哪个CacheManager。并且我们还需要一个默认的缓存管理器不然的话会导致注入异常！ !!!注意 :在springBoot 2.0的版本我没有找到配置序列化的地方了，并且我发现不用配置序列化key是正常的，value是二进制的，但是我觉得没问题，因为生成CacheManager不是用template而是采用builder的方式，所以说我们可以不用配置序列化并且我们的Redis的缓存管理器的类的继承层次和其他几个也不太一样，个人感觉是更好的封装吧，不用再手动配置了。 8.手动操作缓存我们可以直接手动注入一个缓存管理器，然后我们使用管理器获取一个缓存，接着我们剧可以手动的对缓存进行操作了。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"Kafka 入门","slug":"Spark/Kafka入门","date":"2018-05-18T11:01:28.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/05/18/Spark/Kafka入门/","link":"","permalink":"http://lwenxu.coding.me/2018/05/18/Spark/Kafka入门/","excerpt":"","text":"1. Kafka架构 生产者（producer）：生产资源的 消费者（consumer）：消费资源 broker（缓冲）：中间缓冲器 topic（标记）：谁来消费 2. 配置Kafka1. 配置ZK 解压 配置ZK_HOME 配置PATH 修改 zk.cfg 修改存储位置 zkServer.sh 启动 2. 配置Kafka 配置HOME以及PATH 修改 server.porperties 注意以下几个条目 123456$KAFKA_HOME/config/server.propertiesbroker.id=0listenershost.name1og.dirszookeeper.connect 启动Kafka 1kafka-server-start.sh $KAFKA_HOME/config/server.properties 生产消息 1kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic hello 启动消费者 1kafka-console-consumer.sh --zookeeper localhost:2181 --topic hello --from-beginning","categories":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/categories/Spark/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/tags/Spark/"}]},{"title":"Flume 入门","slug":"Spark/Flume入门","date":"2018-05-18T08:01:28.000Z","updated":"2019-06-04T00:54:40.000Z","comments":true,"path":"2018/05/18/Spark/Flume入门/","link":"","permalink":"http://lwenxu.coding.me/2018/05/18/Spark/Flume入门/","excerpt":"","text":"1. 基本架构1. 结构source 源数据：目录/ channel 数据管道 sink 数据输出 2. 几种结构形式 单个的Flume 多个Flume串行工作，前一个Flume的sink作为后一个的source 多个Flume并行工作然后最后用一个Flume进行合并这行并行收集的数据 多个Flume并行工作，分别传送到不同的目的地 2. 安装1. 安装JDK解压到 /app将java配置系统环境变量中：/.bash_profileexport JAVA_HOME=/home/hadoop/app/jdk1.8.0_144export PATH=$JAVA_HOME/bin:$PATHsource下让其配置生效检测：java -version 2. 安装Flume1. 安装export FLUME_HOME=/home/hadoop/app/apache-flume-1.6.0-cdh5.7.0-b export PATH=$FLUME_HOME/bin:$PATHsource下让其配置生效 2. 配置flume-env.sh的配置：export JAVA_HOME=/home/hadoop/app/jdk1.8.0_144 3. 使用Flume使用Flume的关键其实就是书写配置文件，然后启动不同的配置文件的进程就是不同的任务。 1. 配置 配置Source 配置Channel 配置Sink 把上面的组件串联起来 给一个简单的Conf的例子，并做一些注释。 12345678910111213141516#a1:agent名称 r1:source的名称 k1:sink的名称 c1:channel的名称#Name the components on this agental.sources=r1al.sinks=k1al.channels=c1#Describe/configure the sourceal.sources.rl.type=netcatal.sources.r1.bind=localhostal.sources.r1.port =44444#Describe the sinkal.sinks.k1.type=logger# Use a channel which buffers events in memoryal.channels.c1.type=memory#Bind the source and sink to the channelal.sources.r1.channel.=c1al.sinks.k1.channel=c1 2. 启动12345flume-ng agent \\--name a1 \\-c $FLUME_HOME/conf \\-f $FLUME_HOME/conf/example.conf \\-Dflume.root.logger=INFO,console 注意 –name 选项指定的名字必须要和配置文件里面的agent名字一致才行，否则会提示找不到对应的配置。 启动以后使用 telnet 127.0.0.1 4444 访问，然后输入文字flume就可以收集到数据。具体数据如下： 122018-05-18 17:01:21,693 Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F 0D hello. &#125; 2018-05-18 17:01:26,912 Event: &#123; headers:&#123;&#125; body: 77 6F 72 6C 64 0D world. &#125; 可以看到他每一条消息都是一个Event 也就是说在Flume中每一个Event都是一个基本的传送单元。 Event = header + body 3. 实战1. 从文件中读取数据123456789101112131415161718192021# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F /root/data.loga1.sources.r1.shell = /bin/bash -c# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 2. A机向B机传输采集的数据首先配置A机 ，我们采用的是 exec 监控一个文件，然后使用 memory channel 输出到 avro ，所以有配置文件 exec-memcory-avro.conf 12345678910111213141516171819exec-memcory-avro.sources = exec-sourceexec-memcory-avro.sinks = avro-sinkexec-memcory-avro.channels = memory-channelexec-memcory-avro.sources.exec-source.type = execexec-memcory-avro.sources.exec-source.command = tail -F /root/data.logexec-memcory-avro.sources.exec-source.shell = /bin/bash -cexec-memcory-avro.sinks.avro-sink.type = avroexec-memcory-avro.sinks.avro-sink.hostname = masterexec-memcory-avro.sinks.avro-sink.port = 4444exec-memcory-avro.channels.memory-channel.type = memoryexec-memcory-avro.channels.memory-channel.capacity = 1000exec-memcory-avro.channels.memory-channel.transactionCapacity = 100exec-memcory-avro.sources.exec-source.channels = memory-channelexec-memcory-avro.sinks.avro-sink.channel = memory-channel 执行如下的命令可以启动，但是不要现在启动否则会报错 12345flume-ng agent \\--name exec-memcory-avro \\-c $FLUME_HOME/conf \\-f $FLUME_HOME/conf/exec-memcory-avro.conf \\-Dflume.root.logger=INFO,console 那么B机就需要使用avro source来接受了，然后使用memory做channel，最后使用logger做输出。建立配置文件avro-memory-logger.conf 1234567891011121314151617avro-memory-logger.sources = avro-sourceavro-memory-logger.sinks = logger-sinkavro-memory-logger.channels = memory-channelavro-memory-logger.sources.avro-source.type = avroavro-memory-logger.sources.avro-source.bind = masteravro-memory-logger.sources.avro-source.port = 4444avro-memory-logger.sinks.logger-sink.type = loggeravro-memory-logger.channels.memory-channel.type = memoryavro-memory-logger.channels.memory-channel.capacity = 1000avro-memory-logger.channels.memory-channel.transactionCapacity = 100avro-memory-logger.sources.avro-source.channels = memory-channelavro-memory-logger.sinks.logger-sink.channel = memory-channel 启动 12345flume-ng agent \\--name avro-memory-logger \\-c $FLUME_HOME/conf \\-f $FLUME_HOME/conf/avro-memory-logger.conf \\-Dflume.root.logger=INFO,console 我们要先启动后面的那个，也就是B机，不然的话我们先启动A机就会报错。","categories":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/categories/Spark/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/tags/Spark/"}]},{"title":"Vim 使用技巧","slug":"Tools/Vim使用技巧","date":"2018-05-18T04:32:34.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/18/Tools/Vim使用技巧/","link":"","permalink":"http://lwenxu.coding.me/2018/05/18/Tools/Vim使用技巧/","excerpt":"","text":"1.x 删除后面的字符 X 删除前一个字符 删除3个字符就是3x2.caw:改写单词3.J:删除换行符，使下一行并上来。 nJ:连接连同本行的n行4.u:撤销上一次操作 U:撤销当前行的所有修改5.i 在光标前插入 I 在行首插入6.a 在光标后插入 A 在行末插入7.o:在当前行的下面另起一行，并变为插入模式 O：在当前行上面另起一行，变为插入模式8.vim中Nyy可以复制光标后的N行。有时我们不容易得出行数，这时可以用做标记的方法来制定复制范围 1. 在开始行上输入ma作一个标记a 移动到结束行，输入y’a会复制当前行到标记a之间的文本。d’a会删除。9.将光标放在 {或者( 处，然后输入v%就可以把大括号中内容选定10.想删除到“(”为止，则输入dt(就可以了，t(的作用是跳到下一个”(“前。11.%: 移动到与制匹配的括号上去（），{}，[]，&lt;&gt;等12.’ 移动到上一次的修改行13.# 到与当前单词相同的上一个单词上， * 到与当前单词相同的下一个单词上14.如果你要重复键入一个短语或一个句子, 也有一种快捷的方法。Vim有一种记录宏的机制。你键入”qa”开始把一段宏记录入寄存器变量a&#39;中。 按下来你可以象平常一样键入你要的操作, 只是这些操作都会被Vim记录进它命名为a’的宏中, 再次再下”q”键, 就结束了宏`a’的录制。 当你要重复执行你刚才记录的那些操作时只要使用”@a”命令。共有26个可用的寄存器供你记录宏。 使用宏你可以重复多个不同的操作。 而不仅仅是插入文本了。如果你要进行某种重复的操作, 记着要用这一招呀。15.b、3b、w、3w:向前\\后移动几个单词，标点也算一个单词。相应的大写状态为不含标点，即只把空格和换行符作为单词间隔符。16.$：移动到行尾 3$：移动到3行后的行尾 ^:移动到行首，0也是 +：移到下一行的行首 -： 移到上一行的行首17.33G：跳转到33行 此时按``可以返回到原来行 gg:文件头 G： 文件尾 :set nu 设置行号19.ctrl+b\\f 向上\\下滚动一屏 这个比较实用，记住。20.zz:将当前行滚动于屏幕中间，方便查看上下文 zt置顶，zb置尾21./string 查找string，回车后，按n键可以跳到下一个，N上一个，另外按/键后，按上下键可以找到以前查找的记录，同样的 ：也有记录 ?/string 同上，默认向上查找22.:set ignorecase 大小写无关 :set noignorecase 大小写敏感23.&gt;&gt; 向右移动本行一段距离 &lt;&lt; 向左移动本行一段距离 3&lt;&lt; 把下面3行（包括本行），向左移动一段距离 :20,30&gt;&gt; 把20行到30行向右移动一段距离24.:%s/str1/str2/g 替换每一行的 str1为 str2 :10,20s/str1/str2/g 替换从行10到行20之间的 str1为 str2 :10,$s/str1/str2/g 替换从行10到最后一行之间的 str1为 str2 :s/str1/str2/g 替换当前行的 str1为 str225.:10,$ w test2.cpp 取行10到最后一行内容，保存到test2.cpp 26.:r class/User.hpp 读取文件中的内容，插入到当前行的后面27.dw:删除一个单词（光标后部分） 不如：daw实用28.d4w：删除4个单词 d$:删除当前光标到行尾 29.d换成c效果是一样的，只是操作完会变成insert模式30.dnj: 向下删除n行 dnk: 向上删除n行 dn删除本行31.D:相当于d$ C:相当于c$32.r:替换当前字符，但不会进入insert模式 33.yaw： 复制一个单词,光标在单词任意位置 ynw： 复制N个单词 ynj: 向下复制n行 ynk: 向上复制n行34.ci’、ci”、ci(、ci[、ci{、ci&lt; - 分别更改这些配对标点符号中的文本内容 di’、di”、di(或dib、di[、di{或diB、di&lt; - 分别删除这些配对标点符号中的文本内容 yi’、yi”、yi(、yi[、yi{、yi&lt; - 分别复制这些配对标点符号中的文本内容 vi’、vi”、vi(、vi[、vi{、vi&lt; - 分别选中这些配对标点符号中的文本内容. % 快速定位到本行的括号","categories":[{"name":"工具","slug":"工具","permalink":"http://lwenxu.coding.me/categories/工具/"}],"tags":[{"name":"Vim","slug":"Vim","permalink":"http://lwenxu.coding.me/tags/Vim/"}]},{"title":"Scala 入门","slug":"Spark/Scala 入门","date":"2018-05-08T06:01:28.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/05/08/Spark/Scala 入门/","link":"","permalink":"http://lwenxu.coding.me/2018/05/08/Spark/Scala 入门/","excerpt":"","text":"1. 基本语法1. 变量 var123var name:string=\"hello\";var name=\"hello\";var num=3.0; 2. 常量 val1val name=\"string\"; 3. 这里是没有 ++ 操作和 – 操作的4. 函数调用不用使用对象来调用，导入包以后直接调用即可 1234import scala.math._sqrt(2);pow(1,2);min(1,2); 5.apply()默认调用了object的apply函数 1\"hello\"&lt;6&gt;; 6.if-else","categories":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/categories/Spark/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/tags/Spark/"}]},{"title":"SparkStreaming 入门","slug":"Spark/SparkStreming","date":"2018-05-08T06:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/05/08/Spark/SparkStreming/","link":"","permalink":"http://lwenxu.coding.me/2018/05/08/Spark/SparkStreming/","excerpt":"1. 基本原理其实在 SparkStreaming 中和之前的Core不同的就是他会把任务分成批次的进行处理，也就是我们需要设置间隔多久计算一次。 我们从网络，文件系统，Kafka 等等数据源产生的地方获取数据，然后SparkStreaming放到内存中，接着进行对数据进行计算，获取结果。","text":"1. 基本原理其实在 SparkStreaming 中和之前的Core不同的就是他会把任务分成批次的进行处理，也就是我们需要设置间隔多久计算一次。 我们从网络，文件系统，Kafka 等等数据源产生的地方获取数据，然后SparkStreaming放到内存中，接着进行对数据进行计算，获取结果。 在一个Spark应用程序启动以后会产生一个SparkContext和一个StreamingContext，后者是基于前者的，接着就是每一个集群的单节点上就有Executor 这些Executor中是有Receiver的，然后这些Receiver就负责来自于网络以及Kafka等等的数据源的数据收集，这些数据会被拆分成Block分发到各个集群节点上，最后Receiver就把这些block信息发给StreamingContext 他会把告诉 SparkContext 去处理 job ，然后SparkContext 就启动 job 分配给 Executor 2. 基本概念1. StreamingContext这个东西就相当于所有的 Streaming 任务的主入口，所有的 Streaming 任务都需要他来完成。这个东西在定义以后我们书写计算任务的计划，完成之后我们不能在代码中 stop 后继续 start Streaming ，也就是没办法重启，只能在命令行重启。然后再JVM中只能存在一个此对象。 2. DStream这个东西其实就相当于一个RDD的小截断，我们可以把数据想象成一个流，然后我们从里面截取一小段流就是我们说的 DStream ，然后 里面包含的就是各个 RDD。所以说如果我们队一个DStream 进行一个操作就相当于我们对里面的所有的RDD进行操作。那么这个DStream的长度是多少？这就是我们定义的计算的长度，也就是多久计算一次。 3. InputDStream其实在每一个DStream中都包含了一个Receiver，但是除了FileDStream。这个Receiver就是从各个数据源进行获取数据用的， 他会把数据源获取的数据放到内存里面，但是我们文件系统中的数据我们可以直接处理而不需要收集这些数据。 我们基本的Receiver就是文件系统和TCP，然后我们有一些高级的就是 Flume 和 Kafka 等等。 注意一点就是我们在运行这些任务的时候我们不能写 local 或者 local[1] 因为我们在处理的时候必须要有两个线程以上，一个需要进行Receiver另外一个是数据计算。 4. 带状态的数据处理 UpdateStateByKey123456789101112/***把当前的数据去更新已有的或者是老的数据*@param currentValues 当前的*@param preValues 老的的*@return*/def updateFunction(currentValues:Seq[Int],preValues:Option[Int]):Option[Int]=&#123; val current=currentValues.sum //获取新的值 val pre=preValues.getOrElse(0) //获取以前的值，如果以前没有那么就是0 Some(current+pre)&#125; 要注意一点的就是当我们使用了带有状态的算子我们必须要使用，checkpoint 才行，也就是需要创建一个checkpoint目录，否则或报错。 5. 窗口计算窗口计算说的简单点其实就是说每隔多少秒计算多少秒内的结果。windowLength 和 interval 也就是每隔 interval 计算 windowLength 的长度的窗口。 算子在常用的加上一个AndWindow 官网有。 3. 黑名单的例子12345678910111213141516171819202122232425262728/* 12121,zs 12121,ls 12124,ws 12126,ws */object BlackFilter&#123; def main(args: Array[String]): Unit = &#123; System.setProperty(\"hadoop.home.dir\", \"D:\\\\hadoop\\\\winutils\\\\hadoop-2.8.3\") val conf: SparkConf = new SparkConf().setAppName(\"black\").setMaster(\"local[*]\") val session: SparkSession = SparkSession.builder.config(conf).getOrCreate() val sc: SparkContext = session.sparkContext val ssc = new StreamingContext(sc,Seconds(5)) //val sc = new SparkContext(conf) val blackList: RDD[(String, Boolean)] = sc.parallelize(List(\"zs\", \"ls\")).map((_, true)) val logs: ReceiverInputDStream[String] = ssc.socketTextStream(\"master\",6700) // (ls,(12121,ls)) val clicklog=logs.map(log=&gt;(log.split(\",\")(1),log)).transform(rdd=&gt;&#123; // ((ls,(12121,ls)),(ls,true/\"\")) rdd.leftOuterJoin(blackList) .filter(!_._2._2.getOrElse(false)) .map(_._2._1) &#125;) clicklog.print() ssc.start() ssc.awaitTermination() &#125;&#125; 4. SparkStreaming和Flume整合1. 配置对于这个我们有两种配置方式，使用Flume的推送机制，也就是把我们的SparkStreaming作为一个avro的客户端来接受从channel过来的数据。 1. Flume 的推送机制我们把SparkStreaming作为一个avro的客户端，来接受数据进行处理。由于是push的模型，我们的SparkStreaming必须先启动。 1. 配置Flume的配置文件123456789101112131415161718netcat-memcory-avro.sources = netcat-sourcenetcat-memcory-avro.sinks = avro-sinknetcat-memcory-avro.channels = memory-channelnetcat-memcory-avro.sources.netcat-source.type = netcatnetcat-memcory-avro.sources.netcat-source.bind = masternetcat-memcory-avro.sources.netcat-source.port = 44444netcat-memcory-avro.sinks.avro-sink.type = avronetcat-memcory-avro.sinks.avro-sink.hostname = masternetcat-memcory-avro.sinks.avro-sink.port = 44445netcat-memcory-avro.channels.memory-channel.type = memorynetcat-memcory-avro.channels.memory-channel.capacity = 1000netcat-memcory-avro.channels.memory-channel.transactionCapacity = 100netcat-memcory-avro.sources.netcat-source.channels = memory-channelnetcat-memcory-avro.sinks.avro-sink.channel = memory-channel 2 . Scala 代码12345678910111213141516object FlumeWC &#123; def main(args: Array[String]): Unit = &#123; System.setProperty(\"hadoop.home.dir\", \"D:\\\\hadoop\\\\winutils\\\\hadoop-2.8.3\") val conf: SparkConf = new SparkConf().setAppName(\"FlumeWC\").setMaster(\"local[*]\") val sc = new SparkContext(conf) val ssc = new StreamingContext(sc, Seconds(1)) val stream: ReceiverInputDStream[SparkFlumeEvent] = FlumeUtils.createStream(ssc, \"219.245.31.193\", 44445) val res: DStream[(String, Int)] =stream.map(x =&gt; new String(x.event.getBody.array).trim) .flatMap(_.split(\" \")) .map((_, 1)) .reduceByKey(_+_) res.print() ssc.start() ssc.awaitTermination() &#125;&#125; 2. 使用pull的方式这种方式是Flume将数据sink到缓冲区中，然后我们使用Spark事务的去拉取数据，如果拉取到了才会删除那些在缓冲区的数据，也就是说这里的容错性更加的高，更可靠。 1. 配置文件123456789101112131415161718netcat-memcory-avro.sources = netcat-sourcenetcat-memcory-avro.sinks = spark-sinknetcat-memcory-avro.channels = memory-channelnetcat-memcory-avro.sources.netcat-source.type = netcatnetcat-memcory-avro.sources.netcat-source.bind = 127.0.0.1netcat-memcory-avro.sources.netcat-source.port = 44444netcat-memcory-avro.sinks.spark-sink.type = org.apache.spark.streaming.flume.sink.SparkSinknetcat-memcory-avro.sinks.spark-sink.hostname = 219.245.31.193netcat-memcory-avro.sinks.spark-sink.port = 44445netcat-memcory-avro.channels.memory-channel.type = memorynetcat-memcory-avro.channels.memory-channel.capacity = 1000netcat-memcory-avro.channels.memory-channel.transactionCapacity = 100netcat-memcory-avro.sources.netcat-source.channels = memory-channelnetcat-memcory-avro.sinks.spark-sink.channel = memory-channel","categories":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/categories/Spark/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"http://lwenxu.coding.me/tags/Spark/"}]},{"title":"Python 笔记","slug":"Python/Python笔记","date":"2018-05-06T15:18:33.000Z","updated":"2019-09-28T08:10:02.612Z","comments":true,"path":"2018/05/06/Python/Python笔记/","link":"","permalink":"http://lwenxu.coding.me/2018/05/06/Python/Python笔记/","excerpt":"","text":"字符集和编码​","categories":[{"name":"Python","slug":"Python","permalink":"http://lwenxu.coding.me/categories/Python/"}],"tags":[]},{"title":"数字图像处理","slug":"Others/数字图像处理","date":"2018-05-06T02:15:13.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/05/06/Others/数字图像处理/","link":"","permalink":"http://lwenxu.coding.me/2018/05/06/Others/数字图像处理/","excerpt":"1.基本概念1. 图像的定义 图像：一幅图像是一个东西的另一种表示，是其所表示物体信息的一个浓缩和高度概括。 2. 图像分类1. 模拟图像：连续变化的函数2. 数字图像：离散的矩阵表示数字图像的定义:数字图像是指由被称为像素的小区域组成的二维矩阵。 数字图像类型： 二值图像：只有0、1 （黑、白） 灰度图像：像素取值是 0-255 ，有中间过度。","text":"1.基本概念1. 图像的定义 图像：一幅图像是一个东西的另一种表示，是其所表示物体信息的一个浓缩和高度概括。 2. 图像分类1. 模拟图像：连续变化的函数2. 数字图像：离散的矩阵表示数字图像的定义:数字图像是指由被称为像素的小区域组成的二维矩阵。 数字图像类型： 二值图像：只有0、1 （黑、白） 灰度图像：像素取值是 0-255 ，有中间过度。 彩色（索引）图像：两个矩阵，一个就是灰度图像的矩阵，另外一个是颜色映像表矩阵对应使用。 GRB彩色图像：每个像素由 RGB 组成。这是九个像素点，每个像素点有2^24中可能，所以也叫做24位真彩。 2. 图像概念 图像质量 灰度级：表示图像的明暗程度（例如：像素的取值范围为0-255，就称该图像为256个灰度级的图像） 量化级别：表示图像实际拥有的灰度级的数量（例如：具有32种不同取值的图像，可称该图像具有32个量化级别）图像数据的实际量化级别越多，视觉效果就越好，主要就是看起来过度很平滑，没有断层。 数字图像处理概念：对数字图像信息进行加工(处理)和分析,以满足人的视觉、心理需要；或者实际应用或某种目的（如机器识别）的要求。 图像质量参数 分辨率：分辨率就是图像的 水平方向的像素点数*垂直方向的像素点数 图像深度：一个像素点的颜色灰度所占用的二进制位的个数，如 RGB 是 256 * 256 * 256 也就是 2^24 称为 24 位真彩色。 图像数据量：图片占的磁盘空间。 数字图像处理系统： 采集：对某个电磁波的能量段，或者数码相机扫描仪等等 处理分析：可以采用软件完成也可使用硬件完成 通讯/存储：光盘，SD/计算机网络 显示：显示器，胶片等等 图像的数字化过程： 扫描：对图像进行遍历 采样：对于连续的图像编变成离散点的操作 量化：将采样得到的灰度值转换为离散的整数值 3. 影响清晰度的因素包括 亮度 对比度 尺寸大小 细微层次 颜色饱和度 4. 图像处理的层次： 图像处理：对图像进行处理加工以改。善视觉效果。他是一个图像到图像的过程。（比如：图像增强） 图像分析：以感兴趣的部分进行提取分隔和测量。他是一个图像到数据的过程。（比如：图像分割） 图像理解：分析的基础上做含义的理解。（比如：虹膜识别，人体识别） 2. Matlab 基础1.主要窗口 命令窗口 命令历史窗口 工作空间窗口 当前路径窗口 2.常用命令 whos 图像信息 size 图像大小 imshow(i,[low,high]) 高于 high 为白色，低于 low 为黑色，两者之间的进行比例拉伸 figure；创建一个新的窗口，可以在不同窗口显示图像。 Subplot(m,n,p)含义为：打开一个有m行n列图像位置的窗口，并将焦点位于第p个位置上。 mat2gray(f,min,max) ：介于min和max的数据归一化处理， 其余小于min的元素都变为0， 大于max的元素都变为1 im2bw(I,T)：亮度值&lt;T的像素点全部转换为二值图像中值为0的像素点；亮度值&gt;T的像素点全部转换为二值图像中值为1的像素点。 rgb2gray(f)：彩色图像转换为灰度图像 数组： a=1:10 表示创建一个 1-10 的一个行向量 a=[1,2,3 ; 2,3,4] 创建一个二维的数组，用 ; 分隔 数组的索引是从 1 开始的 a(1:5) 表示取 1-5 这5个索引处的数 多维数组用 a(2,3) 索引，表示 2 行 3 列的元素值 只有一个冒号表示选择所有的行或者列 如 a(:,2) 表示选择第2列的所有元素 如果直接是 a(:) 则是表示把所有的列拼接成一列然后显示 zeros(n,m)：n*m大小的 double 0 矩阵 ones：同上 1 矩阵 向量化循环 3.图像增强1.图像增强：图像增强是指对图像进行加工处理，以得到更好的视觉效果和对机器感知来说更好的图像。 空域处理 亮度变换 空间滤波 频域处理 2.亮度变换imadjust(f,[l_in,h_in],[l_out,h_out]) &lt;= l_in 映射值为 l_out &gt;=h_in 映射值为 h_out 处于两者之间的按比例映射到 l_out 与 h_out 之间 就很像 imshow 函数 3. 灰度直方图1.直方图基础 定义：图像中灰度级分布的统计，反映的是一幅图像中各灰度级像素出现的频率。 性质：如果一幅图像由两个不连续的区域组成，并且每个区域的直方图已知，则整幅图像的直方图是这两个区域的直方图之和。 核心函数：imhist(f,b) 对 f 这个图像分割成 b 个灰度级别进行统计 2. 直方图均衡化通过对原始图像的灰度进行非线性的变化，使其直方图能够均匀的分布以增加灰度值的动态范围从而达到增强图像的整体的对比度。 图像均衡化处理后，图像的直方图是均匀分布的，即各灰度级具有相同的出现频数 均衡化的具体步骤 均衡化的内置函数：histeq(f,b) 这个 b 就是均衡化的灰度级数，默认值是 64 一般我们手动赋值为 256 3.直方图规定化就是通过一个灰度映像函数，将原灰度直方图改造成所希望的直方图。 histeq(f,[]) 就是对 f 进行规定化让他近似的形成后面的那个行向量的结果。 4.空间滤波空间滤波就是使用空间模板进行图像处理，模板本身称为空间滤波器。 分类 按照处理的效果分类：分为平滑滤波器和锐化滤波器 按照处理的方式分类：分为线性滤波（均值滤波高斯滤波，也就是原始数据和滤波结果是一中算术运算关系）和非线性滤波（采用一种逻辑关系进行滤波操作，最大值、最小值、中值滤波）。总的来说当邻域中像素的运算为线性运算时，就称为线性滤波，否则称为非线性滤波。 1.线性滤波 基本概念 卷积：是指掩膜w在图像f中移动前，先将w 旋转180º。 相关：模板w在图像上移动的过程。首先需要对齐然后进行零填充，对齐的过程就是把模板的最右下角和图像的左上角对齐，然后漏出来的部分就用零来填充。 卷积：模板 w 在图像上移动过程，移动之前是先把 w 旋转180 度。同上。 上面的两个操作都有一个full 和 same 的说法，其中 full 就是保持以前的零填充不变，然后 same 则是结果去掉以前的零填充。 空间滤波函数 imfilter(f , w , ‘corr/conv’ , ‘replicate ‘ ,’same/full’ ) 手动线性滤波函数 w = fspecial(‘average/gaussian/log/laplacian’,parameters[一般给0就行了]) 生成线性滤波器的工具箱函数 最后我们使用 imfilter 的执行结果是需要去除的东西，而非是我们滤波完成后的结果，也就是我们需要用原图像减去 imfilter 的结果，才是我们最后的滤波结果。这里需要注意的就是我们原图像需要转化成double 的。也就是 im2double(f)-imfilter(f,w,’corr’,’replicate’,’same’) 才是最终的结果。 2.非线性滤波 二维中值滤波：medfilt2(f,[n m],’zero/indexed’) 第二个参数指明的是邻域的范围。中值滤波对椒盐噪声的过滤效果非常好。 4. 频域滤波1. 基本步骤： 使用paddedsize获取填充参数 获得傅立叶变换 生成滤波函数 与滤波函数相乘进行变换 获取变换结果的实部 将左上角的居心修剪为原始大小 代码： 12345678f=imread('path');PQ=paddedsize(f);ff=fft2(f,PQ(1),PQ(2));H=lpfilter('guassian',PQ(1),PQ(2),PQ(1)*10);g=H.*ff;g=real(ifft2(g));g=g(1:size(f,1),1:size(f,2));imshow(g,[]); 2. 频域滤波器和空域滤波器的比较 如果两个域中滤波器尺寸相同，那么通常频域中进行滤波计算更为有效，更为直观，但空域中更适用更小尺寸的滤波器，更为高效。 3. 低通滤波器 从名字就可以听出来就是允许低频的成分过去而去掉高频的成分。低频成分其实就是我们的频域图的中心的白色部分。这些低频成分保留了我们的色彩等信息，也就是如果我们只有一点点低频成分的话却掉所有的高频成分我们看到的是一堆模糊的颜色没有任何的细节。 ![屏幕快照 2018-06-30 18.00.53](/Users/lwen/Pictures/screenshot/屏幕快照 2018-06-30 18.00.53.png) 振铃现象：就是图像出现加边现象。 理想的低通滤波器：就是他的效果不理想，会出现振铃现象。 巴特沃斯低通滤波器：对于2阶的这一类的低通的巴特沃斯低通滤波器是不会出现振铃现象的，但是如果随着阶数增加就会出现明显的振铃现象。 高斯低通滤波器：这种能够完成没有振铃现象的滤波效果，但是他的平滑效果要比巴特沃斯差一些。 以上三种滤波器他们的滤波效果从好到差，但是振铃现象就是从无到有。 4. 高通滤波器 高通滤波器就是滤掉高频的成分，保留低频的，也就是会失去色彩但是保留细节，那么出来的效果其实就是锐化图像。 同样的我们的高频滤波器经典的还是以上三种，因为我们的高通滤波器和低通滤波器不同点就是他们用1减去后就另外一个。然后他们的滤波效果也是同上，依次递减但是振铃现象也是一次递减。越是后面的越能够凸显出图像的细节，对于细小的物体就越清晰。 4. 图像分割1.概念：图像分割就是把图像分割成各具特征的区域，并提取感兴趣的目标的技术。 2.方法 基于边缘检测的方式：找出图像的边缘，检测出图像边缘的不连续性，再将它们连成边界，这些边界把图像分成不同的区域，从而分出各个区域。 基于阈值的方式：根据实现提供的阈值进行对图像中不同的对象进行分类提取需要的部分。 3.检测方法1.点检测使用 imfilter 来检测孤立点。具体的代码可以为 g=abs(imfilter(double(f),w))&gt;T 也就是获取这样的点就是我们需要的点。我们的T值一般可以选择 max(g) 2. 线检测也就是和上面的点检测一模一样只是我们的模板不同而已，然后我们只需要在里面找到最大的点然后依据他来进行划分就好了。例如下面一份完整的代码： 123456f=imread('path');w=[...];gs=abs(imfilter(double(f),w));maxVal=max(gs(:));g=gs&gt;=maxVal;imshow(g); 3.边缘检测边缘检测的方法有两大类： 一阶导数：梯度算子 二阶导数：拉普拉斯算子，拉普拉斯算子一般不做真正的边缘检测只是做辅助角色。 edge函数： 格式：edge(f,’Sobel/Roberts/Prewitt/Canny’,parameters) 一阶算子比较： Sobel 抗干扰能力强，但是检测出来的边缘很宽 Prewitt 既能够抗干扰也能够有合适的边缘的宽度。 Roberts 抗干扰能力不强，但是边缘窄 4.阈值分割 迭代法：就是先取 (max+min)/2 分成两部分，然后每一部分的图像平均值为 g1 和 g2 那么就可以算出下一个阈值为 (g1+g2)/2 重复上面的操作然后一直到达某一个特定的阈值之后才停止。这个过程可以手动编码一可以使用工具箱中的自带的函数 T=graythresh(f) otsu()函数计算阈值。 5.形态学处理1.膨胀腐蚀就是将一个模板进行原点的反转，然后和图形中的每一个像素进行移动，将模板与他交集不为空的位置设置为1。主要使用的函数就是 imdilate(f,w) 作用就是：使图像加粗变大，桥接裂缝。 2.腐蚀腐蚀同上的操作只是只是在模板完全被包裹的时候这个模板的中心才是 1 ，其余位置都为 0。和他相关的函数就是imerode(f,w) 同样的他的作用就是使图像变小变细，消除边界点，消除联通，消除凸起，平滑图像。 3.开运算开运算：使图像的轮廓变得光滑，断开狭窄的间断和消除细的突出物。 imopen(f,w) 先对A进行B腐蚀然后再进行B膨胀，因为主导地位的是腐蚀操作，所以基本他对外表示的特征就是腐蚀的特征。 4.闭运算闭运算也能够平滑图像，它与开运算不同的就是它能够连接细长的鸿沟，填补裂痕。imclose(f,w) 他的操作也就是先进行膨胀操作然后进行腐蚀操作。 5.击中击不中变换这个操作就是一个图像一个模板，第一次进行的是原图像和原模板进行击中变换操作其实就是类似于腐蚀操作，然后就是进行原图像的补与原模板的补的腐蚀操作，最后两次操作的结果进行与运算。 6.顶帽变换其实这个变换就是原图像减去开运算的结果。也有对应的函数就是 12se=strel('disk',10);imtophat(f,se); 6.图像复原1.基本概念 图像退化：图像退化指的就是由于成像系统的各种因素使得图像的成像质量变低 图像复原的目的：就是尽可能的消除图像在获取及传输过程中造成的图像的品质下降的即退化现象退服图像本来的面目。 图像增强：旨在改善图像质量。提高图像的可懂度。更偏向主观判断，即要突出所关心的信息，满足人的视觉系统，具有好的视觉结果。 图像复原：根据图像畸变或退化的原因，进行模型化处理，将质量退化的图像重建或恢复到原始图像，即恢复退化图像的本来面目，忠实于原图像。因此必须根据一定的图像退化模型来进行图像复原。 噪声模型：加型噪声，乘型噪声 几种常见的噪声： 高斯噪声：每一点都有噪声，但是噪声的幅值是随机的。 椒盐噪声：噪声的位置是随机的，但是噪声的幅值是基本相同。 图像复原： 如果是我们的图像的退化仅仅是由噪声引起的那么我们就应该使用空间滤波，至于线性和非线性都是可以的，如线性的就是 imfilter 还有非线性的 medfilt 、ordfilt 利用频域处理消除周期性噪声。 7.图像压缩1.图像数据冗余： 编码冗余：编码冗余就是但我们的灰度级编码多余实际需要的编码的时候就会出现编码冗余。 像素间的冗余：单个像素携带的信息较少，单个像素的贡献是多余的。 心理视觉冗余：不重要的视觉信息称为心理视觉冗余。 图像压缩系统的基本结构 映射转换器：把输入图像转换成冗余度比较小的数据格式，便于压缩、 量化器：产生用于表示被压缩图像的有限数量的符号集合 符号编码器：对每一个符号分配一个码字或者二进制比特流。 符号解码器 反映射转换器 8. 试卷 图像工程的三个层次：图像处理、图像分析、图像理解 低频是细节、高频是轮廓、噪声一般也是高频的。 细节性的图像的空间分辨率精细幅度分辨率粗糙，而那种合照这是刚好相反。 当图像进行缩小变化的时候傅里叶图像是被延展的。 K——L 变化成为最佳变换 WHT 计算最简单但是效果最差 DFT 回复图像有振铃现象 中值滤波器是在消除噪声的同时保护边缘信息。 三个小概念 亮度：指的是画面的明暗度， 对比度：画面的黑与白的渐变层次，比值越大就说明层次越多图像越清晰，色彩明晰靓丽。 饱和度：指的是颜色的纯度 图像分割的方法： 基于区域生长的 边缘检测 基于阈值的方法 拉普拉斯算子为二阶差分，其方向信息丢失，常产生双像素，对噪声有双倍加强作用，因此它很少直接用于边缘检测","categories":[],"tags":[{"name":"数字图像","slug":"数字图像","permalink":"http://lwenxu.coding.me/tags/数字图像/"}]},{"title":"Docker 入门","slug":"Linux/Docker 入门","date":"2018-04-29T04:32:34.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2018/04/29/Linux/Docker 入门/","link":"","permalink":"http://lwenxu.coding.me/2018/04/29/Linux/Docker 入门/","excerpt":"1. Docker 简介直接运行于操作系统内核上的虚拟化解决方案，他是一个操作系统级别的虚拟化也就是说容器只能运行在相同或者相似的内和操作系统之上的。所以我们只能在 docker 中运行 Linux 系统而不能运行 Windows 系统。他是依赖于 Linux 的内核特性：Namespace 和 Cgroup （Control Group）。","text":"1. Docker 简介直接运行于操作系统内核上的虚拟化解决方案，他是一个操作系统级别的虚拟化也就是说容器只能运行在相同或者相似的内和操作系统之上的。所以我们只能在 docker 中运行 Linux 系统而不能运行 Windows 系统。他是依赖于 Linux 的内核特性：Namespace 和 Cgroup （Control Group）。 1. VM vs Docker 可以看到，在虚拟机上我们需要包含到细腻华技术和操作系统，但是我们在 Docker 中只需要依赖底层的操作系统，和一些必要的库，所以在空间上有非常大的优势，另外就是速度上，由于启动的服务更少，无需启动 OS 所以开销更小。 2. 镜像 docker 的镜像组成如上图，最底层就启动层，然后就是 root 文件系统，接着是我们自己叠加的各种应用。注意这里的每一层都是只读的，但是在我们的 linux 中，root 一开始是只读的，加载完毕后是可写的，但是这里不同，主要就是因为可以进行镜像的叠加。然后使用联合加载技术，同时把所有的镜像层加载进去。 3. 容器docker 的镜像相当于一个 class 类，然后容器则是 new 出来的对象。容器是基于镜像运行出来的，但是我们有时候还是需要对镜像或者容器进行修改，这里采用的方式就是在镜像的最上面一层添加上一层虚拟的层，写得操作都是在这一层，当我们要生成新的镜像的时候就是把这一层设置为只读。这也是 docker 的 CopyOnWrite 技术。 4. Namespace 和 CgroupsLinux 内核实现的 Namespace 就是用于文件系统，进程，网络，IPC，MNT，UTS 的隔离。而 Cgroups 是用于对上面的 namespace 的资源限制，优先级设定。 2. 容器基本操作1.启动容器1docker run image args cmd 2.创建交互容器1docker run -i -t ubuntu /bin/bash 3. 查看所有容器/最近创建的容器1docker ps -a/-l 4. 检查 docker 容器，返回详细信息1docker inspect ubuntu 5. 设置容器名1docker run --name ubu ubuntu 6. 以交互方式启动已经停止的容器1docker start -i ubu 7. 删除停止的容器1docker rm ubu 8. 守护运行在运行docker 容器以后我们要退出的时候不要用 ctrl+c 或者 exit ，使用 ctrl+p/q 既可以实现以 Daemon 方式运行容器。而此时如果我们需要再次进入容器我们需要使用 docker attach name 来进入容器。 另外我们还可以使用 -d 参数在运行容器的时候让他进入 Daemon 状态。 9. 查看输出当我们在后台状态运行容器的时候有时候我们需要查看对应的输出，就可以使用 1docker logs -f -t --tail nun name -f 是实时更新输出（follow） -t 则是带有时间的日志（timestamp） —tail 指定结尾行数 10. 查看运行容器中运行的进程1docker top name 11. 在运行的容器中启动新的进程/运行新的命令1docker exec -i/-t name #类似 run 12. 停止容器12docker stop name #信号docker kill name #杀死 3. 镜像操作1. 查看镜像1docker [-f --no-tunck -a -q] images -f 使用过滤器，过滤部分镜像 —no-tunck 不进行 id 的截断 -a 显示所有的镜像 -q 只显示镜像 id 2. tag表示一个镜像的不同版本。 3. 删除镜像1docker rmi name:tag 删除镜像，当我们删除的是很多的镜像的一个 tag 则是 untag 操作。 4. 查找镜像 dockerhub 网站 使用 search 命令 1docker search [-s num] name -s 过滤最低星级 5. 获取镜像1docker [-a] pull name -a 这个参数就是下载所有 tag 的镜像。 6. push 镜像1docker push rep/name 在上传的时候我们只上传了修改的部分，而不是全部。 7. 构建 docker 镜像1. docker commit1docker commit [-a -m ] name rep/name 把镜像提交成一个新的镜像。 -a 作者信息 -m 提交信息 2. docker file创建 dockerfile 然后使用 docker bulid -t name filepath 构建镜像。 8. Dockerfile FROM 第一条非注释命令，表示采用那个镜像作为基础镜像 MAINTAINER 维护者信息 RUN cmd 每一个 run 都会创建一个新的层 EXPOSE port 开放端口 CMD 运行时运行，会被 RUN 覆盖 ENTERPOINT 同上，但是不会被 RUN 覆盖 ADD/COPY src des 复制文件，ADD 有类似解压功能，COPY 没有 4. Docker 容器连接1. docker 之间的连接我们可以使用 1docker run --link=name:alias 接下来访问响应的主机我们只需要使用 alias 即可。因为实际上是在这台机子上做了很多的环境变量还有 host 的修改导致的。 2. 拒绝连接123--icc =false --link--iptables=true 如果配置了 —icc=false 那么就是拒绝所有的连接。而当我们配置了 iptables 则只允许 link 指定的容器。 5. 数据卷 数据卷说白了就是数据映射，将本机的数据映射到 docker 容器中。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://lwenxu.coding.me/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://lwenxu.coding.me/tags/Docker/"}]},{"title":"SpringMVC 踩坑记录","slug":"SpringMVC/Spring踩坑记录","date":"2018-04-22T00:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/04/22/SpringMVC/Spring踩坑记录/","link":"","permalink":"http://lwenxu.coding.me/2018/04/22/SpringMVC/Spring踩坑记录/","excerpt":"","text":"1. 处理静态资源静态资源直接放在 webapp/web 下，而我们的模板一般是在 WEB-INF 下，但是 WEN-INF 下的东西一般不让访问的，模板之所以能访问到是因为有模板引擎的映射，但是我们的警惕资源应该是直接能访问的东西，直接放在 web 下类似于 jsp 直接访问，而不能放在 WEB-INF 下，并且我们要开启静态资源访问 &lt;mvc:default-servlet-handler/&gt; 2. Thymeleaf 乱码问题一开始除了乱码想着直接在 web.xml 中配置编码过滤器，接着发现根本没用还是一样的乱码，并且返回的是 ISO-8859-1的西欧字符集。后来想着如果是不是 SpringMVC 的问题，那么可能就是因为视图是被 Thymeleaf 渲染的导致的问题，然后找到 Thymeleaf 在 SpringMVC 中的配置，然后更改编码。重新启动项目才行。","categories":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://lwenxu.coding.me/categories/SpringMVC/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://lwenxu.coding.me/tags/SpringMVC/"}]},{"title":"SpringMVC 整合","slug":"SpringMVC/Spring 整合","date":"2018-04-21T12:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/04/21/SpringMVC/Spring 整合/","link":"","permalink":"http://lwenxu.coding.me/2018/04/21/SpringMVC/Spring 整合/","excerpt":"","text":"今天一开始直接用了 Idea 来创建一个 SpringMVC+Spring+Mybatis+Thymeleaf 的项目，一开始还是挺顺利的，除了在 Thymeleaf 那个地方卡了一下，后面项目还是顺利跑起来了。 接着想用 Maven 搭建，因为一开始用 Idea 生成的项目使用的手动导入 jar 这样非常费力，为了一劳永逸和简单就采用了 maven 来构建项目。最后发现自己陷入了一个大坑，好久没有跳上来。 接着我就把用 Maven 搭建 SpringMVC + Spring + Mybatis + Thymeleaf 项目过程写下来，免得日后再采坑，以后项目直接拷贝就可以了不用再配置了！ 1. 创建 Maven 项目 2.添加 web 模块 在这里面勾选上 web 模块，接着我们会看到我们的项目中多了一个 web 目录也就是最重要的 WEB-INF 等等。 3. web 模块移动 我们把 web 模块移动到这里，方便观看。以及在 maven 项目之内，接着我们需要改一下项目配置，因为我们移动了这个模块。如果移动的时候更新了依赖就无需这步操作。 4. 配置文件 创建配置文件如上。 spring 的配置文件 applicationContext.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!--配置包扫描--&gt; &lt;context:component-scan base-package=\"com.lwen\"/&gt; &lt;!--配置静态资源访问--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--配置注解--&gt; &lt;mvc:annotation-driven/&gt; &lt;!--配置 thymeleaf 视图解析器 类似于 jsp 解析器--&gt; &lt;bean id=\"templateResolver\" class=\"org.thymeleaf.spring4.templateresolver.SpringResourceTemplateResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/templates/\" /&gt; &lt;property name=\"suffix\" value=\".html\" /&gt; &lt;property name=\"templateMode\" value=\"HTML5\" /&gt; &lt;/bean&gt; &lt;bean id=\"templateEngine\" class=\"org.thymeleaf.spring4.SpringTemplateEngine\"&gt; &lt;property name=\"templateResolver\" ref=\"templateResolver\" /&gt; &lt;/bean&gt; &lt;bean class=\"org.thymeleaf.spring4.view.ThymeleafViewResolver\"&gt; &lt;property name=\"templateEngine\" ref=\"templateEngine\" /&gt; &lt;/bean&gt; &lt;!--配置外部配置文件--&gt; &lt;context:property-placeholder location=\"classpath:properties.properties\"/&gt; &lt;!--配置druid数据库连接池--&gt; &lt;bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"&gt; &lt;!-- 数据库基本信息配置 --&gt; &lt;property name=\"url\" value=\"$&#123;url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;password&#125;\" /&gt; &lt;property name=\"driverClassName\" value=\"$&#123;driverClassName&#125;\" /&gt; &lt;!-- 最大并发连接数 --&gt; &lt;property name=\"maxActive\" value=\"$&#123;maxActive&#125;\" /&gt; &lt;!-- 初始化连接数量 --&gt; &lt;property name=\"initialSize\" value=\"$&#123;initialSize&#125;\" /&gt; &lt;/bean&gt; &lt;!--配置 spring 事务管理器--&gt; &lt;bean class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置注解事务--&gt; &lt;tx:annotation-driven/&gt; &lt;!--配置手动路由--&gt; &lt;mvc:view-controller path=\"/\" view-name=\"index\"/&gt;&lt;/beans&gt; springMVC 配置文件 dispatcher-servlet.xml 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt;&lt;/beans&gt; 数据库配置文件 properties.properties 123456url=jdbc:mysql://localhost:3306/dbspringusername=rootpassword=12345678driverClassName=com.mysql.jdbc.DrivermaxActive=500initialSize=5 5. pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.lwen&lt;/groupId&gt; &lt;artifactId&gt;springmvc&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;jdk‐1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.thymeleaf&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf&lt;/artifactId&gt; &lt;version&gt;3.0.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.thymeleaf&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-spring4&lt;/artifactId&gt; &lt;version&gt;3.0.9.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;aopalliance&lt;/groupId&gt; &lt;artifactId&gt;aopalliance&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.3.14.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-instrument&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-instrument-tomcat&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-messaging&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-oxm&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc-portlet&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-websocket&lt;/artifactId&gt; &lt;version&gt;4.3.16.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 6. 配置 jar 依赖 这步很重要，否则会一直报错，说找不到 class。","categories":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://lwenxu.coding.me/categories/SpringMVC/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://lwenxu.coding.me/tags/SpringMVC/"}]},{"title":"iTerm2 配置及使用技巧","slug":"Tools/iTerm2 配置及使用","date":"2018-04-20T13:09:40.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/04/20/Tools/iTerm2 配置及使用/","link":"","permalink":"http://lwenxu.coding.me/2018/04/20/Tools/iTerm2 配置及使用/","excerpt":"","text":"1. 技巧：1. 选中双击选中，三击选中整行，选中即复制。即任何选中状态的字符串都被放到了系统剪切板中。 2. command 可以拖拽选中的字符串； 点击 url：调用默认浏览器访问该网址； 点击文件：调用默认程序打开文件 3. 快捷键 切换 tab：⌘+←, ⌘+→ 切换分屏：⌘+[/] 新建 tab：⌘+t； 切分屏幕：⌘+d 水平切分，⌘+Shift+d 垂直切分； 智能查找，支持正则查找：⌘+f。 命令 说明 command + t 新建标签 command + w 关闭标签 command + 数字 command + 左右方向键 切换标签 command + enter 切换全屏 command + f 查找 command + d 垂直分屏 command + shift + d 水平分屏 command + option + 方向键 command + [ 或 command + ] 切换屏幕 command + ; 查看历史命令 command + shift + h 查看剪贴板历史 ctrl + u 清除当前行 ctrl + l 清屏 ctrl + a 到行首 ctrl + e 到行尾 ctrl + f/b 前进后退 ctrl + p 上一条命令 ctrl + r 搜索命令历史 4. 自动完成 cmd+; 自动完成 cmd+shift+h 历史记录 5. autojump 使用 j 目录名，无需完整的即可。 输入 d 显示之前跳过的目录 6. suggestions1git clone https://github.com/zsh-users/zsh-autosuggestions ~/.oh-my-zsh/custom/plugins/zsh-autosuggestions.git 在 .zshrc 中添加 zsh-autosuggestions 接着执行如下命令 12➜ ~ source .zshrc➜ ~ source .oh-my-zsh/custom/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh 即可使用了！","categories":[{"name":"开发工具","slug":"开发工具","permalink":"http://lwenxu.coding.me/categories/开发工具/"}],"tags":[{"name":"开发工具","slug":"开发工具","permalink":"http://lwenxu.coding.me/tags/开发工具/"}]},{"title":"SpringMVC 基础","slug":"SpringMVC/SpringMVC 基础","date":"2018-04-18T14:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/04/18/SpringMVC/SpringMVC 基础/","link":"","permalink":"http://lwenxu.coding.me/2018/04/18/SpringMVC/SpringMVC 基础/","excerpt":"","text":"1.SpringMVC 基础原理 C 前端控制器 ——&gt; DispatcherServlet M 数据对象 V 视图处理器ViewResvor &lt;!—more–&gt; 处理步骤： 发起请求到前端控制器 DispatcherServlet 然后这个控制器会调用 HandlerMapping 查找对应的 Controller或者说 Handler 找到了对应的 Controller 就让 HandlerAdaptor 去执行 handler 执行了 handler 以后返回的就是 ModelAndView 对象。 对象返回给前端控制器，然后前端控制器会丢给 ViewResovr 去解析 然后继续返回给前端控制器并返回给用户。 2.基础程序1. 配置基础的 web.xml 加载 SpringMVC在 web.xml 中我们需要配一个 Servlet 和一个 Listener ，这个 Servlet 其实就是我们的路由调度器，然后 Listener 则是上下文监听器。还有一个初始化参数就是指定 spring 的配置文件的位置。 其实这些配置基本都是固定的，在使用 idea 建立 SpringMVC 项目的时候他会自动的帮我们配置好，但是我们还是需要在进行一些配置。主要的配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\" version=\"4.0\"&gt; &lt;!--配置 spring 的配置文件--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;!--1. / 所有的都进行解析，但是不管 jsp 2. *.from 3. /* 不能用 所有的都拦截 --&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;HttpHiddenMethods&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HttpHiddenMethods&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 2. 配置基础的 spring 配置文件接着就是配置 spring 配置文件，可以看到在上面的 web.xml 中我们在初始化参数中指定了 spring 的配置文件就是 applicationContext.xml 放在了 WEB-INF 路径下面。 然后需要配置一些核心的 bean 让 spring 进行自动加载，以需要配置扫描的包。 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt; &lt;!--&amp;lt;!&amp;ndash;处理器映射器&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;bean class=\"org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping\"/&gt;--&gt; &lt;!--&amp;lt;!&amp;ndash;处理器适配器&amp;ndash;&amp;gt;--&gt; &lt;!--&lt;bean class=\"org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter\"/&gt;--&gt; &lt;!--视图解析器--&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;property name=\"prefix\" value=\"/WEB_INF/templates/\"/&gt; &lt;property name=\"suffix\" value=\".jsp\"/&gt; &lt;/bean&gt; &lt;!-- 配置需要扫描的包--&gt; &lt;context:component-scan base-package=\"com.mvc\"/&gt; &lt;!--必须要的，配置了 springMVC 的注解生效，不然的话我们的 url 映射还是通过配置文件的方式生效的 不然一直处于 404 状态，这也就是下面的 dispatcher-servlet.xml 的作用配置 url 映射 --&gt; &lt;mvc:annotation-driven /&gt;&lt;/beans&gt; 3. 控制器12345678@Controllerpublic class Test &#123; @RequestMapping(\"/helloTest\") public String hello()&#123; return \"hello\"; &#125;&#125; 这样我们的程序就能够跑起来了。 3. RESTful 风格的请求一般的我们无法直接使用 RESTful 风格的请求，但是在 SpringMVC 中有一个过滤器可以帮我们把一个 post 请求转化成为 PUT 或者 DELETE 请求。具体的做法如下： 1. 配置过滤器（HiddenHttpMethodFilter）​ 12345678&lt;filter&gt; &lt;filter-name&gt;HttpHiddenMethods&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;HttpHiddenMethods&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 2. 在 post 的表单域中封装一个 hidden 的 input 标签，用来说明提交方式123456&lt;form method=\"post\"&gt; &lt;input type=\"hidden\" name=\"_method\" value=\"PUT\"&gt;&lt;/form&gt;&lt;form method=\"post\"&gt; &lt;input type=\"hidden\" name=\"_method\" value=\"DELETE\"&gt;&lt;/form&gt; 4. @RequestMapping 及参数传递1. @RequestMapping 注解这个注解主要就是用来做方法和类的 url 映射的，也就是相当于一个路由映射文件。这个注解可以使用在类上面也可以使用在方法上面，在类上面的话就是我们访问每一个方法的时候都需要加上类的 url 前缀。 他有几个比较重要的属性，用来管理 url 的： value: 这个是默认的，是 url 地址 method：这个是用来指定请求方式的 RequestMethod.GET/POST/DELETE/PUT …. params：这个是用来规定我们的 url 中携带的参数的他是一个数组，可以放多个值 1params = &#123;\"username\",\"age!=10\"&#125; params 是包含 username age!=10 headers 也是如此只是规定了请求头而已 2. @PathVariable 注解这个注解的作用是用来传递参数的，我们不仅仅可使用 ？ 来传递参数，还可以使用更优雅的 /paramName/value 的方式来传递参数，并且能够直接在方法中绑定这些参数。 12345@RequestMapping(value = \"/helloworld/&#123;id&#125;\") public String hello(@PathVariable(\"id\") String id)&#123; System.out.println(\"hello controller\"); return \"hello\";&#125; 这里的 id 必须和 url 中的保持一致，但是无需和方法的参数保持一致。 3. @RequestParam 注解但是有一个问题，当我们传递过来的参数是通过 ？ 的形式传递过来的，那么我们又该怎么去获取他呢？是的这里我们可以使用 @RequestParam 方法来获取这些值，当我们有些参数不是必须传递的我们就可以使用 require=false 来规定不用必传，这个时候如果我们没有传值，这个参数刚好是一个引用类型的就会是 null 但是如果是一个基本数据类型，就会报错。我们必须手动的设置一个默认值。 1@RequestParam(value = \"age\",required = false,defaultValue = \"0\") Integer age 上面的参数就可以获取到 http://localhost/hello?age=10 这种的 url 的参数了、 4. @RequestHeader 注解用法同上！ 1@RequestHeader(\"Content-Type\") String content 5. @CookieValue 注解这个使用同上，获取 Cookie 的值。 6. POJO 参数（Java 类）我们的表单提交过来的数据会自动的被封装到 POJO 对象中，我们只需要配置好表单的 name 值和 Bean 的属性值一致即可，如果说里面有级联的属性，我们就使用 proA.proB 来封装。例如： 123456&lt;form method=\"post\"&gt; &lt;input type=\"text\" name=\"name\"/&gt; &lt;input type=\"text\" name=\"age\"/&gt; &lt;input type=\"text\" name=\"address.code\"&gt; &lt;input type=\"text\" name=\"address.name\"&gt;&lt;/form&gt; 这个表单就会被封装成一个 POJO 对象，这个对象里面有另外一个类的引用就导致了级联属性的出现，我们是就是使用了点的方式完成的封装。 7.原生的 Servlet API 参数它支持比较多的原生的 Servlet 的 API ，其实是在他内部调用了 request 对象的一些方法获取到的。 HttpServletRequest HTTPServletResponse HttpSession Locale InputStream OutputStream Reader Writer Principal 5. 控制器与视图间数据交互一般我们需要在控制器里面绑定一些数据到视图中，然后我们可以在视图里面采用标签来获取 Controller 里面的数据从而展示这些数据，在 SpringMVC 中有几种方法可以达到这个目的。 1. ModelAndView这个东西其实就像他的名字一样，他是 Model 数据和模型的结合体，我们可以往里面添加数据（Model），也可以把要转发的页面放在里面让视图解析器去渲染。所以说这个对象里面有一个 Model 属性，这个属性就是用来存放数据的，其实就是一个 Map 。Map 里面的这些数据都会被遍历然后放到 request 域对象之中，我们只需要在请求域中获取就好。 12345678910/** * ModelAndView 来用作 Controller 与 View 之间的数据交互的介质 * 也就是 Model 的载体 * @return */public ModelAndView modelAndViewTest()&#123; ModelAndView modelAndView = new ModelAndView(\"hello\"); modelAndView.addObject(\"time\", new Date()); return modelAndView;&#125; 2. Model/Map/ModelMap其实三个东西类型都是 Map 类型的，然后SpringMVC 在真正的传入的对象显然就是他们的实现类，这里我们不过分纠结，基层肯定是一个 Map 。Map 里面的这些数据都会被遍历然后放到 request 域对象之中，我们只需要在请求域中获取就好。 这个用起来也比较简单，就是在方法的入参里面传入这个一个东西就行了，而不是采用的返回值。Map 的具体的泛型就是 string 和 object。看下面的例子。 1234public String modelMap(Map&lt;String,Object&gt; map)&#123; map.put(\"time\", new Date()); return \"hello\"; &#125; 3. @SessionAttributes 注解这个注解只能放在类上面，然后我们使用 value 属性或者 types 属性来规定哪些属性需要被放在 Session 域中，这个两个属性其实都是一个数组，所以我们可以方多个值。 value 这个属性，就是当我们在放入 map 中的一个键名的时候我们就可以把它放到 session 域中。而 types 属性则是当我们放一个 class 的时候他会自动抓取处于 map 中的同类型的数据。 1@SessionAttributes(value = &#123;\"time\",\"username\"&#125;,types = &#123;String.class,Integer.class&#125;) 4. @ModelAttribute 注解这个注解是标识在方法上的，这个注解标识的方法会在所有的方法调用前被调用。在这个被标识的方法里面我们需要从数据库中获取对应的对象，然后把这个对象放到 map 里面，但是注意 map 中的键必须要是我们的 Model 类对应的小写的一个字符串才能起作用。当我们使用其他的方法来进行某个 model 的修改动作的时候我们某个字段不传的话这时候在 map 中的那个对象的对应字段挥起一个补充作用，把对应字段填上。 执行流程： 首先是执行了被这个注解标识的方法，将数据库中获取到的值放到了 map 里面，然后这个 map 是被放到了一个implicitModel 里面 然后在我们提交一个表单的时候，我们对应的方法的参数会到 implicitModel 里面查找对应的对象，查找的 key 就是先看看我们的这个方法的参数是否被 ``@ModelAttribute(value=”…”)` 修饰。如果是的话我们采用的是直接使用它的 value 属性作为 key 去查找。 如果没有这个注解修饰参数，则采用这个 POJO 的类名第一个字母小写作为 key 查找。 如果没有则看看是否这个类被 @SessionAttributes 注解 注释，如果是则是去 session 中查找，如果没有找到抛异常。 如果上面的情况都没找到，则是使用 POJO 反射创建一个新的对象把表单数据封装进去，而如果上面有找到的话我们就使用那个 Model 然后设置对应的属性值。 接着把这个修改后的 model 放到 implicitModel 进而放到 request 域中。 6.视图视图的解析步骤： 首先我们是访问了我们的控制器。 然后我们的控制器会返回 string 或者 VIewAndModel 对象。 他们都会被视图解析器（我们在 spring 中配置的 bean）包装成一个 ModelAndView 对象。 最后渲染视图，并转发到对应的视图。 1. 手动路由配置可以手动配置路由，不经过 controller 就可以访问到对应的视图。在 spring 配置文件里写上如下内容： 123&lt;mvc:annotation-driven /&gt;&lt;!--手动配置路由 直接路由到视图无需经过 controller--&gt;&lt;mvc:view-controller path=\"/success\" view-name=\"hello\"/&gt; 那么我们访问 http://localhost:8080/success 就被转发到 WEB_INF/templates/hello.jsp 具体的目录取决于我们配置的视图解析器的前缀和后缀。 2. 自定义视图解析器我们一般采用的就是 InternalResourceViewResolver 这个视图解析器，我们也可以自定义视图。自定义视图则需要一个特殊的视图解析器完成解析视图的工作，就是 BeanNameViewResolver 就是通过视图的 bean 的 name 来获取视图的。由于我们配置了多个视图解析器则需要定义一个优先级，哪个视图解析器先工作，使用 order 属性。 1234&lt;!--自定义的 Bean视图解析器 直接通过 bean 的 name 获取视图--&gt;&lt;bean class=\"org.springframework.web.servlet.view.BeanNameViewResolver\"&gt; &lt;property name=\"order\" value=\"100\"/&gt;&lt;/bean&gt; 下面是我们使用 bean 定义的一个视图。 123456789101112@Componentpublic class MyViewRevsor implements View &#123; @Override public String getContentType() &#123; return \"text/html\"; &#125; @Override public void render(Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; response.getWriter().write(\"hello\"); &#125;&#125; 3. 转发和重定向我们一般在 controller 中写的东西默认都会转发的，我们需要重定向的话我们只需要在人绘制前面加上 redirect 就可以。 1234@RequestMapping(\"/beanView\")public String beanView()&#123; return \"redirect:/myViewRevsor\";&#125; 4. 静态资源映射对于静态资源我们需要直接获取而不需要进行映射，所以说我们在获取静态资源的时候回出现 404 ，我们就配置一个 &lt;mvc:default-servlet-handler/&gt; 这个就会自动的处理没有映射的 url 。 5. 表单数据到 controller 的映射表单数据在提交以后实际上是依赖于 SpringMVC 里面一个 WebDataBinder 类进行的数据绑定，这个 WebDataBinder 里面有很多其他的对象的引用其中就有数据格式化、数据校验、数据转换的对象，也就是说在这个数据转换的过程我们是可以添加一些对象来手动的控制数据的绑定的。 converter 这个是用来数据转换的，具体的参照文档，就比如我们把前端的一个字符串转成方法入参的一个 bean 对象，就经过这个 converter 来完成。 @initBinder 被这个注解表示的方法，会在数据绑定之前进行运行，其功能就是对 binder 进行一些设置比如忽略一些字段。修改字段，拒绝字段等等。 12345@InitBinder public void initBinder(WebDataBinder binder) &#123; // 拒绝 name 字段 binder.setDisallowedFields(\"name\"); &#125; 数据的格式化，采用注解注解在对应的 bean 的字段上。常用的有时间还有数子。 JSR303 校验规范，这只是 JavaEE 的规范，真正的实现类是 Hibernate ValidData ，然后我们进行数据校验也是使用注解的方式，具体的注解在规范里面都有，都比较简单。并且我们需要在方法的入参的 bean 上加上 @Valid 注解。 错误消息的回显，显然如果我们的校验生效并且有错误的话我们需要回显到表单。我们就需要在方法的参数里面加上一个 BindResult 对象，然后错误的数据都会被放到这个东西里面，同时 BindResult 是一个 Error 类型的对象，所以我们亦可以放这个对象。最后放到 map 里面在前端回显即可。 6. 返回 JSON 数据只需要在方法上加上 @ResponseBody 就可以，返回值是一个 List 或数组。 7. 拦截器（Interceptor）1234567891011&lt;!--配置拦截器--&gt; &lt;mvc:interceptors&gt; &lt;!--自定义的拦截器组件--&gt; &lt;bean class=\"com.mvc.MyInterceptor\"/&gt; &lt;!--更详细的配置可以针对 url--&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=\"/hello\"/&gt; &lt;mvc:exclude-mapping path=\"/hah\"/&gt; &lt;bean class=\"com.mvc.MyInterceptor\"/&gt; &lt;/mvc:interceptor&gt; &lt;/mvc:interceptors&gt; 12345678910111213141516public class MyInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return false; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 8. 统一异常处理统一异常处理就采用对应的 handler 来处理异常，使用 @ExceptionHandler 注解，然后标注要处理的异常类型，但是如果说我们需要把异常带到错误页面我们不能使用 map 而只能使用 ModelAndView 不然那就会报错。 123456@ExceptionHandler(&#123;ArithmeticException.class&#125;)public ModelAndView error(Exception ex)&#123; ModelAndView modelAndView = new ModelAndView(); modelAndView.addObject(\"ex\", ex); return modelAndView;&#125; 如果他在当前的 controller 中找不到对应的 ExceptionHandler 就去查找对应的 @ControllerAdvise 注解表示的类，中的ExceptionHandler 注解方法。也就是默认的处理器。","categories":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://lwenxu.coding.me/categories/SpringMVC/"}],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://lwenxu.coding.me/tags/SpringMVC/"}]},{"title":"NioEventLoop 源码分析","slug":"Netty/NioEventLoop 源码分析","date":"2018-04-16T09:40:24.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/04/16/Netty/NioEventLoop 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/04/16/Netty/NioEventLoop 源码分析/","excerpt":"","text":"NioEventLoop 源码分析1. SingleThreadEventExecutor 的 execute 方法NioEventLoop 的核心就在于它的 run() 他是在第一次添加任务的时候开始执行。那我们先看看第一次添加任务的地方，其实第一次添加任务的地方是在父类中的 execute() 方法。所以先去分析一下 SingleThreadEventExecutor 的execute() 方法。我把代码精简了贴出来，只看核心的部分。 123456789101112public void execute(Runnable task) &#123; boolean inEventLoop = inEventLoop(); // 线程已经启动 直接加入任务 if (inEventLoop) &#123; addTask(task); // 否则先启动任务 再添加任务 &#125; else &#123; startThread(); addTask(task); &#125; &#125; &emsp;&emsp; 很明显，也就是我们往线程池中添加任务的时候，首先要看看我们的线程是不是已经启动了，没有的话首先我们需要启动一下线程。接下来要看看 startThread() 方法干了什么事。里面做了一些检查也就是线程只能被 start 一次，然后直接调用了 NioEventLoop 封装的 thread 的 start() 很简单！ &emsp;&emsp; 但是，等等这个线程是从哪来的？我们并没有显示的传入，来到 SingleThreadEventExecutor 构造方法，我们会发现他在构造器中进行了初始化，但是不是直接 new Thread 而是使用了我们传的线程工厂，然后在工程里面 new 了这个线程需要执行的任务。 &emsp;&emsp; 他的任务就是先执行一下 run 方法，然而他的 run 方法是抽象的，自然就调用到子类去了，这也就解释了为什么说是第一次添加任务的时候调用了 NioEventLoop 的 run 方法。 &emsp;&emsp; 贴一下对 thread 初始化的代码(精简过后的)： 12345678910111213141516// new 了一个新的线程 thread = threadFactory.newThread(new Runnable() &#123; @Override public void run() &#123; boolean success = false; updateLastExecutionTime(); try &#123; // 调用了 run 方法，这个 run 方法在这个类中是抽象的，显然在子类中实现了 SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(\"Unexpected exception from an event executor: \", t); &#125; finally &#123; // 让线程关闭 &#125; &#125;); 2. 再回到 NioEventLoop 的 run 方法&emsp;&emsp; 那好，我们在上面已经看到了我们在创建一个 NioEventLoop 的时候会创建一个线程，这个线程的任务就是去调用子类的 run 方法。当我们执行 execute( task ) 方法，添加一个新任务去运行的时候，就会判断当前线程是不是启动了，否则启动我们一开始创建的那个线程。用一张图说明一下！！！ &emsp;&emsp; 好的现在正式的看一下 run 方法，还是贴一下核心代码： 12345678910111213141516171819202122232425262728293031protected void run() &#123; for (;;) &#123; // 有任务在线程创建之后直接开始 select if (hasTasks()) &#123; selectNow(); //直接调用了 select 的 selectNow 然后再次唤醒同下面的代码 // 没有任务 &#125; else &#123; // 自旋进行等待可进行 select 操作 select(oldWakenUp); // 再次唤醒，解决并发问题 if (wakenUp.get()) &#123; selector.wakeup(); &#125; &#125; // 都是处理 selected 的通道的数据，并执行所有的任务，只是在 runAllTasks 传的参数不同 if (ioRatio == 100) &#123; processSelectedKeys(); runAllTasks(); &#125; else &#123; final long ioStartTime = System.nanoTime(); processSelectedKeys(); final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; &emsp;&emsp; 可以看到在代码里面的死循环中值做了三件事：select、processSelectedKeys、 runAllTasks .借一张图来看： 1. 首先轮询注册到reactor线程对用的selector上的所有的channel的IO事件2. 处理产生网络IO事件的channel3. 处理任务队列具体做的事情放到下面一一道来！ 1. select()&emsp;&emsp; 如果有任务的话直接去 selectNow() 也就是不进行等待的 select() ,而没有任务的时候就进行自旋等待的 select() 。下面是 select() 的核心代码,可以看待里面调用了 selectNow() 所以说这个就是一个自旋的 selectNow() 。 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 这个方法主要干的事情： * 1、如果不需要等待就直接 select * 2、需要等待则等一个超时时间再去 select * 这个过程是不停进行的也就是死循环直达有任务可进行 select 时 select 完毕退出循环 * @param oldWakenUp * @throws IOException */ private void select(boolean oldWakenUp) throws IOException &#123; for (;;) &#123; // 不用等待进行一次 select 操作 long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; selector.selectNow(); selectCnt = 1; &#125; break; &#125; // 等一个超时再去选择 int selectedKeys = selector.select(timeoutMillis); selectCnt ++; if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123; // - Selected something, // - waken up by user, or // - the task queue has a pending task. // - a scheduled task is ready for processing break; &#125; if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; // 解决死循环问题，重建 selector rebuildSelector(); selector = this.selector; // 直接是 selectNow() selector.selectNow(); &#125; &#125; wakenUp 表示是否应该唤醒正在阻塞的 select 操作，netty在进行一次新的loop之前，都会将 wakeUp 被设置成false，标志新的一轮loop的开始。 2. processSelectedKeys()3. runAllTasks()","categories":[{"name":"Netty 源码分析","slug":"Netty-源码分析","permalink":"http://lwenxu.coding.me/categories/Netty-源码分析/"}],"tags":[]},{"title":"SpringBoot 笔记 ( 四 )：web 开发","slug":"SpringBoot/SpringBoot 笔记 ( 四 )：web 开发","date":"2018-04-14T02:01:28.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/04/14/SpringBoot/SpringBoot 笔记 ( 四 )：web 开发/","link":"","permalink":"http://lwenxu.coding.me/2018/04/14/SpringBoot/SpringBoot 笔记 ( 四 )：web 开发/","excerpt":"SpringBoot 笔记 (四): web 开发1、SpringBoot对静态资源的映射规则123456@ConfigurationProperties(prefix = \"spring.resources\", ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123;//静态资源的路径 private static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; \"classpath:/META-INF/resources/\", \"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" &#125;;","text":"SpringBoot 笔记 (四): web 开发1、SpringBoot对静态资源的映射规则123456@ConfigurationProperties(prefix = \"spring.resources\", ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123;//静态资源的路径 private static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; \"classpath:/META-INF/resources/\", \"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\" &#125;; MVC的自动配置 ：WebMvcAuotConfiguration 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071WebMvcAuotConfiguration： @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; // 对 webjars 的请求，也就是我们把类似于 jquery 之类的东西放到 maven 中就叫做 webjars if (!this.resourceProperties.isAddMappings()) &#123; logger.debug(\"Default resource handling disabled\"); return; &#125; Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern(\"/webjars/**\")) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(\"/webjars/**\") .addResourceLocations( \"classpath:/META-INF/resources/webjars/\") .setCachePeriod(cachePeriod)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); //静态资源文件夹映射 //\"classpath:/META-INF/resources/\", //\"classpath:/resources/\", //\"classpath:/static/\", //\"classpath:/public/\" if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); &#125; &#125; //配置欢迎页映射 //所有静态资源的index.html 就是欢迎页。 @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping( ResourceProperties resourceProperties) &#123; return new WelcomePageHandlerMapping(resourceProperties.getWelcomePage(), this.mvcProperties.getStaticPathPattern()); &#125; //配置喜欢的图标 //还是静态资源文件夹下的 favicon.ico @Configuration @ConditionalOnProperty(value = \"spring.mvc.favicon.enabled\", matchIfMissing = true) public static class FaviconConfiguration &#123; private final ResourceProperties resourceProperties; public FaviconConfiguration(ResourceProperties resourceProperties) &#123; this.resourceProperties = resourceProperties; &#125; @Bean public SimpleUrlHandlerMapping faviconHandlerMapping() &#123; SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1); //所有 **/favicon.ico mapping.setUrlMap(Collections.singletonMap(\"**/favicon.ico\", faviconRequestHandler())); return mapping; &#125; @Bean public ResourceHttpRequestHandler faviconRequestHandler() &#123; ResourceHttpRequestHandler requestHandler = new ResourceHttpRequestHandler(); requestHandler .setLocations(this.resourceProperties.getFaviconLocations()); return requestHandler; &#125; &#125; 1）、所有 /webjars/** ，都去 classpath:/META-INF/resources/webjars/ 找资源例如：localhost:8080/webjars/jquery/3.3.1/jquery.js 123456&lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可 &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; 2）、”/**” 这个 路径的意思就是如果没有拦截器或者Servlet去处理的请求我们就映射到这个地方来，访问当前项目的任何资源，都去（静态资源的文件夹）找映射 12345&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &quot;/&quot;：当前项目的根路径 localhost:8080/abc === 去静态资源文件夹里面找abc 3）、欢迎页； 静态资源文件夹下的所有index.html页面；被”/**”映射 ​ localhost:8080/ 找index页面 4）、所有的 **/favicon.ico 都是在静态资源文件下找 2、模板引擎JSP、Velocity、Freemarker、Thymeleaf 但是SpringBoot推荐的Thymeleaf：语法更简单，功能更强大。 1、引入thymeleaf；123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; 2.1.6&lt;/dependency&gt;&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; &lt;!-- 切换thymeleaf版本 布局功能的支持程序 thymeleaf3主程序 layout2以上版本 --&gt; &lt;!-- thymeleaf2 layout1 不使用在 parent 工程中的定义的版本 --&gt; &lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt; &lt;/properties&gt; 2、Thymeleaf使用1234567891011@ConfigurationProperties(prefix = \"spring.thymeleaf\")public class ThymeleafProperties &#123; private static final Charset DEFAULT_ENCODING = Charset.forName(\"UTF-8\"); private static final MimeType DEFAULT_CONTENT_TYPE = MimeType.valueOf(\"text/html\"); public static final String DEFAULT_PREFIX = \"classpath:/templates/\"; public static final String DEFAULT_SUFFIX = \".html\"; // 只要我们把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染； 步骤：1、导入thymeleaf的名称空间为了语法提示！ 1&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt; 2、使用thymeleaf语法在controller中的参数放入一个Map或者ModelAndView对象，然后我们直接在里面put数据，接着我们在返回值返回的时候只需要返回这个模板的逻辑名就行了。 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;成功！&lt;/h1&gt; &lt;!--th:text 将div里面的文本内容设置为 --&gt; &lt;div th:text=\"$&#123;hello&#125;\"&gt;这是显示欢迎信息&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3、语法规则1）、th:text：改变当前元素里面的文本内容 th：任意html属性：来替换原生属性的值 2）、表达式 1. ${…} 获取值底层就是OGNL表达式：属性调用，数组调用，方法调用，方法传参 1）、获取对象的属性、调用方法、数组的取值${obj.name} ${obj[‘name’]} 2）、使用内置的基本对象1234567#ctx : the context object.#vars: the context variables.#locale : the context locale.#request : (only in Web Contexts) the HttpServletRequest object.#response : (only in Web Contexts) the HttpServletResponse object.#session : (only in Web Contexts) the HttpSession object.#servletContext : (only in Web Contexts) the ServletContext object. 对象必须是采用 # 来引用 3）、内置的一些工具对象：12345678910111213141516#execInfo : information about the template being processed.#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #&#123;…&#125; syntax.#uris : methods for escaping parts of URLs/URIs#conversions : methods for executing the configured conversion service (if any).#dates : methods for java.util.Date objects: formatting, component extraction, etc.#calendars : analogous to #dates , but for java.util.Calendar objects.#numbers : methods for formatting numeric objects.#strings : methods for String objects: contains, startsWith, prepending/appending, etc.#objects : methods for objects in general.#bools : methods for boolean evaluation.#arrays : methods for arrays.#lists : methods for lists.#sets : methods for sets.#maps : methods for maps.#aggregates : methods for creating aggregates on arrays or collections.#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration). 2.*{..}这个东西其实和 ${} 是一样的，但是他多了一个辅助功能就是我们在一个标签中使用了 th:object=&quot;obj&quot; 来指定一个对象的时候，我们在这个标签里面可以直接用 *{user} 来用 * 代替我们上面的那个 obj 对象，也就是我们可以简化书写。 12345&lt;div th:object=\"$&#123;session.user&#125;\"&gt; &lt;p&gt;Name: &lt;span th:text=\"*&#123;firstName&#125;\"&gt;Sebastian&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Surname: &lt;span th:text=\"*&#123;lastName&#125;\"&gt;Pepper&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Nationality: &lt;span th:text=\"*&#123;nationality&#125;\"&gt;Saturn&lt;/span&gt;.&lt;/p&gt;&lt;/div&gt; 3.#{..}这个是用来取国际化内容的 4.@{…}定义URL，@{/order/process(execId=${execId},execType=&#39;FAST&#39;)} 就可以表示当前项目下面的一个url 就类似我们的 @GetMapping 里面的映射一样，然后我们的参数就不用使用 ？ 来拼接字符串了，直接使用圆括号即可。 5.~{…}片段引用表达式 1&lt;div th:insert=\"~&#123;commons :: main&#125;\"&gt;...&lt;/div&gt; 6.Literals（字面量）​ Text literals: ‘one text’ , ‘Another one!’ ,… Number literals: 0 , 34 , 3.0 , 12.3 ,… Boolean literals: true , false Null literal: null Literal tokens: one , sometext , main ,… 7.Text operations:（文本操作）​ String concatenation: + Literal substitutions: |The name is ${name}| 8.Arithmetic operations:（数学运算）​ Binary operators: + , - , * , / , % Minus sign (unary operator): - 9.Boolean operations:（布尔运算）​ Binary operators: and , or Boolean negation (unary operator): ! , not 10.Comparisons and equality:（比较运算）​ Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le ) Equality operators: == , != ( eq , ne ) 11.Conditional operators:条件运算（三元运算符）​ If-then: (if) ? (then) If-then-else: (if) ? (then) : (else) Default: (value) ?: (defaultvalue) 12.Special tokens:​ No-Operation: _ 13.foreach12345678&lt;div th:each=\"user:$&#123;users&#125;\"&gt; &lt;div th:text=\"$&#123;user&#125;\"&gt;&lt;/div&gt; 或者使用行内写法 &lt;div&gt; [[$&#123;user&#125;]] text 会转义 [($&#123;user&#125;)] utext 不转义字符 &lt;/div&gt;&lt;/div&gt; 4、SpringMVC自动配置1. Spring MVC auto-configurationSpring Boot 自动配置好了SpringMVC 以下是SpringBoot对SpringMVC的默认配置:WebMvcAutoConfiguration 注入了 ContentNegotiatingViewResolver and BeanNameViewResolver 的 bean. 自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发/重定向）） ContentNegotiatingViewResolver：组合所有的视图解析器的，也就是把容器中所有的视图解析器都放到一块，也就是放到自己的一个集合里面，我们可以在debug的时候去DispatcherServlet 这个地方查看到我们的视图解析器，然后在挑选出一个最合适的视图解析器工作，处理视图。 如何定制自己的视图解析器？：我们可以自己给容器中添加一个视图解析器（实现了ViewResolver接口的类）,ContentNegotiatingViewResolver自动的将其组合进来，放到自己的容器里面。 静态资源文件夹路径,webjars 静态首页访问,index 页面 自定义 favicon.ico 图标 自动注册了 Converter, GenericConverter, Formatter 组件 Converter：转换器就是把网页提交过来的参数转化成我们需要的类型 public String hello(User user)：类型转换使用Converter Formatter 格式化器，2017.12.17===Date。自己添加的格式化器转换器，我们只需要放在容器中即可，然后配置一下对应的配置文件就行 。 12345@Bean@ConditionalOnProperty(prefix = \"spring.mvc\", name = \"date-format\")//需要我们在文件中配置日期格式化的规则，他才进行格式化。public Formatter&lt;Date&gt; dateFormatter() &#123; return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件&#125; HttpMessageConverters Http 请求响应转换。 HttpMessageConverter：SpringMVC用来转换Http请求和响应的，User—Json HttpMessageConverters 是从容器中确定，从容器中自动获取所有的HttpMessageConverter，自己给容器中添加HttpMessageConverter，只需要将自己的组件注册容器中（@Bean,@Component） MessageCodesResolver .定义错误代码生成规则，我们也可以手动的配置，就是向容器中添加bean 使用了 ConfigurableWebBindingInitializer 组件到容器里面。我们可以配置一个ConfigurableWebBindingInitializer来替换默认的,添加到容器。这个东西的功能就是把我们页面提交过来的数据与我们的JavaBean的属性来做绑定，就是我们在 Spring中看到的 WebBinder 。 注意：org.springframework.boot.autoconfigure.web这个包里面有所有的web自动配置场景 &emsp;&emsp; 可以看出来我们的SpringBoot的自动配置基本就是使用 AutoConfiguration 来向容器中添加Bean，条件就是如果容器中没有这个 bean 的话。然后就是如果是这个组价可以存在多个，我们配置的bean就会被SpringBoot给整合掉，形成在一起。 如果说我们想要保留 springboot 的对 mvc 的自动配置，并且希望添加一些新的功能(interceptors, formatters, view controllers etc.)我们可能就要添加自己的配置类，也就是有 @Configuration 的 WebMvcConfigurerAdapter 子类。但是不要有 @EnableWebMvc 因为这个注解是完全的接管 mvc 的配置。 MVC configuration 2、扩展SpringMVC编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型，但是这个类不能标注@EnableWebMvc注解，这样的话我们既保留了所有的自动配置，也能用我们扩展的配置。 123456789101112//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /hello 请求来到 success registry.addViewController(\"/hello\").setViewName(\"success\"); &#125; //... 其他的功能我们就直接重写里面对应的方法即可。&#125; 原理： ​ 1）、WebMvcAutoConfiguration是SpringMVC的自动配置类 ​ 2）、在做其他自动配置时会导入 @Import(EnableWebMvcConfiguration.class) 这个类 123456789101112131415161718 @Configurationpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration &#123; private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); //从容器中获取所有的WebMvcConfigurer @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.configurers.addWebMvcConfigurers(configurers); //一个参考实现，将所有的WebMvcConfigurer相关配置都便利一遍，然后把里面的方法都调用一遍 @Override // public void addViewControllers(ViewControllerRegistry registry) &#123; // for (WebMvcConfigurer delegate : this.delegates) &#123; // delegate.addViewControllers(registry); // &#125; &#125; &#125;&#125; ​ 3）、容器中所有的WebMvcConfigurer都会一起起作用 ​ 4）、我们的配置类也会被调用； ​ 效果：SpringMVC的自动配置和我们的扩展配置都会起作用； 3、全面接管SpringMVC；SpringBoot对SpringMVC的自动配置不需要了，所有都是我们自己配置；所有的SpringMVC的自动配置都失效了 我们需要在配置类中添加@EnableWebMvc即可； 123456789101112//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@EnableWebMvc@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController(\"/atguigu\").setViewName(\"success\"); &#125;&#125; 原理： 为什么@EnableWebMvc自动配置就失效了； 1）@EnableWebMvc的核心，就是帮我们导入这个类，帮我们做一些基本的配置。 12@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123; 2）、 12@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; 3）、 12345678910@Configuration@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class &#125;)//容器中没有这个组件的时候，这个自动配置类才生效@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; 4）、@EnableWebMvc将WebMvcConfigurationSupport组件导入进来； 5）、导入的WebMvcConfigurationSupport只是SpringMVC最基本的功能； 5、如何修改SpringBoot的默认配置模式： ​ 1）、SpringBoot在自动配置很多组件的时候，先看容器中有没有用户自己配置的（@Bean、@Component）如果有就用用户配置的，如果没有，才自动配置；如果有些组件可以有多个（ViewResolver）将用户配置的和自己默认的组合起来； ​ 2）、在SpringBoot中会有非常多的xxxConfigurer帮助我们进行扩展配置 ​ 3）、在SpringBoot中会有很多的xxxCustomizer帮助我们进行定制配置 6、RestfulCRUD1）、默认访问首页1234567891011121314151617181920212223242526//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能//@EnableWebMvc 不要接管SpringMVC@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /hello 请求来到 success registry.addViewController(\"/hello\").setViewName(\"success\"); &#125; //所有的WebMvcConfigurerAdapter组件都会一起起作用，也就是可以有多个这个东西。 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/\").setViewName(\"login\"); registry.addViewController(\"/index.html\").setViewName(\"login\"); &#125; &#125;; return adapter; &#125;&#125; 2）、国际化1）、编写国际化配置文件 2）、使用ResourceBundleMessageSource管理国际化资源文件 3）、在页面使用fmt:message取出国际化内容 步骤： 1）、编写国际化配置文件，抽取页面需要显示的国际化消息2）、SpringBoot自动配置好了管理国际化资源文件的组件； 12345678910111213141516171819202122232425262728@ConfigurationProperties(prefix = \"spring.messages\")public class MessageSourceAutoConfiguration &#123; /** * Comma-separated list of basenames (essentially a fully-qualified classpath * location), each following the ResourceBundle convention with relaxed support for * slash based locations. If it doesn't contain a package qualifier (such as * \"org.mypackage\"), it will be resolved from the classpath root. */ private String basename = \"messages\"; //我们的配置文件可以直接放在类路径下叫messages.properties； @Bean public MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); if (StringUtils.hasText(this.basename)) &#123; //设置国际化资源文件的基础名（去掉语言国家代码的） messageSource.setBasenames(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(this.basename))); &#125; if (this.encoding != null) &#123; messageSource.setDefaultEncoding(this.encoding.name()); &#125; messageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale); messageSource.setCacheSeconds(this.cacheSeconds); messageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat); return messageSource; &#125; 3）、去页面获取国际化的值； 123456789&lt;!DOCTYPE html&gt;&lt;html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\"&gt; &lt;head&gt;&lt;link href=\"asserts/css/bootstrap.min.css\" th:href=\"@&#123;/webjars/bootstrap/4.0.0/css/bootstrap.css&#125;\" rel=\"stylesheet\"&gt; &lt;!-- Custom styles for this template --&gt; &lt;link href=\"asserts/css/signin.css\" th:href=\"@&#123;/asserts/css/signin.css&#125;\" rel=\"stylesheet\"&gt; &lt;/head&gt;&lt;h1 class=\"h3 mb-3 font-weight-normal\" th:text=\"#&#123;login.tip&#125;\"&gt;Please sign in&lt;/h1&gt; 效果：根据浏览器语言设置的信息切换了国际化； 原理： ​ 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）； 12345678910111213 @Bean @ConditionalOnMissingBean @ConditionalOnProperty(prefix = \"spring.mvc\", name = \"locale\") public LocaleResolver localeResolver() &#123; if (this.mvcProperties .getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) &#123; return new FixedLocaleResolver(this.mvcProperties.getLocale()); &#125; AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(this.mvcProperties.getLocale()); return localeResolver; &#125;默认的就是根据请求头带来的区域信息获取Locale进行国际化 4）、点击链接切换国际化 12345678910111213141516171819202122232425262728/** * 可以在连接上携带区域信息 */public class MyLocaleResolver implements LocaleResolver &#123; @Override public Locale resolveLocale(HttpServletRequest request) &#123; String l = request.getParameter(\"l\"); Locale locale = Locale.getDefault(); if(!StringUtils.isEmpty(l))&#123; String[] split = l.split(\"_\"); locale = new Locale(split[0],split[1]); &#125; return locale; &#125; @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123; &#125;&#125; @Bean public LocaleResolver localeResolver()&#123; return new MyLocaleResolver(); &#125;&#125; 3）、登陆开发期间模板引擎页面修改以后，要实时生效 1）、禁用模板引擎的缓存 12# 禁用缓存spring.thymeleaf.cache=false 2）、页面修改完成以后ctrl+f9：重新编译； 登陆错误消息的显示 1&lt;p style=\"color: red\" th:text=\"$&#123;msg&#125;\" th:if=\"$&#123;not #strings.isEmpty(msg)&#125;\"&gt;&lt;/p&gt; 表单重复提交，我们使用post请求提交数据来到新的页面的时候如果我们再次刷新，就会询问我们是否需要重复提交表单数据，这样我们就可以登陆成功以后使用重定向来完成，而不是采用默认的行为。 4）、拦截器进行登陆检查拦截器 12345678910111213141516171819202122232425262728293031/** * 登陆检查， */public class LoginHandlerInterceptor implements HandlerInterceptor &#123; //目标方法执行之前 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; Object user = request.getSession().getAttribute(\"loginUser\"); if(user == null)&#123; //未登陆，返回登陆页面 request.setAttribute(\"msg\",\"没有权限请先登陆\"); request.getRequestDispatcher(\"/index.html\").forward(request,response); return false; &#125;else&#123; //已登陆，放行请求 return true; &#125; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 注册拦截器 1234567891011121314151617181920212223//所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/\").setViewName(\"login\"); registry.addViewController(\"/index.html\").setViewName(\"login\"); registry.addViewController(\"/main.html\").setViewName(\"dashboard\"); &#125; //注册拦截器 @Override public void addInterceptors(InterceptorRegistry registry) &#123; //super.addInterceptors(registry); //静态资源； *.css , *.js //SpringBoot已经做好了静态资源映射 registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns(\"/**\") .excludePathPatterns(\"/index.html\",\"/\",\"/user/login\"); &#125; &#125;; return adapter; &#125; 5）、CRUD-员工列表实验要求： 1）、RestfulCRUD：CRUD满足Rest风格； URI： /资源名称/资源标识 HTTP请求方式区分对资源CRUD操作 普通CRUD（uri来区分操作） RestfulCRUD 查询 getEmp emp—GET 添加 addEmp?xxx emp—POST 修改 updateEmp?id=xxx&amp;xxx=xx emp/{id}—PUT 删除 deleteEmp?id=1 emp/{id}—DELETE 2）、实验的请求架构; 实验功能 请求URI 请求方式 查询所有员工 emps GET 查询某个员工(来到修改页面) emp/1 GET 来到添加页面 emp GET 添加员工 emp POST 来到修改页面（查出员工进行信息回显） emp/1 GET 修改员工 emp PUT 删除员工 emp/1 DELETE 3）、员工列表： thymeleaf公共页面元素抽取12345678910111213141、抽取公共片段&lt;div th:fragment=\"copy\"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt;2、引入公共片段&lt;div th:insert=\"~&#123;footer :: copy&#125;\"&gt;&lt;/div&gt;~&#123;templatename::selector&#125;：模板名::选择器~&#123;templatename::fragmentname&#125;:模板名::片段名3、默认效果：insert的公共片段在div标签中如果使用th:insert等属性进行引入，可以不用写~&#123;&#125;：行内写法可以加上：[[~&#123;&#125;]];[(~&#123;&#125;)]； 三种引入公共片段的th属性： th:insert：将公共片段整个插入到声明引入的元素中 th:replace：将声明引入的元素替换为公共片段 th:include：将被引入的片段的内容包含进这个标签中 1234567891011121314151617181920212223&lt;footer th:fragment=\"copy\"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;引入方式&lt;div th:insert=\"footer :: copy\"&gt;&lt;/div&gt;&lt;div th:replace=\"footer :: copy\"&gt;&lt;/div&gt;&lt;div th:include=\"footer :: copy\"&gt;&lt;/div&gt;效果&lt;div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt;&lt;/div&gt;&lt;footer&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;&lt;div&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt; 引入片段的时候传入参数： 123456789101112131415161718&lt;nav class=\"col-md-2 d-none d-md-block bg-light sidebar\" id=\"sidebar\"&gt; &lt;div class=\"sidebar-sticky\"&gt; &lt;ul class=\"nav flex-column\"&gt; &lt;li class=\"nav-item\"&gt; &lt;a class=\"nav-link active\" th:class=\"$&#123;activeUri=='main.html'?'nav-link active':'nav-link'&#125;\" href=\"#\" th:href=\"@&#123;/main.html&#125;\"&gt; &lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"feather feather-home\"&gt; &lt;path d=\"M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z\"&gt;&lt;/path&gt; &lt;polyline points=\"9 22 9 12 15 12 15 22\"&gt;&lt;/polyline&gt; &lt;/svg&gt; Dashboard &lt;span class=\"sr-only\"&gt;(current)&lt;/span&gt; &lt;/a&gt; &lt;/li&gt;&lt;!--引入侧边栏;传入参数--&gt;&lt;div th:replace=\"commons/bar::#sidebar(activeUri='emps')\"&gt;&lt;/div&gt; 6）、CRUD-员工添加添加页面 123456789101112131415161718192021222324252627282930313233343536&lt;form&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" placeholder=\"zhangsan\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input type=\"email\" class=\"form-control\" placeholder=\"zhangsan@atguigu.com\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class=\"form-check form-check-inline\"&gt; &lt;input class=\"form-check-input\" type=\"radio\" name=\"gender\" value=\"1\"&gt; &lt;label class=\"form-check-label\"&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class=\"form-check form-check-inline\"&gt; &lt;input class=\"form-check-input\" type=\"radio\" name=\"gender\" value=\"0\"&gt; &lt;label class=\"form-check-label\"&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;department&lt;/label&gt; &lt;select class=\"form-control\"&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" placeholder=\"zhangsan\"&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-primary\"&gt;添加&lt;/button&gt;&lt;/form&gt; 提交的数据格式不对：生日：日期； 2017-12-12；2017/12/12；2017.12.12； 日期的格式化；SpringMVC将页面提交的值需要转换为指定的类型; 2017-12-12—Date； 类型转换，格式化; 默认日期是按照/的方式； 7）、CRUD-员工修改修改添加二合一表单 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!--需要区分是员工修改还是添加；--&gt;&lt;form th:action=\"@&#123;/emp&#125;\" method=\"post\"&gt; &lt;!--发送put请求修改员工数据--&gt; &lt;!--1、SpringMVC中配置HiddenHttpMethodFilter;（SpringBoot自动配置好的）2、页面创建一个post表单3、创建一个input项，name=\"_method\";值就是我们指定的请求方式--&gt; &lt;input type=\"hidden\" name=\"_method\" value=\"put\" th:if=\"$&#123;emp!=null&#125;\"/&gt; &lt;input type=\"hidden\" name=\"id\" th:if=\"$&#123;emp!=null&#125;\" th:value=\"$&#123;emp.id&#125;\"&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input name=\"lastName\" type=\"text\" class=\"form-control\" placeholder=\"zhangsan\" th:value=\"$&#123;emp!=null&#125;?$&#123;emp.lastName&#125;\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input name=\"email\" type=\"email\" class=\"form-control\" placeholder=\"zhangsan@atguigu.com\" th:value=\"$&#123;emp!=null&#125;?$&#123;emp.email&#125;\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class=\"form-check form-check-inline\"&gt; &lt;input class=\"form-check-input\" type=\"radio\" name=\"gender\" value=\"1\" th:checked=\"$&#123;emp!=null&#125;?$&#123;emp.gender==1&#125;\"&gt; &lt;label class=\"form-check-label\"&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class=\"form-check form-check-inline\"&gt; &lt;input class=\"form-check-input\" type=\"radio\" name=\"gender\" value=\"0\" th:checked=\"$&#123;emp!=null&#125;?$&#123;emp.gender==0&#125;\"&gt; &lt;label class=\"form-check-label\"&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;department&lt;/label&gt; &lt;!--提交的是部门的id--&gt; &lt;select class=\"form-control\" name=\"department.id\"&gt; &lt;option th:selected=\"$&#123;emp!=null&#125;?$&#123;dept.id == emp.department.id&#125;\" th:value=\"$&#123;dept.id&#125;\" th:each=\"dept:$&#123;depts&#125;\" th:text=\"$&#123;dept.departmentName&#125;\"&gt;1&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input name=\"birth\" type=\"text\" class=\"form-control\" placeholder=\"zhangsan\" th:value=\"$&#123;emp!=null&#125;?$&#123;#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')&#125;\"&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-primary\" th:text=\"$&#123;emp!=null&#125;?'修改':'添加'\"&gt;添加&lt;/button&gt;&lt;/form&gt; 8）、CRUD-员工删除123456789101112131415161718192021&lt;tr th:each=\"emp:$&#123;emps&#125;\"&gt; &lt;td th:text=\"$&#123;emp.id&#125;\"&gt;&lt;/td&gt; &lt;td&gt;[[$&#123;emp.lastName&#125;]]&lt;/td&gt; &lt;td th:text=\"$&#123;emp.email&#125;\"&gt;&lt;/td&gt; &lt;td th:text=\"$&#123;emp.gender&#125;==0?'女':'男'\"&gt;&lt;/td&gt; &lt;td th:text=\"$&#123;emp.department.departmentName&#125;\"&gt;&lt;/td&gt; &lt;td th:text=\"$&#123;#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')&#125;\"&gt;&lt;/td&gt; &lt;td&gt; &lt;a class=\"btn btn-sm btn-primary\" th:href=\"@&#123;/emp/&#125;+$&#123;emp.id&#125;\"&gt;编辑&lt;/a&gt; &lt;button th:attr=\"del_uri=@&#123;/emp/&#125;+$&#123;emp.id&#125;\" class=\"btn btn-sm btn-danger deleteBtn\"&gt;删除&lt;/button&gt; &lt;/td&gt;&lt;/tr&gt;&lt;script&gt; $(\".deleteBtn\").click(function()&#123; //删除当前员工的 $(\"#deleteEmpForm\").attr(\"action\",$(this).attr(\"del_uri\")).submit(); return false; &#125;);&lt;/script&gt;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot 笔记 ( 三 )：日志系统","slug":"SpringBoot/SpringBoot 笔记 ( 三 )：日志系统","date":"2018-04-13T14:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/04/13/SpringBoot/SpringBoot 笔记 ( 三 )：日志系统/","link":"","permalink":"http://lwenxu.coding.me/2018/04/13/SpringBoot/SpringBoot 笔记 ( 三 )：日志系统/","excerpt":"SpringBoot 笔记 ( 三 )：日志系统1、日志框架日志框架就是防止我们再去像以前那样，一直进行System.out.println(“”)将关键数据打印在控制台。框架来记录系统的一些运行时信息，但是随着日志框架的增长，和接口的不一致，导致了使用上的差别很大，这里采用了一个类似于数据库驱动的模式，数据库驱动是 Java 提供的一个 API，然后真正的实现是需要各个数据库厂商去完成的，而 log 也开始采用这种面向接口编程的方法采用日志抽象层。","text":"SpringBoot 笔记 ( 三 )：日志系统1、日志框架日志框架就是防止我们再去像以前那样，一直进行System.out.println(“”)将关键数据打印在控制台。框架来记录系统的一些运行时信息，但是随着日志框架的增长，和接口的不一致，导致了使用上的差别很大，这里采用了一个类似于数据库驱动的模式，数据库驱动是 Java 提供的一个 API，然后真正的实现是需要各个数据库厂商去完成的，而 log 也开始采用这种面向接口编程的方法采用日志抽象层。 市面上的日志框架JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j…. 日志门面 （日志的抽象层） 日志实现 JCL（Jakarta Commons Logging） SLF4j（Simple Logging Facade for Java） jboss-logging Log4j JUL（java.util.logging） Log4j2（log4j 的增强版） Logback(log4j 的重制版) 左边选一个门面（抽象层）、右边来选一个实现；日志门面： SLF4J；日志实现：Logback； SpringBoot：底层是Spring框架，Spring框架默认是用JCL；==SpringBoot选用 SLF4j和logback；== 2、SLF4j使用1、如何在系统中使用SLF4j https://www.slf4j.org以后开发的时候，日志记录方法的调用，不应该来直接调用日志的实现类，而是调用日志抽象层里面的方法； 给系统里面导入slf4j的jar和 logback的实现jar 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld &#123; public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(\"Hello World\"); &#125;&#125; 2、遗留问题a（slf4j+logback）: Spring（commons-logging）、Hibernate（jboss-logging）、MyBatis、xxxx 就是我们的springboot中我们如果配置了一些其他应用，然后这些应用需要使用一些别的日志框架我们就需要配置非常多的配置文件，但是我们希望只配置一个就好了。就统一日志框架！ 如何让系统中所有的日志都统一到slf4j； 将系统中其他日志框架先排除出去，也就是删除那些应用的里的日志抽象层 用也就是日志抽象层和底层的实现整合的中间包（适配包）来替换原有的日志框架的抽象层 我们导入slf4j其他的实现，就是底层的日志实现。 用一个简单的例子来说明，就是我们希望所有的日志门面采用的 slf4j 然后底层使用的 logback 我们就是用了 jcl 、log4j、jul 的中见替换包替换了原来的日志门面，然后我们在整合底层的日志实现，就完成了整合统一。 3、SpringBoot日志关系1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;&lt;/dependency&gt; 总结： ​ 1）、SpringBoot底层也是使用slf4j+logback的方式进行日志记录 ​ 2）、SpringBoot也把其他的日志都替换成了slf4j，也就是他统一了所有的starter的日志框架，那么必然使用了中间替换包。 ​ 3）、中间替换包,使用中间替换包才能把其他的日志框架替换掉。 ​ 4）、如果我们要引入其他框架，一定要把这个框架的默认日志依赖移除掉。 比如我们的Spring框架用的是commons-logging，但是我们的依赖就是直接排除了我们的自带的日志框架，然后引入中间包。如下： 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;!-- 排除包 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; SpringBoot能自动适配所有的日志，而且底层使用slf4j+logback的方式记录日志，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可 4、日志使用1、默认配置SpringBoot默认帮我们配置好了日志； 12345678910111213141516//记录器Logger logger = LoggerFactory.getLogger(getClass());@Testpublic void contextLoads() &#123; //日志的级别； //由低到高 trace&lt;debug&lt;info&lt;warn&lt;error //可以调整输出的日志级别；日志就只会在这个级别以以后的高级别生效 logger.trace(\"这是trace日志...\"); logger.debug(\"这是debug日志...\"); //SpringBoot默认给我们使用的是info级别的，没有指定级别的就用SpringBoot默认规定的级别 logger.info(\"这是info日志...\"); logger.warn(\"这是warn日志...\"); logger.error(\"这是error日志...\");&#125; 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%nSpringBoot修改日志的默认配置 123456789101112131415logging.level.com.atguigu=trace#logging.path=# 不指定路径在当前项目下生成springboot.log日志# 可以指定完整的路径；#logging.file=G:/springboot.log# 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件logging.path=/spring/log# 在控制台输出的日志的格式logging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n# 指定文件中日志输出的格式logging.pattern.file=%d&#123;yyyy-MM-dd&#125; === [%thread] === %-5level === %logger&#123;50&#125; ==== %msg%n logging.file logging.path Example Description (none) (none) 只在控制台输出 指定文件名 (none) my.log 输出日志到my.log文件 (none) 指定目录 /var/log 输出到指定目录的 spring.log 文件中 2、指定配置给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了 Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties logback.xml：直接就被日志框架识别了； logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能 1234&lt;springProfile name=\"staging\"&gt; &lt;!-- configuration to be enabled when the \"staging\" profile is active --&gt; 可以指定某段配置只在某个环境下生效&lt;/springProfile&gt; 如： 12345678910111213141516171819&lt;appender name=\"stdout\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class=\"ch.qos.logback.classic.PatternLayout\"&gt; &lt;springProfile name=\"dev\"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ----&gt; [%thread] ---&gt; %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name=\"!dev\"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ==== [%thread] ==== %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; 如果使用logback.xml作为日志配置文件，还要使用profile功能，会有以下错误 no applicable action for [springProfile] 5、切换日志框架可以按照slf4j的日志适配图，进行相关的切换； slf4j+log4j的方式； 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;/dependency&gt; 切换为log4j2 123456789101112131415 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"SpringBoot笔记 ( 二 )：自定义配置","slug":"SpringBoot/SpringBoot 笔记 ( 二 )：自定义配置","date":"2018-04-13T14:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/04/13/SpringBoot/SpringBoot 笔记 ( 二 )：自定义配置/","link":"","permalink":"http://lwenxu.coding.me/2018/04/13/SpringBoot/SpringBoot 笔记 ( 二 )：自定义配置/","excerpt":"SpringBoot 笔记 ( 二 )：自定义配置1. 配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的： application.properties application.yml &emsp;&emsp; 修改SpringBoot自动配置的默认值，因为在所有的自动配置类中他们都会去读取我们的配置文件，如果说有配置这些项目就按照我们配置的，没有则使用自动配置。","text":"SpringBoot 笔记 ( 二 )：自定义配置1. 配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的： application.properties application.yml &emsp;&emsp; 修改SpringBoot自动配置的默认值，因为在所有的自动配置类中他们都会去读取我们的配置文件，如果说有配置这些项目就按照我们配置的，没有则使用自动配置。 &emsp;&emsp; 支持两种格式，我们主要说说后面一种，前面比较简单就是采用的点的方式定义的。yml 其实也是一种标记语言，YAML 他的语法比较简洁，写起来没有 xml 那么臃肿。 2. YAML 语法1、基本语法k:(空格)v：表示一对键值对（空格必须有） 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的同时属性和值也是大小写敏感； 2. 字面量：普通的值（数字，字符串，布尔）​ k: v：字面直接来写，字符串默认不用加上单引号或者双引号； 3. 对象、Map（属性和值）（键值对）：​ k: v：在下一行来写对象的属性和值的关系，注意缩进 ​ 对象还是k: v的方式 123friends: lastName: zhangsan age: 20 行内写法： 1friends: &#123;lastName: zhangsan,age: 18&#125; 4. 数组、表（List、Set）：用- 值表示数组中的一个元素 1234pets: - cat - dog - pig 行内写法 1pets: [cat,dog,pig] 3. 配置文件注入1.@ConfigurationProperties配置文件： 123456789101112person: lastName: hello age: 18 boss: false birth: 2017/12/12 maps: &#123;k1: v1,k2: 12&#125; lists: - lisi - zhaoliu dog: name: 小狗 age: 12 对应的Bean： 1234567891011121314151617181920/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = \"person\"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = \"person\")public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定 prefix = “person”：配置文件中哪个下面的所有属性进行一一映射 ，这样我们就明白了我们的 springboot 的配置文件的一些属性是绑定的我们的配置类的属性，那么我们的配置类就可以读取我们的配置文件里面的内容了！ 2.@Value除了使用 @ConfigurationProperties 让我们的bean和配置文件绑定，我们还可以使用 @Value(“配置文件属性”) 注解去获取配置文件的内容。这个注解是支持spEL表达式的，这是他的优点。 3.@PropertySource这个注解的作用就是用来导入一些指定的配置文件里面的内容到我们当前的 JavaBean 中，与之关联。也就是方便我们的配置文件的拆分。 比如： @PropertySource(value={&quot;classpath:person.properties&quot;}) 就是加载类路径下面的 person.properties 里面的内容。 4.@ImportResource 导入spring的xml配置文件然后让他生效。其实这个就是Spring的基本注解，导入配置文件配置类。这个东西要标注在主类上，而不是bean中。 注意，如果我们的配置文件和bean关联以后没有自动提示的话我们就需要导入pom ，在导入配置文件处理器以后，编写配置就有提示了。 123456&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 一个小问题就是配置文件中配置的中文读出来会乱码，这主要是 idea 的 properties 文件默认采用的 utf-8 ，我们需要使用自动转 ascii 码。 4. 配置类SpringBoot推荐给容器中添加组件的方式，推荐使用全注解的方式 配置类 @Configuration 等价于 Spring 配置文件 使用 @Bean 给容器中添加组件 12345678910111213141516/** * @Configuration：指明当前类是一个配置类；就是来替代之前的Spring配置文件 * * 在配置文件中用&lt;bean&gt;&lt;bean/&gt;标签添加组件 * */@Configurationpublic class MyAppConfig &#123; //将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名,也可以自己指定。 @Bean public HelloService helloService02()&#123; System.out.println(\"配置类@Bean给容器中添加组件了...\"); return new HelloService(); &#125;&#125; 5. 多环境配置文件1. 多Profile文件我们在主配置文件编写的时候，文件名可以是application-{profile}.properties/yml默认使用application.properties的配置； 2. 文档块方式1234567891011121314151617181920server: port: 8081spring: profiles: active: prod---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod #指定属于哪个环境 3. 激活指定profile 在配置文件中指定 spring.profiles.active=dev 命令行：java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar --spring.profiles.active=dev；可以直接在测试的时候，配置传入命令行参数 虚拟机参数；`-Dspring.profiles.active=dev` 4. 指定外部配置文件所有的配置都可以在命令行上进行指定java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar --server.port=8087 --server.context-path=/abc 6. 自动配置原理 SpringBoot启动的时候加载主配置类，开启了自动配置功能 @EnableAutoConfiguration @EnableAutoConfiguration 作用： EnableAutoConfigurationImportSelector 给容器中导入一些组件 selectImports()方法中的 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); 获取候选的配置 SpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下 META-INF/spring.factories 把扫描到的这些文件的内容包装成 properties 对象，从 properties 中获取到 EnableAutoConfiguration.class 类（类名）对应的值，然后把他们添加在容器中 总之一句话将类路径下 META-INF/spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中如下： 1234# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ 每一个这样的 xxxAutoConfiguration 类都是容器中的一个组件，都加入到容器中，用他们来做自动配置 7.以HttpEncodingAutoConfiguration为例解释自动配置原理12345678910111213141516171819202122232425262728293031//表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@Configuration //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中 所有能在我们的配置文件中配置什么就是看我们的 Properties 中的 prefix和属性有什么。@EnableConfigurationProperties(HttpEncodingProperties.class) //Spring底层@Conditional注解，根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效,判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnWebApplication //判断当前项目有没有这个类CharacterEncodingFilter,SpringMVC中进行乱码解决的过滤器；@ConditionalOnClass(CharacterEncodingFilter.class) //判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的,也就是说即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；@ConditionalOnProperty(prefix = \"spring.http.encoding\", value = \"enabled\", matchIfMissing = true) public class HttpEncodingAutoConfiguration &#123; //他已经和SpringBoot的配置文件映射了 private final HttpEncodingProperties properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; 总结： 1）、SpringBoot启动会加载大量的自动配置类2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类；3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了）4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值 根据当前不同的条件判断，决定这个配置类是否生效，一但这个配置类生效，这个配置类就会给容器中添加各种组件，这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的。&emsp;&emsp; 也就是如下两个类非常重要： xxxxAutoConfigurartion：自动配置类。 xxxxProperties: 封装配置文件中相关属性。 8.@Conditional注解这个是Spring中原生的，就是用一个Class这个Class中重写了 match 方法，来判断这个conditional是否为真。然后我们的SpringBoot 是自己写了很多新的 @Conditional 的新版，就拓展了原来的功能。 @ConditionalOnJava系统的java版本是否符合要求 @ConditionalOnBean容器中存在指定Bean； @ConditionalOnMissingBean容器中不存在指定Bean； @ConditionalOnExpression满足SpEL表达式指定 @ConditionalOnClass系统中有指定的类 @ConditionalOnMissingClass系统中没有指定的类 @ConditionalonSingleCandidate容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty系统中指定的属性是否有指定的值 @ConditionalOnResource类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnjndiJNDI存在指定项 也就是自动配置类是在一定条件下才会生效，不是说每一个自动配置类都会被加载！！我们可以开启 debug 模式然后我们就可以看到自动配置报告。使用 debug:true 在主配置文件中。下面就是自动配置报告！ 1234567891011121314151617181920=========================AUTO-CONF IGURATION REPORT=========================Positive matches:(自动配置类启用的）DispatcherServletAutoconfiguration matched:-@ConditionalonClass found required class‘org.springframework.web.servlet.Dispatcherservlet“；ConditionalonMissingclass did not findunwanted class (Onclasscondition)-@conditionalOnwebApplication(required)found StandardServletEnvironment(onwebApplicationcondition)Negative matches:(没有启动，没有匹配成功的自动配置类）ActiveMQAutoconfiguration:Did not match:-@ConditionalOnClass did not find required classes‘javax.jms.ConnectionFactory“，‘org.apache.activemq.ActivemQConnectionFactory“(Onclasscondition)","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"Shiro安全框架:认证","slug":"Shiro/Shiro 认证框架","date":"2018-04-13T13:01:28.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/04/13/Shiro/Shiro 认证框架/","link":"","permalink":"http://lwenxu.coding.me/2018/04/13/Shiro/Shiro 认证框架/","excerpt":"Shiro 安全框架1. 认证1. 采用简单的对象登陆认证(SimpleAccountRealm)12345678910111213141516171819202122public class AuthenticationTest &#123; // 创建一个简单的认证 realm 也就是认证信息存放在对象中的 SimpleAccountRealm simpleAccountRealm = new SimpleAccountRealm(); @Before public void addUser()&#123; simpleAccountRealm.addAccount(\"lwen\", \"1234\"); &#125; @Test public void authentication()&#123; // 创建一个 securityManager 环境 SecurityManager securityManager = new DefaultSecurityManager(simpleAccountRealm); // 设置环境 SecurityUtils.setSecurityManager(securityManager); // 获取认证主体 Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"lwen\", \"1234\"); subject.login(token); System.out.println(subject.isAuthenticated()); &#125;&#125;","text":"Shiro 安全框架1. 认证1. 采用简单的对象登陆认证(SimpleAccountRealm)12345678910111213141516171819202122public class AuthenticationTest &#123; // 创建一个简单的认证 realm 也就是认证信息存放在对象中的 SimpleAccountRealm simpleAccountRealm = new SimpleAccountRealm(); @Before public void addUser()&#123; simpleAccountRealm.addAccount(\"lwen\", \"1234\"); &#125; @Test public void authentication()&#123; // 创建一个 securityManager 环境 SecurityManager securityManager = new DefaultSecurityManager(simpleAccountRealm); // 设置环境 SecurityUtils.setSecurityManager(securityManager); // 获取认证主体 Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"lwen\", \"1234\"); subject.login(token); System.out.println(subject.isAuthenticated()); &#125;&#125; 2. 简单的角色认证123456789101112131415161718192021public class AuthorizationTest &#123; // 创建一个简单的认证 realm 也就是认证信息存放在对象中的 SimpleAccountRealm simpleAccountRealm = new SimpleAccountRealm(); @Before public void addUser()&#123; simpleAccountRealm.addAccount(\"lwen\", \"1234\",\"user\",\"admin\"); &#125; @Test public void authentication()&#123; // 创建一个 securityManager 环境 SecurityManager securityManager = new DefaultSecurityManager(simpleAccountRealm); // 设置环境 SecurityUtils.setSecurityManager(securityManager); // 获取认证主体 Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"lwen\", \"1234\"); subject.login(token); subject.checkRole(\"user\"); subject.checkRoles(\"user\", \"admin\"); &#125; 2. 内置 Realm 和自定义 Realm1. 配置文件 (initRealm)创建一个配置文件，如下 123456[users]lwen=1234,adminmark=1234,user[roles]admin=update,delete,selectuser=select 在代码中使用 IniRealm 即可。可用下面的代码检查用户权限。 12subject.checkPermission(\"update\");subject.checkPermission(\"select\"); 2. 数据库(JdbcRealm)首先需要创建表，这里我们采用了默认的查询方式，但是这种查询方式是不可用的，这里只做演示用。后面会说到关于自定义 Realm ，会详细说数据库的设计。 这里我们采用了 Jdbc 默认的 sql 语句建表。 12345678910111213141516171819202122232425public class AuthenticationJdbcRealmTest &#123; // 创建一个简单的认证 realm 也就是认证信息存放在对象中的 JdbcRealm jdbcRealm = new JdbcRealm(); @Test public void authentication()&#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(\"jdbc:mysql://127.0.0.1/shiro\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"12345678\"); jdbcRealm.setDataSource(dataSource); jdbcRealm.setPermissionsLookupEnabled(true);//这是一个坑 ，默认权限表不进行查找 // 创建一个 securityManager 环境 SecurityManager securityManager = new DefaultSecurityManager(jdbcRealm); // 设置环境 SecurityUtils.setSecurityManager(securityManager); // 获取认证主体 Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(\"lwen\", \"1234\"); subject.login(token); System.out.println(subject.isAuthenticated()); subject.checkPermission(\"update\"); subject.checkPermission(\"select\"); &#125;&#125; 注意这里有一个坑，就是默认的情况下 Jdbc 不回去查询权限表，导致失败。所以我们需要添加上 setPermissionsLookupEnabled 让他开启。 3. 自定义 Realm自定义 Realm 就是说我们只要继承一个 AuthorizingRealm 类，然后重写里面的认证和授权的方法就可以了，非常的简单。一个是认证的方法也就是 doGetAuthenticationInfo 另外一个就是 授权的方法 doGetAuthorizationInfo ，里很多操作这里采用了一个静态数据表示的，实际上这些是需要从数据库或者缓存中取出来然后进行逻辑判断。 123456789101112131415161718192021222324252627282930313233343536373839public class CustomRealm extends AuthorizingRealm &#123; &#123; this.setName(\"customRealm\"); &#125; // 授权 -&gt; 权限 角色 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; String userName = (String) principalCollection.getPrimaryPrincipal(); // 这个需要使用 service 层然后调用 dao 层去数据库或者缓存中查询，然后返回结果这里为了方便采用静态数据 Set&lt;String&gt; roles = getRolesByUsername(userName); Set&lt;String&gt; permissions = getPermissionsByUsername(userName); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(roles); authorizationInfo.setStringPermissions(permissions); return authorizationInfo; &#125; // 认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; String userName = (String) authenticationToken.getPrincipal(); String password = getPasswordByUsername(userName); if (password != null) &#123; return new SimpleAuthenticationInfo(userName, password,\"customRealm\"); &#125; return null; &#125; private String getPasswordByUsername(String userName) &#123; return \"1234\"; &#125; private Set&lt;String&gt; getPermissionsByUsername(String userName) &#123; return new HashSet&lt;&gt;(Arrays.asList(\"select\", \"delete\", \"update\")); &#125; private Set&lt;String&gt; getRolesByUsername(String userName) &#123; return new HashSet&lt;&gt;(Arrays.asList(\"admin\")); &#125;&#125; 4. 密码加密加盐123HashedCredentialsMatcher matcher = new HashedCredentialsMatcher();matcher.setHashAlgorithmName(\"md5\");customRealm.setCredentialsMatcher(matcher); 在代码逻辑中加上这段，然后在 Relam 中需要自定义盐。 12// 加盐（lwen）authenticationInfo.setCredentialsSalt(ByteSource.Util.bytes(\"lwen\")); 2. 整合 Spring1. 首先配置过滤器也就是类似于其他的登陆授权方式都是通过拦截器或者过滤器来完成登陆的，这里我们也是这样的思路。在 web.xml 中配置过滤器，过滤所有请求，交给 shiro 处理。 12345678910111213&lt;!--shiro 配置--&gt;&lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 2. 配置 beans以前我们手动创建的 securityManager 对象以及 Realm 和 加密函数对象现在我们都交给 Spring 管理，进行自动的依赖注入和管理。 12345678910111213141516171819202122232425&lt;bean class=\"org.apache.shiro.spring.web.ShiroFilterFactoryBean\" id=\"shiroFilter\"&gt; &lt;property name=\"securityManager\" ref=\"securityManager\"/&gt; &lt;property name=\"loginUrl\" value=\"login.html\"/&gt; &lt;property name=\"unauthorizedUrl\" value=\"403.html\"/&gt; &lt;property name=\"filterChainDefinitions\"&gt; &lt;value&gt; /login.html=anon /subLogin=anon /*=authc &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean class=\"org.apache.shiro.web.mgt.DefaultWebSecurityManager\" id=\"securityManager\"&gt; &lt;property name=\"realm\" ref=\"customRealm\"/&gt;&lt;/bean&gt;&lt;bean class=\"realms.CustomRealm\" id=\"customRealm\"&gt; &lt;property name=\"credentialsMatcher\" ref=\"matcher\"/&gt;&lt;/bean&gt;&lt;bean class=\"org.apache.shiro.authc.credential.HashedCredentialsMatcher\" id=\"matcher\"&gt; &lt;property name=\"hashAlgorithmName\" value=\"md5\"/&gt; &lt;property name=\"hashIterations\" value=\"1\"/&gt;&lt;/bean&gt; 可以看到上面我们配置了登录页的 url 和未认证页，最后比较重要的就是我们是否需要认证的页面的配置。我们需要把登录页，和登录数据提交页给排除掉，因为如果有这些的页面的话我们将会进入死循环中，没办法进行登录操作。其中 anon 就是无需认证的，而后面 authc 需要认证，这个东西是按照顺序来的。所以 /* 放在最后面匹配。 3. 编写 controller 进行认证1234567891011121314public class IndexController &#123; @RequestMapping(value = \"/subLogin\", method = RequestMethod.POST,produces = \"application/json;charset=utf-8\") @ResponseBody public String login(User user)&#123; Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(user.getUsername(), user.getPassword()); try &#123; subject.login(token); &#125; catch (AuthenticationException e) &#123; return e.getMessage(); &#125; return \"登陆成功！\"; &#125;&#125; 认证没有抛出异常的话我们就算认证成功了，否则的话就是认证失败。 4. 角色和权限认证首先需要导入 aop 的注解，然后我们进行授权操作的时候只需要进行写一个注解就行了，当然也可以直接编码实现。 导入注解 jar 配置注解springmvc 中： 123456&lt;!--开启 aop--&gt;&lt;aop:config proxy-target-class=\"true\"/&gt;&lt;bean class=\"org.apache.shiro.spring.security.interceptor.AuthorizationAttributeSourceAdvisor\"&gt; &lt;property name=\"securityManager\" ref=\"securityManager\"/&gt;&lt;/bean&gt;&lt;bean class=\"org.apache.shiro.spring.LifecycleBeanPostProcessor\"/&gt; 12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.11&lt;/version&gt;&lt;/dependency&gt; 12345678910111213@RequiresRoles(\"admin\")@GetMapping(\"/testRole\")@ResponseBodypublic String testRole()&#123; return \"testRole\";&#125;@RequiresPermissions(\"select\")@GetMapping(\"/testPermission\")@ResponseBodypublic String testPermission()&#123; return \"has\";&#125; 3. 自动登录要创建一个 cookie 对象，然后在自动登录管理器中注入 cookie ，接着需要传递给 securityManager。 1234567891011&lt;bean class=\"org.apache.shiro.web.mgt.CookieRememberMeManager\" id=\"rememberMeManager\"&gt; &lt;property name=\"cookie\" ref=\"cookie\"/&gt;&lt;/bean&gt;&lt;bean class=\"org.apache.shiro.web.servlet.SimpleCookie\" id=\"cookie\"&gt; &lt;constructor-arg value=\"rememberMe\"/&gt; &lt;property name=\"maxAge\" value=\"200000\"/&gt;&lt;/bean&gt;&lt;bean class=\"org.apache.shiro.web.mgt.DefaultWebSecurityManager\" id=\"securityManager\"&gt; &lt;property name=\"realm\" ref=\"customRealm\"/&gt; &lt;property name=\"rememberMeManager\" ref=\"rememberMeManager\"/&gt;&lt;/bean&gt; 接着只需要在 controller 的登陆方法中进行判断就行了。 12// 设置记住我token.setRememberMe(user.isRememberMe());","categories":[{"name":"Shiro","slug":"Shiro","permalink":"http://lwenxu.coding.me/categories/Shiro/"}],"tags":[{"name":"Shiro","slug":"Shiro","permalink":"http://lwenxu.coding.me/tags/Shiro/"}]},{"title":"SpringBoot笔记(一):启动流程","slug":"SpringBoot/SpringBoot 笔记 ( 一 )：启动流程","date":"2018-04-13T13:01:28.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2018/04/13/SpringBoot/SpringBoot 笔记 ( 一 )：启动流程/","link":"","permalink":"http://lwenxu.coding.me/2018/04/13/SpringBoot/SpringBoot 笔记 ( 一 )：启动流程/","excerpt":"SpringBoot 笔记(一): 启动流程1. 配置开发环境1. 创建 Maven 项目然后我们首先在项目里面加上编译环境，防止每一次更新 Maven 的时候导致项目的语言级别自动被改成 Java5 然后导致编译不通过的问题。","text":"SpringBoot 笔记(一): 启动流程1. 配置开发环境1. 创建 Maven 项目然后我们首先在项目里面加上编译环境，防止每一次更新 Maven 的时候导致项目的语言级别自动被改成 Java5 然后导致编译不通过的问题。 123456789101112&lt;profile&gt; &lt;id&gt;jdk‐1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt;&lt;/profile&gt; 2. Maven 中添加依赖&emsp;&emsp; 一开始加上最基础的依赖就是 parent 父项目和 web 的 starter 。 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; &emsp;&emsp;其实很明显父工程的作用就是用来版本控制的，为什么这么说？我们跟踪一下父工程，来到父工程的 pox.xml 看到如下的配置。 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt; &lt;/parent&gt; &emsp;&emsp; 继续跟踪这个父工程可以看到以下内容。 123456789101112&lt;properties&gt; &lt;!-- Dependency versions --&gt; &lt;activemq.version&gt;5.14.5&lt;/activemq.version&gt; &lt;antlr2.version&gt;2.7.7&lt;/antlr2.version&gt; &lt;appengine-sdk.version&gt;1.9.59&lt;/appengine-sdk.version&gt; &lt;artemis.version&gt;1.5.5&lt;/artemis.version&gt; &lt;aspectj.version&gt;1.8.13&lt;/aspectj.version&gt; &lt;assertj.version&gt;2.6.0&lt;/assertj.version&gt; &lt;atomikos.version&gt;3.9.3&lt;/atomikos.version&gt; .... ....&lt;/properties&gt; &emsp;&emsp; 好的，现在终于算是找到源头了，这些 properties 就是用来规定 springboot 整合的这些框架的版本，所以说我们只用管好 springboot 的版本，对于里面封装的各个组件我们不用操心，他都帮我们配置好了。但是我们也是可以自己继续进行定制的，后面会说到相关的东西。 &emsp;&emsp; 可以看到里面添加的另外一个 starter 就是 web 的 starter ，其实在 springboot 中的 starter 的命名很规范一眼就能看出是干嘛的。什么是 starter ？ 简单来说就是 springboot 用来整合各个框架的包，我们需要什么框架什么功能就添加上这些对应的 starter 在 springboot 中就可以享受开箱即用的快感了！ 3. 编写主类&emsp;&emsp; 做完了这些最简单的配置，我们就可以开始写启动代码了，代码非常简单只有几行。 123456789// @SpringBootApplication 来标注一个主程序类@SpringBootApplicationpublic class MainApplication &#123; public static void main(String[] args) &#123; // Spring启动！SpringApplication.run(MainApplication.class,args); &#125;&#125; &emsp;&emsp; 很神奇这样我们就写好了一个完全可以跑起来的 springboot 应用，我们只是写了一个注解和一行代码而已，为什么会这么简单，让我们看看 @SpringBootApplication 注解。 1. @SpringBootApplication 注解&emsp;&emsp; 首先可以看到的是这是一个组合注解，里面有如下内容： 12345@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;) &emsp;&emsp; 好一个个的来看: @SpringBootConfiguration 这个注解就是标注这是一个 springboot 的配置类，也就是可以进行 springboot 的配置，配置类就等于配置文件，我们要有这个等价的概念。然后我们在打开这个注解发现里面就是 spring的一个 Java Config 注解 @Configuration 所以说这个实际上是 SpringBoot 的主配置类。 @EnableAutoConfiguration 他是用来开启自动配置，也就就是 springboot 的核心，其实最终起作用的就是 spring-boot-configuration-processor-1.5.9.RELEASE.jar 这个包在起作用，后面会分析到。看看这个注解里面的内容！12@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class) 两个注解: 1.@AutoConfigurationPackage第一个是自动导组件的注解，底层调用了Spring 底层注解(@Import)给容器中导入一个组件。也就是 @Import(AutoConfigurationPackages.Registrar.class) 可以看到他导入了一个自动配置包的注册器。Import 是Spring 的一个底层的注解，就是用来导入组件。然后我来查看这个组件到底做了什么： 1234567891011121314@Order(Ordered.HIGHEST_PRECEDENCE)static class Registrar implements ImportBeanDefinitionRegistrar, DeterminableImports &#123; @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; register(registry, new PackageImport(metadata).getPackageName()); //获取元数据中的包信息，然后导入这些包里面的组件 核心！！！！ &#125; @Override public Set&lt;Object&gt; determineImports(AnnotationMetadata metadata) &#123; return Collections.&lt;Object&gt;singleton(new PackageImport(metadata)); &#125;&#125; ​ 如果在上面的那个注册组件的位置打上断点的话，我们就会发现这个地方计算的报名就是我们主类所在的包的包名，也 就是需要导入我们主类所在的包以及子包所对应的组件，我们自己的组件。所以说我们必须把其他的类放到与主类平行的其他包中，否则没办法加载这些类到容器里。 2.@Import(EnableAutoConfigurationImportSelector.class)第二个就是导入一个 Seletor 组件，先看一下这个组件的代码，里面很简单就是一个方法，但是我们发现他是继承了一个类的所以说我们需要看看父类的方法。 123public class EnableAutoConfigurationImportSelector extends AutoConfigurationImportSelector&#123; //.......... &#125; 然后我们看到父类中的一个非常重要的方法， selectImports 这个方法就完成了我们的自动配置！ 1234567891011121314151617181920212223public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; try &#123; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); configurations = sort(configurations, autoConfigurationMetadata); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return configurations.toArray(new String[configurations.size()]); &#125; catch (IOException ex) &#123; throw new IllegalStateException(ex); &#125;&#125; 可以看到里面有个 configurations 变量这个就是我们的自动配置的一些包。可以打断点看到里面的内容。 这个组件底层就是各种 beanFactory 也就是我们 Spring 底层的 Ioc 容器，然后就是向容器里面导入我们的自动配置类，xxxAutoConfiguration 这种类，也就是 spring-boot-configuration-processor-1.5.9.RELEASE.jar 包里面的内容。 那么具体把这个包里面的哪些 xxxAutoConfiguration 加入到容器里面呢？ 这就需要看一个方法。在这个 Selector 的底层有一个 getCandidateConfigurations 方法，这个方法就是去扫描所有包下面的 META-INF/spring.factories 文件，然后这些文件中的 EnableAutoConfiguratio 属性就会有需要配置组件要导入哪些 xxxAutoConfiguration 类对这个组件进行自动配置。可以看一下spring-boot-configuration-processor-1.5.9.RELEASE.jar 里面的具体内容： 123456789org.springframework.boot.test.autoconfigure.orm.jpa.AutoConfigureDataJpa=\\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration &emsp;&emsp; 可以看到这就是他的自动配置机制！ 2. run 方法在这个方法的底层 new 了一个 SpringApplication 的东西，这个很明显就是真正的 springboot 的启动类了。最后调用到了 public ConfigurableApplicationContext run(String... args) 这里面做了一些列的启动操作，就不具体看了。然后我们传入的那个类被放到了 sources = new LinkedHashSet(); 这个数据结构里面。感觉没怎么被使用。 &emsp;&emsp; 这样其实我们的 springboot 应用已经可以开始跑起来了。但是我们不能访问任何页面，主要是因为我们没有 controller ！好的接着编写一个简单的 controller。 4. controller 编写12345678@Controller //标注他是 controller@ResponseBody //能够返回数据public class HelloController &#123; @GetMapping(\"/hello\") //url映射 public String hello()&#123; return \"Hello World!\"; &#125;&#125; &emsp;&emsp; @Controller 、@ResponseBody 这两个注解我们可以合并采用 @RestController 这个其实就是上面两个注解的组合注解。然后下面的那个 @GetMapping 就是采用的 get 方式请求时候的映射，然后对应的还有 post、put、delete 等等，这些都是 restful 接口中有规定的在何种情况使用何种请求方式。 &emsp;&emsp; 此时我们去访问 localhost:8080/hello 就会显示 “Hello World！” 了！ 5. 打包部署&emsp;&emsp; 这个在 springboot 中打包部署非常容易就是采用一个 Maven 插件我们就可以打包成 jar 而非 war 。那么也就是说我们可以直接使用 java -jar 命令来运行这个 jar 包。等等 ！难道不需要 tomcat 之类的 web 容器吗？ 对的！因为springboot 是内嵌了 tomcat 所以我们根本没有部署到 web 容器这一说，所以说部署简洁。那么我们需要加入打包插件。 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; &emsp;&emsp; 接下来只需要在 Maven 中执行 package 命令就可以在 target 目录生成 jar 包。并且我们可以使用 java -jar 来执行这个 jar 。 6. resource 目录结构resources文件夹中目录结构： static：保存所有的静态资源如 js css images。 templates：保存所有的模板页面 html 模板。 application.properties：Spring Boot应用的配置文件。","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/tags/SpringBoot/"}]},{"title":"Bootstrap 源码分析","slug":"Netty/Bootstrap 源码分析","date":"2018-04-07T13:40:24.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/04/07/Netty/Bootstrap 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/04/07/Netty/Bootstrap 源码分析/","excerpt":"Netty 源码分析: Bootstrap1. 结构先看一个这个类的类层次结构，好，这个结构还是比较明晰的，然后看他的主要字段，因为这些字段比较重要，在后面的代码分析中是用的上的。","text":"Netty 源码分析: Bootstrap1. 结构先看一个这个类的类层次结构，好，这个结构还是比较明晰的，然后看他的主要字段，因为这些字段比较重要，在后面的代码分析中是用的上的。 12345678// options 选项private final Map&lt;ChannelOption&lt;?&gt;, Object&gt; childOptions = new LinkedHashMap&lt;ChannelOption&lt;?&gt;, Object&gt;();// 属性private final Map&lt;AttributeKey&lt;?&gt;, Object&gt; childAttrs = new LinkedHashMap&lt;AttributeKey&lt;?&gt;, Object&gt;();// worker 线程池，为啥没有 boss ？ 待会说private volatile EventLoopGroup childGroup;// handlerprivate volatile ChannelHandler childHandler; &emsp;&emsp; 可以看到很多参数就是在我们进行 bootstrap 配置的时候进行设置的。但是我们注意到我们一般配置线程池的时候是有一个 boss 一个 worker ，但是这里只有一个引用是怎么回事？接着我们看一下构造方法。有一行注释 “ Specify the {@link EventLoopGroup} which is used for the parent (acceptor) and the child (client).” 这个意思就是说这里把线程池分为了 parent 和 child ，其中 parent 就是我们说的 boss 他的作用就是用来接收请求的连接，然后 worker 线程池就是用来处理读写事件的。最后我们找到两个参数的构造方法，用来初始化这两个参数，这里明显的能看到原来 boss 是在父类中定义的。所以调用父类的构造方法初始化了。过程和这个里对 Worker 初始化一样，做了检测，就不贴代码了。 12345678910111213public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) &#123; // 初始化 boss super.group(parentGroup); if (childGroup == null) &#123; throw new NullPointerException(\"childGroup\"); &#125; if (this.childGroup != null) &#123; throw new IllegalStateException(\"childGroup set already\"); &#125; // 初始化 worker this.childGroup = childGroup; return this; &#125; 2. 常用方法分析&emsp;&emsp; 好的，上面看到了 bootstrap 里面的属性，接着分析一下我们常用的方法，主要就是 group 、 option 、handler 、childHandler 、 bind 、 connect 。 1. option&emsp;&emsp; 逻辑比较简单，如果 value 为 null 就说明要删除这个 option ，否则就放到表里面。 123456789101112131415public &lt;T&gt; B option(ChannelOption&lt;T&gt; option, T value) &#123; if (option == null) &#123; throw new NullPointerException(\"option\"); &#125; if (value == null) &#123; synchronized (options) &#123; options.remove(option); &#125; &#125; else &#123; synchronized (options) &#123; options.put(option, value); &#125; &#125; return (B) this; &#125; 2. handler/childHandler&emsp;&emsp; 这个是直接设置了引用，就把 handler 设置为传入的参数。childHandler 同理。 1234567public B handler(ChannelHandler handler) &#123; if (handler == null) &#123; throw new NullPointerException(\"handler\"); &#125; this.handler = handler; return (B) this; &#125; 3. channel&emsp;&emsp; 这里面直接调用了 channelFactory ，也就是在 3.x 中设置 channel 工厂，这里做了进一步的封装。这个 channel 工厂的作用就是利用反射 newInstance 。 4. bind&emsp;&emsp; 好吧，这个可能是现在遇到的最麻烦的一个方法了，因为如果要说的话，里面牵扯的东西太多了，又再次引入的了新的类和方法。不着急先了解大概的思路，再看源码。 &emsp;&emsp; 在 bind 方法中写出来只有几行代码，但是每一个方法里面涉及的东西就比较多。首先是进行了验证，验证就是检测线程池 和 channelFactory 是不是正常被赋值了。接着就是重要的 doBind 方法。 &emsp;&emsp; doBind 分为两个重要操作，第一个就是：对 channel 进行初始化和注册操作，然后把执行绑定操作。也就是这里涉及到的两个重要的方法： initAndRegister 和 doBind0 。 我的博客即将搬运同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan","categories":[{"name":"Netty 源码分析","slug":"Netty-源码分析","permalink":"http://lwenxu.coding.me/categories/Netty-源码分析/"}],"tags":[]},{"title":"NioEventLoopGroup 源码分析","slug":"Netty/NioEventLoopGroup 源码分析","date":"2018-04-07T13:40:24.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/04/07/Netty/NioEventLoopGroup 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/04/07/Netty/NioEventLoopGroup 源码分析/","excerpt":"NioEventLoopGroup 源码分析 1. 在阅读源码时做了一定的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限。为了方便 IDE 查看、跟踪、调试 代码，所以在 github 上提供 netty 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ &emsp;&emsp; 从今天开始，就准备进军 ne tty 了，主要的想法是看看 netty4 中一些比较重要的实现，也就是能经常出现在我们面前的东西。主要是： 线程池、通道、管道、编解码器、以及常用的工具类。 &emsp;&emsp; 然后现在看源码应该不会像之前的 jdk 那么细致了，主要是看了一个类以后就发现 netty 对代码封装太强了，基本一个功能可能封装了七八个类去实现，很多的抽象类但是这些抽象类中的功能还非常的多。所以说主要看这个流程，以及里面写的比较好的代码或者比较新的思想会仔细的去看看。具体的子字段，每个方法不可能做到那么细致。","text":"NioEventLoopGroup 源码分析 1. 在阅读源码时做了一定的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限。为了方便 IDE 查看、跟踪、调试 代码，所以在 github 上提供 netty 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ &emsp;&emsp; 从今天开始，就准备进军 ne tty 了，主要的想法是看看 netty4 中一些比较重要的实现，也就是能经常出现在我们面前的东西。主要是： 线程池、通道、管道、编解码器、以及常用的工具类。 &emsp;&emsp; 然后现在看源码应该不会像之前的 jdk 那么细致了，主要是看了一个类以后就发现 netty 对代码封装太强了，基本一个功能可能封装了七八个类去实现，很多的抽象类但是这些抽象类中的功能还非常的多。所以说主要看这个流程，以及里面写的比较好的代码或者比较新的思想会仔细的去看看。具体的子字段，每个方法不可能做到那么细致。 &emsp;&emsp; 好，正式开始 netty 源码征战 ！ 1. 基本思路&emsp;&emsp; 这里首先讲一下结论，也就是先说我看这个类的源码整理出来的思路，主要就是因为这些类太杂，一个功能在好几个类中才完全实现。 &emsp;&emsp; 我们在 new 一个 worker/boss 线程的时候一般是采用的直接使用的无参的构造方法，但是无参的构造方法他创建的线程池的大小是我们 CPU 核心的 2 倍。紧接着就需要 new 这么多个线程放到线程池里面，这里的线程池采用的数据结构是一个数组存放的，每一个线程需要设置一个任务队列，显然任务队列使用的是一个阻塞队列，这里实际采用的是 LinkedBlockQueue ，然后回想一下在 jdk 中的线程池是不是还有一个比较重要的参数就是线程工厂，对的！这里也有这个东西，他是需要我们手动传入的，但是如果不传则会使用一个默认的线程工厂，里面有一个 newThread 方法，这个方法实现基本和 jdk 中的实现一模一样，就是创建一个级别为 5 的非 Daemon 线程。对这就是我们在创建一个线程池时候完成的全部工作！ &emsp;&emsp; 好现在来具体说一下，我们每次创建的是 NioEventLoopGroup 但是他又继承了 n 个类才实现了线程池，也就是线程池的祖先是 ScheduledExecutorService 是 jdk 中的线程池的一个接口，其中里面最重要的数据结构就是一个 children 数组，用来装线程的。 &emsp;&emsp; 然后具体的线程他也是进行了封装的，也就是我们常看到的 NioEventLoop 。这个类里面有两个比较重要的结构：taskQueue 和 thread 。很明显这个非常类似 jdk 中的线程池。 2. NioEventLoopGroup 线程池分析&emsp;&emsp; 首先要创建线程池，传入的线程数为 0，他是一直在调用 this() 最后追溯到 super(nThreads,threadFactory,selectorProvider) 也就是使用了 MultithreadEventLoopGroup 的构造方法，在这一步确定了当传入的线程数为 0 时应该设置的线程数为 CPU 核心的两倍。然后再次上调，调用了 MultithreadEventExecutorGroup 的构造方法，在这里才是真正的开始了线程池的初始化。 &emsp;&emsp; 首先设置了线程池工厂，然后初始化 chooser ，接着创建 n 个线程放到 children 数组中，最后设置线程中断的监听事件。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * 这个方法流程： * 1、设置了默认的线程工厂 * 2、初始化 chooser * 3、创建nTreads个NioEventLoop对象保存在children数组中 * 4、添加中断的监听事件 * @param nThreads * @param threadFactory * @param args */ protected MultithreadEventExecutorGroup(int nThreads, ThreadFactory threadFactory, Object... args) &#123; if (nThreads &lt;= 0) &#123; throw new IllegalArgumentException(String.format(\"nThreads: %d (expected: &gt; 0)\", nThreads)); &#125; // 默认使用线程工厂是 DefaultThreadFactory if (threadFactory == null) &#123; threadFactory = newDefaultThreadFactory(); &#125; children = new SingleThreadEventExecutor[nThreads]; // 二的平方的实现是看 n&amp;-n==n //根据线程个数是否为2的幂次方，采用不同策略初始化chooser if (isPowerOfTwo(children.length)) &#123; chooser = new PowerOfTwoEventExecutorChooser(); &#125; else &#123; chooser = new GenericEventExecutorChooser(); &#125; //产生nTreads个NioEventLoop对象保存在children数组中 for (int i = 0; i &lt; nThreads; i ++) &#123; boolean success = false; try &#123; children[i] = newChild(threadFactory, args); success = true; &#125; catch (Exception e) &#123; // TODO: Think about if this is a good exception type throw new IllegalStateException(\"failed to create a child event loop\", e); &#125; finally &#123; // 没成功，把已有的线程优雅关闭 if (!success) &#123; for (int j = 0; j &lt; i; j ++) &#123; children[j].shutdownGracefully(); &#125; // 没有完全关闭的线程让它一直等待 for (int j = 0; j &lt; i; j ++) &#123; EventExecutor e = children[j]; try &#123; while (!e.isTerminated()) &#123; e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); &#125; &#125; catch (InterruptedException interrupted) &#123; Thread.currentThread().interrupt(); break; &#125; &#125; &#125; &#125; &#125; // 对每一个 children 添加中断线程时候的监听事件，就是将 terminatedChildren 自增 // 判断是否到达线程总数，是则更新 terminationFuture final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() &#123; @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception &#123; if (terminatedChildren.incrementAndGet() == children.length) &#123; terminationFuture.setSuccess(null); &#125; &#125; &#125;; for (EventExecutor e: children) &#123; e.terminationFuture().addListener(terminationListener); &#125; &#125; &emsp;&emsp; 其中有一个 if 分支用来初始化 chooser ，这个 chooser 就是用来选择使用哪个线程来执行哪些操作的。这里用到了判断一个数是否为 2 的次幂的一个方法 isPowerOfTwo() 实现比较有意思，贴出来。 123private static boolean isPowerOfTwo(int val) &#123; return (val &amp; -val) == val;&#125; &emsp;&emsp; 接下来目光要转向 newChild(threadFactory, args) ，因为在这个类里面这个方法是抽象的，在 NioEventLoopGroup 得到了实现。其实看到了也非常的简单粗暴，直接 new 了一个 NioEventLoop ，接下来就应该分析这个线程的包装类了。 123456@Overrideprotected EventExecutor newChild( ThreadFactory threadFactory, Object... args) throws Exception &#123; // 这里才是重点 也就是真正的线程 被放在自己的 children 数组中 return new NioEventLoop(this, threadFactory, (SelectorProvider) args[0]);&#125; 3. NioEventLoop 线程分析&emsp;&emsp; 上面已经看到了，newChild 方法就是 new 了一个 NioEventLoop 。所以有必要好好看看这个线程包装类。 &emsp;&emsp; 这个类的构造方法是调用了父类 SingleThreadEventLoop 的构造,接着继续上调 SingleThreadEventExecutor 构造，在这个类中才真正的实现了线程的构造。里面就做了两件事 ： new 了一个新的线程，新的线程还分配了一个任务，任务的内容就是调用本类中的一个 run 方法，在 NioEventLoop 中实现。 设置任务队列为 LinkedBlockQueue 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 构造方法主要完成了： * 1、new 一个新的线程执行一个 run 方法 * 2、用 LinkedBlockQueue 初始化 taskQueue * @param parent * @param threadFactory * @param addTaskWakesUp */ protected SingleThreadEventExecutor(EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp) &#123; if (threadFactory == null) &#123; throw new NullPointerException(\"threadFactory\"); &#125; this.parent = parent; this.addTaskWakesUp = addTaskWakesUp; // new 了一个新的线程 thread = threadFactory.newThread(new Runnable() &#123; @Override public void run() &#123; boolean success = false; updateLastExecutionTime(); try &#123; // 调用一个 run 方法 SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(\"Unexpected exception from an event executor: \", t); &#125; finally &#123; // 让线程关闭 for (;;) &#123; int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this); if (oldState &gt;= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet( SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) &#123; break; &#125; &#125; // Check if confirmShutdown() was called at the end of the loop. if (success &amp;&amp; gracefulShutdownStartTime == 0) &#123; logger.error( \"Buggy \" + EventExecutor.class.getSimpleName() + \" implementation; \" + SingleThreadEventExecutor.class.getSimpleName() + \".confirmShutdown() must be called \" + \"before run() implementation terminates.\"); &#125; try &#123; // Run all remaining tasks and shutdown hooks. for (;;) &#123; if (confirmShutdown()) &#123; break; &#125; &#125; &#125; finally &#123; try &#123; cleanup(); &#125; finally &#123; STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED); threadLock.release(); if (!taskQueue.isEmpty()) &#123; logger.warn(\"An event executor terminated with non-empty task queue (\" + taskQueue.size() + ')'); &#125; terminationFuture.setSuccess(null); &#125; &#125; &#125; &#125; &#125;); // 使用 LinkedBlockQueue 初始化 taskQueue taskQueue = newTaskQueue(); &#125; &emsp;&emsp; 然后看一下他要执行的 run 方法在 NioEventLoop 中得到了实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** *'wakenUp.compareAndSet(false, true)' 一般都会在 select.wakeUp() 之前执行 * 因为这样可以减少 select.wakeUp() 调用的次数，select.wakeUp() 调用是一个代价 * 很高的操作 * 注意：如果说我们过早的把 wakenUp 设置为 true，可能导致线程的竞争问题，过早设置的情形如下： 1) Selector is waken up between 'wakenUp.set(false)' and 'selector.select(...)'. (BAD) 2) Selector is waken up between 'selector.select(...)' and 'if (wakenUp.get()) &#123; ... &#125;'. (OK) 在第一种情况中 wakenUp 被设置为 true 则 select 会立刻被唤醒直到 wakenUp 再次被设置为 false 但是wakenUp.compareAndSet(false, true)会失败，并且导致所有希望唤醒他的线程都会失败导致 select 进行不必要的休眠 为了解决这个问题我们是在 wakenUp 为 true 的时候再次对 select 进行唤醒。 */ @Override protected void run() &#123; for (;;) &#123; // 获取之前的线程状态，并让 select 阻塞 boolean oldWakenUp = wakenUp.getAndSet(false); try &#123; // 有任务在线程创建之后直接开始 select if (hasTasks()) &#123; selectNow(); //直接调用了 select 的 selectNow 然后再次唤醒同下面的代码 // 没有任务 &#125; else &#123; // 自旋进行等待可进行 select 操作 select(oldWakenUp); // 再次唤醒，解决并发问题 if (wakenUp.get()) &#123; selector.wakeup(); &#125; &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; // 都是处理 selected 的通道的数据，并执行所有的任务，只是在 runAllTasks 传的参数不同 if (ioRatio == 100) &#123; processSelectedKeys(); runAllTasks(); &#125; else &#123; final long ioStartTime = System.nanoTime(); processSelectedKeys(); final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; if (isShuttingDown()) &#123; closeAll(); if (confirmShutdown()) &#123; break; &#125; &#125; &#125; catch (Throwable t) &#123; logger.warn(\"Unexpected exception in the selector loop.\", t); // Prevent possible consecutive immediate failures that lead to // excessive CPU consumption. try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; // Ignore. &#125; &#125; &#125; &#125; &emsp;&emsp; 紧接着就是分析这个 run 方法，也就是线程在被创建之后进行的一系列操作。里面主要做了三件事： 进行 select 处理 selectedKeys 唤醒队列中所有的任务 &emsp;&emsp; 上面的操作都是在一个循环里面一直执行的，所以说 NioEventLoop 这个线程的作用就只有一个那就是：进行任务处理。在这个线程被 new 出来时我们就给他分配了线程的任务就是永不停歇的进行上面的操作。 &emsp;&emsp; 上面的过程说的是有线程安全问题，也就是如果我们过早的把 wakenUp 设置为 true，我们的 select 就会苏醒过来，而其他的线程不清楚这种状态想要设置为 wakenUp 的时候都会失败，导致 select 休眠。主要感觉有点是因为这个东西不是线程间可见的，要是采用 volatile 可能就会解决这个问题，但是 wakenUp 是 final 的不能使用 volatile 关键字修饰。所以作者采用的解决方案就是再次手动唤醒，防止由于其他线程并发设置 wakenUp 的值导致的不必要的休眠。 &emsp;&emsp; 然后要说一下 select 方法，这个方法的调用主要因为在队列中没有任务，所以就暂时不用 select ，这个方法里面做的就是自旋的去 select ，没有任务就 等待一段时间再去 select。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * 这个方法主要干的事情： * 1、如果不需要等待就直接 select * 2、需要等待则等一个超时时间再去 select * 这个过程是不停进行的也就是死循环直达有任务可进行 select 时 select 完毕退出循环 * @param oldWakenUp * @throws IOException */ private void select(boolean oldWakenUp) throws IOException &#123; Selector selector = this.selector; try &#123; int selectCnt = 0; long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) &#123; // 不用等待进行一次 select 操作 long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; selector.selectNow(); selectCnt = 1; &#125; break; &#125; // 等一个超时再去选择 int selectedKeys = selector.select(timeoutMillis); selectCnt ++; if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123; // - Selected something, // - waken up by user, or // - the task queue has a pending task. // - a scheduled task is ready for processing break; &#125; if (Thread.interrupted()) &#123; // Thread was interrupted so reset selected keys and break so we not run into a busy loop. // As this is most likely a bug in the handler of the user or it's client library we will // also log it. // // See https://github.com/netty/netty/issues/2426 if (logger.isDebugEnabled()) &#123; logger.debug(\"Selector.select() returned prematurely because \" + \"Thread.currentThread().interrupt() was called. Use \" + \"NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.\"); &#125; selectCnt = 1; break; &#125; long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; // timeoutMillis elapsed without anything selected. selectCnt = 1; &#125; else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; // The selector returned prematurely many times in a row. // Rebuild the selector to work around the problem. logger.warn( \"Selector.select() returned prematurely &#123;&#125; times in a row; rebuilding selector.\", selectCnt); rebuildSelector(); selector = this.selector; // Select again to populate selectedKeys. selector.selectNow(); selectCnt = 1; break; &#125; currentTimeNanos = time; &#125; if (selectCnt &gt; MIN_PREMATURE_SELECTOR_RETURNS) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Selector.select() returned prematurely &#123;&#125; times in a row.\", selectCnt - 1); &#125; &#125; &#125; catch (CancelledKeyException e) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(CancelledKeyException.class.getSimpleName() + \" raised by a Selector - JDK bug?\", e); &#125; // Harmless exception - log anyway &#125; &#125; &emsp;&emsp; 接着就是 processSelectedKeys(); 和runAllTasks(); 这两个方法，前一个方法不说就是和我们写 Nio 的时候的步骤差不多，遍历 selectedKeys 处理，然后 runAllTasks() 执行所有的任务的 run 方法。 12345678910111213141516171819202122protected boolean runAllTasks() &#123; fetchFromDelayedQueue(); Runnable task = pollTask(); if (task == null) &#123; return false; &#125; // 这个循环就是用来循环任务队列中的所有任务 for (;;) &#123; try &#123; task.run(); &#125; catch (Throwable t) &#123; logger.warn(\"A task raised an exception.\", t); &#125; task = pollTask(); // 循环条件 if (task == null) &#123; lastExecutionTime = ScheduledFutureTask.nanoTime(); return true; &#125; &#125; &#125; 4. 总结&emsp;&emsp; 好了其实到这里线程池其实分析的已经差不多了，对于很多的细节问题并没有仔细的去看，单丝我们清楚流程以及里面的结构基本就差不多了。 &emsp;&emsp; 在 NioEventLoopGroup 中包装了 NioEventLoop 线程任务。具体包装在了 children 数组中，然后使用 newThread 工厂创建线程，接着给线程分配任务，任务就是进行 select 操作。 我的博客即将搬运同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan","categories":[{"name":"Netty 源码分析","slug":"Netty-源码分析","permalink":"http://lwenxu.coding.me/categories/Netty-源码分析/"}],"tags":[]},{"title":"Netty 入门","slug":"Netty/Netty 入门","date":"2018-04-06T10:40:24.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/04/06/Netty/Netty 入门/","link":"","permalink":"http://lwenxu.coding.me/2018/04/06/Netty/Netty 入门/","excerpt":"1. 粘包问题一 .长连接与短连接：1.长连接：Client方与Server方先建立通讯连接，连接建立后不断开， 然后再进行报文发送和接收。长连接在 netty 中是默认开启的，也就是我们创建了一个 Server 以后监听端口，我们的客户端去连接发现只要我们的客户端不主动的断开连接他们之间的连接是一直保持有效的。","text":"1. 粘包问题一 .长连接与短连接：1.长连接：Client方与Server方先建立通讯连接，连接建立后不断开， 然后再进行报文发送和接收。长连接在 netty 中是默认开启的，也就是我们创建了一个 Server 以后监听端口，我们的客户端去连接发现只要我们的客户端不主动的断开连接他们之间的连接是一直保持有效的。 2.短连接：Client方与Server每进行一次报文收发交易时才进行通讯连接，交易完毕后立即断开连接。此种方式常用于一点对多点通讯，比如多个Client连接一个Server。但是在 netty 中默认采用了长连接，我们如何使用短连接呢？其实很简单，在我们的 Server 端需要对客户端进行回写数据的时候我们只需要在回写的后面加上一个监听事件，就是当写完毕，我们就关闭此连接。 1ctx.channel().writeAndFlush(\"Hi Client I'm Server !&amp;&amp;\").addListener(ChannelFutureListener.CLOSE); 二 .什么时候需要考虑粘包问题?1:如果利用tcp每次发送数据，就与对方建立连接，然后双方发送完一段数据后，就关闭连接，这样就不会出现粘包问题，因为只有一种包结构,类似于http协议。2：如果发送数据无结构，如文件传输，这样发送方只管发送，接收方只管接收存储就ok，也不用考虑粘包3：如果双方建立连接，需要在连接后一段时间内发送不同结构数据，则需要考虑粘包问题。 三 .粘包出现原因TCP 是一个字节流的的传输，也就是在流中传输无固定结构的数据包。但是UDP不会出现粘包，因为它有消息边界。1 发送端需要等缓冲区满才发送出去，造成粘包2 接收方不及时接收缓冲区的包，造成多个包接收 具体的在 TCP 中出现这种情况的原因： 由Nagle算法造成的发送端的粘包:Nagle算法是一种改善网络传输效率的算法.简单的说,当我们提交一段数据给TCP发送时,TCP并不立刻发送此段数据,而是等待一小段时间,看看在等待期间是否还有要发送的数据,若有则会一次把这两段数据发送出去.这是对Nagle算法一个简单的解释,详细的请看相关书籍. 接收端接收不及时造成的接收端粘包:TCP会把接收到的数据存在自己的缓冲区中,然后通知应用层取数据.当应用层由于某些原因不能及时的把TCP的数据取出来,就会造成TCP缓冲区中存放了几段数据. 四 .解决办法为了避免粘包现象，可采取以下几种措施： 一是对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满； 二是对于接收方引起的粘包，则可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象； 三是由接收方控制，将一包数据按结构字段，人为控制分多次接收，然后合并，通过这种手段来避免粘包。 &emsp;&emsp; 以上提到的三种措施，都有其不足之处。第一种编程设置方法虽然可以避免发送方引起的粘包，但它关闭了优化算法，降低了网络发送效率，影响应用程序的性能，一般不建议使用。第二种方法只能减少出现粘包的可能性，但并不能完全避免粘包，当发送频率较高时，或由于网络突发可能使某个时间段数据包到达接收方较快，接收方还是有可能来不及接收，从而导致粘包。第三种方法虽然避免了粘包，但应用程序的效率较低，对实时应用的场合不适合。 &emsp;&emsp; 最初遇到”粘包”的问题时,我是通过在两次send之间调用sleep来休眠一小段时间来解决.这个解决方法的缺点是显而易见的,使传输效率大大降低,而且也并不可靠.后来就是通过应答的方式来解决,尽管在大多数时候是可行的,但是不能解决象B的那种情况,而且采用应答方式增加了通讯量,加重了网络负荷. 再后来就是对数据包进行封包和拆包的操作.&emsp;&emsp; 封包:封包就是给一段数据加上包头,这样一来数据包就分为包头和包体两部分内容了(以后讲过滤非法包时封包会加入”包尾”内容).包头其实上是个大小固定的结构体,其中有个结构体成员变量表示包体的长度,这是个很重要的变量,其他的结构体成员可根据需要自己定义.根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据包. 五 .在 netty 中解决粘包的方式 采用了分隔符，类似于链路层的那种使用一个特殊的标记来分割数据，这里主要采用了一个工具类 DelimiterBasedFrameDecoder(arg0,agr1) 其中第一个参数指的是这个分隔符的可占用的空间大小，只能比他大不能小于。第二个参数就是具体的分隔符了，但是不能传递一个字符串而是一个 ByteBuf 对象，也就是我们需要用工具转一下 Unpooled.copiedBuffer(&quot;&amp;&amp;&quot;.getBytes()) ，代码如下： 1pipeline.addLast(new DelimiterBasedFrameDecoder(1024, Unpooled.copiedBuffer(\"&amp;&amp;\".getBytes()))); 第二种方式也比较简单，这个就是采用了定长的报文，当我们的报文长度不够的时候必须要采用空格补齐。比如说，我们发送了 “aaaaacc” 而我们的定长指定的是 5 那么，我们只会收到 “aaaaa” 而没有 c 这就是因为他不足 5 个，我们必须采用空格补齐才能收到，或者等待下次数据比较多的时候会跟着过来。 1.addLast(new FixedLengthFrameDecoder(5)); pojo 方式，也就是自定义数据的头和体部分，其中头中最重要的就是一个长度字段。 参考资料： https://blog.csdn.net/zhangxinrun/article/details/6721495","categories":[{"name":"Netty","slug":"Netty","permalink":"http://lwenxu.coding.me/categories/Netty/"}],"tags":[]},{"title":"你好杭州","slug":"Life/你好杭州","date":"2018-04-04T09:17:35.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/04/04/Life/你好杭州/","link":"","permalink":"http://lwenxu.coding.me/2018/04/04/Life/你好杭州/","excerpt":"","text":"​ 这次已经是我第二次来杭州了，虽然上次来了一次杭州但是待的时间很短。但是也还是各种不良反应，对突然在北方生活了三年的人，突然来到南方好像显得有点 “格格不入” 。从机场到酒店被出租车司机各种坑，下载打车的 app 然后各种交费，最后那个车只打了一半的路程我就花了 160 多，然后真的是饿的不行就在一个店里吃了一点饭，那个时候真的觉得很累很累，折腾了一天也终于吃上了一顿饭，当时心里真的是又幸福又心酸。 ​ 然后吃完以后真的是折腾不动了就想着要不都花了这么多钱了我就直接打车到酒店好了，估计我九点的时候还能到酒店多休息一会。接着又是一顿晕车（晕车这个毛病真的该治治了，可怎么就是治不好呢？），终于在九点的时候成功抵达公司安排的酒店。想着终于能一个人放松一下了，到了前台小姐姐跟我说这个房间是两个人住的，突然感觉又不好了，唉说的是另外一个人什么时候入住还不一定呢，也就是现在就我一个人，那好了我哈能过几天舒服的时间。 ​ 然而….然而….. 令我万万没想到的是我刚洗完澡出来这个小伙就来了。我….. 果然还是不能庆幸太早怎么就这么巧呢。好吧，那就两个人住吧！！！随便说了几句我就想着出去买点生活用品好了，那个时候已经十点多了，想着能不能顺便去阿里踩个点，出门之后我就放弃了。现在是十点多对吧？没有时差对吧？没开玩笑对吧？为啥现在的感觉跟我下午5点多的感觉一模一样。心态有点崩，原来杭州这边的保温效果这么好的啊，冬天完全不用暖气什么的吧。 ​ 就在楼下还没有关门的天猫超市（看到这还有点亲切，因为我就是这个部门的。: &gt; ），这里面的东西也是超级贵啊就买点洗衣液药膏牙刷什么的吧，到时候酒店那个不好用还是用自己的。其他的矿泉水，面包（没有牛奶）。 ​ 接着就和蠢瑾打电话到快十二点了，又聊了一会天才睡的，哎第一天是真的多灾多难！ ​ 第二天早晨七点的阳光晃得我没有了睡意，原来是昨晚没有拉上窗帘，起来洗澡然后各种检查证件。 ​ 出发去阿里！路上的感觉还是一样的，七点四五十的时候和中午的感觉一样，热！没有一点风，两路的树特别绿，桥下的水也很绿，太阳洒在树叶上亮油油的，感觉好像那些树很享受一样。接着就是惯例贴条子到大厅等候，我进去的那个门走的是停车场开始感觉有点乱，往后面走发现走了好久才经过了一栋楼这个地方是真大。走了很久才到等候区，一路上又热又赶时间一张照片也没拍，但是也看到了不少拍照的那应该是刚到的实习生吧，第一次来肯定都很新鲜。 ​ 经过上午加下午两个小时的 hr 小姐姐的絮叨之后终于到了工作区，师兄专门下来帮我搬电脑超感动，师兄也各种跟我攀谈，谁让我平时少言寡语总要别人来带起话题。然后给我分配了 “海景房” 。本来以为我会坐在这个师兄旁边，我旁边的师兄应该20来岁的样子，估计是毕业不是很久的研究生吧。接着我就开始折腾电脑，装各种软件，这个真的是我最喜欢干的事了，可以他是 windows 要是 mac 就好了，真羡慕那些拿 macbook pro 的，我也想要啊 : &lt; ，不过师兄说等我转正了也会配置这种的，怎么说还是很期待。我会努力留下来的，加油！ ​ 可是，第二天我就生病了，没错！是鼻窦炎，感觉整个人都废了，这样的话别说实习了我啥都干不了了。全身瘫软，然后硬硬的撑了一天晚上去买药，坑爹的是去了那边就没有信号，没办法用支付宝我钱刚好不够，我可是走了三公里过来买的药啊别这么坑我，折腾好好一会那个医生的儿子才给我用手机开的热点，艰辛的买完了药，真的在得了病之后才感觉每次拿药真的就像救命稻草一样，回去就喝了一遍，第二天早上还是有点严重比昨天稍微好了一点，后来才知道那个房间的空调对着我又吹了一晚上不出问题才怪。早上起来又喝了一遍药去了公司十点多的时候师兄带我去认人，我真的头都抬不起来脑子一片空白一个人都没记住反正就师兄好！其他都是师兄再帮我说，那个时候真的没办法管了因为我站起来都费劲，中午吃饭的时候把筷子都掉在地上了，拿不住，真的一点不夸张。当时不仅仅是生病的原因，那个药的副作用太大了，我敲键盘的时候手放在那都在抖。那种感觉真的不想体验第二次了。可是下午感冒就有了很大的改观，鼻子塞的也没有那么严重了，药确实有效但是这个副作用真的太可怕了。 ​ 可是这不是最要命的，最要命是我好几天都整夜整夜的失眠至于原因也很明显就是蠢瑾闹的，整天说气我的话，那几天真的让我特别不高兴，可是第二天早上还是要上班啊…. 所以那段时间过的很不开心，给爸妈打了好几个电话。不过最后几天她态度好太多了，我还挺高兴了，工作也慢慢开始上手了…. ​ 第二次来杭州，来阿里继续实习我想这次一定一定要斩杀 offer ！我是你的骄傲哦，所以我才不会让你失望呢！","categories":[{"name":"生活小记","slug":"生活小记","permalink":"http://lwenxu.coding.me/categories/生活小记/"}],"tags":[{"name":"阿里","slug":"阿里","permalink":"http://lwenxu.coding.me/tags/阿里/"}]},{"title":"Exectors框架 源码分析","slug":"Java SourceCode/Exectors框架 源码分析","date":"2018-04-03T14:28:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/04/03/Java SourceCode/Exectors框架 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/04/03/Java SourceCode/Exectors框架 源码分析/","excerpt":"Exectors框架 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构&emsp;&emsp; 由于 Exector 这个家族还是比较大的，所以先导出一下类图，对这个家族有一个大概的认识。","text":"Exectors框架 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构&emsp;&emsp; 由于 Exector 这个家族还是比较大的，所以先导出一下类图，对这个家族有一个大概的认识。 2. Exector&emsp;&emsp; 可以看到，Exector 属于一个接口，其实它里面只有一个 void execute(Runnable) 方法。注意它里面的参数是 Runnable ，并且返回值是 void 类型。 3. ExectorService&emsp;&emsp; 紧接着就是另外一个 ExectorService 接口，这个接口继承了上面的 Exector 但是他在原来的接口上添加了非常多的方法，其中有两类方法比较重要。 其中一类就是submit() 这里提供了三个重载的方法： 1234567// 返回一个 Future 对象，表示将要执行的线程的状态// Future 对象的 get 方法会一直阻塞直到算出值&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);// Runnable 本来是不返回 Future 对象的，这里使用了一个参数传递&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);// 普通的执行，类似于 execute 方法Future&lt;?&gt; submit(Runnable task); &emsp;&emsp; 注意，这三个方法都是有返回值的，并且返回值都是一个 Future 对象，然后就是参数的问题，他们的参数可以是 Runnable 也可以是 Callable 。Runnable 我们都比较熟悉了，Callable 我们就可以理解成带有返回值的 Runnable。 &emsp;&emsp; 然后另外一类方法就是用来判断线程状态的方法，以及操作线程池中的线程的方法。 12345678// 启动一次顺序关闭，执行以前提交的任务，但不接受新任务。void shutdown();// 尝试终止正在执行的线程，暂停处理正在等待的任务，并返回等待执行的任务列表。List&lt;Runnable&gt; shutdownNow();//当前线程结束boolean isShutdown();//全部结束boolean isTerminated(); 4. AbstractExectorService&emsp;&emsp; 虽然又是一个抽象类，但是他完全没有一个抽象方法，就像 AQS 一样。然后主要讨论这里面的几个重要方法。他增加了两个重载方法，然后实现了接口的三个 submit() 。 &emsp;&emsp; 先说 submit() 方法，这个方法如果接受的是 Runnable 参数的话就直接调用了 newTaskFor(Runnable runnable, T value) ，在前面会看到对于 Runnable 是有两个重载方法的，那么这里就给 T 传参不同，可以是 null 。然后另外一个传参为 callable 的就调用 newTaskFor(Callable&lt;T&gt; callable) 。可以看到，他们底层都是调用了 execute ，最后返回的还是 RunnableFuture。RunnableFuture 这个就是继承了 Runnable 和 Future 接口的一个空接口。 1234567891011121314151617181920// 调用的都是 newTaskFor 的 Runnable 参数方法public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125;public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;&#125;// 调用的 newTaskFor 的 Callable 方法public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;&#125; &emsp;&emsp; 好，既然上面的方法都调用了 newTaskFor ，那么这个方法就是 submit 的执行基础，接着看一下这个方法。 1234567// 这两个是 AES 的核心方法，主要就是创建任务 是 submit 的依赖protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable);&#125; &emsp;&emsp; 可以看到上面的方法全都是采用了 FutureTask 创建的新任务。返回后交给 execute 方法执行。那很明显， FutureTask 肯定是 RunnableFuture 的子类，确实 FutureTask 只实现了 RunnableFuture 这一个接口。 5. FutureTask 介绍&emsp;&emsp; 在前面看到，这个类实现了 RunnableFuture 然后 RunnableFuture 又继承了 Runnable 和 Future ，这个名字取的还真是可以，直接把两个接口组合了。Runnable 我们知道他就只有一个 Run 方法，用来放任务代码。而 Future 又是干嘛的呢。我们来看一下里面的方法，比较少。 123456789// 取消任务boolean cancel(boolean mayInterruptIfRunning);// 状态判断boolean isCancelled();boolean isDone();// 阻塞获取结果V get() throws InterruptedException, ExecutionException;// 超时阻塞获取结果V get(long timeout, TimeUnit unit) &emsp;&emsp; 好的，其实就是在原来的任务的基础上加上了关于状态判断和结果获取的方法，主要是结果的阻塞获取是非常重要的，这也是 Runnable 的一大缺陷。 &emsp;&emsp; FutureTask 其实就是 RunnableFuture 的一个实现类。所以说我们大致的看一下这个实现类就好。 123456789101112131415// 任务状态private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6;// 任务private Callable&lt;V&gt; callable;// 结果private Object outcome; // non-volatile, protected by state reads/writes// 执行任务的线程，他是 volatile 的private volatile Thread runner; 里面的一些其他的方法就是用来对任务进行操作的，主要就是实现了父类的一些方法。里面也采用了 CAS 对线程的设定等待。 6. ThreadPoolExector&emsp;&emsp; 然后介绍完了 AES 以后，就是真正的可用的类了，这里我们首先介绍的是 ThreadPoolExector 也就是我们常说的线程池。但是我们很少看到看到我们直接的去 new 一个 ThreadPoolExector 而更常用的是采用 Executors 这个类去创建线程池。主要就是 Executors 算是一个工厂方法，new 一个线程池的过程是比较麻烦的，需要配置很多的参数，这个工厂方法把一些我们会经常用到的的线程池都通过一个工厂方法返回给我们，减少我们的工作量。 &emsp;&emsp; 这个类其实也是比较复杂的，他的代码比较多，这里只分析一部分比较重要的参数和方法。 1. 字段1. 基本字段12345678910111213141516171819202122232425262728293031323334353637// 任务的后备队列 private final BlockingQueue&lt;Runnable&gt; workQueue; // 锁 private final ReentrantLock mainLock = new ReentrantLock(); // 用来支持等待中断的 private final Condition termination = mainLock.newCondition(); // 存放的工作线程，只有当获取到锁的时候才能访问这个 Set private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); // 线程池最大数量 private int largestPoolSize; // 完成的线程数，只有在获取锁的时候才能更新这个值 private long completedTaskCount; //============================================================================== // 这里有提到用户自定义的变量我们都是用 volatile 来修饰 以保证获取到最新的值 //============================================================================== // 线程创建工厂类 private volatile ThreadFactory threadFactory; // 当任务队列饱和或者线程池关闭后 再往里面提交任务时候的执行策略 private volatile RejectedExecutionHandler handler; // 默认的执行策略是采用的 AbortPolicy (这是一个函数式接口的子类，里面实现的方法默认是抛异常) private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); // 非核心线程的存活时间 private volatile long keepAliveTime; // 是否允许核心线程具有存活时间，允许则上面的参数也会作用于核心线程 private volatile boolean allowCoreThreadTimeOut; // 核心线程的大小 private volatile int corePoolSize; // 最大线程数 private volatile int maximumPoolSize; // 池控参数 非常重要！！！！ private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // ctl 的解包 -&gt; workerCount 和 runState private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; // 打包操作 两个变量或一下 private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; &emsp;&emsp; 其中比较重要的属性有： workQueue(任务队列)、一个 Set(线程集合)、池参数、线程工厂类、拒绝策略、池控参数。 &emsp;&emsp; 其中池控参数是将两个只是变量都打包进去了，分别是 workerCount 和 runState 。 &emsp;&emsp; workerCount有效线程数.runState表明线程池的状态是否为运行，还是关闭。为了方便表示我们把 workerCount 和 runState 打包到了一个变量里面就是 ctl。runState 表示生命周期，有以下状态： RUNNING：接受新任务并处理排队的任务 SHUTDOWN：不接受新任务，但处理排队的任务 STOP：不接受新任务，不处理排队的任务，并中断正在进行的任务 TIDYING：所有任务都已终止，workerCount为零，线程转换到状态TIDYING 将运行terminate() 勾子 TERMINATED：terminated()已完成 &emsp;&emsp; 并且这些值之间顺序很重要，以允许有序的比较。 runState在整个过程中是单调递增的但不需要经过每一个状态，具体规律如下： RUNNING -&gt; SHUTDOWN 在执行 shutdown()的时候 (RUNNING or SHUTDOWN) -&gt; STOP 在执行shutdownNow() SHUTDOWN -&gt; TIDYING 当任务队列和线程池为空的时候 STOP -&gt; TIDYING 当池为空的时候 TIDYING -&gt; TERMINATED 钩子方法调用完毕 2. Worker&emsp;&emsp; 这个类其实比较有意思，一般我们会想到它里面必然是有一个线程的引用的，也就是把线程用 Worker 类来包装一下。然后还有一个就是他当前正在执行的任务引用。&emsp;&emsp; 但是我们看这个类的继承及实现的时候就会发现比较有意思的事情，他继承了 AQS 实现了 Runnale 也就是他此时从结构来看既是一个 同步器 还是一个 任务。 1. 字段1234// 线程final Thread thread;// 该线程当前领到的任务Runnable firstTask; 2. 方法&emsp;&emsp; 里面比较重要的就是一些锁的实现，这里采用的全是互斥锁。然后实现的 Runnable 的 run 就是执行当前的任务。待会看运用这些方法再具体分析，里面的代码不多。 3. BlockQueue&emsp;&emsp; 这里采用了 BlockQueue 来存放任务，然后 BlockQueue 其实是一个接口，他有很多子类，而我们使用 Exectors 工厂方法 new 出新的线程池的时候其实不同种类的线程池采用的也是不同的 BlockQueue 。&emsp;&emsp; 在 doc 中提到的子类有：ArrayBlockingQueue, DelayQueue, LinkedBlockingDeque, LinkedBlockingQueue, PriorityBlockingQueue, SynchronousQueue 但是我们真正常用的就是 ：ArrayBlockingQueue,LinkedBlockingQueue, SynchronousQueue 而我们在 Exectors 中就用了 LinkedBlockingQueue, SynchronousQueue 这两种。这个到时候会专门写一篇关于阻塞队列的博客，不然这个文章的篇幅太大了。 4. ThreadFactory&emsp;&emsp; 好很明显，这是一个函数式接口，里面就只有一个 newThread 方法，在线程池中，如果我们没有自己传入的话采用的都是 Executors.defaultThreadFactory() 创建一个 非 Daemon 优先级为 NORM_PRIORITY 的线程。这样主线程退出时不会直接退出JVM，而是等待线程池中的线程结束。所有线程都调为同一个级别，这样在操作系统角度来看所有系统都是公平的，不会导致竞争堆积。 2. 主要方法1. ctor1234567public ThreadPoolExecutor(int corePoolSize, //核心线程容量 int maximumPoolSize,//线程池的允许线程的最大容量 long keepAliveTime,//存活时间 TimeUnit unit,//时间单位 BlockingQueue&lt;Runnable&gt; workQueue,//任务队列 ThreadFactory threadFactory) &#123;//线程工厂 &#125; 2. execute&emsp;&emsp; 这个方法是把提交到线程池中的任务在将来的某个时间运行起来，但是不一定能够保证这个任务肯定能执行到，为什么这么说？这是由于我们在前面看到提交到线程池中的线程不一定被马上执行，如果说线程池中线程都在忙现有的任务，新提交的就会被放到任务队列中 (BlockQueue)，然而我们在上面还看到了一个拒绝策略，就是当线程池饱和或者线程池马上关闭了提交的任务会被拒绝，在这里就是抛出异常！ &emsp;&emsp; 好，现在来理一下 execute 方法的执行过程。 如果少于corePoolSize线程正在运行，开始一个新的线程领取任务。 对addWorker的调用会自动检查runState和workerCount，从而防止可能会添加的错误警报线程时它不应该通过返回false。 把任务放入后备队列，如果成功我们还是需要再次检查，因为自上次检查依赖我们可能遇到线程池关闭如果有必要的话需要回退任务队列 如果排队失败，我们会尝试添加一个新的线程。而线程添加失败则说明线程池关闭了或者已经处于饱和状态 12345678910111213141516171819202122232425262728public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 如果正在运行的线程数小于核心池大小 可以添加一个新的线程领取这个任务 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; // 如果说添加新线程失败了我们需要重新获取线程池的工作程数量，可能有变化 // 等看到 addWorker 的时候再说 c = ctl.get(); &#125; // 如果线程池在工作状态，我们就把这个任务放到后备队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; // 重新检查 ctl int recheck = ctl.get(); // 如果线程池关闭了，我们需要做回退动作，也就是撤销刚才放入的任务 // 如果撤销成功，执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果撤销失败，并且没有工作线程不管他 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 线程池已经关闭了 添加线程也失败则执行拒绝 else if (!addWorker(command, false)) reject(command); &#125; 3. addWorker&emsp;&emsp; 这个方法的功能是：根据当前线程池的状态和给的边界条件来检测是否需要添加新的线程，如果是，则添加到线程队列中并调整工作线程数并启动线程执行第一个任务。 如果该方法检测到线程池处于STOP状态或者是察觉到将要停止，则返回false。 如果线程工厂创建线程失败(可能是由于发生了OOM异常)则也返回false。 今天有点累 ，先写到这里！明天继续，清明小长假还要继续学习 ：(","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"CountDownLatch 源码分析","slug":"Java SourceCode/CountDownLatch 源码分析","date":"2018-04-03T12:05:02.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2018/04/03/Java SourceCode/CountDownLatch 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/04/03/Java SourceCode/CountDownLatch 源码分析/","excerpt":"CountDownLatch 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本介绍&emsp;&emsp; Latch 这个单词的意思就是 “闭锁” ，这也是 jdk1.5 引入的一个并发组件，名字听上去并没有让我们对他的功能并没有什么直观的感受。先粗略解释一下他的功能：我们定义了一个带有数值 n 的 Condition 对象，然后我们调用这个对象上的 await 方法，如果说我们要这个线程继续执行，我们不是调用 signal 而是调用 n 次 countDown 方法。这样等待在这个 Condition 上的所有线程都将被唤醒。","text":"CountDownLatch 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本介绍&emsp;&emsp; Latch 这个单词的意思就是 “闭锁” ，这也是 jdk1.5 引入的一个并发组件，名字听上去并没有让我们对他的功能并没有什么直观的感受。先粗略解释一下他的功能：我们定义了一个带有数值 n 的 Condition 对象，然后我们调用这个对象上的 await 方法，如果说我们要这个线程继续执行，我们不是调用 signal 而是调用 n 次 countDown 方法。这样等待在这个 Condition 上的所有线程都将被唤醒。 &emsp;&emsp; 好先来举个例子理解一下上面的文字。 123456789101112131415161718public class CountDownLatchTest &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch latch1 = new CountDownLatch(1); for (int i = 0; i &lt; 10; i++) &#123; new Thread(()-&gt;&#123; try &#123; latch1.await(); System.out.println(Thread.currentThread().getName()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; System.out.println(\"main must done something !\"); Thread.sleep(1000); latch1.countDown(); &#125;&#125; 先打印了 1main must done something ! 隔了一秒钟打印了 12345678910Thread-0Thread-1Thread-2Thread-3Thread-4Thread-5Thread-8Thread-7Thread-6Thread-9 &emsp;&emsp; 很明显，这个组件非常适合我们在一些线程开始之前需要完成 n 件其他的准备工作，每完成一件我们就执行一次 countDown() 也就是计数值减一，唯有在计数值为 0 时我们的线程才会被唤醒继续执行。 2. 结构&emsp;&emsp; 好的，先给一张类图看看他的结构。 &emsp;&emsp; 毫无疑问，底层还是采用了 AQS 作为基础并发组件。并且这个类要比我们想像中的简单的多。这个类没有继承和实现任何的接口及父类，他但一个独立的组件，里面就封装了 AQS。 3. 主要方法分析&emsp;&emsp; 其实这这个类里面只有两个有价值的方法，就是 await 和 countDown ，但是这两个方法全都是委托给了 AQS 的 acquireSharedInterruptibly 和 releaseShared 。好了又回到了 AQS ，那么上面的这个 Sync 肯定需要对 tryAcquireShared 和 tryReleaseShared 进行重写。所以说我们只需要分析两个方法。 1. tryAcquireShared&emsp;&emsp; 逻辑超简单，当 state 变量为 0 就返回 1 ，否则返回 -1 也就是失败。很明显我们调用了 await 肯定是当时的 state 值不为 0，自然会阻塞，并尝试唤醒后面的线程。 123protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; 2. tryReleaseSharedcountDown 就是让信号量减一操作，所以说他就是进行了减一操作，当为 0 的时候，就会触发唤醒后继节点的操作。 1234567891011protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125;","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"AQS 与 Sync 源码分析","slug":"Java SourceCode/AQS 与 Sync 源码分析","date":"2018-04-01T12:05:02.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2018/04/01/Java SourceCode/AQS 与 Sync 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/04/01/Java SourceCode/AQS 与 Sync 源码分析/","excerpt":"ReentrantReadWriteLock 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ &emsp;&emsp; 虽然前面几篇文章，已经分析过很多次 AQS 但是有时候分析分析着就会陷入一种调用链分不清楚的情况。为了更好的理解 AQS 中的锁机制，专门用一篇文章分析 AQS 结构，理清调用关系！","text":"ReentrantReadWriteLock 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ &emsp;&emsp; 虽然前面几篇文章，已经分析过很多次 AQS 但是有时候分析分析着就会陷入一种调用链分不清楚的情况。为了更好的理解 AQS 中的锁机制，专门用一篇文章分析 AQS 结构，理清调用关系！ 1. AQS 结构分析 &emsp;&emsp;好了，一开始我们就能明显的看到有两个内部类 Node 和 ConditionObject 。这是 AQS 中的重点，其中 Node 是 AQS 中的线程表示，而 ConditionObject 则是等待唤醒机制的核心。 &emsp;&emsp; 接着就是一些重要方法： enq addWaiter setHead unparkSuccessor doReleaseShared setHeadAndPropagate cancelAcquire acquireQueued doAcquireInterruptibly doAcquireShared doAcquireSharedInterruptibly tryAcquire tryRelease tryAcquireShared tryReleaseShared acquire acquireInterruptibly acquireShared acquireSharedInterruptibly release releaseShared hasQueuedThreads hasQueuedPredecessors transferForSignal fullyRelease 2. Node 节点和 ConditionObject1. Node 节点&emsp;&emsp; Node 节点其实就是我们对线程的一个封装，让线程能够被加入到我们设定的队列中进行等待或唤醒，其中里面有几个特别重要的属性： next，pre 这是对于同步队列中的线程来说的，构建的双向链表 nextWaiter 则是给等待队列使用的单向链表 thread 线程引用 waitStatus 等待状态 2. ConditionObject&emsp;&emsp; 这个对象就是一个等待队列的管理者，里面有对线程进行等待唤醒机制的操作。 &emsp;&emsp; 重要属性：first/lastWaiter 就是用来指示链表的首尾节点。 &emsp;&emsp; 重要方法： await 首先需要判断是否被中断，然后加入等待队列(addConditionWaiter)，释放他具有的锁 (fullyRelease).然后用死循环检测自己是否在同步队列，并将自己 park。清理等待队列中的非 Condition 的任务。 signal-&gt;doSignal ，用 while 循环将线程从等待队列中移除，然后调用尝试放入同步队列(transferForSignal)并unpark。否则的话继续在等待队列中找。 3. 重要方法调用过程1. acquire&emsp;&emsp; 获取独占锁，首先使用尝试获取锁(tryAcquire)，失败则加入同步队列(addWaiter),然后如果是队列中的第一个等待者自旋获取锁。&emsp;&emsp; 一般来说 tryAcquire 是一个模板方法，在 AQS 中没有实现，然后其他的并发组件中使用了 AQS 后必然实现自己的 tryAcquire 因为不同的锁类型实现方式不同。使用图例解释一下执行过程。 2. releas&emsp;&emsp; 这个逻辑更加简单，首先尝试释放锁(tryRelease)，成功则唤醒后继节点(unparkSuccessor)。 3. acquireShared&emsp;&emsp; 先尝试获取共享锁(tryAcquireShared),失败则加入同步队列如果是头结点自旋获取锁，并尝试唤醒后继节点(doAcquireSharedInterruptibly)。基本是 acquire 中的 addWaiter 和 acquireQueued 的组合。 4. releaseShared&emsp;&emsp; 这个和 release 有点类似，但是里面方法不太一样，首先还是调用了 tryReleaseShared 成功后，传播释放后继节点 doReleaseShared。这里面主要还是调用了 unparkSuccessor，但是还有标记传播的阶段。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"ReentrantReadWriteLock 源码分析","slug":"Java SourceCode/ReentrantReadWriteLock 源码分析","date":"2018-04-01T08:05:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/04/01/Java SourceCode/ReentrantReadWriteLock 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/04/01/Java SourceCode/ReentrantReadWriteLock 源码分析/","excerpt":"ReentrantReadWriteLock 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 概述&emsp;&emsp; 这个类听名字好像是和 ReentrantLock 差不多，但是实际上他们两没有任何关系，他并没有直接或间接的继承 ReentrantLock。ReentrantLock 属于独占锁，也就是我们前面所说的在临界区之内只能有一个线程运行。比如说我们的 Hashtable 采用的就是这种方式，哪怕在 get 元素的时候都对表加了锁，其他线程希望读取都没办法，但事实上我们知道多个线程同时读不会引起安全问题。至于什么时候会出现安全问题，这里介绍一个操作系统中常提到的 Bernstein条件 ，概括的来说就是两个线程对同一个资源不能同时进行如下操作： 读写、写读、写写 。所以我们对数据进行并发访问是不会有问题的，于是诞生了 读锁 和 写锁的概念，在 Java 中提供的 ReentrantReadWriteLock 就是一个具体实现。","text":"ReentrantReadWriteLock 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 概述&emsp;&emsp; 这个类听名字好像是和 ReentrantLock 差不多，但是实际上他们两没有任何关系，他并没有直接或间接的继承 ReentrantLock。ReentrantLock 属于独占锁，也就是我们前面所说的在临界区之内只能有一个线程运行。比如说我们的 Hashtable 采用的就是这种方式，哪怕在 get 元素的时候都对表加了锁，其他线程希望读取都没办法，但事实上我们知道多个线程同时读不会引起安全问题。至于什么时候会出现安全问题，这里介绍一个操作系统中常提到的 Bernstein条件 ，概括的来说就是两个线程对同一个资源不能同时进行如下操作： 读写、写读、写写 。所以我们对数据进行并发访问是不会有问题的，于是诞生了 读锁 和 写锁的概念，在 Java 中提供的 ReentrantReadWriteLock 就是一个具体实现。 &emsp;&emsp; 对于 ReentrantReadWriteLock，当写操作时，其它线程无法读取或写入数据，而当读操作时，其它线程无法写数据，但却可以读取数据。 &emsp;&emsp; 介绍一下线程进入读写锁的条件。 读锁：没有其他线程的写锁，没有其他线程的写请求。 写锁：没有其他线程的读锁，没有其他线程的写锁。 &emsp;&emsp; 这个锁有以下的特性： WriteLock 中可以加 ReadLock。反之不可！ WriteLock 可以降级为 ReadLock，反之不可！ 获取锁可被中断。 锁数量有限制。 1. 实现实现了 ReadWriteLock 接口，里面就两个方法让返回读写锁。 2. 字段三个字段，一个读锁，一个写锁，一个锁的实现核心 sync。 1234// 维护两个锁，这两个锁里面的实现就是 syncprivate final ReentrantReadWriteLock.ReadLock readerLock;private final ReentrantReadWriteLock.WriteLock writerLock;final Sync sync; 3. 结构 &emsp;&emsp; 还是似曾相识的结构，里面采用了 AQS 衍生出来的 Sync 以及两个公平锁和非公平锁。接着就是两个新的内部类，分别是读锁，和写锁。里面引用了 sync 核心组件。现在可以说明的是，读锁采用的是共享锁，而写锁使用独占锁。也就是把 AQS 中的两类方法都用上了。 2. ReadLock 实现1. lock&emsp;&emsp; lock 方法直接调用了 acquireShared ，在前面我们已经分析过好多次 acquireShared 方法，这里再大概说一下逻辑：先调用 tryAcquireShared 尝试获取锁，如果获取失败，则调用 doAcquireShared 加入等待队列，尝试自旋获取锁，并且唤醒同步队列中的线程。 &emsp;&emsp; 这里重点说一下 tryAcquireShared 方法，因为在公平锁和非公平锁中实现不同，所以放到了子类中实现，但是这里公平和非公平是一样的，都在 Sync 中实现，在 FairSync/NonfairSync 子类中只是实现了是否需要阻塞读写线程的判断条件。在 tryAcquireShared 中核心思想是这样的： 如果没有非当前线程的写锁，则可以继续开始获取，否则返回失败。但是当前线程的写锁和要加读锁不冲突，这也就解释了上面提到的读锁中可重入写锁，反之不可以，不可以的情况待会再解释。 如果当前线程不用等待，并且未达到读上限，读数量更新成功，没有并发抢占此方法则可以开始获取锁。 更新读锁的重入次数。里面采用了缓存机制。 出现等待，达到读上限，有并发抢占，再接着重试获取锁，重试获取锁和这里的逻辑一样，只是做了更加详细的判断在并发情况下更适用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586// 获取读锁 protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); // 有其他线程的写锁，直接失败 自己线程的写锁可以允许 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c); // 如果当前线程不用等待，并且未达到读上限，没有并发抢占此方法 可以获取读锁 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; // 唯一一个读线程 if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; // 可重入读线程 &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; // 加入读线程，更新重入次数 &#125; else &#123; // 这一系列操作只是为了获取到当前线程的重入次数，本来直接用 readHolds.get() 就能搞定的，但是这里写了一大堆 // 是为了缓存，减少 readHolds.get() 开销 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; // 出现等待，达到读上限，有并发抢占，再接着重试获取锁 return fullTryAcquireShared(current); &#125; // 这个代码就是上面的代码的重复，但是他在非并发情况下会更简单 条件判断的更加详细，其余真的没什么了 final int fullTryAcquireShared(Thread current) &#123; HoldCounter rh = null; for (;;) &#123; int c = getState(); // 与上面等价 不能有其他线程的写 if (exclusiveCount(c) != 0) &#123; if (getExclusiveOwnerThread() != current) return -1; // 准备获取锁 &#125; else if (readerShouldBlock()) &#123; // 不请求重入锁，只是为了判断 firstReaderHoldCount &gt; 0 ？？为啥 if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; &#125; else &#123; // 这么大一段就是为了删除重入数为 0 的线程 if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; rh = readHolds.get(); if (rh.count == 0) readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; &#125; &#125; // 不能超限 if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 重复代码 if (compareAndSetState(c, c + SHARED_UNIT)) &#123; if (sharedCount(c) == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125; &#125; 2. unlock&emsp;&emsp; unlock 也是调用了 releaseShared(1) ,然后里面的逻辑也是说过的，首先尝试释放当前线程执行 tryReleaseShared ，如果成功 doReleaseShared 唤醒后继线程。 &emsp;&emsp; 还是 tryReleaseShared 方法。就是对读锁的重入次数进行减，删除那些计数值为0 的线程。 12345678910111213141516171819202122232425262728293031// 释放读锁 protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); // 第一个读锁 if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; // 查找锁 &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; --rh.count; &#125; for (;;) &#123; int c = getState(); int nextc = c - SHARED_UNIT; // 没有读锁对读线程没有影响，但是对写线程有影响的 if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; 3. WriteLock 实现1. lock&emsp;&emsp; 调用 acquire(1) ，这个方法逻辑我们已经清楚了，现在就看一下 tryAcquire() 。先介绍一下基本思路： 如果没有任何读写线程直接获取。 要等待或者有竞争更新则失败 有读线程或者非当前写、超过写重入限失败，否则更新重入次数，也就是设置 state 的值。这里也就解释了写锁中可以重入读锁（必须为当前线程的写锁），但是写锁中不允许有任何的读锁。 123456789101112131415161718192021222324252627282930// 读锁获取 /* 1. 没任何锁直接获取 2. 有读锁或非当前写，失败（也就是为什前面提到的在读锁中不能重入写锁的原因，但是反过来可以必须是当前写） 3. 如果有等待条件失败 */ protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); // 可能有读写线程 if (c != 0) &#123; // (Note: if c != 0 and w == 0 then shared count != 0) // 有读线程或者非当前写线程不可获取写锁 巧妙！！！ if (w == 0 || current != getExclusiveOwnerThread()) return false; // 超过锁容量 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 重入写锁，获取成功 setState(c + acquires); return true; &#125; // 是否要等待 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; // 没有读写线程 直接获取 setExclusiveOwnerThread(current); return true; &#125; 2. unlock&emsp;&emsp; 调用 release(1) ，还是看 tryRelease ，减去那个值如果为0说明释放成功。 1234567891011121314//读锁释放 protected final boolean tryRelease(int releases) &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 低位为写锁，可以直接减 int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; // 写锁个数为 0 释放线程 if (free) setExclusiveOwnerThread(null); // state 设置为 0 setState(nextc); return free; &#125; 4. 总结&emsp;&emsp; 好了现在算是把独占锁和共享锁来了一个大整合。说到底四个重要的方法，然后里面的调用链必须要清楚，一会我会再写一篇文章分析调用链。不然很容易就蒙了，方法有点多。&emsp;&emsp; 对于这个类需要明白以下几点： 也是采用了 state 变量来维护锁，高位读，低位写 读锁全是共享锁，写锁全是独占锁了一下。 锁重入问题，读不可重入写，反之可以。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"Semaphore 源码分析","slug":"Java SourceCode/Semaphore 源码分析","date":"2018-03-31T13:35:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/03/31/Java SourceCode/Semaphore 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/31/Java SourceCode/Semaphore 源码分析/","excerpt":"Semaphore 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. Semephore 简单介绍&emsp;&emsp; 一般来说，在 Java 中比较常用的同步工具就是 Lock 和 Synchronized 但是 Java 也加入了很多新的机制比如这里提到的信号量。他其实给人的感觉就是操作系统中的信号量，如果一个线程要运行需要获取一个资源进行一次 P 操作，在这里就是调用 acquire 方法，然后运行结束后调用 V 操作，释放这个资源以供其他线程使用，这里的 release 方法。那么如果资源都被其他线程抢光了，那么这个线程只能处于等待状态。也就是 P 操作返回的 -1 。 &emsp;&emsp; 上面我们所说的信号量是多值信号量，主要用于进程之间的同步。还有一种称之为二值信号量，也就是操作系统中常提到的 mutex 。对，此时他就是锁！因为做了一个 P 操作后，只有进行 V 操作其他线程才能进入临界区。此时和 Lock 作用一样了。","text":"Semaphore 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. Semephore 简单介绍&emsp;&emsp; 一般来说，在 Java 中比较常用的同步工具就是 Lock 和 Synchronized 但是 Java 也加入了很多新的机制比如这里提到的信号量。他其实给人的感觉就是操作系统中的信号量，如果一个线程要运行需要获取一个资源进行一次 P 操作，在这里就是调用 acquire 方法，然后运行结束后调用 V 操作，释放这个资源以供其他线程使用，这里的 release 方法。那么如果资源都被其他线程抢光了，那么这个线程只能处于等待状态。也就是 P 操作返回的 -1 。 &emsp;&emsp; 上面我们所说的信号量是多值信号量，主要用于进程之间的同步。还有一种称之为二值信号量，也就是操作系统中常提到的 mutex 。对，此时他就是锁！因为做了一个 P 操作后，只有进行 V 操作其他线程才能进入临界区。此时和 Lock 作用一样了。 &emsp;&emsp; 下面写个简单的程序来感受一下这个同步工具。 123456789101112131415161718public class SemaphoreTest &#123; public static void main(String[] args) &#123; Semaphore semaphore = new Semaphore(2); for (int i = 0; i &lt; 4; i++) &#123; new Thread(()-&gt;&#123; try &#123; semaphore.acquire(); System.out.println(Thread.currentThread().getName()); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; semaphore.release(); &#125; &#125;).start(); &#125; &#125;&#125; 最后输出的如下：先打印了 12Thread-0Thread-1 隔了一秒打印了 12Thread-2Thread-3 &emsp;&emsp; 可以看到临界区内只有两个线程同时执行。其实当我们理解了上一篇文章中的 AQS 我们大概也能猜到 Semaphore 的实现原理，也是借助于 AQS 中的 state 属性，下面具体分析一下 Semaphore 的结构及原理。 2. 基本结构1. 继承null2. 实现Serializable 感觉好多类都能序列化啊！！有没有觉得。3. 主要字段1private final Sync sync; &emsp;&emsp; 好的，就一个锁字段，真干脆，那么证明前面的猜测也是对的，这个 Sync 肯定是一个内部类，继承了 AQS。在上面一篇文章中我们看到了一些 AQS 中的共享锁我没有分析，其实共享锁就是放在这使用的，所以在这篇文章中主要就是介绍 AQS 中剩下的共享锁部分。看一下整体结构。&emsp;&emsp; 有没有觉得很熟悉，简直和 ReentrantLock 结构极其相似。Semaphore的内部类公平锁(FairSync)和非公平锁(NoFairSync)各自实现不同的获取锁方法即tryAcquireShared(int arg)，毕竟公平锁和非公平锁的获取稍后不同，而释放锁tryReleaseShared(int arg)的操作交由Sync实现，因为释放操作都是相同的，因此放在父类Sync中实现。 4. 方法概览 acquire() release() ctor-2 hasQueuedThreads() tryAcquire() 3. 主要方法分析1. ctor-2&emsp;&emsp; 两个构造方法，分别指定了底层采用公平锁还是非公平锁！其中 permits 的值直接传给了 AQS 父类，也就是设置了 AQS 的 state 属性。 12345678//默认创建公平锁，permits指定同一时间访问共享资源的线程数public Semaphore(int permits) &#123; sync = new NonfairSync(permits); &#125;public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; 2. acquire&emsp;&emsp; 这个方法里面就直接调用了，acquireSharedInterruptibly(1) 。先不看代码，介绍一下过程：当线程调用了 acquire ， state 值代表的资源数足够使用，那么请求线程将会获得同步状态即对共享资源的访问权，并更新 state 的值(一般是对state值减1)，但如果state值代表的许可数已为0，则请求线程将无法获取同步状态，线程将被加入到同步队列并阻塞，直到其他线程释放同步状态(一般是对state值加1)才可能获取对共享资源的访问权。 &emsp;&emsp; 那么现在分析一下 acquireSharedInterruptibly 这个方法显然是可以被中断的，也就是说我们在 acquire 时也可以被中断。进入方法的第一件事就是判断是否有中断事件发生。然后调用了 tryAcquireShared 来获取共享锁。如果失败调用 doAcquireSharedInterruptibly 加入等待队列。 doAcquireSharedInterruptibly 这个方法真的和 acquireQueued 方法如出一辙，大部分代码是一样的！！！仅仅小部分不一样我已经注释出来了。 1234567891011121314151617181920212223242526272829303132333435// 这个方法真的是似曾相识，感觉就是 acquireQueued 的方法稍稍修改了一下 /* 1. 那个方法不抛异常 2. 那个方法在调用前把节点加入了等待队列，封装了独占锁 3. 那个方法设置标志位，这里直接抛异常 */ private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 加入等待队列 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 前驱 final Node p = node.predecessor(); // 如果前驱是 head 。自旋获取锁 简直一样！！！ // 就是写法不一样，意思一模一样 if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // 那个方法设置标志位，这里直接抛异常 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; &emsp;&emsp; 接着又是那个模板方法的问题了， tryAcquireShared ，在公平锁和非公平锁中的实现也不同。下面详细介绍一下两个的区别。在公平锁中还是和前面的 ReentrantLock 中的操作一样，先判断一下同步队列中是不是还有其他的等待线程，有则直接返回失败。否则对 state 值进行减操作并返回剩下的信号量。注意一点的是，如果我们请求的信号量大于可用信号量，返回的值是负值，而在 doAcquireSharedInterruptibly 中要求我们的方法返回正值才会继续执行。举个例子：当我们一开始有 2 信号量，而第一个线程直接请求了 10 个，这个线程就会被挂起，让其他线程来抢资源。并且如果发现请求后的资源数为负，他是不会对 state 进行更新的。 &emsp;&emsp; 然后再分析非公平锁，非公平锁直接调用了父类中的 nonfairTryAcquireShared 和 ReentrantLock 一样，调用父类的 nonfairTryAcquire ，这个方法比较简单，就是把上文中的 tryAcquireShared 里面的同步队列的判断删除了。注意一下，上面的这些方法都是死循环直到有条件对应时才会跳出循环。 12345678910111213141516171819202122232425// 非公平锁的获取方式protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125;final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; // 公平锁获取protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors()) return -1; // 仅仅多了这一行代码而已。 int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; 3. release&emsp;&emsp; release 方法，主要作用就是释放资源，提醒一下一定要保证 release 的执行，否则线程退出但是资源没有释放。所以一般这个代码写在 finally 中是最好的。并且获取多少资源就要释放多少资源，否则还是资源没被争确释放，举个例子 一开始执行了 acquire(10) 最后释放的时候不能只写一个 release() 而是 release(10) 才对。 &emsp;&emsp; 前面我们也看到了，其实 release 方法中调用的释放锁的操作肯定是一个公共操作，毕竟释放锁就不涉及公平和非公平一说了。在 release 中调用了 AQS 中的releaseShared 。这个方法毫无疑问首先会调用 tryReleaseShared 。这个又是模板方法等子类来实现，事实上就是在 Sync 中实现的。逻辑也很简单就是对 state 做增量操作。 &emsp;&emsp; 如果 tryReleaseShared 成功，执行 doReleaseShared ，就是唤醒后继线程。注意到前面的 ReentrantLock 中有 release 方法，他是直接尝试释放锁，如果成功就唤醒后继节点，两者逻辑基本一样。实际上 release 和 releaseShared 方法代码结构及逻辑完全一致，不同的就是在 tryAcquire 后的唤醒同步队列中的节点的操作不同。不然也就没必要弄两个方法了。 1234567891011121314151617181920// 尝试释放锁public final boolean release(int arg) &#123; // 如果释放锁成功 唤醒同步队列中的后继节点 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;// 为了方便对比把两个代码放在一块 可以看到 release 中的结构完全一样// 区别就在于 doReleaseShared 中有更多的判断操作public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); //在里面执行的 unparkSuccessor(h) return true; &#125; return false;&#125; &emsp;&emsp; 重点看一下 doReleaseShared ，一个比较特殊的方法，由于共享的特性，在获取锁和释放锁的过程都需要唤醒后继节点，因为可以有多个线程同时进入临界区。这个方法的主要作用是： 在执行 acquireShared 申请资源时，执行 tryAcquireShared 失败则执行 doAcquireShared 方法将线程加入同步队列，然后判断同步队列中是否只有当前这一个等待线程，是则自旋获取锁，如果获取到了锁，就把当前节点设为头结点。然后 setHeadAndPropagate 继续唤醒后继节点，因为上次释放的资源可能特别多，现在的资源支持较多的线程同时执行，所以要唤醒后继节点。唤醒后继节点的条件是 资源数 &gt; 0 或者 当前节点的后继节点的 waitStatus &lt; 0 在这里只能是 PROPAGATE 或者 SIGNAL。这里也就解释了为什么在 doReleaseShared 中需要设置头为 PROPAGATE 状态，就是为了后续的唤醒。 而在执行 releaseShared 释放资源时，首先执行 tryReleaseShared ，如果成功则执行 doReleaseShared 释放后继节点，因为释放了资源让更多的线程来运行。如果说现在队列中没有任何节点在等待就把头结点设置为 PROPAGATE ，说明有过剩的资源可用。如果此时刚好遇到上面执行 acquireShared 需要唤醒后继节点的时候先要判断头结点的 waitStatus 的值，如果是 PROPAGATE 肯定可以唤醒后面的。如果说等待队列中有等待线程那么就唤醒他们就行。 好了这个 doReleaseShared 方法需要在以上两种情况下分析，否则始终不清楚为什么要设置 PROPAGATE 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 这个方法中与 release 中的唤醒不同点在于他保证了释放动作的传递 // 如果后继节点需要唤醒，则执行唤醒操作，如果没有后继节点则把头设置为 PROPAGATE // 这里的死循环和其他的操作中的死循环一样，为了检测新的节点进入队列 // 其实这个方法比较特殊，在 acquireShared 和 releaseShared 中都被执行了，主要就是共享模式允许多个线程进入临界区 private void doReleaseShared() &#123; for (;;) &#123; Node h = head; // 等待队列中有正在等待的线程 if (h != null &amp;&amp; h != tail) &#123; // 获取头节点对应的线程的状态 int ws = h.waitStatus; // 如果头节点对应的线程是SIGNAL状态，则意味着头结点正在运行，后继结点所对应的线程需要被唤醒。 if (ws == Node.SIGNAL) &#123; // 修改头结点，现在后继节点要成为头结点了，状态设置初始值 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // 唤醒头结点h的后继结点所对应的线程 unparkSuccessor(h); &#125; // 队列中没有等待线程，只有一个正在运行的线程。 // 将头结点设置为 PROPAGATE 标志进行传递唤醒 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; // 如果头结点发生变化有一种可能就是在 acquireShared 的时候会调用 setHeadAndPropagate 导致头结点变化，则继续循环。 // 从新的头结点开始唤醒后继节点。 if (h == head) // loop if head changed break; &#125; &#125; // 被 acquireShard 调用 private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below // 当前线程设为头结点 setHead(node); // propagate 代表的是当前剩余的资源数，如果还有资源就唤醒后面的共享线程，允许多个线程获取锁， // 或者还有一个比较有意思的条件就是 h.waitStatus &lt; 0 他其实是说 h.waitStatus 要么是 signal 要么是 propagate // 从而唤醒后继节点 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125; &#125; 4. 总结&emsp;&emsp; 好了，其实到了这里基本就分析的差不多了，其他的一些很少用的方法，其实里面的写法类似，比如说不进行中断的判断等等。&emsp;&emsp; 小结一下前面所说的，Semaphore 是一个信号同步工具，线程通过向 Semaphore 申请资源和释放资源，来进入临界区。一般情况下资源的个数比较多，所以我们允许多个线程同时进入临界区，而当我们资源个数只有一个的时候他就退化成锁也就是只允许一个线程进入临界区。但我们用的比较多的还是多个线程进入，毕竟要使用锁的话 Lock 可能做得更好。&emsp;&emsp; 好，Semaphore 一般被认为是多个线程可同时进入临界区，那么我们底层的实现就不能采用独占锁，而是使用了共享锁，也就是 AQS 中的另外一部分 “江山” 共享锁的实现。资源数就直接采用了 AQS 中的 state 变量来维护。 &emsp;&emsp; 下面完整的跑一遍流程： 使用构造方法创建一个 Semaphore 对象，默认底层 new 了一个非公平锁，传入的资源数被父类(AQS)的构造方法使用，初始化了 state 变量。 调用 acquire 方法，这个方法直接调用了 acquireSharedInterruptibly() 他首先调用了 Sync 子类中的 tryAcquireShared（因为公平锁和非公平锁的缘故） 如果获取资源失败需要调用 doAcquireSharedInterruptibly() 这个方法和独占锁中的 acquireQueued 方法如出一辙，首先加入等待队列，然后如果等待队列中只有这一个等待的线程则自旋获取锁。如果获取到了锁并且还有可用就尝试唤醒他之后等待的线程，也就是调用了setHeadAndPropagate() ，否则的话直接等待。 这里很巧妙的一点，当我们自旋获取到了锁就说明在自旋的这段时间中有线程释放了资源，然后我们发现资源数还是大于 0 ，那么可以让更多的线程运行（这个时候肯定是新的线程加入了同步队列，也就解释了为什么要使用死循环来执行这段代码），所以才调用了 setHeadAndPropagate() 这个方法里面不仅仅设置了头结点，还调用了 doReleaseShared() 这看起来是需要在 release 方法中调用的在 acquire 中也调用了。 好了，现在如果调用 release 方法 ，他首先调用 releaseShared 之后，里面的逻辑是：先释放锁调用 tryReleaseShared() ，如果成功需要唤醒同步队列中等待的线程。所以会调用 doReleaseShared 。这里面的代码我们已经说过好几次了，因为在很多地方都调用了他。 好，看懂了这些基本对于 Semaphore 了解的差不多了，对于 AQS 中的共享锁部分也算是有了一个完整的介绍。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"ReentrantLock 与 AQS 源码分析","slug":"Java SourceCode/ReentrantLock 与 AQS 源码分析","date":"2018-03-29T14:55:02.000Z","updated":"2019-01-30T22:10:38.000Z","comments":true,"path":"2018/03/29/Java SourceCode/ReentrantLock 与 AQS 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/29/Java SourceCode/ReentrantLock 与 AQS 源码分析/","excerpt":"ReentrantLock 与 AQS 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构&emsp;&emsp; 重入锁 ReetrantLock，JDK 1.5新增的类，作用与synchronized关键字相当，但比synchronized更加灵活。ReetrantLock本身也是一种支持重进入的锁，即该锁可以支持一个线程对资源重复加锁，但是加锁多少次，就必须解锁多少次，这样才可以成功释放锁。","text":"ReentrantLock 与 AQS 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构&emsp;&emsp; 重入锁 ReetrantLock，JDK 1.5新增的类，作用与synchronized关键字相当，但比synchronized更加灵活。ReetrantLock本身也是一种支持重进入的锁，即该锁可以支持一个线程对资源重复加锁，但是加锁多少次，就必须解锁多少次，这样才可以成功释放锁。 1. 继承没有继承任何类，因为很多操作都使用了组合完成。 2. 实现Lock, java.io.Serializable&emsp;&emsp;这里着重介绍一下 Lock 接口，接口定义了几个必要的方法，也是在 ReentrantLock 中的重点需要分析的方法。&emsp;&emsp; 三类方法：获取锁、释放锁、获取条件。 1234567891011121314public interface Lock &#123; // 阻塞获取锁，如果获取不到锁就一直等待 void lock(); // 可中断获取锁，在获取锁的过程可以被中断，但是 Synchronized 是不可以 void lockInterruptibly() throws InterruptedException; // 非阻塞获取锁，没有获取到锁立即返回 boolean tryLock(); // 超时获取锁，没获取到锁等待一段时间 boolean tryLock(long time, TimeUnit unit) throws InterruptedException; // 解锁 void unlock(); // 等待唤醒机制的条件 Condition newCondition();&#125; 从上面可以看到 Synchronized 和 Lock 的一些重要区别： Lock 的获取锁的过程是可以中断的，Synchronized 不可以，Synchronized 只能在 wait或同步代码块执行过程中才可以被中断。 由于 Lock 显示的加锁，锁可以横跨几个方法，也就是临界区的位置可以更加自由。 Lock 支持超时获取锁。 后面会看到 Lock 还支持公平及非公平锁。 绑定多个 Condition 条件 3. 主要字段&emsp;&emsp;很好，这个类的字段非常的少，真正起作用的字段只有一个 “锁” 字段。 12// 同步锁private final Sync sync; &emsp;&emsp; 这个锁（Sync）是一个继承自 AQS 的抽象内部类，说明一下 AQS (AbstractQueuedSynchronizer) 一般被称为队列同步器，他是并发包中的核心组件，绝大多数锁机制都是采用的这个类来实现的。虽然看到他是一个抽象类，但是你会发现里面没有一个方法是抽象方法，他实现了锁机制中的必要的通用的方法，待会会专门讲这个类。不然 ReentrantLock 没办法说，ReentrantLock 里面的锁操作都是依赖于 AQS。 &emsp;&emsp; 然后这个锁是有两个子类，分别是 NonfairSync 和 FairSync 从名字上也可以看出这两个类分别代表了 公平锁 和 非公平锁 。何为锁的公平性？ 实际上就是新来的线程需要征用锁必须要要等到先于他到达的线程获取并释放锁。也就是获取锁的过程是按照下来后到的顺序进行的，反之就称为非公平锁。后面我们会看到其实这两种锁不同就在于非公平锁在新线程创建后首先会直接进行锁的获取，如果没有获取到会进行一段时间的自旋，始终没获取到锁才进行等待状态。 &emsp;&emsp; 一般而言，公平锁开销比非公平锁大，这也是比较符合我们的直观感受。公平锁是需要进行排队的，但在某些场景下，可能更注重时间先后顺序，那么公平锁自然是很好的选择。 &emsp;&emsp; 好总结一下，在 ReentrantLock 中只维护了一个 “锁” 变量，这个锁是继承了 AQS 同步器，然后这个锁又有两种派生的锁：公平锁，非公平锁。那么 ReentrantLock 实现其实就有两种方式：公平锁，非公平锁。 4. 主要方法概览 ctor-2 lock lockInterruptibly tryLock tryLock(time) unlock newCondition 2. 基础并发组件 AQS1. 基本字段1. 重要字段&emsp;&emsp; AQS 是维护了一个同步队列（双向链表），这个队列里面线程都是需要竞争锁的，没有竞争到的就在同步队列中等待。head 和 tail 就指向队列的首尾。state 是一个标志字段，表示当前有多少线程在临界区。一般来说 state 只能是 0 或 1 但是由于锁是可重入的，所以也有大于 1 的情况。 &emsp;&emsp; 除了一个同步队列还有 0~n 个等待队列，等待队列就是调用了 await 方法的线程，会被挂到调用了 await 的 condition 上面的等待队列，所以有多少个 condition 就有多少等待队列。 123456//同步队列头指针private transient volatile Node head;// 同步队列尾指针private transient volatile Node tail;// 状态标志，0 则没有线程在临界区，非零表示有 state 个线程在临界区（由于锁可重入）private volatile int state; 2. Node 节点&emsp;&emsp;Node 节点也就是上文所提到的 同步队列 和 等待队列 中的元素，注意两个队列之间的元素类型是一样的因为他们之间会有相互移动转换的动作，这两个队列中的元素自然是线程，为了方便查找和表示 AQS 将线程封装到了 Node 节点中，构成双向队列。 1234567891011121314151617181920212223242526272829static final class Node &#123; // 共享非 null/独占为 null static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; /** * 线程状态 */ static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; // 双向链表 这两个指针用于同步队列构建链表使用的 下面还有一个 nextWaiter 是用来构建等待单链表队列 volatile Node prev; volatile Node next; // 线程 volatile Thread thread; // 等待队列单链表 Node nextWaiter; /** * Returns true if node is waiting in shared mode. */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; &#125; &emsp;&emsp; 可以看到上面有一个 waitStatus 属性，代表了线程当前的状态，状态标识就是那些常量。具体如下： SIGNAL: 正在执行的线程结束释放锁或者被取消执行，他必须唤醒后续的状态为 SIGNAL 节点 CANCELLED: 在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node的结点， 其结点的waitStatus为CANCELLED，即结束状态，进入该状态后的结点将不会再变化。 CONDITION: 该标识的结点处于等待队列中（不是同步队列），结点的线程等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。 PROPAGATE:在共享模式中，该状态标识结点的线程处于可运行状态。 0:代表初始化状态。 &emsp;&emsp; 可以看到，Node 里面的主要字段就是一个状态标志位、一个线程的引用、用于构建链表的指针。注意，有三个指针，其中前两个 next 和 pre 是用来构建同步队列的（双向链表），后面 nextWaiter 是用来构建等待队列。所以说虽然同步队列和等待队列使用的同一个数据类型，数据结构是不同的，并且在后面我们会看到等待队列中的节点只有两种状态 Condition 和 CANCELLED 前者表示线程已结束需要从等待队列中移除，后者表示条件结点等待被唤醒。 &emsp;&emsp;下面画图说明一下同步队列和等待队列的情况。等待队列同步队列 3. ConditionObject&emsp;&emsp; 这个内部类是等待唤醒机制的核心，在他上面绑定了一个等待队列。在这个类中使用了两个指针（ firstWaiter/lastWaiter ）指向队列的首尾。这里主要看一下 await 、signal 和 signalAll 方法。 await&emsp;&emsp; 当一个线程调用了await()相关的方法，那么首先构建一个Node节点封装当前线程的相关信息加入到等待队列中进行等待，并释放锁直到被唤醒（移动到同步队列）、中断、超时才被队列中移出。被唤醒后的第一件事是抢锁和检查是否被中断，然后才是移除队列。被唤醒时候的状态应该为 SIGNAL ，而在方法中执行的移除队列的操作就是移除状态非 Condition 的节点。 12345678910111213141516171819202122232425262728public final void await() throws InterruptedException &#123; // 等待可中断 if (Thread.interrupted()) throw new InterruptedException(); // 加入等待队列， new 新的 Node 做一个尾插入 Node node = addConditionWaiter(); // 释放当前线程的锁，失败则将当前线程设置为取消状态 int savedState = fullyRelease(node); int interruptMode = 0; // 如果没在同步队列就让线程等待也就是看是否被唤醒 // 如果有中断或者被唤醒那么退出循环 while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; // 运行到此处说明已经被唤醒了，因为结束了循环 // 唤醒后，首先自旋一下获取锁，同时判断是否中断 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; // 清理队列中状态不是 Condition 的的任务，包括被唤醒的 SIGNAL 和 被取消的 CANCELLED if (node.nextWaiter != null) unlinkCancelledWaiters(); //被中断 抛异常 if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; signal/doSignal/signalAll&emsp;&emsp; 执行 signal 首先进行锁的判断，如果没有获取到独占锁就直接抛出异常。这也就是为什么只有拥有锁的线程才能执行 signal ，然后获取等待队列中的第一个节点执行 doSignal。 123456789public final void signal() &#123; // 获取独占锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 唤醒等待队里中的第一个线程 Node first = firstWaiter; if (first != null) doSignal(first);&#125; &emsp;&emsp; doSignal 方法主要就干了三个事 ： 将被唤醒的节点从等待队列中移除（while 循环体），如果被唤醒的节点被取消了就继续唤醒后面的节点（transferForSignal 返回 false） 否则把这个节点加入到同步队列 （ enq 方法 ） 当同步队列中当前节点的前驱被取消或者没办法唤醒时则唤醒这个线程 （ unpark ），这时候调用了 unpark 正好和 await 中的 park 相对应使得 await 的线程被唤醒，接着执行循环体判断自己已经被移入到同步队列了，接着就可以执行后面的获取锁的操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private void doSignal(Node first) &#123; do &#123; // 头指针指向唤醒节点的下一个节点，并顺便判断等待队列是否空 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; // 解除引用 first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); //移入同步队列失败则继续唤醒下一个线程，否则唤醒成功 // 唤醒成功的线程不一定马上能开始执行，只有在前驱节点被取消或者没办法被唤醒时 &#125; // 将节点从等待队列移动到同步队列 成功返回 true 失败 false final boolean transferForSignal(Node node) &#123; // 在等待队列中的节点只有 condition 和 cancelled 两种状态，如果状态更新失败说明任务被取消 // 否则更新为初始状态 直接返回的话上面的 doSignal 就会继续唤醒后面的线程 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 把当前节点加入同步队列 Node p = enq(node); // 获取同步队列中倒数第二个节点的状态，当前节点的前驱 int ws = p.waitStatus; // 如果前驱节点被取消或者在设置前驱节点状态为Node.SIGNAL状态失败时，唤醒被通知节点代表的线程 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; &#125; // 插入一个节点到同步队列，如果同步队列是空的则加入一个空节点做为头结点 // 死循环保证肯定能插入 返回插入节点的前驱 private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // 这一步不需要 cas 是因为并发没关系，只是指向链表结尾，不会多线程更新问题 node.prev = t; // 可能有多个线程抢 if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; &emsp;&emsp; 有一个小问题,就是在某个线程中执行了别人的 signal 不会导致当前线程立即放弃锁，之所以会这样正是由于 ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL) 这个判断，即前驱线程都结束了。比如下面的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package util.AQSTest;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;// test signal 执行后不会导致当前线程立即释放锁public class AQSTest &#123; static Lock lock = new ReentrantLock(); static Condition run1Cond = lock.newCondition(); static Condition run2Cond = lock.newCondition(); static class Runner1 implements Runnable &#123; @Override public void run() &#123; lock.lock(); try &#123; System.out.println(\"runner 1 start\"); run1Cond.await(1, TimeUnit.SECONDS); run2Cond.signal(); System.out.println(\"runner 1 exit\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; static class Runner2 implements Runnable &#123; @Override public void run() &#123; lock.lock(); try &#123; System.out.println(\"runner 2 start\"); run2Cond.await(); System.out.println(\"runner 2 exit\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) &#123; new Thread(new Runner1(),\"runner1\").start(); new Thread(new Runner2(),\"runner2\").start(); &#125;&#125; 输出的结果始终是： 1234runner 1 startrunner 2 startrunner 1 exitrunner 2 exit &emsp;&emsp; 我使用了工具对上面的代码进行了调试，大致说一下流程，顺便用来捋一捋等待唤醒机制。 &emsp;&emsp; 首先 runner1 启动，获取到锁，打印出 “runner1 start” ，然后调用了 await 方法，此时 runner1 线程就执行了 AQS 中的 ConditionObject 中的 await 方法，该方法首先 new 了一个新的节点，把 runner1 封装到这个节点里面。挂在了 run1Con 的等待队列上，然后执行了释放锁并判断中断。紧接着 runner1 线程执行循环体判断是否被唤醒也就是是否在同步队列，显然这时候不在，就直接调用了 park 方法，执行休眠 1 秒钟操作， park 方法是 native 方法由操作系统实现。在上面线程释放锁的时候执行的操作是 fullyRelease 这个方法调用了 release 方法，而 release 方法中释放了锁之后，会检查同步队列中是否还有以前因为没抢到锁而等待的线程，如果有执行 unparkSuccessor 也就是唤醒同步队列中的后继线程。那么此时 runner2 会被唤醒，唤醒后就去抢锁，获取到 lock 锁后输出了 “runner2 start” ，然后 runner2 线程又会因为调用 await 处于和 runner1 同样的境地，也就是被放入 run2Con 的等待队列。好！此时 runner1 的超时时间到了，就会被 unpark 这个 unpark 是被操作系统调用的，之后继续执行循环体发现超时时间小于等于 0 ，则调用 transferAfterCancelledWait 里面调用了 enq 就是加入同步队列，接着开始竞争锁，开始执行 run2Con 上的 signal 此时 signal 调用 doSignal 先执行 do while 中的循环体，runner2 从 run2Con 的等待队列上移除，然后执行 transferForSignal 里面又调用了 enq 将他加入同步队列，并返回同步队列中的前驱，前驱节点状态不是 Cancelled 或者 可以被置为 SIGNAL 则 signal 方法结束。接着打印了 “runner1 exit” 。接着需要执行 finally 里面的释放锁的操作了，显然 unlock 肯定调用了 release ，而 release 会唤醒同步队列中的后继的线程，那么位于同步队列中的 runner2 之前的 park 状态就会被打断，从而跳出 while 循环，执行获取锁的操作。打印出 “runner2 exit” ，最后释放锁整个程序结束。 &emsp;&emsp; 现在总算是吧 Condition 的等待唤醒机制弄清楚了。也把 AQS 中的两个内部类的功能都解释完了。接下来就看 AQS 中的方法。 2. 重要方法 get/setState release/tryRelease/unparkSuccessor/fullyRelease acquire/tryAcquire/addWaiter/tryQueued acquireShared releaseShared &emsp;&emsp; 这些属于 AQS 中常用的方法，但是里面的核心方法都是模板方法，也就是说由继承他的子类来实现，所以只能看个大概的逻辑。一会等到讲 ReentrantLock 时再详细说这里面的方法。 3. ReentrantLock 内部类 Sync/fairSync/noFairSync1. Sync&emsp;&emsp; 这三个内部类实际上是继承自 AQS ，也就是说 ReentrantLock 是采用了 AQS 作为自己的核心并发控制组件完成的一系列的锁操作，及等待唤醒机制。 &emsp;&emsp; 首先看一下 Sync 他是后面两个的父类，他直接继承自 AQS 。AQS 中留了几个比较重要的模板方法 tryAcquire 、tryRelease 。这个方法直接实现了一些在公平锁和非公平锁中的通用操作，也就是释放锁的操作 tryRelease 。 &emsp;&emsp; tryRelease 的实现很简单，主要就是依赖于 AQS 中的 state 属性，如果state 值减去要释放的信号量为 0 则释放成功，否则失败。 12345678910111213141516// 释放锁的公共操作protected final boolean tryRelease(int releases) &#123; // 释放锁首先就是使用 AQS 中的 state 的值减去信号量 判断是否为0 // 如果是 0 则表明成功释放锁，独占线程设为 null，否则说明还占用锁 int c = getState() - releases; // 必须获取到锁才能解锁，否则抛异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 2. fairSync&amp;emsp;&amp;emsp; 公平锁执行 lock 操作就是执行了 AQS 中的 acquire(1) 也就是请求一个锁资源。但是注意，在 AQS 中的 acquire 中的 tryAcquire 方法没有实现，所以必须由当前类实现。 &amp;emsp;&amp;emsp; 在 tryAcquire 中做的事情就是看是否有代码在临界区。没有则还要看同步队列中是否有线程等待，当只有这一个线程在获取锁的时候才能正常的获取锁，其他情况都失败。123456789101112131415161718192021222324252627282930// 公平锁 static final class FairSync extends Sync &#123; final void lock() &#123; acquire(1); &#125; // 没有代码在临界区或者是当前线程的重入 则获取成功，否则失败 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 如果当前线程在获取锁的过程没有其他线程在临界区 if (c == 0) &#123; // 如果同步队列中没有等待的线程，就设置 state ，并且当前线程设为独占线程 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 有程序在临界区，如果是当前线程可重入，加上请求的资源数 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; // 竞争锁失败，因为他是公平的锁竞争 return false; &#125; &#125; 3. noFairSync同理，这个方法也需要实现 lock 和 tryAcquire 操作。在 lock 中直接判断是否有代码在临界区，没有则直接获取到锁，与公平锁不同的是：公平锁还判断了等待队列中是否有等待的线程。有在临界区的情况时执行 acquire 操作。同样的，首先要执行 tryAcquire 如果失败，加入同步队列并自旋获取锁。还是 tryAcquire 的实现，这里又调用了 nonfairTryAcquire。 12345678910111213141516171819202122232425262728293031323334353637// 非公平锁static final class NonfairSync extends Sync &#123; final void lock() &#123; // 如果没有代码在临界区 直接获取锁，独占 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else // 有代码在临界区则执行尝试获取锁 acquire(1); &#125; // 和公平锁中的 tryAcquire 一模一样只是少了关于同步队列中是否有等待线程的判断 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 没有线程获取锁 直接获取到锁 和公平锁中的 tryAcquire 一模一样只是少了关于同步队列的判断 if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 重入锁 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125; &emsp;&emsp; 好了，现在我们 AQS 中的空的核心方法也被子类实现了，那么现在 fairSync 和 noFairSync 就算是一个完整的 AQS 了。此时看一下加解锁的流程。 只说公平锁，因为非公平锁就只是少了一个判断。 首先 sync 调用 lock 方法，让后 lock 调用了 AQS 的 acquire(1) 也就是获取一个锁资源。 acquire 就先调用 tryAcquire(1) 尝试获取锁，这时候代码又回调到 sync 中的实现的 tryAcquire 方法，这个方法先判断锁是否已经被别的线程使用，然后需要确定没有更早的线程在同步队列等待获取锁，才把当前线程设置为独占线程，并设置 state 值获取锁。但是如果有代码在临界区需要判断是否为当前线程，因为锁是可重入的。如果是当前线程则 state 加上请求锁的个数，返回。 这时候又回到 AQS 中，如果上面尝试获取锁的过程失败，就需要调用 addWaiter 将当前线程封装成一个独占节点，等待状态默认为 0，并且返回当前节点。 加入同步队列后，再调用 acquireQueued 方法，当此线程是同步队列中等待的第一个线程则自旋尝试获取锁，毕竟很可能正在执行的线程马上就会释放锁了，再进行休眠不合适。如果自旋获取锁失败则判断节点状态是否为 SIGNAL 然后执行等待操作。 锁获取成功则把当前节点设置为头结点，把 thread = null 至此，Acquire 方法执行结束。 然后调用 unlock 方法解锁操作。 解锁操作就没那么麻烦，首先还是调用到了 AQS 中的 release 方法，这个方法首先尝试解锁当前线程，又回调到了 sync 中的 tryRelease 。 tryRelease 逻辑比较简单，使用 AQS 中的 state 减去释放的资源数，等于 0 代表完全释放，否则释放失败。 如果 tryRelease 成功执行就要去唤醒同步队列中的后继节点，继续执行。 至此，release 方法执行完毕。 4. AQS 中的要方法1. get/setState&emsp;&emsp;这两个方法主要是对 state 变量的 volatile 的读写，其实里面就就是普通的 get/set 方法。但是注意的一点就是 state 是 volatile 的。 1234567// 对状态变量的 volatile 读写protected final int getState() &#123; return state;&#125;protected final void setState(int newState) &#123; state = newState;&#125; 2. release/tryRelease/unparkSuccessor/fullyRelease&emsp;&emsp; 这几个方法在一起说主要是因为他们之间存在调用链，首先来看 release 这个方法我们在上面也分析了，里面调用了 tryRelease 、unparkSuccessor。 也就是首先调用 tryRelease 来释放当前线程的锁，如果释放成功就调用 unparkSuccessor 来唤醒同步队列中后继节点。其中 tryRelease 是由子类来实现，里面的主要逻辑就是看当前的 state 变量的值在修改过后是否为0 。这里还有一个 fullRelease 主要是在 ConditionObject 中调用的，当执行 await 的操作的时会执行此方法释放锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 尝试释放锁 public final boolean release(int arg) &#123; // 如果释放锁成功 唤醒同步队列中的后继节点 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; // 唤醒同步队列中的后继节点 private void unparkSuccessor(Node node) &#123; // node 一般就是当前正在运行的线程 int ws = node.waitStatus; // 当前线程置为初始状态 可以失败 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 找到同步队列中的下一个节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; //没有下一个节点或者被取消 s = null; // 从后往前找第一个没有被取消的线程 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 唤醒那个线程 if (s != null) LockSupport.unpark(s.thread); &#125; final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; int savedState = getState(); if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125; &#125; 3. acquire/tryAcquire/addWaiter/acquireQueued这个和上面的一样，在执行了 acquire 后，会去调用子类复写的 tryAcquire 方法，这个方法就是看有否有代码块在临界区，没有的话直接获取锁（非公平锁），设置 state，有的话要判断是不是当前线程能否进行重入操作，否则就获取失败。失败后会调用 addWaiter ，new 一个新的节点加入到同步队列，接着调用了 acquireQueued 如果这个节点是同步队列中的第一个等待的线程（但不是第一个节点，因为第一个节点是 thread=null 的运行中的线程）就自旋一段时间看能否获取到锁。不能则 park 等待。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 获取锁 public final void acquire(int arg) &#123; // 尝试获取锁 失败则加入同步队列 如果是同步队列中的第一个线程就自旋获取锁 // 上面的步骤的自旋获取锁阶段，返回的是是否需要中断，所以下面就进行 selfInterrupt // tryAcquire 是模板方法，因为对于公平锁和非公平锁获取锁方式不同 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; // 创建一个节点放入到同步对列中 可传入是否为独占锁 返回当前节点 private Node addWaiter(Node mode) &#123; // 默认的 status 是 0 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; // 把 tail 设置为 node 成功说明没有竞争 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 失败则就说明空队列 创建头结点 enq(node); return node; &#125; final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; // 自旋获取锁 for (;;) &#123; // 获取前驱节点 final Node p = node.predecessor(); // 如果前驱是空的头结点，那么也就是说当前线程就是队列中的第一个线程 并尝试获取锁 成功的话方法返回中断情况 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 把当前节点设置为头结点 thread=null 也就可以看做当前线程在运行，所以就不在同步队列 setHead(node); // gc p.next = null; // help GC failed = false; return interrupted; &#125; // 如果获取锁失败，检测为 SIGNAL 或者设置为 SIGNAL 然后让此线程等待 等待操作在 parkAndCheckInterrupt 中完成 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 失败 取消 if (failed) cancelAcquire(node); &#125; &#125; 5. 总结&emsp;&emsp; 其实到这里 ReentrantLock 已经讲完了，因为他底层全部调用的是 Sync 中的方法，也就是全都是调用了 AQS 中的方法。而 AQS 中的大部分重要的方法都已经看过了。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"synchronized 原理分析","slug":"Java SourceCode/synchronized 原理分析","date":"2018-03-29T10:15:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/03/29/Java SourceCode/synchronized 原理分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/29/Java SourceCode/synchronized 原理分析/","excerpt":"synchronized 原理分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. synchronized 介绍&emsp;&emsp; 在并发程序中，这个关键字可能是出现频率最高的一个字段，他可以避免多线程中的安全问题，对代码进行同步。同步的方式其实就是隐式的加锁，加锁过程是有 jvm 帮我们完成的，再生成的字节码中会有体现，如果反编译带有不可消除的 synchronized 关键字的代码块的 class 文件我们会发现有两个特殊的指令 monitorenter 和 monitorexit ，这两个就是进入管程和退出管程。为什么说不可消除的 synchronized ，这是由于在编译时期会进行锁优化，比如说在 StringBuffer 中是加了锁的，也就是锁对象就是他自己，然而我们编译以后会发现根本没有上面的两条指令就是因为，锁消除技术。","text":"synchronized 原理分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. synchronized 介绍&emsp;&emsp; 在并发程序中，这个关键字可能是出现频率最高的一个字段，他可以避免多线程中的安全问题，对代码进行同步。同步的方式其实就是隐式的加锁，加锁过程是有 jvm 帮我们完成的，再生成的字节码中会有体现，如果反编译带有不可消除的 synchronized 关键字的代码块的 class 文件我们会发现有两个特殊的指令 monitorenter 和 monitorexit ，这两个就是进入管程和退出管程。为什么说不可消除的 synchronized ，这是由于在编译时期会进行锁优化，比如说在 StringBuffer 中是加了锁的，也就是锁对象就是他自己，然而我们编译以后会发现根本没有上面的两条指令就是因为，锁消除技术。 &emsp;&emsp; Synchronized 使用的一般场景，在对象方法和类方法上使用，以及自定义同步代码块。但是在方法上使用 Synchronized 关键字和使用同步代码块是不一样的，方法上采用同步是采用的字节码中的标志位 ACC_SYNCHRONIZED 来进行同步的。而同步代码块则是采用了对象头中的锁指针指向一个监视器（锁），来完成同步。 &emsp;&emsp; 当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取 monitor ，获取成功之后才能执行方法体，方法执行完后再释放 monitor 。在方法执行期间，其他任何线程都无法再获得同一个 monitor 对象。 其实本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。 2. 对象头和锁&emsp;&emsp; 一个对象在内存中分为三部分：对象头、实例数据、对齐填充。 对象头中主要存放了 GC 分代年龄、偏向锁、偏向 id、锁类型、hash 值等。jvm 一般会用两个字来存放对象头，(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由Mark Word 和 Class Metadata Address 组成。MarkWord里默认数据是存储对象的HashCode等信息，但是会随着对象的运行改变而发生变化，不同的锁状态对应着不同的记录存储方式 实例数据就包括对象字段的值，不仅有自己的值还有继承自父类的字段的值。一般字段的顺序是同类型的字段放在一起，空间比较大的字段放在前面。在满足上面的规则下父类的放在子类的前面。 对其填充并非必要的，整个对象需要是 8 字节的整数倍，当不足的时候会进行填充以达到 8 字节整数倍，主要还是为了方便存取。 &emsp;&emsp; 这里我们主要分析一下重量级锁也就是通常说synchronized的对象锁，锁标识位为10，其中指针指向的是monitor对象（在 Synchronized 代码块中的监视器 ）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如 monitor 可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下。 1234567ObjectMonitor() &#123; _count = 0; //记录个数 _owner = NULL; // 运行的线程 //两个队列 _WaitSet = NULL; //调用 wait 方法会被加入到_WaitSet _EntryList = NULL ; //锁竞争失败，会被加入到该列表 &#125; &emsp;&emsp; ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成ObjectWaiter对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSe t集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。 3. Synchronized 代码块原理反编译下面的代码得到的字节码如下： 1234567891011public class SynchronizedTest &#123; public static void main(String[] args) &#123; synchronized (SynchronizedTest.class) &#123; System.out.println(\"hello\"); &#125; &#125; public synchronized void test()&#123; &#125;&#125; &emsp;&emsp; 当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor ，重入时计数器的值也会加 1。倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。所以看到上面有两条 monitorexit ！ 4. Synchronized 方法原理&emsp;&emsp; 先看一个反编译的实例方法的结果，确实比普通的方法多了一个标志字段。方法级的同步是隐式，即无需通过字节码指令来控制的，它实现在方法调用和返回操作之中。当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有 monitor ， 然后再执行方法，最后再方法完成(无论是正常完成还是非正常完成)时释放monitor。在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。 5. 偏向锁&emsp;&emsp; 偏向锁是 Java 为了提高程序的性能而设计的一个比较优雅的加锁方式。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做获取锁的过程。如果有其他线程竞争锁的时候就需要膨胀为轻量级锁。这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。 &emsp;&emsp; 所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。 &emsp;&emsp; 偏向锁获取的过程如下，当锁对象第一次被线程获取的时候，虚拟机把对象头中的标志位设为“01”，即偏向模式。同时使用CAS操作把获取到这个锁的线程的ID记录在对象的Mark Word之中的偏向线程ID，并将是否偏向锁的状态位置置为1。如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，直接检查ThreadId是否和自身线程Id一致，如果一致，则认为当前线程已经获取了锁，虚拟机就可以不再进行任何同步操作（例如Locking、Unlocking及对Mark Word的Update等）。 &emsp;&emsp; 其实一般来说偏向锁很少又说去主动释放的，因为只有在其他线程需要获取锁的时候，也就是这个锁不仅仅被一个线程使用，可能有两个线程交替使用，根据对象是否被锁定来决定释放锁（恢复到未锁定状态）还是升级到轻量锁状态。 6.轻量级锁&emsp;&emsp; 轻量级锁,一般指的是在有两个线程在交替使用锁的时候由于没有同时抢锁属于一种比较和谐的状态，就可以使用轻量级锁。他的基本思想是，当线程要获取锁时把锁对象的 Mark Word 复制一份到当前线程的栈顶，然后执行一个 CAS 操作把锁对象的 Mark Word 更新为指向栈顶的副本的指针，如果成功则当前线程拥有了锁。可以进行同步代码块的执行，而失败则有两种可能，要么是当前线程已经拥有了锁对象的指针，这时可以继续执行。要么是被其他线程抢占了锁对象，这时候说明了在同一时间有两个线程同时需要竞争锁，那么就打破了这种和谐的局面需要膨胀到重量级锁，锁对象的标志修改，获取线程的锁等待。&emsp;&emsp; 在轻量级锁释放的过程就采用 CAS 把栈上的赋值的 Mark Word 替换到锁对象上，如果失败说明有其他线程执抢占过锁，锁对象的 Mark Word 的标志被修改过，在释放的同时唤醒等待的线程。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"ConcurrentHashMap 源码分析","slug":"Java SourceCode/ConcurrentHashMap 源码分析","date":"2018-03-27T08:15:02.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2018/03/27/Java SourceCode/ConcurrentHashMap 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/27/Java SourceCode/ConcurrentHashMap 源码分析/","excerpt":"ConcurrentHashMap 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 前言&emsp;&emsp; 终于到这个类了，其实在前面很过很多次这个类，因为这个类代码量比较大，并且涉及到并发的问题，还有一点就是这个代码有些真的晦涩，不好懂。前前后后大概花了三天的时间看完的一些重要操作，接着今天来整理一下。","text":"ConcurrentHashMap 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 前言&emsp;&emsp; 终于到这个类了，其实在前面很过很多次这个类，因为这个类代码量比较大，并且涉及到并发的问题，还有一点就是这个代码有些真的晦涩，不好懂。前前后后大概花了三天的时间看完的一些重要操作，接着今天来整理一下。 &emsp;&emsp; 好了首先介绍一个个人的感受： 首先这个类很多操作和 HashMap 是类似的，但是麻烦就麻烦在 锁分离技术 和 并发处理 底层还是采用的 数组 + 链表 + 红黑树 来实现的，但是红黑树的 TreeNode 改成了 TreeBin 里面有很多 CAS （Compare And Swap）操作，比如说 unsafe.compareAndSwapInt(this, valueOffset, expect, update)意思是如果 valueOffset 位置包含的值与 expect 值相同，则更新 valueOffset 位置的值为update，并返回true，否则不更新，返回false。 不仅仅是 CAS 还有一些重量级的锁。也就是 synchronized代码块 用来保证操作同一数组元素下的节点的一致性，后面会看到。 2. 基本结构1. 继承AbstractMap 2. 实现ConcurrentMap&lt;K, V&gt; 和 Serializable 没有克隆。应该也是出于安全考虑！ 3. 属性1. 基本属性12345678910111213141516171819202122232425262728293031323334353637383940414243// 最大容量，同 hashmapprivate static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认大小 16private static final int DEFAULT_CAPACITY = 16;// 数组的最大值static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;// 并发数，不可修改 默认 16private static final int DEFAULT_CONCURRENCY_LEVEL = 16;// 负载因子 0.75private static final float LOAD_FACTOR = 0.75f;// 转成树链表最大长度 8static final int TREEIFY_THRESHOLD = 8;// 转链表的节点数static final int UNTREEIFY_THRESHOLD = 6;// 最小转换步长 16 常量不可修改private static final int MIN_TRANSFER_STRIDE = 16;//private static int RESIZE_STAMP_BITS = 16;// 最大 transfer helper 数 默认 2^16-1private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;//private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;// 标志位static final int MOVED = -1; // 正在 transfer 的节点的 hash 值static final int TREEBIN = -2; // 树根的 hash 值static final int RESERVED = -3; // 不进行序列化的 hash 值// 可用 cpu 数static final int NCPU = Runtime.getRuntime().availableProcessors();// 底层的数组 注意是 volatile 的transient volatile Node&lt;K, V&gt;[] table;// 在 resize 的时候使用的数组，只有在 resize 的时候才不是 null 一样volatileprivate transient volatile Node&lt;K, V&gt;[] nextTable;// 在没有竞争的时候使用，或者在初始化的时候作为一个反馈private transient volatile long baseCount;// sizeCtl 是一个控制标志// -1 表示初始化// -N 表示有 N-1 个线程在 resize// 正数或0代表hash表还没有被初始化，这个数值表示初始化// 大于 0 表示下一次进行扩容的时候的阈值// 它的值始终是当前ConcurrentHashMap容量的0.75倍，这与loadfactor是对应的。private transient volatile int sizeCtl; 其中尤其要注意那个 sizeCtl 现在不知道他的意思后面可能就看不懂了！！ 2. Node和 HashMap 一样的。但是注意这个地方采用了 volatile 关键字，其他的真的一样，只有两个是 volatile 原因在于只有这两个是可变的，会变的。 123456789101112131415161718static class Node&lt;K, V&gt; implements Map.Entry&lt;K, V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K, V&gt; next; // hashcode 比较有意思 HashMap 中使用了 Objects.hashCode(key) ^ Objects.hashCode(value) // 但是 Objects 里面还是调用了 key 和 val 的 hashCode 所以原理一样 public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; // 虽然 val 是 volatile 的变量但是不提供修改方法，否则抛异常 public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; &#125; 3. Segment&emsp;&emsp; 这个以前是特别重要的一个数据结构，基本所有的查删改都是依靠他的，但是在 1.8 中他的作用被削弱了，里面什么方法都没有。 12345678static class Segment&lt;K, V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; final float loadFactor; Segment(float lf) &#123; this.loadFactor = lf; &#125; &#125; 4. TreeNode由于直接继承了 Node 节点 所以相比 HashMap 中的 TreeNode 少了 before 和 after 属性。他的方法比较少主要是因为红黑树已经不用这个数据结构了而是采用的 TreeBin ，但是它存在是因为在转成红黑树的时候是先把 Node 封装成 TreeNode 然后再封装到 TreeBin 中的。 1234567static final class TreeNode&lt;K, V&gt; extends Node&lt;K, V&gt; &#123; TreeNode&lt;K, V&gt; parent; // red-black tree links TreeNode&lt;K, V&gt; left; TreeNode&lt;K, V&gt; right; TreeNode&lt;K, V&gt; prev; // needed to unlink next upon deletion boolean red; &#125; 5. TreeBin123456789101112static final class TreeBin&lt;K, V&gt; extends Node&lt;K, V&gt; &#123; TreeNode&lt;K, V&gt; root; //用了上文中的 TreeNode volatile TreeNode&lt;K, V&gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock // 大量的 rb-tree 的方法 不分析了 &#125; 4. 主要方法概览1. ctor-4&emsp;&emsp; 在构造方法中类似于 HashMap 的做法，在构造方法里面只进行一下参数的判断以及对一些属性进行赋值，但是没有对数组进行初始化。还是那个原理：延时加载，在 put 方法中肯定会对数组进行初始化。&emsp;&emsp; 在这里主要设置的值肯定就是我们前面提到的 sizeCtl 属性，当他为整数的时候就是阈值，我们也看到阈值字段但是没有见到那个字段被使用，主要就是被 sizeCtl 实现了！还有需要设置的属性就是负载因子和初始的数组大小，默认是 0.75 和 16 。&emsp;&emsp; 好具体说一下每一个方法的实现: 第一个无参的就是空方法，所有的值采用默认 有初始大小的，就按照 1.5*n 转成 2^n 这个格式。 如果传入一个 Map 就和 HashMap 一样，调用 putAll 方法，然后 putAll 就是循环原来的数组，然后 put 到新的数组中。 其他的就是手动设置大小和阈值。 1234567891011121314151617181920212223242526272829303132333435363738// 空方法，注释说会创建大小为 16 的数组，估计是延时加载 在 put 里面 public ConcurrentHashMap() &#123; &#125; // 设置了 sizeCtl 就是下一次扩容的容量 public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); // 如果要开的数组比最大的一半还大，那就直接分配最大容量 // 否则分配 1.5n+1 向上取 2^n int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap; &#125; // 同 HashMap public ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.sizeCtl = DEFAULT_CAPACITY; putAll(m); &#125; public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, 1); &#125; // 设置容量和负载因子 public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); // 容量不能小于并发数 if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long) (1.0 + (long) initialCapacity / loadFactor); int cap = (size &gt;= (long) MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int) size); this.sizeCtl = cap; &#125; 2. size/sumCount&emsp;&emsp; size 方法直接调用了 sumCount ，然后 sumCount 作用就是统计一下 cellCount 数组中的值的和，这时候我们会发现 cellCount 是一个类，自己定义了一个静态内部类，作用就是专门来统计节点的数量。可见统计节点在并发情况是一件很困难的事，这里还专门设计了一个类来进行统计。里面就一个字段 volatile 的 long 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 public int size() &#123; long n = sumCount(); // 如果有一些奇怪的值，比如大于最大小于最小就设置为最大，或者最小 // 否则就是正常的值 return ((n &lt; 0L) ? 0 : (n &gt; (long) Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int) n); &#125; static final class CounterCell &#123; volatile long value; CounterCell(long x) &#123; value = x; &#125; &#125; final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum; &#125;``` #### 3. get&amp;emsp;&amp;emsp; get 方法就和 HashMap 差不多，因为我们会发现他连锁都没有加，直接就以前的那个套路，首先计算 hash 然后找到数组的节点，看第一个是不是，然后看是否是红黑树或者是链表，它们采用了顺序查找，就 while 循环。&amp;emsp;&amp;emsp; 那么我们需要考虑一下为什么不需要加锁，难道我们在读元素的时候同时有别的线程在写不会出现安全问题？举个例子，当我们在遍历一个链表寻找元素的时候刚好有线程在链表的结尾做插入操作，要么我们读到链表结尾的时候，写线程没有更新链表的结尾元素那么我们就认为读先于写也就没有安全问题，因为我们在读的时候不会发现尾节点指针正好发生变化，简单来说写线程的节点指针操作是原子的，对其他线程也是可见的，这时你应该清楚为什么链表的 `next` 是 `volatile` 。```javapublic V get(Object key) &#123; Node&lt;K, V&gt;[] tab; Node&lt;K, V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 判断头结点是不是 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; // 红黑树查找 &#125; else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 顺序查找 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; 4. containsKey/Value（Traverser对象）&emsp;&emsp; containsKey 这个方法比较简单，因为我们直接可以调用 get 方法就可以判断。因此它的实现就是调用了 get 方法。&emsp;&emsp; containsValue 方法必然是需要遍历节点的，因为他需要一个个的比较元素的值。里面并没有像 get 一样遍历，而是采用了一个遍历器 Traverser 这个遍历器的主要作用是如果发现正在 transfer ，就切换到新的数组里面，获取最新插入的值。 123456789101112131415161718public boolean containsKey(Object key) &#123; return get(key) != null; &#125; public boolean containsValue(Object value) &#123; if (value == null) throw new NullPointerException(); Node&lt;K, V&gt;[] t; if ((t = table) != null) &#123; Traverser&lt;K, V&gt; it = new Traverser&lt;K, V&gt;(t, t.length, 0, t.length); for (Node&lt;K, V&gt; p; (p = it.advance()) != null; ) &#123; V v; if ((v = p.val) == value || (v != null &amp;&amp; value.equals(v))) return true; &#125; &#125; return false; &#125; 5. put/putVal&emsp;&emsp; 好了，现在就准备开始介绍最重要的，put 方法了。这个方法里面直接调用了 putVal ，其实 putVal 的逻辑有点复杂，就单看代码来说，代码量还是比较大的。&emsp;&emsp; 那么我们先介绍一下 putVal 的大概的逻辑然后再看代码。 首先就判断了 key 和 value 不能为空的情况，一开始觉得还挺奇怪的 HashMap 就允许 null 作为键值为什么 ConcurrentHashMap 却不行，这里我查了一下这段源码作者 Doug Lea 的解释是 “ 在普通的非并发的 HashMap 中我们可以存放 null 然后至于这个地方是否是真的为 null 还是由于键不存在呢，我们可以采用 containsKey 来判断。但是在并发情况下在调用方法时可能会发生引用关系的变化导致歧义 ”。感觉还是有点抽象难懂，我自己的理解就是：当我们调用 map.get(key) 时候返回 null 的时候假如根本不存在这个 key ，但是我们由于不清楚这个地方的值到底是 null 还是这个 key 根本不存在，我们就会调用 containsKey 来检查，但是在这个时间间隙中有其他线程往里面放了一个 key -&gt; null 导致我们检测的结果是有这个键值对，从而误判！ 然后我们前面也提到了，在构造方法中没有任何初始化表的操作，所以说我们在 putVal 中如果判断到表空，就需要进行初始化工作。这个初始化调用了一个 initTable() 这个方法稍后专门分析。 接着就是利用 hash 值来获取数组的索引了，首先还是判断那个对应的位置有没有元素，如果没有的话就简单了，采用 CAS 操作添加一个新节点此时添加工作就完成了可以返回了。如果不是这种情况就继续往下看。 我们看头结点的 Hash 值是否是 MOVED ，如果是就说明当前的表正在进行 transfer 我们就让当前线程去帮助 transfer 。现在没看懂没关系等看到 transfer 方法的时候就知道为什么了。 否则的话就是一个正常的链表或者红黑树了，这时候我们就和 HashMap 一样，如果是一个链表我们就遍历链表，然后遇到相同的 key 进行 value 的替换，否则插入到链表的结尾。 如果是一个红黑树就执行红黑树的插入操作。 注意这个操作是在同步代码块中进行的，因为我们不能保证多线程的修改安全，但是这个代码块的锁是头结点，也就是数组有多少元素我们就可以同时操作多少把锁，这样并发数就是数组的长度。而前面定义的并发数没有实质的作用。 最后由于我们插入了一个节点需要判断一下当前的节点数是不是大于转红黑树的阈值(默认为8)。是则调用 treeifyBin ，这个方法也比较复杂，待会专门来说。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091// 直接调用public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // 不允许 null 键值 解释是在我们没办法判断是没有对应的值还是值为 null 。 // 在非并发的情况下我们可以使用 containsKey/Value(null) 来明确知道 是不是有 null key/val // 这也就解释了为什么 hashmap 在查找的时候采用了先使用 null 来查找的策略 // 但是并发的话，他底层调用了 get 方法，而 get 方法不是同步的，有可能会发生改变产生歧义 if (key == null || value == null) throw new NullPointerException(); // 得到 hash 值 int hash = spread(key.hashCode()); // 用于记录相应链表的长度 int binCount = 0; for (Node&lt;K, V&gt;[] tab = table; ; ) &#123; Node&lt;K, V&gt; f; int n, i, fh; // 如果数组为 null 也就是没有初始化(延时加载)或者数组没有元素，进行数组初始化 if (tab == null || (n = tab.length) == 0) // 初始化数组，后面会详细介绍 tab = initTable(); // 找该 hash 值对应的数组下标，得到第一个节点 f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 如果数组该位置为空， 用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到方法的最后面了 // 如果 CAS 成功，那就是没有并发操作 方法可以结束了 有并发操作就进行下一次循环，注意外面的循环是死循环 if (casTabAt(tab, i, null, new Node&lt;K, V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容 else if ((fh = f.hash) == MOVED) // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了 tab = helpTransfer(tab, f); // 到这里就是说，f 是该位置的头结点，而且不为空 也就是一般情况 else &#123; V oldVal = null; // 获取数组该位置的头结点的监视器锁 synchronized (f) &#123; // 判断是否有新的节点插入到头部，或者删除头部节点造成不匹配 进行下一次循环 if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; // 头结点的 hash 值大于等于 0，说明是链表 binCount = 1; // 遍历链表 for (Node&lt;K, V&gt; e = f; ; ++binCount) &#123; K ek; // 如果发现了\"相等\"的 key，直接覆盖他的 value ，方法结束 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; // 到了链表的最末端，将这个新值放到链表的最后面 Node&lt;K, V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K, V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; // 红黑树 Node&lt;K, V&gt; p; binCount = 2; // 调用红黑树的插值方法插入新节点 if ((p = ((TreeBin&lt;K, V&gt;) f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // 退出链表/红黑树的操作 的同步代码块 // binCount != 0 说明上面在做链表操作 if (binCount != 0) &#123; // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8 if (binCount &gt;= TREEIFY_THRESHOLD) // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换， // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树 // 具体源码我们就不看了，扩容部分后面说 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 6. initTable&emsp;&emsp; 好，上面已经分析了关于 put 方法，我们还有两个问题没有解决，一个是初始化表，另外一个是转成红黑树，先分析表的初始化。那先回顾一下 HashMap 他是采用同样的延时加载然后在 resize 方法中进行了表的初始化工作。也就是 HashMap 的 resize 方法同时进行了初始化和扩容以及迁移的工作，在 ConcurrentHashMap 中划分的更细致，初始化就只进行初始化，因为他是并发的要考虑到更多。&emsp;&emsp; 一样的，我们先分析一下大致的思路。 首选先需要看是不是有别的线程在进行初始化，如果是我们就不要进行初始化了让出 cpu 资源让别的线程继续初始化。这个如何判断别的线程是否在初始化？就涉及到了前面的 sizeCtl 属性，当他是 -1 的时候就说明在进行表的初始化工作。 显然当别的线程没有初始化，当前线程就要初始化。并且不让别的线程进行争夺，就把 sizeCtl 用 CAS 置为 -1，并开始初始化。 初始化的工作有两个，一是 new 一个容量为 16 的新数组，其次设置扩容的阈值也就是 sizeCtl 的值，设置好了也说明初始化完毕。 1234567891011121314151617181920212223242526272829private final Node&lt;K, V&gt;[] initTable() &#123; Node&lt;K, V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; // 别的线程已经初始化好了或者正在初始化 sizeCtl 为 -1 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // 让出线程的执行权 // CAS 一下，将 sizeCtl 设置为 -1，代表抢到了锁 基本在这就相当于同步代码块 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; // DEFAULT_CAPACITY 默认初始容量是 16 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; // 初始化数组，长度为 16 或初始化时提供的长度 Node&lt;K, V&gt;[] nt = (Node&lt;K, V&gt;[]) new Node&lt;?, ?&gt;[n]; // 将这个数组赋值给 table，table 是 volatile 的 他的写发生在别人的读之前 table = tab = nt; // 如果 n 为 16 的话，那么这里 sc = 12 其实就是 0.75 * n sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; // 设置下次扩容的时候的阈值 sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 7. treeifyBin&emsp;&emsp; 行，解决了初始化接下来就要看看链表转红黑树的操作了。这个操作没有像我想的那样直接进行转树的操作，而是做了一系列的判断。&emsp;&emsp; 当链表长度大于等于 16 但数组长度小于 64 时，需要进行一次扩容操作，扩容操作又委托给了 tryPresize 扩容是预计扩容到原来的两倍。注意区分链表长度和数组长度不要弄混了！！！&emsp;&emsp; 接下来就是真正的链表转成树的操作了。 12345678910111213141516171819202122232425262728293031323334private final void treeifyBin(Node&lt;K, V&gt;[] tab, int index) &#123; Node&lt;K, V&gt; b; int n, sc; if (tab != null) &#123; // MIN_TREEIFY_CAPACITY 为 64 // 所以，如果数组长度小于 64 的时候，其实也就是 32 或者 16 或者更小的时候，会进行数组扩容 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 扩容操作 大小扩容为 (3*n+1)--&gt; 2^n tryPresize(n &lt;&lt; 1); // b 是头结点 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; // 加锁 synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; // 下面就是遍历链表，建立一颗红黑树 TreeNode&lt;K, V&gt; hd = null, tl = null; for (Node&lt;K, V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K, V&gt; p = new TreeNode&lt;K, V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; // 将红黑树设置到数组相应位置中 setTabAt(tab, index, new TreeBin&lt;K, V&gt;(hd)); &#125; &#125; &#125; &#125; &#125; 8. tryPresize&emsp;&emsp; 继续分析上面遗留下来的问题，扩容操作。 首先判断表是否为空，空则进行初始化，代码同 initTable 如果 3*tableSize+1 &lt; 扩容阈值 就不扩容，这个情况基本不会发生。 将 sizeCtl 设置为下次要进行扩容的阈值，然后进行 transfer ，这个方法里面才是真正的将数组大小扩充为原来的两倍并且进行数据迁移。 &emsp;&emsp; 整体看起来还是以前的 HashMap 的套路，他的 resize 进行初始化、扩容、数据迁移。而这里把这三步拆成了三个方法分别来做，以保证高并发。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private final void tryPresize(int size) &#123; // c：size*1.5+1 ，再往上取最近的 2 的 n 次方。 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; // sizeCtl &gt; 0 表示下次扩容的阈值 while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K, V&gt;[] tab = table; int n; // 数组初始化 // 这个 if 分支和之前说的初始化数组的代码基本上是一样的，在这里，我们可以不用管这块代码 if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings(\"unchecked\") Node&lt;K, V&gt;[] nt = (Node&lt;K, V&gt;[]) new Node&lt;?, ?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); // 0.75 * n &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; // 如果扩容后的值还小于等于阈值或者，当前数组长度已经达到最大了 不进行扩容 &#125; else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; // 进行扩容操作 else if (tab == table) &#123; int rs = resizeStamp(n); // 不可能发生 if (sc &lt; 0) &#123; Node&lt;K, V&gt;[] nt; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0 ) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; // 1. 将 SIZECTL 设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 这个值等于 // (n的32位二进制中空位数 &lt;&lt; 16 ) + 2 肯定是正数 也就是下次扩容的阈值 // 调用 transfer 方法，此时 nextTab 参数为 null // 2. 这个 cas 操作保证了只有一个线程会最先进行 transfer 操作 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125; &#125; 9. transfer&emsp;&emsp; 好了，该进入正题了，transfer 是这个类中最麻烦也是最精巧的一个方法，还是先说思路再阅读代码。 如果当前的 nextTab 是空，也就是说需要进行扩容的数组还没有初始化，那么初始化一个大小是原来两倍的数组出来，作为扩容后的新数组。 我们分配几个变量，来把原来的数组拆分成几个完全相同的段，你可以把他们想象成一个个大小相同的短数组，每个短数组的长度是 stride 。 我们先取最后一个短数组，用 i 表示一个可变的指针，可指向短数组的任意一个位置，最开始指向的是短数组的结尾。bound 表示短数组的下界，也就是开始的位置。也就是我们在短数组选择的时候是采用从后往前进行的。 然后使用了一个全局的属性 transferIndex（线程共享），来记录当前已经选择过的短数组和还没有被选择的短数组之间的分隔。 那么当前的线程选择的这个短数组其实就是当前线程应该进行的数据迁移任务，也就是说当前线程就负责完成这一个小数组的迁移任务就行了。那么很显然在 transferIndex 之前的，没有被线程处理过的短数组就需要其他线程来帮忙进行数据迁移，其他线程来的时候看到的是 transferIndex 那么他们就会从 transferIndex 往前数 stride 个元素作为一个小数组当做自己的迁移任务。 &emsp;&emsp; 好，现在可能感觉有点乱，来总结一下。当前的数组的迁移被分为很多的任务包，每一个任务包中有 stride 个元素，然后这些任务包需要被从后往前的分配给不同的线程。分配过程依赖于共享的全局变量 transferIndex 。这样做的原因就是为了高并发，不得不佩服写这个类源码的大师！ 下面用一张图在来总结一下上面所说的内容。 &emsp;&emsp; 现在线程收到自己的任务包了，肯定就需要进行数据迁移的工作了。迁移工作就比较简单了，由于是需要对链表或红黑树节点进行操作，必须要对过程同步，锁还是头结点。进行节点迁移的时候，就是和 HashMap 一样，把原来的链表和树拆成两部分，分别放到 i 和 i+n 上。&emsp;&emsp; 我们还是主要看链表的拆分，采用的看 hash 值的某一特定位是 0 还是 1 来决定放在哪个位置，节点采用的头插法，也就是部分的节点的顺序是反的。为什么说部分是反的？那是因为他在里面一大段代码都在干一件事，去找原链表的最后一段特定位相同的完整序列保持顺序不变。这个比较难说清楚还是用一张图来说明一下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194// 把节点拷贝到新数组里面 // 调用情况： 1.在 put 中的转红黑树的时候，如果大小不足 64 试着扩容 时候调用了 transfer // 2.在调用 put 完成以后，有一个 addCount 操作里面也调用了 transfer // 3.helpTransfer 中 private final void transfer(Node&lt;K, V&gt;[] tab, Node&lt;K, V&gt;[] nextTab) &#123; int n = tab.length, stride; // 将这些节点分成若干个任务迁移，每一个任务里面的节点数就是 stride // 所以当只有一个 cpu 的时候就是一个任务，多个 cpu 按下面的规则 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range // 如果 nextTab 为 null，先进行一次初始化，在属性字段里面我们就看到了这个字段是只有在迁移的时候不是 null // 其他时间都是 null //由于前面的 cas 操作已经保证了只有一个线程进行 transfer 所以不担心每个线程都会 new 出自己的新数组 if (nextTab == null) &#123; try &#123; // 容量翻倍，所以说前面那个 tryPresize 方法里面计算的希望要扩容的大小只是为了与阈值比较一下 // 真正在扩容的时候只扩充为原来的 2 倍 Node&lt;K, V&gt;[] nt = (Node&lt;K, V&gt;[]) new Node&lt;?, ?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; // volatile 赋值 nextTable = nextTab; // 用于控制迁移的位置 transferIndex = n; &#125; // 新数组长度 int nextn = nextTab.length; // 标志节点 // 这个构造方法会生成一个Node，key、value 和 next 都为 null，关键是 hash 为 MOVED // 后面我们会看到，原数组中位置 i 处的节点完成迁移工作后， // 就会将位置 i 处设置为这个 ForwardingNode，用来告诉其他线程该位置已经处理过了 ForwardingNode&lt;K, V&gt; fwd = new ForwardingNode&lt;K, V&gt;(nextTab); // advance 指的是做完了一个位置的迁移工作，可以准备做下一个位置的了 boolean advance = true; // 在对 nextTable 赋值后记得清理节点 待会说 boolean finishing = false; // 死循环 for (int i = 0, bound = 0; ; ) &#123; Node&lt;K, V&gt; f; int fh; // 说了这么多 很多都是废话，其实就一句话就是：我们从数组的结尾开始把元素分成任务，其中每一个任务的节点数就是 stride // 任务是从后往前分配的，也就是最先分出去的是数组结尾的那一段。任务开始的元素下标是 i 结束的下标是 bound 注意 bound &lt; i // 因为是从后往前来的 while (advance) &#123; int nextIndex, nextBound; // 刚领取的任务完成了 也就是 i&gt;=bound 一开始我找了半天的 --i 竟然藏在这里 if (--i &gt;= bound || finishing) advance = false; // 任务领完了 transferIndex 本来是数组的长度，现在都成0 了说明任务都分派完了 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; // 实施任务分派，更新了 TRANSFERINDEX 其他线程能看到 &#125; else if (U.compareAndSwapInt(this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; // 主要就是判断 i&lt;0 ， 也就是是不是都迁移完了 至于 i&gt;=n 是 i = n 导致的 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; // 所有的迁移操作已经完成 // 将新的 nextTab 赋值给 table 属性，完成迁移 // 重新计算 sizeCtl = 1.5*n 下次的阈值 结束迁移方法 if (finishing) &#123; nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; // 之前我们说过，SIZECTL 在迁移前会设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 // d但是怎么会出现这种情况？？？？？ if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // 任务结束，方法退出 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // 到这里，说明 (sizeCtl - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT， // 也就是说，所有的迁移任务都做完了，也就会进入到上面的 if(finishing)&#123;&#125; 分支了 finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 如果原数组 i 处是空的，没有任何节点，那么放入 ForwardingNode 作为标志 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 该位置处是一个 ForwardingNode，代表该位置已经迁移过了 else if ((fh = f.hash) == MOVED) advance = true; // already processed // 原数组处有值 else &#123; // 对数组该位置处的结点加锁，开始处理数组该位置处的迁移工作 // 迁移干的事同样的事 就是把链表拆成两部分，树也分裂成两部分 和 HashMap 真的几乎一样 synchronized (f) &#123; // 重复判断防止多线程修改 if (tabAt(tab, i) == f) &#123; Node&lt;K, V&gt; ln, hn; // 头结点的 hash 大于 0，说明是链表的 Node 节点 if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K, V&gt; lastRun = f; // p.hash &amp; n 其实是取某一特定的位，只能是 0/1 所以这个做法是把原来一个链表分成两个 // lastRun 指向最后一段 runBit 相同的连续的节点的开始 // 感觉这一段代码写得有点蠢，就是为了找到最后一段完整的同类型的节点遍历了整个链表 ？ 还是我理解错了？ for (Node&lt;K, V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; // 分链表的准备工作 if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; // 最后还是按照那个特定的位是 0/1 分成两个链表 // 链表的顺序翻转了，采用的头插 for (Node&lt;K, V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K, V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K, V&gt;(ph, pk, pv, hn); &#125; // 链表放在新数组的位置 i 和 i+n setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕， // 其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; &#125; else if (f instanceof TreeBin) &#123; // 红黑树的迁移 TreeBin&lt;K, V&gt; t = (TreeBin&lt;K, V&gt;) f; TreeNode&lt;K, V&gt; lo = null, loTail = null; TreeNode&lt;K, V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K, V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K, V&gt; p = new TreeNode&lt;K, V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 如果一分为二后，节点数少于 8，那么将红黑树转换回链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K, V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K, V&gt;(hi) : t; // 处理同链表 setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125; &#125; 10. helpTransfer&emsp;&emsp;这个方法主要是让其他线程在对表做操作的时候刚好遇到了，表在扩容，数据迁移。就让这些线程帮助完成这个数据迁移，也就是去领取 transfer 中的数据迁移的任务包。 123456789101112131415161718192021222324//1. putVal 当有 MOVED 节点的时候 2.replaceNode 也就是在 remove 中 当有 MOVED 节点的时候 //3. clear 4.conpute/IfPresent 干嘛的？ 5.merge 干嘛的？ // 好了发现规律了就是当我们在有遍历节点的操作的时候遇到了 MOVED 就去 helpTransfer 也就是 transfer final Node&lt;K, V&gt;[] helpTransfer(Node&lt;K, V&gt;[] tab, Node&lt;K, V&gt; f) &#123; Node&lt;K, V&gt;[] nextTab; int sc; // 条件判断 + 把正在 transfer 的 nextTab 赋值给 nextTab if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K, V&gt;) f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); // 当 transfer 还没有结束 sizeCtl &lt; 0 表示在迁移 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; // 把 SIZECTL 加一 然后 transfer if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table; &#125; 11. tableAt/casTableAt/setTableAt&emsp;&emsp; 这些方法,不细看，里面主要就是封装了一些对表的 CAS 操作。只是用的比较多。 11. remove/replaceNode、&emsp;&emsp; remove 方法也是调用了 replaceNode 方法，这个方法里面就是常规思路。如果看到有节点在 transfer 就调用 helpTransfer， 由于需要操作节点需要进行同步。对树和链表进行删除操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final V replaceNode(Object key, V value, Object cv) &#123; int hash = spread(key.hashCode()); for (Node&lt;K, V&gt;[] tab = table; ; ) &#123; Node&lt;K, V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) &amp; hash)) == null) break; // 有正在移动的节点就帮助移动 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; boolean validated = false; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; // 链表节点 if (fh &gt;= 0) &#123; validated = true; for (Node&lt;K, V&gt; e = f, pred = null; ; ) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; V ev = e.val; if (cv == null || cv == ev || (ev != null &amp;&amp; cv.equals(ev))) &#123; oldVal = ev; //value不为空，则更新值 if (value != null) e.val = value; //value为空，则删除此节点 else if (pred != null) pred.next = e.next; //符合条件的节点e为头结点的情况 else setTabAt(tab, i, e.next); &#125; break; &#125; pred = e; if ((e = e.next) == null) break; &#125; // 红黑树 &#125; else if (f instanceof TreeBin) &#123; validated = true; TreeBin&lt;K, V&gt; t = (TreeBin&lt;K, V&gt;) f; TreeNode&lt;K, V&gt; r, p; if ((r = t.root) != null &amp;&amp; (p = r.findTreeNode(hash, key, null)) != null) &#123; V pv = p.val; if (cv == null || cv == pv || (pv != null &amp;&amp; cv.equals(pv))) &#123; oldVal = pv; if (value != null) p.val = value; else if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); &#125; &#125; &#125; &#125; &#125; // 进行了节点的删除 cas 更新 Count if (validated) &#123; if (oldVal != null) &#123; if (value == null) addCount(-1L, -1); return oldVal; &#125; break; &#125; &#125; &#125; return null; &#125; 12. clear清空操作也要说一下，因为不再和以前一样就直接把所有元素置为 null 等待垃圾回收。因为这里涉及到表的大小统计，以及其他的线程同时在操作表可能会导致混乱。他是一个元素下的所有节点统计一遍然后修改容器的大小，也就是他是对每一个数组下的每一个节点进行回收的。显然回收节点需要同步。当然由于涉及到了修改表如果遇到了在扩容的情况也是需要帮助数据迁移。 123456789101112131415161718192021222324252627282930313233343536public void clear() &#123; // 这个变量记录了要删除的节点数的负数 long delta = 0L; int i = 0; Node&lt;K, V&gt;[] tab = table; while (tab != null &amp;&amp; i &lt; tab.length) &#123; int fh; Node&lt;K, V&gt; f = tabAt(tab, i); // 空节点 进行下一趟 if (f == null) ++i; // 帮助移动 else if ((fh = f.hash) == MOVED) &#123; tab = helpTransfer(tab, f); i = 0; // restart // 删除节点 &#125; else &#123; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; // 如果是链表节点就返回链表头 // 如果是树节点就返回他的下一个 否则返回 null Node&lt;K, V&gt; p = (fh &gt;= 0 ? f : (f instanceof TreeBin) ? ((TreeBin&lt;K, V&gt;) f).first : null); // 遍历链表或者树 while (p != null) &#123; --delta; p = p.next; &#125; // 直接把数组对应的位置设置为 null setTabAt(tab, i++, null); &#125; &#125; &#125; &#125; if (delta != 0L) addCount(delta, -1); &#125; 13. read/writeObject&emsp;&emsp;他的序列化也是自己实现的，只存放 key 和 value，在反序列化的时候进行整个表的重建。 3.总结&emsp;&emsp; 这个类确实比较麻烦，但是整体思路确实和 HashMap 差不多，但是由于需要做到高并发，访问安全做了很多的更细节的操作，把原来 HashMap 中一步能做完的拆成好几步，并且并发度感觉比 1.7 版本的更高，因为在加锁的时候只加了一个元素，而 1.7 是加一个 Segment 的锁，锁粒度更小，并发度更高。以及在 transfer 中的任务分包真的很巧妙，加速扩容。其实写文字说明只是一个大概的流程，我对源码写了大量的注释，看完说明在看源码就会轻松很多，并且很多源码里面的细节在说明里面没有提到，所以了解大致思路后一定要仔细阅读源码。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"HashSet 源码分析","slug":"Java SourceCode/HashSet 源码分析","date":"2018-03-27T06:15:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/03/27/Java SourceCode/HashSet 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/27/Java SourceCode/HashSet 源码分析/","excerpt":"HashSet 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构1. 继承这个类简直适合 HashMap 如出一辙，他们继承的类都极其相似。继承的是 AbstractSet 。 2. 实现实现了 Set 接口，之后还有两个普遍的接口 Cloneable, java.io.Serializable 。 3. 主要字段&emsp;&emsp; 这个字段非常的少，只有一个 HashMap 和一个常量。估计你已经猜到这个容器的底层是采用HashMap 实现的了，但是具体又是怎么实现的呢？","text":"HashSet 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构1. 继承这个类简直适合 HashMap 如出一辙，他们继承的类都极其相似。继承的是 AbstractSet 。 2. 实现实现了 Set 接口，之后还有两个普遍的接口 Cloneable, java.io.Serializable 。 3. 主要字段&emsp;&emsp; 这个字段非常的少，只有一个 HashMap 和一个常量。估计你已经猜到这个容器的底层是采用HashMap 实现的了，但是具体又是怎么实现的呢？ &emsp;&emsp; 我们都知道，set 集合 是不允许有重复元素的，那么他怎么让他没有重复元素呢，答案就是把元素存放在 HashMap 的键中，因为 HashMap 的键是用来唯一区别两个 Node 节点是否相同的，而 value 就存放那个常量。 123private transient HashMap&lt;E,Object&gt; map;// Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object(); 4. 主要方法 ctor-5 add remove read/writeObject 2.主要方法分析1. 构造方法&emsp;&emsp; 这里提供了五个构造方法，其实有一个构造方法是比较特殊的，他在方法里面 new 了一个 LinkedHashMap ，也就是底层的数据结构是双链表。你可能会注意到上面我们声明的是一个 HashMap 的引用，new 的 LinkedHashMap 不会有问题吗？别忘了 后者继承了前者，并在他的基础上添加了一个双向指针。其他的四个方法其实都没什么好说的，全是调用了 HashMap 的构造，然后默认大小还是 16. 123456789101112131415161718192021222324public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;// 包内可用！ 底层采用 LinkedHashMapHashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 2. add&emsp;&emsp; 就是由于上面也提到了底层采用的 HashMap 结构，所以 add 就调用了 put 方法，然后看返回的值是不是 null 从而判断是否是重复元素。 123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 3. remove&emsp;&emsp; remove 和上面的add 一样的操作。 123public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; 4. read/writeObject&emsp;&emsp; 和其他的容器一样重写了序列化反序列化的操作。 5.其他方法&emsp;&emsp; 其他方法都是直接调用了 HashMap 的方法，所以比较简单。总共代码才三百多行，只要我们注意他的底层实现是 HashMap 就够了。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"LinkedHashSet 源码分析","slug":"Java SourceCode/LinkedHashSet 源码分析","date":"2018-03-27T05:15:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/03/27/Java SourceCode/LinkedHashSet 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/27/Java SourceCode/LinkedHashSet 源码分析/","excerpt":"LinkedHashSet 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构&emsp;&emsp; 如果你看了 HashSet 现在基本一分钟就能弄明白 LinkedHashSet 的底层原理。里面没有任何字段，只有一个序列化 id，这个我们不说。然后他继承的是 HashSet ，有没有注意到简直就和 LinkedHashMap 一个套路，然后就调用一下父类的构造方法，但是调用的父类的构造方法都是同一个，很明显肯定是那个比较特殊的构造，也就是只能在包内访问，并且比其他的方法多一个 bool 参数的那个，因为它能指定底层的数据结构是 LinkedHashMap ，这也就解释了为什么 LinkedHashSet 中的四个方法都是 public 的，而最后一个是 default。","text":"LinkedHashSet 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构&emsp;&emsp; 如果你看了 HashSet 现在基本一分钟就能弄明白 LinkedHashSet 的底层原理。里面没有任何字段，只有一个序列化 id，这个我们不说。然后他继承的是 HashSet ，有没有注意到简直就和 LinkedHashMap 一个套路，然后就调用一下父类的构造方法，但是调用的父类的构造方法都是同一个，很明显肯定是那个比较特殊的构造，也就是只能在包内访问，并且比其他的方法多一个 bool 参数的那个，因为它能指定底层的数据结构是 LinkedHashMap ，这也就解释了为什么 LinkedHashSet 中的四个方法都是 public 的，而最后一个是 default。 好的介绍完了！！！ ：）","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"LinkedHashMap 源码分析","slug":"Java SourceCode/LinkedHashMap 源码分析","date":"2018-03-26T08:15:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/03/26/Java SourceCode/LinkedHashMap 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/26/Java SourceCode/LinkedHashMap 源码分析/","excerpt":"LinkedHashMap 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构1. 实现实现的接口是 Map 2. 继承&emsp;&emsp; 继承的是 HashMap 这个就比较熟悉了，事实上我们会看到 LinkedHashMap 代码量非常的少，主要就是因为他继承的 HashMap ，继承了大多数的操作。 仔细一点的都会发现 HashMap 里面有非常多的空白方法，这些方法其实是模板方法，为了让继承 HashMap 的类重写一些自己的特性。而不破坏代码结构。","text":"LinkedHashMap 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 基本结构1. 实现实现的接口是 Map 2. 继承&emsp;&emsp; 继承的是 HashMap 这个就比较熟悉了，事实上我们会看到 LinkedHashMap 代码量非常的少，主要就是因为他继承的 HashMap ，继承了大多数的操作。 仔细一点的都会发现 HashMap 里面有非常多的空白方法，这些方法其实是模板方法，为了让继承 HashMap 的类重写一些自己的特性。而不破坏代码结构。 3. 数据域1. 基本字段&emsp;&emsp; 在 HashMap 的基础上他添加了三个字段，这三个字段都非常重要，首先就是关于双向链表的两个字段 以及决定是否进行 LRU 的标志位。 123456// 双向链表的头结点transient LinkedHashMap.Entry&lt;K,V&gt; head;// 双向链表的尾节点transient LinkedHashMap.Entry&lt;K,V&gt; tail;// 决定是否进行 LRU 算法final boolean accessOrder; 2. Entry 节点&emsp;&emsp; 可能看过前面关于 HashMap 源码分析的都清楚，里面有一个 TreeNode 节点，他继承的就是 LinkedHashMap 中的 Entry 节点。这个节点里是在 HashMap 的 Node 节点上添加了 before 和 after ,也就是用来构造双向链表的指针。 4. 重点方法概览 ctor-5 最重要的能实现 LRU 的是设置 accessOrder 的那个 afterNodeRemoval afterNodeInsertion afterNodeAccess containsValue get removeEldestEntry 2. 重要方法分析1. 构造方法&emsp;&emsp; 这个类有 5 个构造方法，一开始我以为和 HashMap 一样只有四个，后来又找到一个隐藏的比较深的方法，也是实现 LRU 最重要的一个方法。 &emsp;&emsp; 那么我们重点分析最后一个特殊的方法，前面几个方法我们都见过和 HashMap 中的差不多，就是多了一个设置 accessOrder=false 的操作。最后那个方法如果我们设置了 accessOrder=true 那么我们在访问一个元素的时候，这个元素会自动的排到双向链表的结尾。也就是所谓的 LRU。 &emsp;&emsp; 既然提到构造方法我们顺带说一下 reinitialize 方法这个方法是设置了头结点和尾节点。这些方法是在 clone 和 反序列化 的时候使用的。 123456789101112 public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder; &#125; // 初始化双链表void reinitialize() &#123; super.reinitialize(); head = tail = null; &#125; 2. afterNodeRemoval这个方法比较简单，也是模板方法，里面的主要作用就是修改一下双向链表，从而达到删除一个节点的作用。 1234567891011121314// 这个方法还 ok 就是修改一下双向指针void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b;&#125; 3. afterNodeInsertion&emsp;&emsp; 在插入节点以后，如果说我们实现的 LRU 算法是需要删除一些旧的节点时候，这个方法就会在插入节点完成之后自动删除旧节点。删除的逻辑是 removeEldestEntry 方法决定的，如果要启用删除这个方法里面做删除逻辑，并且返回 true 。这里没有任何实现！ 12345678910// 插入新的节点以后，如果说定义了删除老元素的方法，这个方法返回 true 的话就直接删除原来的旧元素 注意老元素是在头部 所以删除头部的元素即可// 在这个地方是不做人事事情的 removeEldestEntry 返回了 falsevoid afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; // 删除头部元素 K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125; 4. afterNodeAccess&emsp;&emsp; 在节点访问以后，如果说我们没有开启 LRU 算法，那没什么关系，访问了以后顺序不变，而如果accessOrder=true 那么访问的元素必须要放到双向链表的结尾。 12345678910111213141516171819202122232425// 如果accessOrder 为 true，也就是支持 LRU 算法，那么就把这个元素先从双向链表中删除（在数组中的位置不变），然后插到链表的头部作为最新的元素 void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125; &#125; 5. containsValue重写了父类的方法，主要是因为有了 双向链表的支持，遍历会更快。 12345678910// 重写了 containsValue 因为有了双链表了遍历起来更方便 public boolean containsValue(Object value) &#123; // after 指针 for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) &#123; V v = e.value; if (v == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; return false; &#125; 6. getget 方法属于访问元素，还是 LRU 的问题、 12345678910// 重写了，获取元素以后，如果用了 LRU 需要重新排列该元素的位置 public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; // 重新排列该元素位置 if (accessOrder) afterNodeAccess(e); return e.value; &#125; 7. removeEldestEntry空实现。 123456// 这个方法是用来被覆盖的，也就是子类来用，本类用不着。// 如果有必要，则删除掉该近期最少使用的节点，// 这要看对removeEldestEntry的覆写,由于默认为false，因此默认是不做任何处理的。protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 3. 总结其实在理解这个容器的时候我们就把他当做 HashMap 加上一个无关的双向指针即可。 然后注意一下他的 LRU 算法的利用！","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"HashMap 源码分析","slug":"Java SourceCode/HashMap 源码分析","date":"2018-03-26T08:15:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/03/26/Java SourceCode/HashMap 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/26/Java SourceCode/HashMap 源码分析/","excerpt":"HashMap 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1.结构1. 继承&emsp;&emsp;该类继承自 AbstractMap 这个类似于 ArrayList 2. 实现具体如下： 首先这个类是一个 Map 自然有 Map 接口 然后就是两个集合框架肯定会实现的两个接口 Cloneable, Serializable 。","text":"HashMap 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1.结构1. 继承&emsp;&emsp;该类继承自 AbstractMap 这个类似于 ArrayList 2. 实现具体如下： 首先这个类是一个 Map 自然有 Map 接口 然后就是两个集合框架肯定会实现的两个接口 Cloneable, Serializable 。 3. 主要字段1. 属性字段12345678910111213141516// 默认大小 16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 最大容量 2^30 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 负载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 链表转成树，链表的长度 8 static final int TREEIFY_THRESHOLD = 8; // 树转成链表时树大节点数 6 static final int UNTREEIFY_THRESHOLD = 6; // Node 数组 transient Node&lt;K,V&gt;[] table; // 大小 transient int size; // 阈值 他等于容量乘以负载因子 int threshold; 2. Node​&emsp;&emsp; 这个其实就是在 JDK1.7 中我们常说的 Entry ，但是在 Java8 把 Entry 更进一步抽象了，放到了 Map 接口里面，那里面的内部接口。里面并没有定义任何的字段，只有一些公共的方法。 ​&emsp;&emsp; 然后这个 Node 是实现了 Entry 接口，里面定义了四个属性，这几个属性也就是 HashMap 的关键了，分别就是 hash 、key、value 、next 。下面具体的看下代码。 123456static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; &#125; 3. TreeNode&emsp;&emsp; TreeNode 着很明显，我们在上面的属性字段提到了关于链表转成树的操作，那么我们就需要把 Node 节点包装成 TreeNode 。这里有一个比较有意思的事情就是这个 TreeNode 是继承自 LinkedHashMap 的 Entry 但是他又继承自 HashMap 的 Node ，而 那个 Entery 在 Node 基础上添加了属性就是 before 和 after 。有点绕，那么简单来说就是 TreeNode 在 Node 里面添加了 before 、after 还有其他的红黑树的信息。来具体看一下结构。 12345678static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; //before after inhert from Entry&#125; 4. 主要方法概览 cotr-4 put/putVal resize putAll/putMapEntries get/getNode/containsKey remove/removeNode/clear containsValue read/writeObject 2. 主要方法分析###1. cotr-4 &emsp;&emsp; 首先介绍一下构造方法，这里我们会看到四个构造方法，他们在里面做的事情都差不多，主要是设置容器的 容量 和阈值 。其中在上面的字段中我们看到了一些常量，其中就有说明初始大小就是 16 ，然后负载因子是 0.75 ，还有提到最大容量 2^30 。 &emsp;&emsp; 在进行数组大小设置的时候有一个比较有意思的方法，tableSizeFor(int size) 这个方法能够保证最后返回出来的值是一个比 size 大的最小的 2^n 这样一个数。这样说可能有点不好理解，举个例子吧。 假如我们传入一个 18 那么返回的就是 32 ，因为 32 是 2 的 n 次方 这类的数，然后他是最接近 18 的 2 的 n 次方 。 &emsp;&emsp; 然后你可能会发现为什么没有初始化 Node 数组， 这是因为在 jdk1.8 里面 HashMap 的实现他的空间是延时分配的，也就是在我们真正往里面 put 值的时候才会真的创建 Node数组 ，这个到我们分析 put方法 的时候我们会看到这一机制。 ​ 12345678910111213141516171819202122232425262728293031// 设置负载因子和初始大小 public HashMap(int initialCapacity, float loadFactor) &#123; // 参数判断 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; // 这个方法就是把一个不是 2 的次幂的数转换成一个大于当前数的最小的 2 的次幂的数 this.threshold = tableSizeFor(initialCapacity); &#125; // 大小设置一下，负载因子默认 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; // 设置负载因子为默认的 0.75 public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; // putMapEntries 这个方法就是 new 新数组然后 foreach 拷贝 public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; ​ 2. put/putVal ​ put 方法是今天的重头戏，因为大部分的代码其实都集中在这里，put 方法直接调用了 putVal 这个方法里面就进行了真正的存放元素的操作。 ​ 我先大概说一下 putVal 的逻辑，然后再看代码就不会那么头疼了。 一开始判断当前的 Node 数组 是否是空，如果是空则进行初始化，也就是分配空间（这里就是啊前面提到的延时分配空间） 接着需要计算这个插入的值在数组中的位置，计算的方法就是 hash % capacity ，但是你可能看到的代码不是这样而是采用的 hash &amp; (capacity-1) ，但是他们是等价的！！！不过这个等价是有条件的，那就是 capacity 的值必须是 2 ^ n 。所以你现在可能理解为什么 HashMap 的大小一直需要为 2 ^ n 以及 tableSizeFor 的作用。这个等价是可以证明的，比较简单不再赘述。 找到需要插入元素的位置以后，如果说这个位置没有元素那好，我们直接把这个元素插入即可。 但是如果这个地方的元素并不是空的，那么我们要么就是插入了完全一样的 key 要么就是 key 不一样但是 hash 函数发生了冲突。 如果是完全一样的 key 那我们就用新的 value 替换掉原来的 value 返回老值即可。 但是如果是发生了 hash 冲突我们就需要解决冲突。在 jdk1.8 里面采用的解决冲突的方法就是在这个节点上生成一个链表或红黑树。至于具体生成哪种据坎节点的数量了，节点数量少链表就很快多了的话我们肯定采用平衡二叉树（红黑树）。这个分水岭的节点数是 8 ，在上面的数据域可以看到他是一个常量。 对红黑树直接调用红黑树的 putTreeVal 方法插入，而链表的话我们直接插入到链表的尾部即可。对链表插入完成以后需要检测一下是不是需要转成红黑树。 最后进行一下扩容判断，毕竟有新的节点加入。 ​ 以上就是 putVal 的全部过程， 其中有一个扩容操作没有说，一会会单独讲这个方法。下面看看这个方法的源码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125;// 第三个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作// 第四个参数 evict 我们这里不关心 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 第一次 put 值的时候，会触发下面的 resize()。这是因为我们调用了默认的无参的构造方法导致的，无参的里面只设置了负载因子 // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 找到具体的数组下标，如果此位置没有值，那么直接初始化一下 Node 并放置在这个位置就可以了 // 这个地方采用的 (n - 1) &amp; hash 来寻找数组的下标，他和 hash%n 的效果一样的 但是仅仅限制在 n 是 2 的次幂 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null);//newNode 方法不用看 就直接 new else &#123;// 数组该位置有数据 Node&lt;K,V&gt; e; K k; // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是\"相等\"，如果是，把这个节点放到 e 里面 // 最后还有一个判断 e 是不是 null 然后对这个节点的 value 进行替换也就是说，如果 key 一样的话直接替换 vaule key 不一样说明是碰撞 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 下面两种情况都是碰撞处理 // 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 数组该位置上是一个链表 else &#123; // 循环找链表的最后一个节点 for (int binCount = 0; ; ++binCount) &#123; // 找到尾部就插入尾部 (Java7 是插入到链表的最前面) if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 9 个，会触发下面的 treeifyBin，也就是将链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 不可能发生，所以直接 break 了 ，这个条件在前面就过滤掉了，也就是 key 相同的情况应该进行 value 的替换 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // e!=null 说明存在旧值的key与要插入的key\"相等\"，不是碰撞情况而是一致的 key 需替换返回老值 if (e != null) &#123; V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); //这个操作是空操作 模板设计模式 是给 LinkedHashMap 使用的 return oldValue; &#125; &#125; ++modCount; // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); // 同 afterNodeAccess return null; &#125; 3. resize​ 扩容方法也有点复杂，方法体有点长，没关系我们慢慢分析，先了解思路在看源码。 虽然这个方法是扩容方法，但是他也承担着初始化的任务。前面我们提到在 putVal方法 中有为 Node 数组 分配空间的事情，但是这个分配空间是委托给了 这个方法进行的。 所以开始确认当前是分配空间还是在扩容，如果是扩容我们要判断当前的容量是不是已经到达极限了也就是最大容量 2^3 ，如果大于等于这个值我们不进行扩容把阈值设置为最大的整数，防止下次再进行扩容操作。否则的话我们正常扩容把容量调整为原来的二倍，这样做的原因很明显容量要是 2 ^ n 。 接下来我们就可以 new 一个新数组了，当然如果是这个操作是初始化那么我们的工作就完成了，但是如果是扩容操作我们还需要把原来的数组中的元素迁移到新的数组中。 接下来的操作就是数据迁移工作。迁移就是遍历原来的数组，然后如果这个位置只有一个元素那直接迁移，如果不是的话就只能是红黑树或者单链表了。 遇到红黑树我们就调用红黑树的迁移方法，单链表就把原来的链表拆成两部分。挂在新的数组的位置，拆分的方法也很巧妙源码中会看到。 &emsp;&emsp; 所以流程大概清楚了就看源码，源码注释的比较清楚。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102final Node&lt;K,V&gt;[] resize() &#123; //前面这一大堆都是关于计算扩容的操作 不管他 Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 对应数组扩容 if (oldCap &gt; 0) &#123; //到极限了不扩容 修改阈值防止下一次又进入扩容操作 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 将数组大小扩大一倍 将阈值扩大一倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 对应使用两个有参的构造方法初始化后，第一次 put 的时候 也就是说 HashMap 在初始化的时候没有分配数组，空间是延时分配的 else if (oldThr &gt; 0) newCap = oldThr; // 对应使用 new HashMap() 初始化后，第一次 put 的时候 else &#123; newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; // 用新的数组大小初始化新的数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; // 如果是初始化数组，到这里就结束了，返回 newTab 即可 接下来的操作就是数据迁移 table = newTab; if (oldTab != null) &#123; // 开始遍历原数组，进行数据迁移。 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; // 如果该数组位置上只有单个元素，那就简单了，简单迁移这个元素就可以了 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 如果是红黑树，就进行分裂操作 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 链表的话就要把这些数据迁移到对应的位置 ，注意不是直接把整个链表放到数组的新位置 而是拆成两个链表 else &#123; // 这块是处理链表的情况，需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序 // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表，代码还是比较简单的 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; //一条链表拆成两条 do &#123; next = e.next; //这里就是用了一个条件拆分成了两条链表 //他代码这样写的原因在于：oldCap 是一个2的次幂，那么也就是说 他是形如 \"100000000...000\" 这个格式的 //那么任何一个数和他相与必然只有两种结果 0 / 非0 就看最高位，其他位出来肯定是0 这样就区分了两个链表 巧妙！ if ((e.hash &amp; oldCap) == 0) &#123; //这里面的逻辑其实就是链表按照原来的顺序连接 也就是说原来 a 在 c 前面只要 ac 在同一条链表上 a 就在 c 前面 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; // 同上 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //用来把两条链表分别挂在正确的数组位置 if (loTail != null) &#123; loTail.next = null; // 第一条链表新位置就是原来的位置 newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; // 第二条链表的新的位置是 j + oldCap，这个很好理解 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 4. putAll/putMapEntries&emsp;&emsp; 前面分析完比较困难的 putVal 和 resize 方法后接下来的方法都很轻松了。 &emsp;&emsp; 这个 putAll 方法调用了 putMapEntries ，在构造函数中也调用了这个方法的。其具体的就是 foreach 拷贝元素。 5. get/getNode/containsKey​ 这几个方法底层调用的都是 getNode 方法，它的原理就是判断第一个元素是不是，然后看是红黑树还是单链表再遍历得到结果。 12345678910111213141516171819202122232425262728293031public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断第一个节点是不是就是需要的。 // 至于为什么要判断第一个元素我认为可能是作者觉得虽然说我们可能会碰到冲突，但是元素不多的情况下真的不会冲突. //也就是最理想的情况就是一个元素。 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; // 判断是否是红黑树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 链表遍历 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 5. remove/removeNode/clear这几个方法也很简单，remove 就是底层依赖的 removeNode 就是先遍历找到对应的节点，然后在遍历去删除。 ​ clear 方法和前面介绍的 ArrayList 一样就是把数组元素设置为 null 让他去 gc 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //首先 hash 对应的位置是有东西的 否则直接返回 null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //这个 if else 是用来寻找那个要删除的节点的 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //这个 if 是用来删除上面找到的那个节点 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125;public void clear() &#123; Node&lt;K,V&gt;[] tab; modCount++; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; size = 0; for (int i = 0; i &lt; tab.length; ++i) tab[i] = null; &#125; &#125; 6. containsValue​ 这个方法还是采用遍历的方法，他没有区分是树还是链表统一的采用了 next 指针，这是因为 key 是作为红黑树的索引条件但是 value 并不是，并且在 TreeNode 中是有 next 的因为他间接继承了 Node。 12345678910111213public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false; &#125; 7. read/writeObject​ 最后还是序列化的问题，Node数组 并没有采用默认的序列化可以看到他加了 transient 关键字。这里手动序列化只是序列化了 key value 其他的一概不存储。原因还是节省空间。 123456789101112131415161718192021private void writeObject(java.io.ObjectOutputStream s) throws IOException &#123; int buckets = capacity(); // Write out the threshold, loadfactor, and any hidden stuff s.defaultWriteObject(); s.writeInt(buckets); s.writeInt(size); internalWriteEntries(s); &#125; void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException &#123; Node&lt;K,V&gt;[] tab; if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; s.writeObject(e.key); s.writeObject(e.value); &#125; &#125; &#125; &#125; 3. Hashtable​ &emsp;&emsp; 就像是 ArrayList 和 Vector 一样我们需要讨论一下 Hashtable 和 HashMap 之间的异同。 继承结构他们的实现接口一致，继承的类却不同，Hashtable 继承的是 Dictionary 里面采用的结构是 Entry 数组 ,没有采用延时空间分配，默认大小是 11 ，容量也不是 2^n 扩容是 2n+1 的增长 。他的扩容叫做 rehash ,但是注意在扩容的时候把元素的位置颠倒了，也就是链表反插。 迭代接口含有比较古老的 Enumeration 123456789101112131415161718192021222324252627282930protected void rehash() &#123; int oldCapacity = table.length; Entry&lt;?,?&gt;[] oldMap = table; // overflow-conscious code int newCapacity = (oldCapacity &lt;&lt; 1) + 1; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) &#123; if (oldCapacity == MAX_ARRAY_SIZE) // Keep running with MAX_ARRAY_SIZE buckets return; newCapacity = MAX_ARRAY_SIZE; &#125; Entry&lt;?,?&gt;[] newMap = new Entry&lt;?,?&gt;[newCapacity]; modCount++; threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); table = newMap; for (int i = oldCapacity ; i-- &gt; 0 ;) &#123; // 倒序插入到新的数组中，也就是老链表从头到尾遍历的节点头插到新的链表的头。 for (Entry&lt;K,V&gt; old = (Entry&lt;K,V&gt;)oldMap[i] ; old != null ; ) &#123; Entry&lt;K,V&gt; e = old; old = old.next; int index = (e.hash &amp; 0x7FFFFFFF) % newCapacity; e.next = (Entry&lt;K,V&gt;)newMap[index]; newMap[index] = e; &#125; &#125; &#125; 确定数组的下标采用的直接 (hash &amp; 0x7FFFFFFF) % tab.length ，并且在计算 hash 的时候是直接采用了 key.hashCode() 而在 HashMap 中还使用了扰动计算用来降低冲突的概率。 简单来说就是结合高低位来降低 Hash冲突 123h ^= k.hashCode();h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); 不允许 null 的键值，他在源码中的做法就是先判断 value 是不是 null ，如果是直接抛异常。至于为什么没有判断 key 这是由于一会我们进行 put 操作的时候自然会调用 key.hashCode() 异常妥妥的抛出来了。 123456789101112131415161718192021222324252627282930public synchronized V put(K key, V value) &#123; // Make sure the value is not null if (value == null) &#123; throw new NullPointerException(); &#125; // Makes sure the key is not already in the hashtable. Entry&lt;?,?&gt; tab[] = table; int hash = key.hashCode(); /* 关键在于一个对象的 HashCode可以为负数，这样操作后可以保证它为一个正整数 0x7FFFFFFF is 0111 1111 1111 1111 1111 1111 1111 1111 (hash &amp; 0x7FFFFFFF) 将会得到一个正整数 因为hash是要作为数组的index的，这样可以避免出现下标为负数而出现异常 */ int index = (hash &amp; 0x7FFFFFFF) % tab.length; @SuppressWarnings(\"unchecked\") Entry&lt;K,V&gt; entry = (Entry&lt;K,V&gt;)tab[index]; for(; entry != null ; entry = entry.next) &#123; if ((entry.hash == hash) &amp;&amp; entry.key.equals(key)) &#123; V old = entry.value; entry.value = value; return old; &#125; &#125; addEntry(hash, key, value, index); return null; &#125; 扩容迁移采用链表倒序插入，只有链表没有红黑树。 全部的方法都是 synchronized 的方法。 &emsp;&emsp; 关于为什么 &amp;0x7ffffffff 这里提一下，关键在于一个对象的 HashCode可以为负数，这样操作后可以保证它为一个正整数0x7FFFFFFF is 0111 1111 1111 1111 1111 1111 1111 1111(hash &amp; 0x7FFFFFFF) 将会得到一个正整数。因为hash是要作为数组的index的，这样可以避免出现下标为负数而出现异常。 12","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"LinkedList 源码分析","slug":"Java SourceCode/LinkedList 源码分析","date":"2018-03-26T07:15:02.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2018/03/26/Java SourceCode/LinkedList 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/26/Java SourceCode/LinkedList 源码分析/","excerpt":"LinkedList 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1.结构1. 继承&emsp;&emsp;该类继承自 AbstractSequentialList 这个是由于他是一个顺序的列表，所以说继承的是一个顺序的 List 2. 实现这个类实现的接口比较多，具体如下： 首先这个类是一个 List 自然有 List 接口 然后由于这个类是实现了 Deque 这个接口是双端队列的接口，所以说它是具有双端队列的特性的。后面我们会看到很多关于双端队列的方法。 然后就是两个集合框架肯定会实现的两个接口 Cloneable, Serializable 。","text":"LinkedList 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1.结构1. 继承&emsp;&emsp;该类继承自 AbstractSequentialList 这个是由于他是一个顺序的列表，所以说继承的是一个顺序的 List 2. 实现这个类实现的接口比较多，具体如下： 首先这个类是一个 List 自然有 List 接口 然后由于这个类是实现了 Deque 这个接口是双端队列的接口，所以说它是具有双端队列的特性的。后面我们会看到很多关于双端队列的方法。 然后就是两个集合框架肯定会实现的两个接口 Cloneable, Serializable 。 3. 主要字段1. 属性字段1234transient int size = 0;//指向链表的头指针和尾指针transient Node&lt;E&gt; first;transient Node&lt;E&gt; last; 2. Node 节点Node 节点是主要存放数据的地方这个节点数据结构也比较简单就是一个泛型加上前驱后继指针。也就是一个双向链表。 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 4. 主要方法概览 ctor-2 addFirst addLast addAll add indexOf lastIndexOf peek 获取第一个元素，是 null 就返回 null peekFirst/Last 获取第一个最后一个元素 poll 删除第一个元素并返回 没有返回 null pollFirst/Last offer 调用了 add offerFirst/Last push pop set remove(noArgs) == removeFirst 继承自 deque remove(E e) 查找删除 read/writeObject 还是手动的序列化，原因一样，直接序列化元素而没有 pre/next 2. 构造方法分析只有两个构造方法。其中一个是默认的空构造也就是生成一个空的 LinkedList 另外一个就是接受一个 Collection 接口。里面调用了 PutAll 方法。 1234567public LinkedList() &#123;&#125;public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; 3. 主要方法分析1. add这个方法就直接调用了 linkLast 而 linkLast 里面就是直接把元素添加到元素的结尾。 12345678910111213141516 public boolean add(E e) &#123; linkLast(e); return true;&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; 2. addFrist/Last这两个方法同上还是调用了 linkFirst 和 linkLast 所以说这几个添加修改的方法基本都是靠底层的同样的方法实现的。 1234567public void addFirst(E e) &#123; linkFirst(e);&#125;public void addLast(E e) &#123; linkLast(e);&#125; 3. addAll 该方法我们在构造方法中也看到了，在它里面实现的时候和 ArrayList 一样是直接把集合转成数组，然后进行创建新的节点插入进来。 1234567891011121314151617181920212223242526272829303132333435363738public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; Node&lt;E&gt; pred, succ; if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings(\"unchecked\") E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true; &#125; 4. indexOf这个方法里面采用 for 循环遍历，遍历的时候是从头结点开始遍历，只要找到那个元素立即返回，而不继续进行下去。 1234567891011121314151617public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1; &#125; 5. lastIndexOf这个方法和上面的方法实现的方式一样的，但是注意这个方法的意思是找到最后一个与之匹配的元素，他并不是从头开始找，而是直接从尾节点开始遍历。做法同理找到即停止。 6. peek/peekFirst/peekLastpeek 方法的意思就是返回最顶端的元素，如果这个元素不存在，那么直接返回 null 。之后还有 peekFirst 这类的就是返回第一个的意思。底层调用的就是头结点的属性。这些方法其实在 Collection 接口中是不存在的，主要就是因为他实现了 Deque 所带来的的新特性。 7. poll/pollFirst/pollLastpoll 用来删除头结点并返回，如果不存在就返回 null剩下的两个方法同理。 8. offer/offerFirst/offerLast插入头结点。 9. push/pop底层的方法就是 addFirst 和 removeFirst 10. remove(noargs)/remove(E e)无参的调用 removeFirst 有参数的就是去查找然后删除。 11. read/writeObject这里同 ArrayList 自己手动的进行了序列化。序列化的时候只是对 Node 节点里面的元素进行序列化，而前驱后继直接省略，也是节约空间的想法。 4.总结好，其实在完全理解 ArrayList 的基础之上看这篇文章就比较好理解，里面的操作更加简单。只是注意一下两者的区别，实现了 Deque 带来的不少新的方法。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"ArrayList 源码分析","slug":"Java SourceCode/ArrayList 源码分析","date":"2018-03-25T13:15:02.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2018/03/25/Java SourceCode/ArrayList 源码分析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/25/Java SourceCode/ArrayList 源码分析/","excerpt":"ArrayList 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 结构&emsp;&emsp;首先我们需要对 ArrayList 有一个大致的了解就从结构来看看吧. 1. 继承&emsp;&emsp;该类继承自 AbstractList 这个比较好说 2. 实现这个类实现的接口比较多，具体如下： 首先这个类是一个 List 自然有 List 接口 然后由于这个类需要进行随机访问，所谓随机访问就是用下标任一访问，所以实现了RandomAccess 然后就是两个集合框架肯定会实现的两个接口 Cloneable, Serializable 前面这个好说序列化一会我们具体再说说","text":"ArrayList 源码分析 1. 在阅读源码时做了大量的注释，并且做了一些测试分析源码内的执行流程，由于博客篇幅有限，并且代码阅读起来没有 IDE 方便，所以在 github 上提供JDK1.8 的源码、详细的注释及测试用例。欢迎大家 star、fork ！2. 由于个人水平有限，对源码的分析理解可能存在偏差或不透彻的地方还请大家在评论区指出，谢谢！ 1. 结构&emsp;&emsp;首先我们需要对 ArrayList 有一个大致的了解就从结构来看看吧. 1. 继承&emsp;&emsp;该类继承自 AbstractList 这个比较好说 2. 实现这个类实现的接口比较多，具体如下： 首先这个类是一个 List 自然有 List 接口 然后由于这个类需要进行随机访问，所谓随机访问就是用下标任一访问，所以实现了RandomAccess 然后就是两个集合框架肯定会实现的两个接口 Cloneable, Serializable 前面这个好说序列化一会我们具体再说说 3. 主要字段12345678910// 默认大小为10private static final int DEFAULT_CAPACITY = 10;// 空数组 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;// 默认的空数组 这个是在传入无参的是构造函数会调用的待会再 add 方法中会看到private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;// 用来存放 ArrayList 中的元素 注意他的修饰符是一个 transient 也就是不会自动序列化transient Object[] elementData; // 大小private int size; 4. 主要方法下面的方法后面标有数字的就是表示重载方法 ctor-3 get set add-2 remove-2 clear addAll write/readObject fast-fail 机制 subList iterator forEach sort removeIf 2. 构造方法分析1. 无参的构造方法&emsp;&emsp; 里面只有一个操作就是把 elementData 设置为 DEFAULTCAPACITY_EMPTY_ELEMENTDATA 这个空数组。 1234// 无参的构造函数，传入一个空数组 这时候会创建一个大小为10的数组，具体操作在 add 中 public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; 2. 传入数组大小的构造&emsp;&emsp; 这个就是 new 一个数组，如果数组大小为0就 赋值为 EMPTY_ELEMENTDATA 1234567891011// 按传入的参数创建新的底层数组 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125; &#125; 3. 传入 Collection 接口&emsp;&emsp; 在这个方法里面主要就是把这个 Collection 转成一个数组，然后把这个数组 copy 一下，如果这个接口的 size 为0 和上面那个方法一样传入 EMPTY_ELEMENTDATA 1234567891011121314public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) // 上面的注释的意思是说 jdk 有一个 bug 具体来说就是一个 Object 类型的数组不一定能够存放 Object类型的对象，有可能抛异常 // 主要是因为 Object 类型的数组可能指向的是他的子类的数组，存 Object 类型的东西会报错 if (elementData.getClass() != Object[].class) // 这个操作是首先new 了新的数组，然后再调用 System.arraycopy 拷贝值。也就是产生新的数组 elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // 传入的是空的就直接使用空数组初始化 this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; &emsp;&emsp; 但是注意一点这里有一个 jdk 的 bug 也就是一个 Object 类型的数组不一定能够存放 Object类型的对象，有可能抛异常，主要是因为 Object 类型的数组可能指向的是他的子类的数组，存 Object 类型的东西会报错。 为了测试这个 bug 写了几行代码测试一下。这个测试是通不过的，就是存在上面的原因。 &emsp;&emsp; 一个典型的例子就是 我们创建一个 string 类型的 list 然后调用 toArray 方法发现返回的是一个 string[] 这时候自然就不能随便存放元素了。 123456789101112131415class A&#123;&#125;class B extends A &#123;&#125;public class JDKBug &#123; @Test public void test1() &#123; B[] arrB = new B[10]; A[] arrA = arrB; arrA[0]=new A(); &#125;&#125; 3. 修改方法分析1. Set 方法&emsp;&emsp; 这个方法也很简单 ，首先进行范围判断，然后就是直接更新下标即可。 12345678// 也没啥好说的就是，设置新值返回老值public E set(int index, E element) &#123; rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue;&#125; 2. Add(E e) 方法&emsp;&emsp;这个方法首先调用了 ensureCapacityInternal() 这个方法里面就判断了当前的 elementData 是否等于 DEFAULTCAPACITY_EMPTY_ELEMENTDATA 如果是的话，就把数组的大小设置为 10 然后进行扩容操作,这里刚好解释了为什么采用无参构造的List 的大小是 10 ，这里扩容操作调用的方法是 ensureExplicitCapacity 里面就干了一件事如果用户指定的大小 大于当前长度就扩容，扩容的方法采用了 Arrays.copy 方法，这个方法实现原理是 new 出一个新的数组，然后调用 System.arraycopy 拷贝数组，最后返回新的数组。 12345678910111213141516171819202122232425262728293031323334353637public boolean add(E e) &#123; // 当调用了无参构造，设置大小为10 ensureCapacityInternal(size + 1); // Increments modCount elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; // 如果当前数组是默认空数组就设置为 10和 size+1中的最小值 // 这也就是说为什么说无参构造 new 的数组大小是 10 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 若用户指定的最小容量 &gt; 最小扩充容量，则以用户指定的为准，否则还是 10 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 1.5倍增长 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; 3. Add(int index, E e) 方法&emsp;&emsp; 这个方法比较简单和上面基本一样，然后只是最后放元素的时候的操作不一样，他是采用了 System.arraycopy 从自己向自己拷贝，目的就在于覆盖元素。 注意一个规律这里面只要涉及下标的操作的很多不是自己手写 for 循环而是采用类似的拷贝覆盖的方法。算是一个小技巧。 123456789public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount // 覆盖 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125; 4. remove(int index)&emsp;&emsp;同理这里面还是用了拷贝覆盖的技巧。 但是有一点注意的就是不用的节点需要手动的触发 gc ，这也是在 Efftive Java 中作者举的一个例子。 123456789101112public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; //覆盖 if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; &#125; 5. remove(E e)&emsp;&emsp; 这个方法操作很显然会判断 e 是不是 null 如果是 null 的话直接采用 == 比较，否则的话就直接调用 equals 方法然后执行拷贝覆盖。 123456789101112131415161718public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; // 覆盖 fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) // 调用 equals 方法 if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; 6. clear()&emsp;&emsp; 这个方法就干了一件事，把数组中的引用全都设置为 null 以便 gc 。而不是仅仅把 size 设置为 0 。 1234567891011121314151617181920212223// gc 所有节点 public void clear() &#123; modCount++; // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0; &#125;``` ### 7. addAll(Collection e)&amp;emsp;&amp;emsp; 这个没啥好说的就是，采用转数组然后 copy```java // 一个套路 只要涉及到 Collection接口的方法都是把这个接口转成一个数组然后对数组操作 public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; 4. 访问方法分析1. get&emsp;&emsp; 直接访问数组下标。 12345// 没啥好说的直接去找数组下标public E get(int index) &#123; rangeCheck(index); return elementData(index);&#125; 2. subList&emsp;&emsp; 这个方法的实现比较有意思，他不是直接截取一个新的 List 返回，而是在这个类的内部还有一个 subList 的内部类，然后这个类就记录了 subList 的开始结束下标，然后返回的是这个 subList 对象。你可能会想返回的 subList 他不是 List 不会有问题吗，这里这个 subList 是继承的 AbstractList 所以还是正确的。 123456789101112public List&lt;E&gt; subList(int fromIndex, int toIndex) &#123; subListRangeCheck(fromIndex, toIndex, size); return new SubList(this, 0, fromIndex, toIndex); &#125; // subList 返回的是一个位置标记实例，就是在原来的数组上放了一些标志，没有修改或者拷贝新的空间private class SubList extends AbstractList&lt;E&gt; implements RandomAccess &#123; private final AbstractList&lt;E&gt; parent; private final int parentOffset; private final int offset; int size; // other functions ..... &#125; 5. 其他功能方法1. write/readObject&emsp;&emsp;前面在介绍数据域的时候我就有标注 elementData 是一个 transition 的变量也就是在自动序列化的时候会忽略这个字段。 &emsp;&emsp; 然后我们又在源码中找到到了 write/readObject 方法，这两个方法是用来序列化 elementData 中的每一个元素，也就是手动的对这个字段进行序列化和反序列化。这不是多此一举吗？ &emsp;&emsp; 既然要将ArrayList的字段序列化（即将elementData序列化），那为什么又要用transient修饰elementData呢？ &emsp;&emsp; 回想ArrayList的自动扩容机制，elementData数组相当于容器，当容器不足时就会再扩充容量，但是容器的容量往往都是大于或者等于ArrayList所存元素的个数。 &emsp;&emsp; 比如，现在实际有了8个元素，那么elementData数组的容量可能是8x1.5=12，如果直接序列化elementData数组，那么就会浪费4个元素的空间，特别是当元素个数非常多时，这种浪费是非常不合算的。 &emsp;&emsp; 所以ArrayList的设计者将elementData设计为transient，然后在writeObject方法中手动将其序列化，并且只序列化了实际存储的那些元素，而不是整个数组。 123456789101112131415private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; 2. fast-fail&emsp;&emsp; 所谓的 fast-fail 就是在我们进行 iterator 遍历的时候不允许调用 Collection 接口的方法进行对容器修改，否则就会抛异常。这个实现的机制是在 iterator 中维护了两个变量，分别是 modCount 和 expectedModCount 由于 Collection 接口的方法在每次修改操作的时候都会对 modCount++ 所以如果在 iterator 中检测到他们不相等的时候就抛异常。 12345678910private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; 3. forEach&emsp;&emsp; 这个是一个函数式编程的方法，看看他的参数 forEach(Consumer&lt;? super E&gt; action) 很有意思里面接受是一个函数式的接口，我们里面回调了 Consumer 的 accept 所以我们只需要传入一个函数接口就能对每一个元素处理。 123456789101112131415@Overridepublic void forEach(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); final int expectedModCount = modCount; @SuppressWarnings(\"unchecked\") final E[] elementData = (E[]) this.elementData; final int size = this.size; for (int i=0; modCount == expectedModCount &amp;&amp; i &lt; size; i++) &#123; //回调 action.accept(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125; 写了一段测试代码，但是这个方法不常用，主要是 Collection 是可以自己生成 Stream 对象，然后调用上面的方法即可。这里提一下。 123456789101112public class ArrayListTest &#123; @Test public void foreach() &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(2); list.add(1); list.add(4); list.add(6); list.forEach(System.out::print); //打印每一次元素。 &#125;&#125; 4. sort底层调用了 Arrays.sort 方法没什么好说的。 12345678public void sort(Comparator&lt;? super E&gt; c) &#123; final int expectedModCount = modCount; Arrays.sort((E[]) elementData, 0, size, c); if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; modCount++; &#125; 5. removeIf&emsp;&emsp; 这个和 forEach 差不多，就是回调写好了。 6. Vector以上基本是把 ArrayList 的重要的方法和属性介绍完了，我们已经比较清楚他底层的实现和数据结构了。然后提到 ArrayList 自然也少不了一个比较古老的容器 Vector 这个容器真的和 ArrayList 太像了。因为你会发现他们连继承和实现的接口都是一样的。但是也会有一些不同的地方，下面分条介绍一下。 在 Vector 中基本所有的方法都是 synchronized 的方法，所以说他是线程安全的 ArrayList 构造方法不一样，在属性中没有两个比较特殊的常量，所以说他的构造方法直接初始化一个容量为 10 的数组。然后他有四个构造方法。 遍历的接口不一样。他还是有 iterator 的但是他以前的遍历的方法是 Enumeration 接口，通过 elements 获取 Enumeration 然后使用 hasMoreElements 和 nextElement 获取元素。 缺少一些函数式编程的方法。","categories":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/categories/JDK-源码分析/"}],"tags":[{"name":"JDK 源码分析","slug":"JDK-源码分析","permalink":"http://lwenxu.coding.me/tags/JDK-源码分析/"}]},{"title":"P2P 浅析","slug":"NetWork/P2P 浅析","date":"2018-03-25T01:40:24.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/03/25/NetWork/P2P 浅析/","link":"","permalink":"http://lwenxu.coding.me/2018/03/25/NetWork/P2P 浅析/","excerpt":"P2P 浅析&emsp;&emsp; 对等网络(P2P)技术,是在传统的客户机和服务器模式来说的一种方式。在C/S模式中，数据的分发采用专门的服务器，多个客户端都从此服务器获取数据。这种模式的优点是：数据的一致性容易控制，系统也容易管理。但是此种模式的缺点是：因为服务器的个数只有一个(即便有多个也非常有限)，系统容易出现单一失效点；单一服务器面对众多的客户端，由于CPU能力、内存大小、网络带宽的限制，可同时服务的客户端非常有限，可扩展性差。","text":"P2P 浅析&emsp;&emsp; 对等网络(P2P)技术,是在传统的客户机和服务器模式来说的一种方式。在C/S模式中，数据的分发采用专门的服务器，多个客户端都从此服务器获取数据。这种模式的优点是：数据的一致性容易控制，系统也容易管理。但是此种模式的缺点是：因为服务器的个数只有一个(即便有多个也非常有限)，系统容易出现单一失效点；单一服务器面对众多的客户端，由于CPU能力、内存大小、网络带宽的限制，可同时服务的客户端非常有限，可扩展性差。 &emsp;&emsp; P2P技术正是为了解决这些问题而提出来的一种对等网络结构。在P2P网络中，每个节点既可以从其他节点得到服务，也可以向其他节点提供服务,他是一种是一种无中心服务器的对等网络泛型。这样，庞大的终端资源被利用起来，一举解决了C/S模式中的两个弊端。 &emsp;&emsp; 但是一说到 P2P 肯定哟啊说关于 NAT 穿透的问题，因为这是干扰 P2P 最重要的一个因素。 待续。。 1. NAT 类型2. STUN 鉴别 NAT 类型3. P2P 结构4. BitTorrent 基本原理5. DHT 基本原理","categories":[{"name":"-计算机网络","slug":"计算机网络","permalink":"http://lwenxu.coding.me/categories/计算机网络/"}],"tags":[]},{"title":"TCP 总结","slug":"NetWork/TCP 详解","date":"2018-03-25T01:40:24.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/03/25/NetWork/TCP 详解/","link":"","permalink":"http://lwenxu.coding.me/2018/03/25/NetWork/TCP 详解/","excerpt":"TCP 总结 计算机网络中比较中要的无非就是 TCP/IP 协议栈，以及应用层的 HTTP 和 HTTPS 。前几天一直炒的的比较火的就是 HTTP/2.0 了，但是其实 HTTP/2.0 早在2015年的时候就已经出来了，并且这个版本是基于 Google 公司的 SPDY 协议发布的，其实说白了就是用的 SPDY 做了一点修改。好了今天的主题是 TCP 就不过多的介绍 HTTP/2.0 了,以后会专门写一篇关于 HTTP/2.0 的文章，介绍一下他的新特性。","text":"TCP 总结 计算机网络中比较中要的无非就是 TCP/IP 协议栈，以及应用层的 HTTP 和 HTTPS 。前几天一直炒的的比较火的就是 HTTP/2.0 了，但是其实 HTTP/2.0 早在2015年的时候就已经出来了，并且这个版本是基于 Google 公司的 SPDY 协议发布的，其实说白了就是用的 SPDY 做了一点修改。好了今天的主题是 TCP 就不过多的介绍 HTTP/2.0 了,以后会专门写一篇关于 HTTP/2.0 的文章，介绍一下他的新特性。 1.引言&emsp;&emsp;我们都知道 TCP 是位于传输层的协议，他还有一个兄弟就是 UDP ，他们两共同构成了传输层。显然他们之间有很大的区别要不然的话在传输层只需要一个就好了。 &emsp;&emsp;其中最重要的区别就是一个面向连接另外一个不是，这个区别就导致了他们是否能够保证稳定传输，显然不面向连接的 UDP 是没办法保证可靠传输的，他只能靠底层的网络层和链路层来保证。我们都知道网络层采用的是不可靠的 IP 协议。好吧，网络层也保证不了可靠传输，所以 UDP 保证可靠传输只能依靠链路层了。 &emsp;&emsp;而 TCP 就好说了他不仅仅有底层的链路层的支持，还有自己的面向链接服务来保证可靠传输。当然 TCP也不仅仅就是比 UDP 多了一个可靠传输，前面也说到了这只是他们之间一个重要的区别。其实他的三个重要特性就是它们之间的区别。 &emsp;&emsp;* 可靠传输&emsp;&emsp;* 流量控制&emsp;&emsp;* 拥塞控制 2.可靠传输TCP 主要是确认重传机制 数据校验 数据合理分片和排序 流量控制 拥塞控制依靠来完成可靠传输的 , 下面详细介绍这几种保证可靠传输的方式。 1. 确认和重传确认重传，简单来说就是接收方收到报文以后给发送方一个 ACK 回复，说明自己已经收到了发送方发过来的数据。如果发送方等待了一个特定的时间还没有收到接收方的 ACK 他就认为数据包丢了，接收方没有收到就会重发这个数据包。 好的，上面的机制还是比较好理解的，但是我们会发现一个问题，那就是如果接收方已经收到了数据然后返回的 ACK 丢失，发送方就会误判导致重发。而此时接收方就会收到冗余的数据，但是接收方怎么能判定这个数据是冗余的还是新的数据呢？ 这就涉及到了 TCP 的另外一个机制就是采用序号和确认号，也就是每次发送数据的时候这个报文段里面包括了当前报文段的序号和对上面的报文的确认号，这样我们的接收方可以根据自己接受缓存中已经有的数据来确定是否接受到了重复的报文段。这时候如果出现上面所说的 ACK 丢失，导致接受重复的报文段时客户端丢弃这个冗余的报文段。 好现在我们大致了解了确认重传机制，但是还有些东西还没有弄清楚，也就是 TCP 真正的实现究竟是怎样的。 确认是每发一个报文段就确认一次还是一次确认多个呢？ 还有上面所说的发送方等待一个特定的时间，这个时间究竟等多长比较合适？ 重传的时候是只重传那个没收到的报文还是重传那个报文段及它以后的报文段？ 1.累计确认/单停等协议这就是我们要解决的第一个问题就是如何确认。这里涉及到两种确认方式，分别称为累计确认（捎带确认） 和 单停等协议 。 单停等协议 用一张图来快速理解，就是每发送一次数据，就进行一次确认。等发送方收到了 ACK 才能进行下一次的发送。 累计确认 一样的也是采用的 ACK 机制，但是注意一点的是，并非对于每一个报文段都进行确认，而仅仅对最后一个报文段确认，捎带的确认了上图中的 203 号及以前的报文。总结：从上面可以看到累计确认的效率更加高，首先他的确认包少一些那么也就是在网络中出现的大部分是需要传输的数据，而不是一半的数据一半的 ACK ，然后我们在第二张图中可以看到我们是可以连续发送多个报文段的（究竟一次性能发多少这个取决于发送窗口，而发送窗口又是由接受窗口和拥塞窗口一起来决定的。），一次性发多个数据会提高网络的吞吐量以及效率这个可以证明，比较简单这里不再赘述！ 结论：显然怎么看都是后者比较有优势，TCP 的实现者自然也是采用的累计确认的方式！ 2. 超时时间计算上文中的那个特定的时间就是超时时间，为什么有这个值呢? 其实在发送端发送的时候就为数据启动了一个定时器，这个定时器的初始值就是超时时间。 超时时间的计算其实有点麻烦，主要是我们很难确定一个确定的值，太长则进行了无意义的等待，太短就会导致冗余的包。TCP 的设计者们设计了一个计算超时时间的公式，这个公式概念比较多，有一点点麻烦，不过没关系我们一点点的来。 首先我们自己思考如何设计一个超时时间的计算公式，超时时间一般肯定是和数据的传输时间有关系的，他必然要大于数据的往返时间（数据在发送端接收端往返一趟所用的时间）。好，那么我们就从往返时间下手，可是又有一个问题就是往返时间并不是固定的我们有如何确定这个值呢？自然我们会想到我们可以取一小段时间的往返时间的平均值来代表这一时间点的往返时间，也就是微积分的思想！ 好了我们找到了往返时间（RTT），接下来的超时时间应该就是往返时间再加上一个数就能得到超时时间了。这个数也应该是动态的，我们就选定为往返时间的波动差值，也就是相邻两个往返时间的差。 下面给出我们所预估的超时时间（TimeOut）公式： 1TimeOut = AvgRTT2 + | AvgRTT2 - AvgRTT1 | 很好，看到这里其实你已经差不多理解了超时时间的计算方式了，只不过我们这个公式不够完善，但是思路是对的。我们这时候来看看 TCP 的实现者们采用的方式。 123RTT_New = (1-a)RTT_Current + a*Avg_RTT (计算平均 RTT，a 通常取0.125)DevRTT = (1-b)DevRTT + b|RTT_New - Avg_RTT| （计算差值，b 通常取0.25）TimeOut = RTT_New + 4*DevRTT （计算超时时间） 好的，这就是 TCP 实现的超时时间的方式，但是在实际的应用中并不是一直采用的这种方式。假如说我们现在网络状态非常的差，一直在丢包我们根本没必要这样计算，而是采用直接把原来的超时时间加倍作为新的超时时间。 **总结：好的现在我们知道了在两种情况下的超时时间的计算方式，正常的情况下我们采用的上面的比较复杂的计算公式，也就是 `RTT+波动值` 否则直接加倍** 3. 快速重传上面我们看到在发送方等待一个超时重传时间后会开始重传，但是我们计算的超时重传时间也不定就很准，也就是说我们经常干的一件事就会是等待，而且一般等的时间还挺长。那么可不可以优化一下呢？ 当然，在 TCP 实现中是做了优化的，也就是这里说到的快速重传机制。他的原理就是在发送方收到三个冗余的 ACK 的时候，就开始重传那个报文段。那么为什么是三个冗余的 ACK 呢？注意三个冗余的 ACK 其实是四个 ACK 。我们先了解一下发送 ACK 策略，这个是 RFC 5681 文档 规定的。 第一种情况收到一个期望的有序的数据时，最多延时 500ms 发送一个 ACK 表示该数据及以前的数据都收到了。 第二种情况是收到一个期望的有序的数据时，前面的有序数据等待发送 ACK 的时候立即发送一个 ACK 捎带确认前面那个数据，也就是第一个数据还在延时的时候又来一个那么久两个一起确认。 第三种情况，收到比期望序号大的数据的时候立即发送冗余 ACK ，ACK 确认的值就是中间缺少的第一个序号的值。 收到能部分填充或者完全填充中间缺少的数据的，如果这个报文是起始于缺少的数据的低端就立即发送一个 ACK。 好的，那么现在我们可以看到如果出现了三个冗余的 ACK 他只可能是发生了两次情况三，也就是发送了两个比期望值大的数据。但是注意出现情况三有两种可能，一个是丢包，另外一个是乱序到达。比如说我们现在是数据乱序到达的，我们来看一下。 第一种乱序情况 另外一种乱序 丢包情况 **结论: 很显然我们可以看到，如果发生了乱序有可能会出现三次冗余 ACK，但是如果发现了丢包必然会有三次冗余 ACK 发生，只是 ACK 数量可能更多但是不会比三次少** 4.数据重传方式在我们发现丢包以后我们需要重传，但是我们重传的方式也有两种方式可以选择分别是 GBN 和 SR 翻译过来就是 拉回重传 和 选择重传 。好其实我们已经能从名字上面看出来他们的作用方式了，拉回重传就是哪个地方没收到那么就从那个地方及以后的数据都重新传输，这个实现起来确实很简单，就是把发送窗口和接受窗口移回去，但是同样的我们发现这个方式不实用干了很多重复的事，效率低。 那么选择重传就是你想到的谁丢了，就传谁。不存在做无用功的情况。 **结论: TCP 实际上使用的是两者的结合，称为选择确认，也就是允许 TCP 接收方有选择的确认失序的报文段，而不是累计确认最后一个正确接受的有序报文段。也就是跳过重传那些已经正确接受的乱序报文段。** ### 2. 数据校验 ![](http://ojrw3x8j2.bkt.clouddn.com/18-3-25/40689669.jpg) &emsp;&emsp;数据校验，其实这个比较简单就是头部的一个校验，然后进行数据校验的时候计算一遍 checkSum 比对一下。 3. 数据合理分片和排序&emsp;&emsp;在 UDP 中，UDP 是直接把应用层的数据往对方的端口上 “扔” ，他基本没有任何的处理。所以说他发给网络层的数据如果大于1500字节,也就是大于MTU。这个时候发送方 IP 层就需要分片。把数据报分成若干片，使每一片都小于MTU.而接收方IP层则需要进行数据报的重组。这样就会多做许多事情,而更严重的是 ，由于UDP的特性,当某一片数据传送中丢失时 ， 接收方便无法重组数据报，将导致丢弃整个UDP数据报。 &emsp;&emsp;而在 TCP 中会按MTU合理分片，也就是在 TCP 中有一个概念叫做最大报文段长度（MSS）它规定了 TCP 的报文段的最大长度，注意这个不包括 TCP 的头，也就是他的典型值就是 1460 个字节（TCP 和 IP 的头各占用了 20 字节）。并且由于 TCP 是有序号和确认号的，接收方会缓存未按序到达的数据，根据序号重新排序报文段后再交给应用层。 4. 流量控制&emsp;&emsp;流量控制一般指的就是在接收方接受报文段的时候，应用层的上层程序可能在忙于做一些其他的事情，没有时间处理缓存中的数据，如果发送方在发送的时候不控制它的速度很有可能导致接受缓存溢出，导致数据丢失。 &emsp;&emsp;相对的还有一种情况是由于两台主机之间的网络比较拥塞，如果发送方还是以一个比较快的速度发送的话就可能导致大量的丢包，这个时候也需要发送方降低发送的速度。 &emsp;&emsp;虽然看起来上面的两种情况都是由于可能导致数据丢失而让发送主机降低发送速度，但是一定要把这两种情况分开，因为前者是属于流量控制 而后者是 拥塞控制 ，那将是我们后面需要讨论的事情。不要把这两个概念混了。 &emsp;&emsp;其实说到流量控制我们就不得不提一下滑动窗口协议，这个是流量控制的基础。由于 TCP 连接是一个全双工的也就是在发送的时候也是可以接受的，所以在发送端和接收端同时维持了发送窗口和接收窗口。这里为了方便讨论我们就按照单方向来讨论。 &emsp;&emsp;接收方维持一个接受窗口，发送方一个发送窗口。发送的时候要知道接受窗口还有多少空间，也就是发送的数据量不能超过接受窗口的大小，否则就溢出了。而当我们收到一个接收方的 ACK 的时候我们就可以移动接受窗口把那些已经确认的数据滑动到窗口之外，发送窗口同理把确认的移出去。这样一直维持两个窗口大小，当接收方不能在接受数据的时候就把自己的窗口大小调整为 0 发送窗口就不会发送数据了。但是有一个问题，这个时候当接收窗口再调大的时候他不会主动通知发送方，这里采用的是发送方主动询问。 &emsp;&emsp;还是画个图看的比较直观： 5. 拥塞控制&emsp;&emsp;拥塞控制一般都是由于网络中的主机发送的数据太多导致的拥塞，一般拥塞的都是一些负载比较高的路由，这时候为了获得更好的数据传输稳定性，我们必须采用拥塞控制，当然也为了减轻路由的负载防止崩溃。 &emsp;&emsp;这里主要介绍两个拥塞控制的方法，一个是慢开始，另外一个称为快恢复。 1.慢开始 一开始我们不知道网络中的拥塞情况，我们就发一个数据包 如果没有发生拥塞我们成倍的增加发送的数据的数量。 当然我们也不能到无休止的增加，这里有一个慢开始门限，到达门限则加法增加，每次加一。 这时候如果遇到了拥塞，我们直接跳到第一步，也就是从头开始，并且把慢开始门限调整为拥塞时候的数据量的一半再次开始。 2.快恢复 一开始我们不知道网络中的拥塞情况，我们就发一个数据包 如果没有发生拥塞我们成倍的增加发送的数据的数量。 当然我们也不能到无休止的增加，这里有一个慢开始门限，到达门限则加法增加，每次加一。 这时候如果遇到了拥塞，这里就是唯一和慢开始不一样的地方，直接从新的慢开始门限加法增长。 3.连接管理1. 建立连接3次握手 客户端像服务端发起连接，首先向服务端发送一个特殊的报文，这个报文的 SYN 位被置 1 ，然后生成一个随机的序号填入到 TCP 的头部。这个报文段称为 SYN 报文，用于请求连接。 服务器接收到客户端的 SYN 报文以后，也要生成一个特殊的报文段来允许客户端的接入，这个报文是设置一个自己的初始序号，SYN 设置为 1，ACK 设置为 SYN 报文序号加一。这个报文段称之为 SYNACK 报文。并且根据 SYN 报文的参数来分配本地变量，但是也是由于这么早的分配变量就有一种 SYN 洪泛攻击。注意一下，上面的这两个报文段都没有数据部分。 在客户端收到 SYNACK 报文段时候需要对客户端分配变量，然后对服务器的允许进行确认。这时候 SYN 位要置位 0 ，并且可以携带数据，也就是这时候是已经开始了数据传输的。 那么问题来了，为什么需要序号呢？为什么又是三次握手而不是两次？以及什么是 SYN 洪泛攻击？ 序号存在的目的是为了能否区分多个 TCP 连接，毕竟是一个服务器，多个客户端，不然各个 TCP 连接就会变得非常混乱。 其实我们单方向来看其实就是两次握手，之所以是三次握手是因为 TCP 是双工的，中间那次的 SYNACK 其实试一次合并。 SYN 洪泛攻击就是让客户端乱遭一些 IP 然后和服务器简历 TCP 连接，由于服务器收不到 ACK 但是他分配了变量，导致一直在消耗服务器资源。这个解决方法就是采用 SYNCookie 这个 Cookie 其实就是服务器在发送 SYNACK 的头部的 seq 序号的值，那么客户端必须返回一个比 Cookie 大一的 ACK 回来才是正确的，否则不分配变量，也就是变量延时分配。 2.释放链接四次挥手 首先客户端发起终止会话的请求，FIN=1 服务器接收到后相应客户端 ACK=1 服务器发送完毕终止会话 FIN=1 客户端回应 ACK=1 这里需要说明一下的是最后的那个长长的 TIME_WAIT 状态一般是为了客户端能够发出 ACK 一般他的值是 1分钟 或者2分钟 4.总结&emsp;&emsp;好了，今天真的写了不少，主要就是把 TCP 的可靠传输以及连接管理讲清楚了，以及里面的一下细节问题，真的很花时间。然后其他没有涉及到的就是关于 TCP 的头并没有详细的去分析，这个东西其实也不是很难，但是现在篇幅真的已经很大就先这样，头里面的都是固定的不需要太多的理解。","categories":[{"name":"-计算机网络","slug":"计算机网络","permalink":"http://lwenxu.coding.me/categories/计算机网络/"}],"tags":[]},{"title":"今天是个转折点","slug":"Life/今天是个转折点","date":"2018-03-04T13:36:04.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/03/04/Life/今天是个转折点/","link":"","permalink":"http://lwenxu.coding.me/2018/03/04/Life/今天是个转折点/","excerpt":"","text":"今天是个转折点今天是一个转折点，人生的转折点。 等待这天好久好久了，上高中到现在我好像没有任何改变，只是一个比较努力的傻子。慢慢的我的生活好像失去了那些本该有的颜色，开心，以及能够让我高兴半个月或者好久好久的事情了。 只是每个周惯例的给爸爸妈妈打电话，我想跟他们多聊聊可是话到了嘴边又咽下去了，好像不知道什么时候起突然就变得这么懂事，乖巧，大家眼里的好孩子。可是啊，我一点也不开心，找不到开心的事，就连收到那么久以来梦寐以求的阿里 offer 的时候我也非常平静，只是高兴了那么一会会，也就一会会。 今天发生了两件事，一个是我从阿里离职了，另外就是我跟父母说了我很想说的这些事。 我爸说 22 岁的我能达到目前的这个程度，我是他的骄傲！听到这句话的时候，怎么猛地眼泪就掉下来了，长时间积郁在胸口的悲伤，失望与痛苦瞬间随着眼泪涌了出来。我也明白了我告诉他们我睡不着的时候爸妈整晚的说我的事，为我想办法，也明白我是真的有多么幸运，一个爱你的人究竟能有多爱你。 所以什么才是对你真的用心的那种好，我想绝对不是那种看心情对你呼之即来挥之即去的爱。五点多的时候因为妈妈的关心，我大声说话时她有多么伤心，我说完她就没说话了，坐在那发呆，弟弟告诉她：“妈妈别担心，哥哥那么优秀怎么会找不到工作”，电话的尾声她还是不住的提醒爸爸关心我明天怎么坐车，有没有买药。电话意外挂断的时候，第一时间去打我的电话。从未觉得我的人生如此的幸运 ：） 另外一个就是从阿里离职，办完离职手续的那一刻其实心里空空的，我不确信我这辈子是否还有机会踏入阿里的大门，我也不清楚明天的路会是怎样的，只是我明白了我不会去选择那条别人眼中的完美的充满鲜花和掌声的路，我想我选择的会是那条能让自己开心，有色彩的路。 是啊，我可以无趣，但不可以不开心。","categories":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/categories/生活/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/tags/生活/"}]},{"title":"6月8号","slug":"Life/6月8号","date":"2018-03-04T13:36:04.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2018/03/04/Life/6月8号/","link":"","permalink":"http://lwenxu.coding.me/2018/03/04/Life/6月8号/","excerpt":"","text":"无论事情怎么糟糕，将来多么不确定，当下多么痛苦，保持一颗让自己有好心情的❤。","categories":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/categories/生活/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/tags/生活/"}]},{"title":"二叉搜索树","slug":"Algorithm/二叉搜索树","date":"2018-03-04T12:01:05.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/03/04/Algorithm/二叉搜索树/","link":"","permalink":"http://lwenxu.coding.me/2018/03/04/Algorithm/二叉搜索树/","excerpt":"一、操作： 判断元素是否存在：递归的在左右子树中查找 查找最小元素：在左子树中递归或者循环 查找最大元素：在右子树中递归或循环 插入：递归的插入，大于则插入在节点的右子树，小于则左子树，等于则是重复节点不作处理 删除：递归删除( 或者说递归查找需要删除的元素 )，找到该元素后，如果元素有两个子节点那么久找到这个元素的右子树的最小元素代替要删除的元素，然后再删除那个右子树上的最小元素。如果只有一个子节点直接让要被删除的节点赋值上他的子节点。","text":"一、操作： 判断元素是否存在：递归的在左右子树中查找 查找最小元素：在左子树中递归或者循环 查找最大元素：在右子树中递归或循环 插入：递归的插入，大于则插入在节点的右子树，小于则左子树，等于则是重复节点不作处理 删除：递归删除( 或者说递归查找需要删除的元素 )，找到该元素后，如果元素有两个子节点那么久找到这个元素的右子树的最小元素代替要删除的元素，然后再删除那个右子树上的最小元素。如果只有一个子节点直接让要被删除的节点赋值上他的子节点。 二、代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247package Tree;import sun.tools.tree.ThisExpression;import java.util.Stack;public class MyBinaryTree &#123; public class BinaryNode implements Comparable&lt;Integer&gt; &#123; BinaryNode lChild; BinaryNode rChild; Integer ele; BinaryNode(Integer ele) &#123; this(ele, null, null); &#125; BinaryNode(Integer ele, BinaryNode lChild, BinaryNode rChild) &#123; this.ele = ele; this.lChild = lChild; this.rChild = rChild; &#125; @Override public int compareTo(Integer o) &#123; return ele - o; &#125; &#125; private BinaryNode root; public MyBinaryTree() &#123; root = null; &#125; public MyBinaryTree(Integer ele) &#123; root = new BinaryNode(ele, null, null); &#125; public void makeEmpty() &#123; this.root = null; &#125; public boolean isEmpty() &#123; return root == null; &#125; public boolean contains(Integer node) &#123; return contains(node, root); &#125; public boolean contains(Integer node, BinaryNode root) &#123; if (root == null) &#123; return false; &#125; int result = root.ele.compareTo(node); if (result &gt; 0) &#123; return contains(node, root.lChild); &#125; else if (result &lt; 0) &#123; return contains(node, root.rChild); &#125; else &#123; return true; &#125; &#125; public Integer findMin() &#123; if (isEmpty()) &#123; throw new RuntimeException(); &#125; return (Integer) findMin(root); &#125; public Integer findMin(BinaryNode root) &#123; if (root == null) &#123; return null; &#125; else if (root.lChild == null) &#123; return root.ele; &#125; else &#123; return findMin(root.lChild); &#125; &#125; public Integer findMax() &#123; if (isEmpty()) &#123; throw new RuntimeException(); &#125; return (Integer) findMax(root).ele; &#125; public BinaryNode findMax(BinaryNode root) &#123; if (root == null) &#123; return null; &#125; else if (root.rChild == null) &#123; return root; &#125; else &#123; return findMax(root.rChild); &#125; &#125; public void insert(Integer x) &#123; root = insert(x, root); &#125; public BinaryNode insert(Integer ele, BinaryNode root) &#123; if (root == null) &#123; return new BinaryNode(ele); &#125; int result = root.compareTo(ele); if (result &lt; 0) &#123; root.rChild = insert(ele, root.rChild); &#125; else if (result &gt; 0) &#123; root.lChild = insert(ele, root.lChild); &#125; else ; return root; &#125; public BinaryNode remove(Integer ele) &#123; root = remove(ele, root); return root; &#125; public BinaryNode remove(Integer ele, BinaryNode root) &#123; if (root == null) &#123; return null; &#125; int result = root.compareTo(ele); if (result &gt; 0) &#123; root.lChild = remove(ele, root.lChild); &#125; else if (result &lt; 0) &#123; root.rChild = remove(ele, root.rChild); &#125; //这个地方就是递归的结束条件 也就是当我们找到了要删除的节点，这时候要分情况如果两个子节点都不空我们需要把右子树的最小值的替换到当前节点然后删除右子树最小节点 //当有一个或者0个节点的时候我们只需要把左边或者右边挂上去就行 else if (root.lChild != null &amp;&amp; root.rChild != null) &#123; root.ele = findMin(root.rChild); root.rChild = remove(root.ele, root.rChild); &#125; else &#123; root = root.lChild == null ? root.rChild : root.lChild; &#125; return root; &#125; public void printTree() &#123; preOrder(root); &#125; public void preOrder(BinaryNode root) &#123; if (root == null) &#123; return; &#125; System.out.print(root.ele + \" \"); if (root.lChild != null) &#123; preOrder(root.lChild); &#125; if (root.rChild != null) &#123; preOrder(root.rChild); &#125; &#125; public void inOrder(BinaryNode root) &#123; if (root == null) &#123; return; &#125; if (root.lChild != null) &#123; inOrder(root.lChild); &#125; System.out.print(root.ele + \" \"); if (root.rChild != null) &#123; inOrder(root.rChild); &#125; &#125; public void subOrder(BinaryNode root) &#123; if (root == null) &#123; return; &#125; if (root.lChild != null) &#123; inOrder(root.lChild); &#125; if (root.rChild != null) &#123; inOrder(root.rChild); &#125; System.out.print(root.ele + \" \"); &#125; public void preOrder_1(BinaryNode root) &#123; Stack&lt;BinaryNode&gt; stack = new Stack&lt;&gt;(); if (root == null) &#123; return; &#125; // stack.push(root); BinaryNode p = root; System.out.printf(p.ele + \" \"); while (p != null || !stack.isEmpty()) &#123; if (p != null) &#123; System.out.printf(p.ele + \" \"); stack.push(p); p = p.lChild; &#125; else &#123; p = stack.pop(); p = p.rChild; &#125; &#125; &#125; public void inOrder_1(BinaryNode root) &#123; BinaryNode p = root; Stack&lt;BinaryNode&gt; stack = new Stack&lt;&gt;(); while (p != null || !stack.isEmpty()) &#123; if (p != null) &#123; stack.push(p); p = p.lChild; &#125; else &#123; p = stack.pop(); System.out.printf(p.ele + \" \"); p = p.rChild; &#125; &#125; &#125; public void subOrder_1(BinaryNode root) &#123; Stack&lt;BinaryNode&gt; stack = new Stack&lt;&gt;(); BinaryNode p = root; BinaryNode q = null; while (p != null || !stack.isEmpty()) &#123; if (p != null) &#123; stack.push(p); p = p.lChild; &#125; else &#123; p = stack.peek(); if (p.rChild == null || p.rChild == q) &#123; q = p; p = stack.pop(); System.out.printf(p.ele + \" \"); p = null; &#125; else &#123; p = p.rChild; &#125; &#125; &#125; &#125; public BinaryNode getRoot() &#123; return this.root; &#125;&#125;","categories":[{"name":"-数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/categories/数据结构/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://lwenxu.coding.me/tags/二叉树/"}]},{"title":"八大排序算法","slug":"Algorithm/八大排序算法","date":"2018-03-03T12:50:07.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/03/03/Algorithm/八大排序算法/","link":"","permalink":"http://lwenxu.coding.me/2018/03/03/Algorithm/八大排序算法/","excerpt":"​ 八大排序算法是面试经常考到的，尤其是快排，希尔排序和归并也是经常会让写代码的题目，其实只要用一句话说明了他们的原理我们写起代码就没那么困难。 冒泡排序思想：有 n 个数我们就进行 n-1 趟排序，每一趟我们都选取最大的一个数放到已经排序的位置即可。伪代码：两个 For 循环，外层表示要进行的趟数，内层则是找出最大的数，找最大的数的方法就是比较、交换。","text":"​ 八大排序算法是面试经常考到的，尤其是快排，希尔排序和归并也是经常会让写代码的题目，其实只要用一句话说明了他们的原理我们写起代码就没那么困难。 冒泡排序思想：有 n 个数我们就进行 n-1 趟排序，每一趟我们都选取最大的一个数放到已经排序的位置即可。伪代码：两个 For 循环，外层表示要进行的趟数，内层则是找出最大的数，找最大的数的方法就是比较、交换。 时间复杂度：O(n2)空间复杂度：O(n)代码：12345678910111213141516171819202122232425262728293031package Sorting;import org.junit.jupiter.api.Test;import java.util.Arrays;public class Bubble &#123; public static void sort(int[] arr) &#123; for (int i=1;i&lt;arr.length-1;++i) &#123; for(int j=0;j&lt;arr.length-i;++j) &#123; if (arr[j] &gt; arr[j + 1]) &#123; swap(arr,j); &#125; &#125; &#125; &#125; private static void swap(int[] arr, int j) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; @Test public void test() &#123; int[] arr = new int[]&#123;2, 1, 4, 5, 3, 2&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125; 插入排序思想：插入排序就是把元素分成两部分,一部分就是有序的，而另外一部分无序。我们每次在无序的集合里面找到一个元素插入到他在有序集合中对应的位置。因此总的来说他就是把一个数据插入到已经排好序的数据中。####分类：实际上插入排序是一个类别，它里面有很多具体的排序方式。直接插入排序，折半插入排序，希尔排序 ( 又称缩小增量排序 )。他们都是属于稳定排序。 直接插入排序思想：把待排序的记录按其关键码值的大小逐个插入到一个已经排好序的有序序列中，直到所有的记录插入完为止，得到一个新的有序序列。形象的可以理解为打扑克抓拍的过程，通常我们右手抓牌，没抓一张牌，就放到左手，抓下一张牌后，会把这张牌依次与左手上的牌比较，并把它插入到一个合适的位置（按牌面大小）。应用优势：插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率。时间复杂度：O(n2)1234567891011121314151617181920212223242526package Sorting;import org.junit.jupiter.api.Test;import java.util.Arrays;public class SimpleInsert &#123; public void sort(int[] arr) &#123; for (int i = 1; i &lt; arr.length; i++) &#123; int temp = arr[i]; int j = i - 1; while (j &gt; -1 &amp;&amp; temp &lt; arr[j]) &#123; arr[j + 1] = arr[j]; --j; &#125; arr[j + 1] = temp; &#125; &#125; @Test public void test()&#123; int[] arr = new int[]&#123;5, 3, 2, 6, 8, 1, 3, 0&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125; 二分插入排序思想：也就是和上面的简单插入排序一样，只是简单插入排序做了很多的判断，元素到底应该插入哪个位置，而这里我们是使用这般查找来确定位置，因为那一部分是有序的。时间复杂度：n2希尔排序思想：希尔排序的基本思想就是设置一个步长，首先步长是整个元素的长度的一半，这样我们每一个分组只有两个元素在这个分组中我们进行排序，然后我们减小步长也就是再次除以二，继续上面的步骤，最后我们会得到整个元素的集合成为一个分组。稳定性：不稳定时间复杂度：n(logn)1234567891011121314151617181920212223242526272829303132333435package Sorting;import org.junit.jupiter.api.Test;import java.util.Arrays;public class Shell &#123; public void sort(int[] arr) &#123; int step = arr.length / 2; //这是循环每一个步长 while (step &gt; 0) &#123; //这是循环每一个分组的第一个元素的下标 for (int i = 0; i &lt;= step; i++) &#123; //这是一层简单插入排序 for (int ptr = i; ptr + step &lt; arr.length; ptr += step) &#123; int temp = arr[ptr + step]; int j = ptr; while (j &gt;= 0 &amp;&amp; arr[j] &gt; temp) &#123; arr[j + step] = arr[j]; j -= step; &#125; arr[j+step] = temp; &#125; &#125; step /= 2; &#125; &#125; @Test public void test()&#123; int[] arr = new int[]&#123;5, 3, 2, 6, 8, 1, 3, 0&#125;; sort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125; 简单选择排序思想：始终选取最小的元素往前面的有序序列中插入稳定性：不稳定时间复杂度：O(n2)1234567891011121314151617181920212223242526272829303132package Sorting;import org.junit.jupiter.api.Test;public class SimpleSorting &#123; void sort(int[] arr) &#123; int min; for (int i = 0; i &lt; arr.length; i++) &#123; min = minIndex(arr, i); int temp = arr[min]; arr[min] = arr[i]; arr[i] = temp; &#125; &#125; private int minIndex(int[] arr, int start) &#123; int min = start; for (int i = start; i &lt; arr.length; i++) &#123; min = arr[i] &lt; arr[min] ? i : min; &#125; return min; &#125; @Test public void fun() &#123; int[] arr = new int[]&#123;6, 2, 3, 4, 51, 32, 52, 33&#125;; sort(arr); for (int ele : arr) &#123; System.out.printf(ele + \" \"); &#125; &#125;&#125; 快速排序思想：寻找一个枢轴元素，然后我们把枢轴元素归位，也就是比他小的放在他的左边比他大的放右边，然后继续在他的左边右边选取枢轴元素继续如此进行。时间复杂度：稳定性：这就是在我们输入数据基本有序甚至完全有序的时候，这算法退化为冒泡排序，不再是O(n㏒n)，而是O(n^2)了。12345678910111213141516171819202122232425262728293031323334353637383940414243444546package Sorting;import org.junit.jupiter.api.Test;public class QuickSorting &#123; void sort(int[] arr, int start, int end) &#123; if (start &gt;= end) &#123; return; &#125; int center = getMid(arr, start, end); sort(arr, start, center - 1); sort(arr, center + 1, end); &#125; void sort(int[] arr) &#123; sort(arr, 0, arr.length - 1); &#125; int getMid(int[] arr, int start, int end) &#123; int temp = arr[start]; while (start &lt; end) &#123; while (start &lt; end &amp;&amp; arr[end] &gt;= temp) &#123; end--; &#125; arr[start] = arr[end]; while (start &lt; end &amp;&amp; arr[start] &lt;= temp) &#123; start++; &#125; arr[end] = arr[start]; &#125; arr[start] = temp; return start; &#125; @Test public void fun() &#123; int[] arr = new int[]&#123;5, 3, 2, 6, 8, 1, 3, 0&#125;; sort(arr); for (int ele : arr) &#123; System.out.printf(ele + \" \"); &#125; &#125;&#125; 归并排序思想：就是先把元素分成两部分，然后对这两部分继续排序，最后进行合并这两部分。这也是一个重要的分治思想归并法。分治思想：经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。时间复杂度：O(nlogn)空间复杂度：O(n)稳定性：稳定123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package Sorting;import org.junit.jupiter.api.Test;import java.util.Arrays;public class Merge &#123; public static void sort(int []arr)&#123; int []temp = new int[arr.length];//在排序前，先建好一个长度等于原数组长度的临时数组，避免递归中频繁开辟空间 sort(arr,0,arr.length-1,temp); &#125; private static void sort(int[] arr,int left,int right,int []temp)&#123; if(left&lt;right)&#123; int mid = (left+right)/2; sort(arr,left,mid,temp);//左边归并排序，使得左子序列有序 sort(arr,mid+1,right,temp);//右边归并排序，使得右子序列有序 merge(arr,left,mid,right,temp);//将两个有序子数组合并操作 &#125; &#125; private static void merge(int[] arr,int left,int mid,int right,int[] temp)&#123; int i = left;//左序列指针 int j = mid+1;//右序列指针 int t = 0;//临时数组指针 while (i&lt;=mid &amp;&amp; j&lt;=right)&#123; if(arr[i]&lt;=arr[j])&#123; temp[t++] = arr[i++]; &#125;else &#123; temp[t++] = arr[j++]; &#125; &#125; while(i&lt;=mid)&#123;//将左边剩余元素填充进temp中 temp[t++] = arr[i++]; &#125; while(j&lt;=right)&#123;//将右序列剩余元素填充进temp中 temp[t++] = arr[j++]; &#125; t = 0; //将temp中的元素全部拷贝到原数组中 while(left &lt;= right)&#123; arr[left++] = temp[t++]; &#125; &#125; @Test public void fun() &#123; int[] arr = new int[]&#123;5, 3, 2, 6, 8, 1, 3, 0, 9&#125;; int[] temp = new int[arr.length]; sort(arr, 0, arr.length - 1, temp); System.out.println(Arrays.toString(arr)); &#125;&#125; 堆排序思想：将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根节点。将其与末尾元素进行交换，此时末尾就为最大值。然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次小值。如此反复执行，便能得到一个有序序列了稳定性：不稳定时间复杂度：O(nlogn)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package Sorting;import org.junit.jupiter.api.Test;import java.util.Arrays;public class HeapSort &#123; public static void sort(int []arr)&#123; //1.构建大顶堆 for(int i=arr.length/2-1;i&gt;=0;i--)&#123; //从第一个非叶子结点从下至上，从右至左调整结构 swim(arr,i,arr.length); &#125; //2.调整堆结构+交换堆顶元素与末尾元素 for(int j=arr.length-1;j&gt;0;j--)&#123; swap(arr,0,j);//将堆顶元素与末尾元素进行交换 swim(arr,0,j);//重新对堆进行调整 &#125; &#125; /** * 调整大顶堆（仅是调整过程，建立在大顶堆已构建的基础上） * @param arr * @param i * @param length */ public static void swim(int []arr,int i,int length)&#123; int temp = arr[i];//先取出当前元素i for(int k=i*2+1;k&lt;length;k=k*2+1)&#123;//从i结点的左子结点开始，也就是2i+1处开始 if(k+1&lt;length &amp;&amp; arr[k]&lt;arr[k+1])&#123;//如果左子结点小于右子结点，k指向右子结点 k++; &#125; if(arr[k] &gt;temp)&#123;//如果子节点大于父节点，将子节点值赋给父节点（不用进行交换） arr[i] = arr[k]; i = k; &#125;else&#123; break; &#125; &#125; arr[i] = temp;//将temp值放到最终的位置 &#125; /** * 交换元素 * @param arr * @param a * @param b */ public static void swap(int []arr,int a ,int b)&#123; int temp=arr[a]; arr[a] = arr[b]; arr[b] = temp; &#125; @Test public void fun() &#123; int[] arr = new int[]&#123;5, 3, 2, 6, 8, 1, 3, 0&#125;; sort(arr); for (int ele : arr) &#123; System.out.printf(ele + \" \"); &#125; &#125;&#125; 总结稳定性：堆排序、快速排序、希尔排序、直接选择排序 不是稳定的排序算法，而基数排序、冒泡排序、直接插入排序、折半插入排序、归并排序是稳定的排序算法。应用场景：(1)若n较小(如n≤50)，可采用直接插入或直接选择排序。 当记录规模较小时，直接插入排序较好；否则因为直接选择移动的记录数少于直接插人，应选直接选择排序为宜。(2)若文件初始状态基本有序(指正序)，则应选用直接插人、冒泡或随机的快速排序为宜；(3)若n较大，则应采用时间复杂度为O(nlgn)的排序方法：快速排序、堆排序或归并排序。 快速排序是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短； 堆排序所需的辅助空间少于快速排序，并且不会出现快速排序可能出现的最坏情况。这两种排序都是不稳定的。 若要求排序稳定，则可选用归并排序。但前面介绍的从单个记录起进行两两归并的排序算法并不值得提倡，通常可以将它和直接插入排序结合在一起使用。先利用直接插入排序求得较长的有序子序列，然后再两两归并之。因为直接插入排序是稳定 的，所以改进后的归并排序仍是稳定的。 复杂度：","categories":[{"name":"-数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/categories/数据结构/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://lwenxu.coding.me/tags/算法/"}]},{"title":"数据结构Generic","slug":"Algorithm/数据结构Generic","date":"2018-03-02T08:50:14.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/03/02/Algorithm/数据结构Generic/","link":"","permalink":"http://lwenxu.coding.me/2018/03/02/Algorithm/数据结构Generic/","excerpt":"​ 接下来我们要处理的是前面实现里另一个 根本性的缺陷 那些实现只适用于字符串，想要实现其他类型数据的队列和栈怎么办呢？ 这个问题就涉及泛型的话题了。","text":"​ 接下来我们要处理的是前面实现里另一个 根本性的缺陷 那些实现只适用于字符串，想要实现其他类型数据的队列和栈怎么办呢？ 这个问题就涉及泛型的话题了。 ​ 有一个广泛采用的捷径是 使用强制类型转换对不同的数据类型重用代码 我们对Object类实现数据结构，Java中所有的类都是Object的 子类，当客户端使用时，就将结果转换为 对应的类型。这个我不想花很多时间来讲 因为我认为这样的解决方案不能令人满意。 ​ 第二种方法是用的是泛型 这种方法中客户端程序不需要强制类型转换。在编译时就能 发现类型不匹配的错误，而不是在运行时。优秀的模块化编程的指导原则就是我们应当欢迎编译时错误，避免运行时错误。因为如果我们能在编译时 检测到错误，我们给客户交付产品或者部署对一个API的实现时 有把握对于任何客户都是没问题的，然而 直到运行时才会出现的错误可能在某些客户的开发中几年之后出现。 ​ 基于数组的实现，这种方法不管用。目前很多编程语言 这方面都有问题，而对Java尤其是个难题 我们想做的是用泛型名称item直接声明一个新的数组， 不幸的是，Java不允许创建泛型数组。对于这个问题有各种 技术方面的原因。这里，要行得通我们需要 加入强制类型转换。我们创建Object数组，然后将类型转换为 item数组。我的观点是优秀的代码应该不用强制类型转换。要 尽量避免强制类型转换因为它确实在我们的实现中 留下隐患。但这个情况中我们必须加入这个强制类型转换 我们听到过的教导是蹩脚的强制类型转换让你看你的代码不爽 这样的想法不仅仅你一个人有 我认为像这么简单的代码强制类型转换是讨厌的特性。当我们编译这个程序的 时候，Java会发出警告信息说我们在使用未经检查 或者不安全的操作，详细信息需要使用-Xlint=unchecked参数 重新编译。我们加上这个参数重新编译之后显示 你在代码中加入了一个未经检查的强制类型转换，对此发出 警告，你不应该加入未经检查的强制类型转换。好吧，当你 编译这样的代码的时候看到这个警告信息没事。 ​ 接下来，是个跟Java有关的 细节问题，关于基本类型。我们用的泛型类型是针对 Object及其子类的。前面讲过，是从Object数组强制类型转换 来的。为了处理基本类型，我们需要使用Java的包装对象类型 如大写的Integer是整型的包装类型等等。","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/tags/数据结构/"}]},{"title":"数据结构Queue","slug":"Algorithm/数据结构Queue","date":"2018-03-02T08:24:11.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/03/02/Algorithm/数据结构Queue/","link":"","permalink":"http://lwenxu.coding.me/2018/03/02/Algorithm/数据结构Queue/","excerpt":"​ 栈和队列其实是相同的，只是名字不一样 入栈换成了入队（enqueue），出栈换成了出队（dequeue）。语义 是不同的。入队操作向队尾添加元素，而出队操作从 队首移除元素。","text":"​ 栈和队列其实是相同的，只是名字不一样 入栈换成了入队（enqueue），出栈换成了出队（dequeue）。语义 是不同的。入队操作向队尾添加元素，而出队操作从 队首移除元素。 ​ 现在，队列的链表表示中 我们需要维护两个指针引用。一个是链表中的第一个 元素，另一个是链表最后一个元素。插入的时候我们在 链表末端添加元素，而不是在链表头。移除元素的时候 不变，依然从链表头取出元素。那么这就是出队操作的实现 和栈的出栈操作的代码是一样的。保存元素，前进指针 指向下一个节点，这样就删除了第一个节点，然后返回该元素。一模一样 添加节点，或者入队操作时，向链表添加新节点。我们要把它放在链表末端 这样它就是最后一个出队的元素。首先 要做的是保存指向最后一个节点的指针，因为我们需要 将它指向下一个节点的指针从null变为新的节点。然后给 链表末端创建新的节点并对其属性赋值，将旧的指针 从null变为指向新节点。 ​ 那么用数组实现呢？用可调大小的数组实现并不难 。我们维护两个指针，分别指向队列中的 第一个元素和队尾，即下一个元素要加入的地方 那么对于入队操作在tail指向的地方加入新元素，出队操作移除 head指向的元素。棘手的地方是一旦指针的位置超过了数组 的容量，必须重置指针回到0，这里需要多写一些代码 而且和栈一样实现数据结构的时候你需要加上调整容量的方法 。下面给出完整的实现。 1234567891011121314151617181920212223242526272829303132333435363738394041package Queue;/** * 同 Stack 我们遇到的问题就是调整队列大小的问题，以及处理碎片空间的问题 * 调整大小我们依然使用倍增法，碎片空间就涉及到了循环队列的处理方法 */public class QueueArray &#123; private int[] arr; private int head = 0; private int tail = 0; public QueueArray() &#123; arr = new int[20]; &#125; private void resize(int size) &#123; int[] temp = new int[size]; System.arraycopy(arr, 0, temp, 0, arr.length); arr = temp; &#125; public boolean isEmpty() &#123; return head == tail; &#125; public void enqueue(int num) &#123; if (isFull()) &#123; resize(arr.length * 2); &#125; tail = (++tail) % arr.length; arr[tail] = num; &#125; public int dequeue() &#123; return arr[++head % arr.length]; &#125; public boolean isFull() &#123; return (tail + 1) % arr.length == head; &#125;&#125;","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/tags/数据结构/"}]},{"title":"数据结构Stack","slug":"Algorithm/数据结构Stack","date":"2018-03-02T07:09:57.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2018/03/02/Algorithm/数据结构Stack/","link":"","permalink":"http://lwenxu.coding.me/2018/03/02/Algorithm/数据结构Stack/","excerpt":"​ 在很多应用中，我们需要维护多个对象的集合，这种操作非常简单。我们可能想要向集合中 加入某个元素，去掉某个元素，以及遍历 集合中的元素并对他们执行某种操作，当然还有 检查集合是否为空。对于大多数操作来说，目的都很明确 关键是当需要去掉一个元素时，去掉哪一个元素呢？处理这类问题 有两个经典基础数据结构，栈和队列。","text":"​ 在很多应用中，我们需要维护多个对象的集合，这种操作非常简单。我们可能想要向集合中 加入某个元素，去掉某个元素，以及遍历 集合中的元素并对他们执行某种操作，当然还有 检查集合是否为空。对于大多数操作来说，目的都很明确 关键是当需要去掉一个元素时，去掉哪一个元素呢？处理这类问题 有两个经典基础数据结构，栈和队列。 ​ 它们的区别就在于 去除元素的选择方式。在栈中，我们取出 最近加入的元素。插入元素对应的术语是入栈（push） 去掉最近加入的元素叫做出栈（pop）。这也叫做后进先出原则 ( LIFO )。在队列中，我们关注最先加入队列的元素 为了和栈的操作区分，队列加入元素的操作叫做入队（enqueue） 去除元素的操作叫做出队（dequeue）。这也叫做先入先出原则 (FIFO) ​ 如何实现这些操作 ,我们今天隐含的主题是模块式编程。这也将是我们需要特别遵守的原则,这一原则主要思想是将接口与实现完全分离,比如我们精确定义了一些如栈、队列等数据结构的时候和数据类型，我们想要的是实现的细节与客户端的 完全分离。客户端可以选择不同的实现 但是客户端代码只能执行基本操作 另一方面，实现部分无法知道客户端需求的细节 它所要做的只是实现这些操作 这样，很多客户端能够共用同一个实现 这使得我们能够用模块式可复用的算法与数据结构库 来构建更复杂的算法和数据结构。在 Java 这门语言中就是使用接口俩统一 API，我们的所有实现必须遵从我们先前的 API。 ​ 现在，我们来看实现栈的代码 我们要看的第一个实现使用链表。 12345678910111213141516171819202122232425262728package Stack;public class StacksLink &#123; private class Node&#123; String item; Node next; &#125; private Node first = null; public boolean isEmpty()&#123; return first == null; &#125; public void push(String item) &#123; Node oldFirst = first; first = new Node(); first.item = item; first.next = oldFirst; &#125; public String pop()&#123; Node temp = first; first = first.next; return temp.item; &#125;&#125; ​ 好，我们来看代码 这门课中所有的链式数据结构中 我们使用Java中内部类来实现，这只是 描述我们要操作的节点对象的一种方法 节点对象由一个字符串和指向另一个节点的引用组成。 ​ 所以，链表的 出栈操作非常容易实现。首先，我们需要 返回链表中第一个元素，所以先将它存在变量item中 然后，要去掉第一个节点，我们只需要将 链表指向第一个元素的指针指向下一个元素 然后第一个节点就等着被垃圾回收处理 最后，返回保存的元素。 ​ 入栈操作呢？ 我们要在链表头加入新的节点 首先，将指向链表头的指针存起来，oldfirst = first 然后创建新节点，这是我们要插入链表头 的新节点。first = new Node() 这是个实例变量，它的元素就是我们想要插入链表头 的字符串，这个例子中是“not”，它的next指针指向链表oldfirst元素 现在成了链表第二个元素。在这个操作之后 first指向链表头处的元素，链表中的元素依照 入栈时间降序排列。实现入栈操作 只需要四行代码。 ​ 这个类中构造函数不做任何操作 也就不用写构造函数。内部类用来构成链表中的元素 将它写成了内部类，这样我们能够直接访问这些实例变量 栈唯一的实例变量是 链表中第一个节点的引用。 ​ 现在，我们分析实现的性能 这样我们就能提供给客户算法数据结构的 性能信息。这个例子中，很容易就能看出每个操作 最坏情况下只需要常数时间。每个操作没有循环，这显然是我们很想要的特性。那么空间需求呢？这和机器具体 实现有关。这是个典型Java实现，每个对象会有16字节的 额外空间，因为有内部类，所以还有8字节的额外空间 在类Node中有两个引用 一个指向字符串，另一个指向Node类 各需要8字节，每个栈节点需要40字节，如果栈大小为N 需要大约40N字节。 ​ 另一种实现栈的自然的方式是使用数组来储存栈上的元素。 12345678910111213141516171819202122package Stack;public class StackArray &#123; private int top; private int[] arr; public StackArray(int size) &#123; arr = new int[size]; &#125; public boolean isEmpty() &#123; return top == 0; &#125; public void push(int num) &#123; arr[top++] = num; &#125; public int pop()&#123; return arr[--top]; &#125;&#125; ​ 使用数组 我们将栈中N个元素保存在数组中，索引为N的 数组位置对应栈顶的位置，即下一个元素加入的地方。好，要入栈 我们只需要将心元素加入s[N]，要出栈则移除s[N-1]处的元素 并将N减1。那么能看到使用数组一个根本性的缺点 必须事先声明数组的大小。将元素入栈，我们将元素放在N索引的位置 并将N增加1。这是现在很多编程语言表示使用索引N 并增加1的简洁表示。将元素出栈，我们将索引N减1并用它 返回数组中的元素。每个操作都只需要一行代码。有一个问题 客户端是否能向数据结构中插入空元素。这种情况中，我们 确实允许客户端插入空元素，但在Java中我们需要操心一个问题 叫做对象游离（loitering）,即在栈的数组 实现中有对象的引用，而我们并没有真正使用它 所以当减小N时，在数组中仍然有我们已经出栈 的对象的指针。尽管我们知道我们不再使用它了，但是Java系统 不知道。所以为了避免这个问题，最有效地使用内存 最好将去除的元素对应的项设为null，这样就不会剩下 旧元素的引用。因为不存在引用了接下来垃圾回收器会收回那些内存。这个问题比较细节，但是很重要 我们必须在实现中要确保充分利用内存。 ​ 那么，栈的基本数组实现具有需要 客户端事先提供栈的最大容量的缺点。我们没有 严格按照API的要求。API就是要求我们能够建立一个栈 并且能够增长或者缩小到任意大小。首先会想到的也许是当客户端入栈新元素时 将栈的大小增加1，当出栈时 将栈的大小减小1。代码实现不难，但是不值得这么做，因为这么做 开销太大了。因为你必须创建大小大一个元素的 新的数组，然后把所有的元素复制到新的数组中。所以如果栈大小为N-1 插入N个元素需要的时间和N成正比 如果栈大小为N-2，需要正比于N-1的时间。所以前N个元素需要的时间就是对 前N个整数求和，我们知道这大约是N^2 / 2。往栈里插入N个元素 需要平方时间，我们已经看到过很多次，这样的性能对于 巨大的问题是不可接受的。 ​ 那么，调整大小是个挑战 但要通过某种方式确保它并不会经常发生。处理这个问题 有个著名的方法叫反复倍增，当数组填满时 建立一个大小翻倍的新数组，然后将所有元素复制过去，我们就不会 那么频繁地创建新数组。这就是那个方法的实现。从大小为1的 数组开始。如果我们检测到N即栈中元素的个数与数组 长度相等，则栈满了，那么我们就在插入元素之前 将数组长度调整为两倍。我们如何调整为更大的数组呢？ 我们创建具有目标容量的新的数组，然后把 当前栈复制到新数组的前一半，然后返回 重新设置实例变量，我们的栈就有了更大的数组 这样做导致如果你向一个具有这种 数组表示的栈中插入N个元素，时间复杂度 与N而不是N^2成正比。因为你只有在数组大小翻倍时 才创建新的数组。而当数组翻倍时，你已经往栈里插入了 那么多的元素。所以平均下来就像每次插入只需要一个操作 所以，如果我们计算一下开销，插入前N个元素 你不需要花费从1到N之和的时间，而是 对二的幂从1到N求和 这样，总的开销大约是3N。所以，push 时先要访问数组一次，对于复制 要访问两次。所以，要插入元素，大约需要访问数组三次 这个图标是观察时间开销的另一种方式，表示出了实现 入栈操作需要访问数组的次数。每次遇到2的幂，需要进行那么多次 数组访问，但是从宏观上来看你是将那些元素放在栈上花去了那么多时间 这叫做平摊分析。考虑开销时 将总的开销平均给所有的操作。 ​ ​ 这是一个很好而且 有用的平摊分析的例子，我们分析出了栈实现的效率 出栈呢？我们需要考虑如何缩小数组 我们也许这么考虑，当数组满了的时候将容量翻倍，那么当它 只有一半满的时候，将容量缩减一半。我们不想这样做，这个办法并不如我们所愿解决问题。因为有一种现象叫做 抖动（thrashing）。如果客户端刚好反复交替入栈出栈入栈出栈 当数组满了就会反复翻倍减半翻倍减半，并且 每个操作都会新建数组，都要花掉正比与N的时间 这样就会导致平方时间，我们不想这样 有效的解决方案是直到数组变为1/4满的时候才将容量减半 实现起来也很容易，我们只要测试数组是否为 1/4满，如果是，则调整大小使其为半满。 ​ 这是两种 API相同的不同的实现，客户端可以互换使用。哪个更好呢？ 很多情形中，我们会有同一API的多种实现 你需要根据客户端的性质选择 合适的实现。对于链表，每个操作最坏情况下 需要常数时间，这是有保障的。但是为了处理链接 我们需要一些额外的时间和空间。所以链表实现会慢一些 可调大小的数组实现有很好的分摊时间，所以整个过程 总的平均效率不错，浪费更少的空间，对于每个操作 也许有更快的实现，所以对于一些客户端，也许会有区别 以下这样的情形你不会想用可调大小数组实现 你有一架飞机进场等待降落 你不想系统突然间不能高效运转 或者互联网上的一个路由器，数据包以很高的速度涌进来 你不想因为某个操作突然变得很慢而丢失 一些数据。客户端就可以权衡，如果想要 获得保证每个操作能够很快完成，就使用 链表实现，如果不需要，只是关心总的时间 可能就是用可调大小数组实现，因为总的 时间会小得多，单个操作非常快。","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/tags/数据结构/"}]},{"title":"Java 虚拟机对象布局及创建过程","slug":"JVM/Java-虚拟机对象布局及创建过程","date":"2017-12-10T13:38:50.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/12/10/JVM/Java-虚拟机对象布局及创建过程/","link":"","permalink":"http://lwenxu.coding.me/2017/12/10/JVM/Java-虚拟机对象布局及创建过程/","excerpt":"一. 对象创建过程一、类加载​ 这个阶段其实主要做的就是类的加载验证，以及类的准备等等一系列的工作。为后面的类的初始化和解析做铺垫。","text":"一. 对象创建过程一、类加载​ 这个阶段其实主要做的就是类的加载验证，以及类的准备等等一系列的工作。为后面的类的初始化和解析做铺垫。 二、类解析​ 这个阶段主要对上面已经加载入内存的类进行词法语法的解析，形成语法树等操作。 三、类初始化​ 类初始化执行的就是 &lt;clinit&gt; 方法，以及在类中的各种常量的初始化（放入常量池中的常量）。 四、分配内存​ 虚拟机对所需要创建的对象分配内存，在类的解析的时候其实已经知道实例变量需要的堆空间了。此时只需要调用操作系统的系统调用为当前的对象分配内存即可。 ​ 但是为对象分配内存如果是在大型环境下，肯定是并发的也就是可能会出现正当当前指针分配内存的时候另外一个线程把指针指向了别处，这样一来自然就会出现多线程的安全问题。这里 jvm 通常采用两种方式来解决： 使用操作系统的CAS算法来分配内存，保证分配内存动作的原子性，CAS 也就是 Compare And Save 其算法的基本思想就是拿线程需要改变的变量写入内存之前从内存中读取的值 A 和该变量的最初从内存读取的值 V 进行比较如果他们相等就可以将当前的修改后的值 B 写入内存，否则则放弃当前的操作重新开始尝试。 另外一种就是使用了线程的临时分配表叫做 TLAB 表，每个线程获得一块这样的内存这样一来每个线程就拿到了相互独立的内存空间，只有当 TLAB 表分配没有剩余的时候才使用 CAS 同步操作。 五、内存的初始化​ 虚拟机对这块刚分配的内存进行初始化的时候是非常暴力的或者说简单的，直接使用了 1memset( bf , 0 ) ; 这是真正的 0 值，所以说对象在分配内存以后其实就是可用的，里面的引用类型就是 NULL 而普通变量的内容则是 0 。这个操作其实不一定到现在才进行，如果说我们采用的 TLAB 的方式的话我们只需要在为线程分配 TLAB 表的时候执行那个 memset 函数即可完成内存初始化。 六、对象进行必要的初始化​ 在经过上面的暴力的 0 值初始化之后对象还是不能使用的，因为对象不是一块充满数据的内存，对象里面有一些特殊的标记信息，标识当前对象的状态，这个就叫做对象头也称作 MarkWord ，这里对对象的必要的初始化说的就是对对象头进行设置。比如说 GC 分代年龄，hashCode，偏向锁，偏向 ID，时间戳，线程持有的锁等等。 ​ 至此 jvm 对一个对象的创建才算是真正的完成，但是这个对于 java 程序员来说对象的创建才刚刚开始，因为此时才开始执行用户代码，这个要取决于字节码中是否有 invokespecial 指令，这个指令就会去执行实例的 &lt;init&gt; 方法来初始化对象。 二、对象的内存布局","categories":[{"name":"-Java -虚拟机","slug":"Java-虚拟机","permalink":"http://lwenxu.coding.me/categories/Java-虚拟机/"}],"tags":[{"name":"Java 虚拟机","slug":"Java-虚拟机","permalink":"http://lwenxu.coding.me/tags/Java-虚拟机/"}]},{"title":"Java 虚拟机运行时数据区","slug":"JVM/Java-虚拟机运行时数据区","date":"2017-12-10T12:14:43.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/12/10/JVM/Java-虚拟机运行时数据区/","link":"","permalink":"http://lwenxu.coding.me/2017/12/10/JVM/Java-虚拟机运行时数据区/","excerpt":"运行时数据区：Java 虚拟机的运行时数据区按照大的可以分为线程独立使用的数据区，和所有线程共享的数据区。 一.线程独立使用数据区1.程序计数器 程序计数器其实就是 jvm 里面的pc，他指向的都是字节码的偏移量，也就是下一条要执行的字节码 当然这是 jvm 在执行 java 方法的时候，当程序在执行 navtive 方法的时候这时候起作用的其实是我们物理机上的 pc 此时 jvm 的 pc 是空值（undefine） 并且这个地方也是所有的 jvm 内存区完全不会抛出 OutOfMemary 异常的位置","text":"运行时数据区：Java 虚拟机的运行时数据区按照大的可以分为线程独立使用的数据区，和所有线程共享的数据区。 一.线程独立使用数据区1.程序计数器 程序计数器其实就是 jvm 里面的pc，他指向的都是字节码的偏移量，也就是下一条要执行的字节码 当然这是 jvm 在执行 java 方法的时候，当程序在执行 navtive 方法的时候这时候起作用的其实是我们物理机上的 pc 此时 jvm 的 pc 是空值（undefine） 并且这个地方也是所有的 jvm 内存区完全不会抛出 OutOfMemary 异常的位置 2.虚拟机栈 虚拟机栈其实也就是我们日常所说的堆栈中的栈 他的生命周期是和当前的线程完全一样 当在执行一个新的 java 方法的时候他会在 java 虚拟机栈创建一个栈帧。 栈帧中存放的内容： 局部变量表 操作数栈 动态链接 方法的出入口 局部变量表是一个非常重要的数据结构这里面存放的主要就是这个 java 方法中的局部变量。而这些变量都是在编译时期确定的。后来会看到其实在 class 中有一个 code 属性，这个属性里面会有一个 Local_max 他的作用就是计算当前的方法需要多少个 Slot ，并且注意这个 Slot 并不是局部变量有多少他就会产生多少，而是根据作用域对这些 Slot 进行复用。（这些都是后面 Class 结构部分需要说的，暂时可以放放） 局部变量表存放的数据类型除了一些常用 int，float，char，long，short，double，byte 等等还有两个比较特殊的分别是 returnValue 类型和引用类型 reference 类型，reference 类型其实就是我们常说的当我们创建一个对象的时候 jvm 会在栈上创建一个对象的引用，然后真正的对象数据放在堆上。这里的引用就是 reference 类型变量。当然这个引用并不是一定指向的堆中的那个对象还可能指向的是堆中的句柄池中的一个句柄。（后面会详细解释） 3.本地方法栈 本地方法栈其实就用于执行 Native 方法，也就是本地方法。一般来说 jvm 的规范对这方面没有过多的要求，一般的 jvm 都是直接把本地方法栈和虚拟机栈直接合并了。 本地方法也就是 Native 方法其实这是 Jvm 对外提供的一个接口，这个接口的作用就是使用 java 的接口去调用其他编程语言写的代码，一般一个 Native 方法里面的方法体不是 java 代码，而是去调用其他的编程语言的代码，也就是此时代码就不归 jvm 来管了，此时调用的什么编程语言就由什么编程语言来管，所以说白了这块内存不完全算是 jvm 的内存。例如说 java 调用了 c++代码这时候的方法堆栈就是 c++的堆栈，jvm 这边应该就是用一个指针指向那块内存。java 的这一特性叫做 JNI （Java Native Interface），其实也不是 java 才有这一特性，很多的编程语言都可以这么玩，例如说在 c++中调用 c 代码其实我们用了 extern 这也是类似的。 二.线程共享数据区1. 堆 其实一提到堆我们对他都比较熟悉，也就是我们经常说的和栈结构相对的就是堆了。 一般来说我们会认为所有的对象都是在堆上开辟的，但是当我们了解了 jvm 内部的一些原理之后我们就应该转变这种观念，其实并非所有的对象都是在堆上开辟的主要是现在的 JIT（Just In Time 即时编译技术） 以及对象逃逸造成部分对象是在栈上开辟的。 堆目前也是 jvm 进行内存自动管理的部分，GC 堆。 堆上的内存其实在物理机的内存上不必完全就是连续的。 2.方法区 方法区其实是一个比较复杂的内存区域，里面存放的内容主要为： JIT 即时编译的代码 静态变量 常量池 加载的类和接口的信息 这个区域可以看到里面的东西都不是朝生夕死的一些数据，也就是更换的速率不是很频繁，所以对这个区域的 GC 并不是很对，而且这里的 GC 区域比较困难。部分区域的 GC 条件较为苛刻。 3.常量池​ 常量池其实就是方法区的一部分（当然这是 jdk1.7之前的位置），其实现在（也就是 jdk1.7 以后）java 虚拟机团队把常量池移动到了堆中。这个区域也叫做 “ 永久代 ” （PermGen），但是当前的 jdk1.8 虚拟机团队直接把常量池这个永久代取消了，然后取而代之的叫做元空间（MateSpace）。好吧这里我们还是讨论常量池还存在的情况的吧。之后会专门写关于 jdk1.7 以及1.8 中的做的很大的更改。 ​ 其实在 jdk1.7 之前这个地方主要存放的就是 class 字节码中的常量池的内容以及在运行过程中动态生成的常量。尤其是使用的比较多的 String.intern() 方法。这个方法的主要作用就是当程序第一个遇到这个字符串的时候会把他放入常量池中。然后返回常量池中的引用。 4.直接内存 直接内存是不同于 Native 堆的，因为这个地方主要作用在于进行 NIO 的时候做数据缓冲用的。 NIO 中采用的是通道缓冲区的方式进行 IO 操作的，这里他们为了减少 Java 堆和 Native 堆来回复制数据而采用的一种方式也就是在 java 堆中使用一个 DirectByteBuffer 对象引用这块直接内存然后直接把数据读取到直接内存避免往 Java 堆里面复制。","categories":[],"tags":[{"name":"JVM Java 虚拟机","slug":"JVM-Java-虚拟机","permalink":"http://lwenxu.coding.me/tags/JVM-Java-虚拟机/"}]},{"title":"今日总结20180304","slug":"Life/今日总结20180304.md","date":"2017-12-06T13:36:04.000Z","updated":"2019-09-30T10:04:12.982Z","comments":true,"path":"2017/12/06/Life/今日总结20180304.md/","link":"","permalink":"http://lwenxu.coding.me/2017/12/06/Life/今日总结20180304.md/","excerpt":"","text":"八大排序算法 优先队列 红黑树 并查集 左式堆 栈的应用：逆波兰表达式计算、中缀表达式转后缀表达式 队列应用：杨辉三角、 最大子序列的和：分治、贪心 递归的四大原则： 基准情型：所有的递归都有一个基准，或者说是递归停止的界限，他是无序计算就能够得到的 不断推进：向着基准方向不断的推进，也就是递归的过程。 设计法则：我们假定递归的每一个环节都能运行，也就是我们无需考虑递归甚至调试追踪递归内部的情形 合成效益：不要进行重复的计算. 内部类的作用，静态内部类的特点。 二叉树表示表达式，先序、中序、后序分别代表了对应的表达式 二叉搜索树的定义操作： 判断元素是否存在：递归的在左右子树中查找 查找最小元素：在左子树中递归或者循环 查找最大元素：在右子树中递归或循环 插入：递归的插入，大于则插入在节点的右子树，小于则左子树，等于则是重复节点不作处理 删除：递归删除( 或者说递归查找需要删除的元素 )，找到该元素后，如果元素有两个子节点那么久找到这个元素的右子树的最小元素代替要删除的元素，然后再删除那个右子树上的最小元素。如果只有一个子节点直接让要被删除的节点赋值上他的子节点。","categories":[{"name":"-生活","slug":"生活","permalink":"http://lwenxu.coding.me/categories/生活/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/tags/生活/"}]},{"title":"博客迁移到 coding 了","slug":"Life/博客迁移到-coding-了","date":"2017-12-06T13:36:04.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/12/06/Life/博客迁移到-coding-了/","link":"","permalink":"http://lwenxu.coding.me/2017/12/06/Life/博客迁移到-coding-了/","excerpt":"​ 从这个博客搭建成功到现在已经过了两年了，哎！时间真的过的超快。纪念一下 ：） ​ 但是一直以来我的博客都是托管到 github 上面的，每次最讨厌去访问博客了，做一次翻页我的等几秒，用户体验极差（虽然还是我自己写的，要是别人的博客估计直接一个 ctrl+w 伺候着了 ）。 ​","text":"​ 从这个博客搭建成功到现在已经过了两年了，哎！时间真的过的超快。纪念一下 ：） ​ 但是一直以来我的博客都是托管到 github 上面的，每次最讨厌去访问博客了，做一次翻页我的等几秒，用户体验极差（虽然还是我自己写的，要是别人的博客估计直接一个 ctrl+w 伺候着了 ）。 ​ ​ 后来也是看到简书上有人说使用 coding 也可以部署 hexo 一直想迁移来着，昨天终于是完全的迁移过来了。感觉速度真的没的说，比我用梯子访问 github 不知道快了多少，想着还是要不注册一个域名实名认证一下。那个 fmzero 域名真的没法用，我也就懒得认证了。不知道当时咋想的（让我哭一会，白白浪费一个58的域名）。 ​ 好了，以后还是要认认真真的写博客，毕竟买了这么多书，除了看书还有看博客总会有收获的，不仅仅记录自己的成长我想我能把我的一些东西分享出来也是对自己的提升吧 ：） 加油！！","categories":[{"name":"-杂记","slug":"杂记","permalink":"http://lwenxu.coding.me/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"http://lwenxu.coding.me/tags/杂记/"}]},{"title":"SpingBoot笔记一","slug":"Java Web/SpingBoot笔记一","date":"2017-10-23T14:09:38.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/10/23/Java Web/SpingBoot笔记一/","link":"","permalink":"http://lwenxu.coding.me/2017/10/23/Java Web/SpingBoot笔记一/","excerpt":"","text":"一.目录配置1、Application.java 建议放到跟目录下面,主要用于做一些框架配置 2、domain目录主要用于实体（Entity）与数据访问层（Repository） 3、service 层主要是业务类代码 4、controller 负责页面访问控制 ##二.pom.xml 配置 引入web模块 1、pom.xml中添加支持web的模块： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; pom.xml文件中默认有两个模块： spring-boot-starter：核心模块，包括自动配置支持、日志和YAML； spring-boot-starter-test：测试模块，包括JUnit、Hamcrest、Mockito。 ##三.编写controller内容 1234567@RestControllerpublic class HelloWorldController &#123; @RequestMapping(\"/hello\") public String index() &#123; return \"Hello World\"; &#125;&#125; @RestController的意思就是controller里面的方法都以json格式输出，不用再写什么jackjson配置的了！ 四.单元测试 打开的src/test/下的测试入口，编写简单的http请求来测试；使用mockmvc进行，利用MockMvcResultHandlers.print()打印出执行结果。","categories":[{"name":"-SpringBoot","slug":"SpringBoot","permalink":"http://lwenxu.coding.me/categories/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lwenxu.coding.me/tags/Spring/"}]},{"title":"SpingBoot依赖包","slug":"Java Web/SpingBoot依赖包","date":"2017-10-23T13:23:43.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/10/23/Java Web/SpingBoot依赖包/","link":"","permalink":"http://lwenxu.coding.me/2017/10/23/Java Web/SpingBoot依赖包/","excerpt":"","text":"Spring Boot的启动器Starter详解作者：chszs，转载博客主页：http://blog.csdn.net/chszsSpring Boot应用启动器基本的一共有44种，具体如下： 1）spring-boot-starter这是Spring Boot的核心启动器，包含了自动配置、日志和YAML。 2）spring-boot-starter-actuator帮助监控和管理应用。 3）spring-boot-starter-amqp通过spring-rabbit来支持AMQP协议（Advanced Message Queuing Protocol）。 4）spring-boot-starter-aop支持面向方面的编程即AOP，包括spring-aop和AspectJ。 5）spring-boot-starter-artemis通过Apache Artemis支持JMS的API（Java Message Service API）。 6）spring-boot-starter-batch支持Spring Batch，包括HSQLDB数据库。 7）spring-boot-starter-cache支持Spring的Cache抽象。 8）spring-boot-starter-cloud-connectors支持Spring Cloud Connectors，简化了在像Cloud Foundry或Heroku这样的云平台上连接服务。 9）spring-boot-starter-data-elasticsearch支持ElasticSearch搜索和分析引擎，包括spring-data-elasticsearch。 10）spring-boot-starter-data-gemfire支持GemFire分布式数据存储，包括spring-data-gemfire。 11）spring-boot-starter-data-jpa支持JPA（Java Persistence API），包括spring-data-jpa、spring-orm、Hibernate。 12）spring-boot-starter-data-mongodb支持MongoDB数据，包括spring-data-mongodb。 13）spring-boot-starter-data-rest通过spring-data-rest-webmvc，支持通过REST暴露Spring Data数据仓库。 14）spring-boot-starter-data-solr支持Apache Solr搜索平台，包括spring-data-solr。 15）spring-boot-starter-freemarker支持FreeMarker模板引擎。 16）spring-boot-starter-groovy-templates支持Groovy模板引擎。 17）spring-boot-starter-hateoas通过spring-hateoas支持基于HATEOAS的RESTful Web服务。 18）spring-boot-starter-hornetq通过HornetQ支持JMS。 19）spring-boot-starter-integration支持通用的spring-integration模块。 20）spring-boot-starter-jdbc支持JDBC数据库。 21）spring-boot-starter-jersey支持Jersey RESTful Web服务框架。 22）spring-boot-starter-jta-atomikos通过Atomikos支持JTA分布式事务处理。 23）spring-boot-starter-jta-bitronix通过Bitronix支持JTA分布式事务处理。 24）spring-boot-starter-mail支持javax.mail模块。 25）spring-boot-starter-mobile支持spring-mobile。 26）spring-boot-starter-mustache支持Mustache模板引擎。 27）spring-boot-starter-redis支持Redis键值存储数据库，包括spring-redis。 28）spring-boot-starter-security支持spring-security。 29）spring-boot-starter-social-facebook支持spring-social-facebook 30）spring-boot-starter-social-linkedin支持pring-social-linkedin 31）spring-boot-starter-social-twitter支持pring-social-twitter 32）spring-boot-starter-test支持常规的测试依赖，包括JUnit、Hamcrest、Mockito以及spring-test模块。 33）spring-boot-starter-thymeleaf支持Thymeleaf模板引擎，包括与Spring的集成。 34）spring-boot-starter-velocity支持Velocity模板引擎。 35）spring-boot-starter-webS支持全栈式Web开发，包括Tomcat和spring-webmvc。 36）spring-boot-starter-websocket支持WebSocket开发。 37）spring-boot-starter-ws支持Spring Web Services。 Spring Boot应用启动器面向生产环境的还有2种，具体如下： 1）spring-boot-starter-actuator增加了面向产品上线相关的功能，比如测量和监控。 2）spring-boot-starter-remote-shell增加了远程ssh shell的支持。 最后，Spring Boot应用启动器还有一些替换技术的启动器，具体如下： 1）spring-boot-starter-jetty引入了Jetty HTTP引擎（用于替换Tomcat）。 2）spring-boot-starter-log4j支持Log4J日志框架。 3）spring-boot-starter-logging引入了Spring Boot默认的日志框架Logback。 4）spring-boot-starter-tomcat引入了Spring Boot默认的HTTP引擎Tomcat。 5）spring-boot-starter-undertow引入了Undertow HTTP引擎（用于替换Tomcat）。","categories":[],"tags":[{"name":"Sping","slug":"Sping","permalink":"http://lwenxu.coding.me/tags/Sping/"}]},{"title":"PalindromicSubstrings","slug":"Leet Code/PalindromicSubstrings","date":"2017-10-12T11:58:32.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/10/12/Leet Code/PalindromicSubstrings/","link":"","permalink":"http://lwenxu.coding.me/2017/10/12/Leet Code/PalindromicSubstrings/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041package Classify.DP.Medium;import org.junit.jupiter.api.Test;public class PalindromicSubstrings &#123; /** * 基本思路：这里的 dp 方程的每一个元素就代表我要以当前元素作为回文子串的结尾时候的回文子串的数量 * 那么递推公式就是以上一个元素结尾时候的子串数量加上本次的结尾的子串的数量就能获得总数量了 * 而判断当前结尾的回文子串就是判断到对称的元素，然后翻转操作做判断即可 * @param s * @return */ public int countSubstrings(String s) &#123; int[] dp = new int[s.length()]; dp[0] = 1; for (int i = 1; i &lt; dp.length; i++) &#123; dp[i] = dp[i - 1] + currentCount(s, i); &#125; return dp[s.length() - 1]; &#125; private int currentCount(String string, int i) &#123; int count = 0; for (int j = i; j &gt;= 0; --j) &#123; if (string.charAt(i) != string.charAt(j)) &#123; continue; &#125; if (new StringBuilder(string.substring(j, i + 1)).reverse().toString().equals(string.substring(j, i + 1))) &#123; ++count; &#125; &#125; return count; &#125; @Test public void fun() &#123; System.out.println(countSubstrings(\"aaa\")); &#125;&#125;","categories":[{"name":"-leetcode","slug":"leetcode","permalink":"http://lwenxu.coding.me/categories/leetcode/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"DP刷题记录Medium","slug":"Leet Code/DP刷题记录Medium","date":"2017-10-11T14:09:34.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/10/11/Leet Code/DP刷题记录Medium/","link":"","permalink":"http://lwenxu.coding.me/2017/10/11/Leet Code/DP刷题记录Medium/","excerpt":"","text":"House Robber II 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package Classify.DP.Medium;import org.junit.jupiter.api.Test;public class HouseRobberII &#123; /** * 思路一：这道题的意思就是成一个环，也就是偷了第一个不能头最后一个。 * 所以我们的思路就是让他从第一个偷到倒数第二个 * 从第二个偷到最后一个 * 算两个的最大值 * 思路二：这种方法就是去掉头和尾，计算中间的最大值，然后加上第一个与最后一个中的最大值 * @param nums * @return */ public int rob(int[] nums) &#123; if (nums.length == 0) &#123; return 0; &#125; else if (nums.length == 1) &#123; return nums[0]; &#125; else if (nums.length == 2) &#123; return Math.max(nums[0], nums[1]); &#125; int result1; int result2; int[] dp=new int[2]; dp[0] = 0; dp[1] = nums[0]; int tmp; for (int i = 1; i &lt; nums.length-1; i++) &#123; tmp = dp[0]; dp[0] = Math.max(dp[0], dp[1]); dp[1] = tmp + nums[i]; &#125; result1 = Math.max(dp[0], dp[1]); dp[0] = 0; dp[1] = nums[1]; for (int i = 2; i &lt; nums.length; i++) &#123; tmp = dp[0]; dp[0] = Math.max(dp[0], dp[1]); dp[1] = tmp + nums[i]; &#125; result2 = Math.max(dp[0], dp[1]); return Math.max(result1, result2); &#125; @Test public void fun()&#123; System.out.println(rob(new int[]&#123;1,1,1&#125;)); &#125;&#125; 2 Keys Keyboard 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package Classify.DP.Medium;import org.junit.jupiter.api.Test;/** * Initially on a notepad only one character 'A' is present. You can perform two operations on this notepad for each step: Copy All: You can copy all the characters present on the notepad (partial copy is not allowed). Paste: You can paste the characters which are copied last time. Given a number n. You have to get exactly n 'A' on the notepad by performing the minimum number of steps permitted. Output the minimum number of steps to get n 'A'. Example 1: Input: 3 Output: 3 Explanation: Intitally, we have one character 'A'. In step 1, we use Copy All operation. In step 2, we use Paste operation to get 'AA'. In step 3, we use Paste operation to get 'AAA'. Note: The n will be in the range [1, 1000]. */public class KeysKeyboard &#123; /** * 这题的思路就是 dp 代表的就是当前的 A 的数量,然后我们优先考虑上一步复制过的情况，因为这样能够最快的填满 n 个 A ，但是使用这种情况要注意的就是 * 我们可能上部赋值我们最后收不了尾，所以必须有一个判断就是我们能用上一步的复制的内容填满剩下的 A ，也就是 n % dp[i - 1] == 0 * 里面的内容的意思就是我们使用了上一步的复制的内容那么我们的字符串就直接翻倍，而且我们进行了一次复制，那么我们 count 就得加2 * @param n * @return */ public int minSteps(int n) &#123; if (n == 1) &#123; return 0; &#125; int[] dp = new int[1000]; dp[0] = 1; int paste = 1; int i = 0; int count = 1; while (dp[i] &lt;= n) &#123; ++i; if (n % dp[i - 1] == 0) &#123; paste = dp[i - 1]; dp[i] = dp[i - 1] * 2; ++count; if (paste != 1) &#123; ++count; &#125; &#125; else &#123; dp[i] = dp[i - 1] + paste; ++count; &#125; if (dp[i] == n) &#123; return count; &#125; &#125; return count; &#125; @Test public void fun() &#123; System.out.println(minSteps(10)); &#125;&#125;","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"DP 刷题记录 Easy","slug":"Leet Code/DP刷题记录Easy","date":"2017-10-11T13:28:29.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/10/11/Leet Code/DP刷题记录Easy/","link":"","permalink":"http://lwenxu.coding.me/2017/10/11/Leet Code/DP刷题记录Easy/","excerpt":"","text":"House robber 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package Classify.DP;import org.junit.jupiter.api.Test;public class HouseRobber &#123; /** * 解法一：思路就是一个二维的动态规划问题，然后0代表不偷当前的房子，1就是偷 * 那么就可以写出两个地推公式出来，这次不偷的话就是看上一次的最多的情况，然后如果这次偷那么就上一次肯定没有偷，就可以用上一次的没有偷的加上本次的 * @param nums * @return */ public int rob(int[] nums) &#123; if (nums.length == 0) &#123; return 0; &#125; int[][] dp = new int[nums.length][2]; dp[0][0] = 0; dp[0][1] = nums[0]; int i; for (i = 1; i &lt; nums.length; i++) &#123; dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1]); dp[i][1] = dp[i - 1][0] + nums[i]; &#125; return Math.max(dp[i-1][0], dp[i-1][1]); &#125; /** * 解法二：也就是使用上面的方法然后进行降为，从二维到一维，空间复杂度成 o one * 观察可以发现我们每次进行递推的时候我们只用到了上一步的偷了或者没偷的情况所以我们直接就可以用两个变量来代替 * @param nums * @return */ public int rob_1(int[] nums)&#123; int[] dp=new int[2]; dp[0] = 0; dp[1] = nums[0]; int tmp; for (int i = 1; i &lt; nums.length; i++) &#123; tmp = dp[0]; dp[0] = Math.max(dp[0], dp[1]); dp[1] = tmp + nums[i]; &#125; return Math.max(dp[0], dp[1]); &#125; @Test public void fun()&#123; System.out.println(rob_1(new int[]&#123;1,2,3,43&#125;)); &#125;&#125; Maximum Subarray 12345678910111213141516171819202122package Classify.DP;import org.junit.jupiter.api.Test;public class MaximumSubarray &#123; public int maxSubArray(int[] A) &#123; if (A == null || A.length == 0) return 0; int global = A[0]; int local = A[0]; for (int i = 1; i &lt; A.length; i++) &#123; local = Math.max(A[i], local + A[i]); global = Math.max(local, global); &#125; return global; &#125; @Test public void fun() &#123; System.out.println(maxSubArray(new int[]&#123;-2, 1, -3, 4, -1, 2, 1, -5, 4&#125;)); &#125;&#125; Best Time to Buy and Sell Stock 123456789101112131415161718192021222324252627282930313233package Classify.DP;import org.junit.jupiter.api.Test;public class BestTimeBuyAndSellStock &#123; /** * 思路：这个动态规划问题就是定义 dp 数组就是当前的最大利润。那么递推式就是上一次的最大利润和今天与昨天的差值利润之间的较大的那个，如果是 * 昨天收盘加上今天的的利润还不如仅仅今天的利润大就直接拿今天的否则就拿昨天的 * 也就是这一行！ * dp[1] = Math.max(dp[0] + prices[i] - prices[i - 1], prices[i] - prices[i - 1]); * @param prices * @return */ public int maxProfit(int[] prices) &#123; if (prices.length == 0) &#123; return 0; &#125; int[] dp = new int[2]; int result = 0; for (int i = 1; i &lt; prices.length; i++) &#123; dp[1] = Math.max(dp[0] + prices[i] - prices[i - 1], prices[i] - prices[i - 1]); dp[0] = dp[1]; result = Math.max(dp[1], result); &#125; return result; &#125; @Test public void fun()&#123; System.out.println(maxProfit(new int[]&#123;7, 1, 5, 3, 6, 4&#125;)); &#125;&#125; Climbing Stairs 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package Classify.DP;import org.junit.jupiter.api.Test;public class ClimbingStairs &#123; /** * Time Limit Exceeded 暴力破解法 */ private int count = 0; public int climbStairs(int n) &#123; find(0, n); return count; &#125; private void find(int n,int level) &#123; if (n == level) &#123; count++; return; &#125; else if (n &gt; level) &#123; return; &#125; find(n + 1,level); find(n + 2, level); &#125; /** * 上面的暴力破解的方式导致超时了，其实一般来说绝大多数的 dp 问题都可以使用暴力破解的方法来解决，也就是上面的递归枚举，但是我们知道 dp 的出现就是 * 为了记录一些东西防止重复计算的，也就是为枚举剪枝，所以说还是要用枚举，这里我们定义了 dp 的含义就是到达当前位置的方法数，而递推公式写法就是 * 到达当前位置要么是跳两部要么是跳一步来的。所以递推公式就是 * dp[i] = dp[i - 2] + dp[i - 1]; * 最重要的就是首先要确定 dp 数组的含义 * @param n * @return */ public int climbStairs_1(int n) &#123; int[] dp = new int[n+2]; dp[0] = 0; dp[1] = 1; int i; for (i = 2; i &lt;= n+1; i++) &#123; dp[i] = dp[i - 2] + dp[i - 1]; &#125; return dp[i-1]; &#125; @Test public void fun()&#123; System.out.println(climbStairs_1(10)); &#125;&#125; 以上的题全部都是 Easy 的题，然后也就是我们发现最后我们都可以转为一维的 dp 问题，我们都没设计二维的问题。下一篇开始就是 Mid 的题，估计主要就是类似背包问题的那一类二维的不可分解的问题。","categories":[],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"刷题记录","slug":"Leet Code/刷题记录","date":"2017-10-11T13:26:52.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/10/11/Leet Code/刷题记录/","link":"","permalink":"http://lwenxu.coding.me/2017/10/11/Leet Code/刷题记录/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"动态规划","slug":"Algorithm/动态规划","date":"2017-10-10T12:00:49.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/10/10/Algorithm/动态规划/","link":"","permalink":"http://lwenxu.coding.me/2017/10/10/Algorithm/动态规划/","excerpt":"​ 动态规划一般来说和分治有点类似都是让他们去处理相同的子问题，但是在动态规划里面你会遇到更多的相同子问题。然后我们就会导致很多的重复计算，所以一般我们可以使用递归来完成一个动态规划要完成的任务，但是这样一般会重复计算很多东西，所以动态规划一般就增加了一些矩阵来存放上一次计算的结果。","text":"​ 动态规划一般来说和分治有点类似都是让他们去处理相同的子问题，但是在动态规划里面你会遇到更多的相同子问题。然后我们就会导致很多的重复计算，所以一般我们可以使用递归来完成一个动态规划要完成的任务，但是这样一般会重复计算很多东西，所以动态规划一般就增加了一些矩阵来存放上一次计算的结果。 ​ 例如斐波那契数列，这个如果我们直接使用地柜计算的话，我们会很多重复计算。然后当我们要使用一个阵列计算的时候我们在每一次计算之前我们都需要进行一次判断看看我们目前的结果是不是已经被计算了，如果计算了就相当于查表直接获取答案，否则我们才开始计算。 ​ 状态：状态就是对于每一个字问题都可以使用一个数字 n 来描述这个子问题，如果状态相同就说明他们的答案相同。 ​ 状态也可以有很多维度，例如排列组合就可以使用二维的，距离使用三维的，所谓的维度就是影响这个子问题的因素，也就是上面的那个 n 以及其他自定义的 j 等等！ ​ 状态转移方程：就是使用当前的状态来获取其他的状态。 ​ 一般状态转移方程可以使用 top down 也可使用 bottom up 方法。 ​ 给一个例子：现在有红 绿 蓝 三种颜色的油漆图一面墙，这面墙 红绿 和 绿蓝不能相邻问共有多少中涂色的方法。 ​ 状态：定义长度为 n 的时候的涂色的方法数，然后出事值就是当 n 等于 1 的时候涂色的方法就是三种。但是这样我们发现很难写出状态方程，所以我们就再添加一个维度。第二个维度的意思就是颜色。 于是就可以得到这样的状态转移方程。看起来稍微有点复杂。而我们最后求结果就是 另外一个例子就是骨牌的问题，这个问题就是费时数列的问题，但是我们需要自己进行研究开始的几种情况。","categories":[{"name":"-算法设计","slug":"算法设计","permalink":"http://lwenxu.coding.me/categories/算法设计/"}],"tags":[{"name":"算法设计","slug":"算法设计","permalink":"http://lwenxu.coding.me/tags/算法设计/"}]},{"title":"分治算法","slug":"Algorithm/分治算法","date":"2017-10-10T11:45:57.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/10/10/Algorithm/分治算法/","link":"","permalink":"http://lwenxu.coding.me/2017/10/10/Algorithm/分治算法/","excerpt":"","text":"​ 分治算法分为 “分” 和 “治” 两个部分，所谓的分就是寻找分割点，然后对问题划分成相同的子问题，但是问题的规模变小了，这些步骤其实就是使用递归来完成的。之后就是治的问题，也就是递归里面具体的内容。最后一步就是把所分的结果要合并成为一个完整的结果。 ​ 一个例子就是求出逆序数对，这个就是分治法来计算，首席我们分就是中间划分，分别求左右的两边的逆序数对，然后还需要加上横跨中间的逆序数对即可完成。重点就是横跨中间的逆序数对，中间的如果直接暴力枚举就会出现 n 平方的，所以我们首先对两边分别排序，然后在进行计算，这样复杂度就变成了 n/2 复杂度。","categories":[{"name":"-算法设计","slug":"算法设计","permalink":"http://lwenxu.coding.me/categories/算法设计/"}],"tags":[{"name":"算法设计","slug":"算法设计","permalink":"http://lwenxu.coding.me/tags/算法设计/"}]},{"title":"贪心","slug":"Algorithm/贪心","date":"2017-10-09T14:22:16.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/10/09/Algorithm/贪心/","link":"","permalink":"http://lwenxu.coding.me/2017/10/09/Algorithm/贪心/","excerpt":"","text":"​ 贪心算法，这个算法就是大胆的猜测，然后小心求证！求证一般就是使用反证法进行证明。假如我们说这个顺序是对的，也就是始终选取大的，或者小的，我们就要证明一下我们的猜测正确性。这里的反正方式就是交换顺序发现不符合预期结果原来的结论就是对的。","categories":[{"name":"-算法设计","slug":"算法设计","permalink":"http://lwenxu.coding.me/categories/算法设计/"}],"tags":[{"name":"算法设计","slug":"算法设计","permalink":"http://lwenxu.coding.me/tags/算法设计/"}]},{"title":"枚举","slug":"Algorithm/枚举","date":"2017-10-09T07:14:24.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/10/09/Algorithm/枚举/","link":"","permalink":"http://lwenxu.coding.me/2017/10/09/Algorithm/枚举/","excerpt":"​ 枚举就是尝试所有的可能性，尤其是当我们在确定一个问题是不是的这一类问题中尤其有用，例如说给一堆数，让我我们判断他们是不是素数，或者素数的数量的时候，这里他们就是判断类问题我们就可以使用枚举。 ​ 但是注意这里我们需要考虑的就是枚举的方式，也就是枚举的角度。这里有一个小的例子就是最长回文子串的问题。","text":"​ 枚举就是尝试所有的可能性，尤其是当我们在确定一个问题是不是的这一类问题中尤其有用，例如说给一堆数，让我我们判断他们是不是素数，或者素数的数量的时候，这里他们就是判断类问题我们就可以使用枚举。 ​ 但是注意这里我们需要考虑的就是枚举的方式，也就是枚举的角度。这里有一个小的例子就是最长回文子串的问题。 ​ 首先我们就是用一个最简单的方式就是枚举出所有的字串，然后在这些字串里面找回文串。这样我们首先需要进行枚举就需要 n 平方的复杂度，然后我们还需要 n 的时间去判断这个串是不是回文，那么也就是说我们需要 n 三次方的时间复杂度。 ​ 然后上面的方式枚举的对象就是所有的字串，但是我们仔细就会发现重点在于回文子串的中心，如果我们枚举的是回文子串的中心以及回文的长度，我们就更简单的找到最长回文子串。中心不仅仅就是每一个字符还包括他们之间的缝隙，这样我们就有了 2n + 1 个中心，然后在对他们进行回文判断，最后的时间复杂度也就是 n 平方。 ​ 这里是从 n 三次方降到了 n 平方的复杂度，这样的原因在于我们去掉了很多的无用的字串，第一个枚举的方法就是枚举所有的字串，然后第二个就是仅仅找出那些具有回文形式的字串，这样就少了一个 n 。经常这样思考会慢慢锻炼我们优化时间复杂度的能力。 ​ 并且这里看着是 n 平方其实他根本没有那么多的复杂度，因为每一个中心能找到的会问其实并不多除非我们给的一个串是一个完全相同的字符，这也就是第二种算法的最坏情况。 ​ 其实在枚举的过程中有的枚举并没有必要，因为这些就是用来占用了时间复杂度但是没有给程序带来多大的帮助。然后我们在计算的时候有时候题目给的条件很少，这时候我们就需要使用枚举来增加我们已知的条件。 ​ 再看一个例子就是在一个矩阵中填满数，然后这些数有正有负我们需要获取一个和的最大矩阵。这里我们先不考虑 DP 而是使用枚举的方式来解这道题。因为这道题的内容是静态的，也就是矩阵是不变化的，我们可以使用计算存储，然后再使用排容原理解题。首先我们考虑一维的情况，我们可以新开一个矩阵，这个矩阵的目的就在于把原来的矩阵的到当前位置的和记录下来。这样我们仅仅需要一次的扫描就能获取从 0 到当前位置的和，然后我们可以计算出任何两个点的之间的和，使用排容原理，就是后面的下标的和减去前面的下标的和即可。这样一个最大的和我们就可以使用 n 的复杂度完成。 ​ 然后我们扩展到二维的情况，就是新开一个矩阵，然后每一个位置记录 ( 0 , 0 ) 位置到当前位置的和。至于这个和怎么算还需要一个过程，中间我们还需要构造一个矩阵，这个矩阵就是先计算出每一行的和，也就是我们上面所说的一维的情况，然后再过渡到二维的辅助阵列。 ​ 那么这个算法的复杂度就是一开始我们需要算出这个辅助矩阵的和需要 n 平方的时间，然后需要进行排容原理，也就是我们要枚举左上角和右下角的位置这里就需要 n 的四次方的时间。 ​ 但是这样做还是不够好，也就是我们枚举了每一个矩形，我们只是优化了 计算矩形的和。但是我们可以使用另外一种思路就是枚举左右边界，然后我们计算出上下界，这样的话这里的时间复杂度就是 n 平方乘以我们算出上下界的时间。而我们算上下界的时候因为我们已经指定了宽度所以说这个宽度之间的东西我们可以把它影射成一维的解决即可。","categories":[{"name":"-算法设计","slug":"算法设计","permalink":"http://lwenxu.coding.me/categories/算法设计/"}],"tags":[{"name":"算法设计","slug":"算法设计","permalink":"http://lwenxu.coding.me/tags/算法设计/"}]},{"title":"犒劳一下自己","slug":"Life/犒劳一下自己","date":"2017-09-27T14:31:10.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/27/Life/犒劳一下自己/","link":"","permalink":"http://lwenxu.coding.me/2017/09/27/Life/犒劳一下自己/","excerpt":"","text":"​ 心情不好的时候，可能这时候真的已经很疲惫了。 ​ 不要继续沮丧让自己的心情更糟糕，或许这个时候应该犒劳一下自己，让自己的心情放松，晴朗起来或许一切看起来回事那么情切舒服！","categories":[{"name":"-杂文","slug":"杂文","permalink":"http://lwenxu.coding.me/categories/杂文/"}],"tags":[{"name":"杂文","slug":"杂文","permalink":"http://lwenxu.coding.me/tags/杂文/"}]},{"title":"HouseRobberIII","slug":"Leet Code/HouseRobberIII","date":"2017-09-27T14:12:07.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/27/Leet Code/HouseRobberIII/","link":"","permalink":"http://lwenxu.coding.me/2017/09/27/Leet Code/HouseRobberIII/","excerpt":"","text":"The thief has found himself a new place for his thievery again. There is only one entrance to this area, called the “root.” Besides the root, each house has one and only one parent house. After a tour, the smart thief realized that “all houses in this place forms a binary tree”. It will automatically contact the police if two directly-linked houses were broken into on the same night. Determine the maximum amount of money the thief can rob tonight without alerting the police. Example 1: 12345 3 / \\2 3 \\ \\ 3 1 Maximum amount of money the thief can rob = 3 + 3 + 1 = 7. Example 2: 12345 3 / \\ 4 5 / \\ \\ 1 3 1 Maximum amount of money the thief can rob = 4 + 5 = 9. 所以说纯粹是怎么多怎么来，那么这种问题是很典型的递归问题，我们可以利用回溯法来做，因为当前的计算需要依赖之前的结果，那么我们对于某一个节点，如果其左子节点存在，我们通过递归调用函数，算出不包含左子节点返回的值，同理，如果右子节点存在，算出不包含右子节点返回的值，那么此节点的最大值可能有两种情况，一种是该节点值加上不包含左子节点和右子节点的返回值之和，另一种是左右子节点返回值之和不包含当期节点值，取两者的较大值返回即可： 1234567891011121314//直接使用递归public int rob(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int var = 0; if (root.left != null) &#123; var += rob(root.left.left) + rob(root.left.right); &#125; if (root.right != null) &#123; var += rob(root.right.left) + rob(root.right.right); &#125; return Math.max(root.val + var, rob(root.right) + rob(root.left));&#125; 由于上面的方法超时了，所以我们必须优化上面的方法，上面的方法重复计算了很多地方，比如要完成一个节点的计算，就得一直找左右子节点计算，我们可以把已经算过的节点用哈希表保存起来，以后递归调用的时候，现在哈希表里找，如果存在直接返回，如果不存在，等计算出来后，保存到哈希表中再返回，这样方便以后再调用，参见代码如下： 123456789101112131415161718192021222324//使用hash 表对多余的递归进行优化public int rob_1(TreeNode root) &#123; HashMap&lt;TreeNode, Integer&gt; map = new HashMap&lt;&gt;(); return dfs(root, map);&#125;private int dfs(TreeNode root, HashMap&lt;TreeNode, Integer&gt; map) &#123; if (root == null) &#123; return 0; &#125; if (map.containsKey(root)) &#123; return map.get(root); &#125; int var = 0; if (root.left != null) &#123; var += dfs(root.left.right, map) + dfs(root.left.left, map); &#125; if (root.right != null) &#123; var += dfs(root.right.left, map) + dfs(root.right.right, map); &#125; int max = Math.max(var + root.val, dfs(root.left, map) + dfs(root.right, map)); map.put(root, max); return max;&#125; 下面再来看一种方法，这种方法的递归函数返回一个大小为2的一维数组res，其中res[0]表示不包含当前节点值的最大值，res[1]表示包含当前值的最大值，那么我们在遍历某个节点时，首先对其左右子节点调用递归函数，分别得到包含与不包含左子节点值的最大值，和包含于不包含右子节点值的最大值，那么当前节点的res[0]就是左子节点两种情况的较大值加上右子节点两种情况的较大值，res[1]就是不包含左子节点值的最大值加上不包含右子节点值的最大值，和当前节点值之和，返回即可，参见代码如下： 12345678910111213public int rob_2(TreeNode root) &#123; int[] result = dfs_1(root); return Math.max(result[0], result[1]); &#125; private int[] dfs_1(TreeNode root) &#123; if (root == null) &#123; return new int[]&#123;0, 0&#125;; &#125; int[] left = dfs_1(root.left); int[] right = dfs_1(root.right); return new int[]&#123; Math.max(left[0], left[1]) + Math.max(right[0], right[1]),root.val + left[0] + right[0]&#125;; &#125; 整理于：http://www.cnblogs.com/grandyang/p/5275096.html","categories":[],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://lwenxu.coding.me/tags/动态规划/"}]},{"title":"Target Sum","slug":"Leet Code/TargetSum","date":"2017-09-27T13:32:05.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/27/Leet Code/TargetSum/","link":"","permalink":"http://lwenxu.coding.me/2017/09/27/Leet Code/TargetSum/","excerpt":"","text":"You are given a list of non-negative integers, a1, a2, …, an, and a target, S. Now you have 2 symbols + and -. For each integer, you should choose one from + and - as its new symbol. Find out how many ways to assign symbols to make sum of integers equal to target S. Example 1:Input: nums is [1, 1, 1, 1, 1], S is 3.Output: 5Explanation: -1+1+1+1+1 = 3+1-1+1+1+1 = 3+1+1-1+1+1 = 3+1+1+1-1+1 = 3+1+1+1+1-1 = 3 There are 5 ways to assign symbols to make the sum of nums be target 3.Note:The length of the given array is positive and will not exceed 20.The sum of elements in the given array will not exceed 1000.Your output answer is guaranteed to be fitted in a 32-bit integer. 这题主要就是给一个算式，然后让我们填符号，要是最后的算式的结果等于一个特定的数，现在发现这种阶梯方法比较好就使用了动态规划，里面具体的东西就是递归求解了。 与此类似的体还有很多就是台阶问题等等，都可以使用类似的方法求解！ 123456789101112131415161718192021package LeetCode;public class TargetSum &#123; int count = 0; public int findTargetSumWays(int[] nums, int S) &#123; calculate(nums, 0, 0, S); return count; &#125; private void calculate(int[] nums,int i,int sum,int S)&#123; if (i == nums.length) &#123; if (sum == S) &#123; count++; &#125; &#125;else &#123; calculate(nums, i + 1, sum + nums[i], S); calculate(nums, i + 1, sum - nums[i], S); &#125; &#125;&#125;","categories":[],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://lwenxu.coding.me/tags/动态规划/"}]},{"title":"QueueReconstructionbyHeight","slug":"Leet Code/QueueReconstructionbyHeight","date":"2017-09-27T13:29:51.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/27/Leet Code/QueueReconstructionbyHeight/","link":"","permalink":"http://lwenxu.coding.me/2017/09/27/Leet Code/QueueReconstructionbyHeight/","excerpt":"","text":"Suppose you have a random list of people standing in a queue. Each person is described by a pair of integers (h, k), where h is the height of the person and k is the number of people in front of this person who have a height greater than or equal to h. Write an algorithm to reconstruct the queue. Note:The number of people is less than 1,100. Example Input:[[7,0], [4,4], [7,1], [5,0], [6,1], [5,2]] Output:[[5,0], [7,0], [5,2], [6,1], [4,4], [7,1]] 这道题给了我们一个队列，队列中的每个元素是一个pair，分别为身高和前面身高不低于当前身高的人的个数，让我们重新排列队列，使得每个pair的第二个参数都满足题意。 基本思路： 首先按照高度排序，如果两个人的高度一样的话我们就就按照第二个数字排序 最后把他们插入到一个新的数组里面，就按照他们的第二个数字的下标，插入到对应的下标 1234567891011121314151617181920212223242526272829303132333435package LeetCode;import java.util.ArrayList;import java.util.Arrays;import java.util.Comparator;import java.util.List;public class QueueReconstructionbyHeight &#123; public int[][] reconstructQueue(int[][] people) &#123; if (people == null || people.length == 0) &#123; return people; &#125; Arrays.sort(people, new Comparator&lt;int[]&gt;() &#123; @Override public int compare(int[] p1, int[] p2) &#123; return p1[0] == p2[0] ? p1[1] - p2[1] : p2[0] - p1[0]; &#125; &#125;); List&lt;int[]&gt; temp = new ArrayList&lt;&gt;(); for (int[] aPeople : people) &#123; if (people.length == aPeople[1]) &#123; temp.add(aPeople); &#125; else &#123; temp.add(aPeople[1], aPeople); &#125; &#125; int ans[][] = new int[people.length][2]; for (int i = 0; i &lt; temp.size(); i++) &#123; ans[i] = temp.get(i); &#125; return ans; &#125;&#125;","categories":[],"tags":[{"name":"排序","slug":"排序","permalink":"http://lwenxu.coding.me/tags/排序/"}]},{"title":"Dp经典问题LongestIncreasingSubsequence","slug":"Leet Code/Dp经典问题LongestIncreasingSubsequence","date":"2017-09-27T13:26:51.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/27/Leet Code/Dp经典问题LongestIncreasingSubsequence/","link":"","permalink":"http://lwenxu.coding.me/2017/09/27/Leet Code/Dp经典问题LongestIncreasingSubsequence/","excerpt":"","text":"Given an unsorted array of integers, find the length of longest increasing subsequence. For example, Given [10, 9, 2, 5, 3, 7, 101, 18], The longest increasing subsequence is [2, 3, 7, 101], therefore the length is 4. Note that there may be more than one LIS combination, it is only necessary for you to return the length. Your algorithm should run in O(n2) complexity. Follow up: Could you improve it to O(n log n) time complexity? Credits: Special thanks to @pbrother for adding this problem and creating all test cases. 思路： 这道题主要考察的就是动态规划 如果使用暴力破解的方式要么就是超时要么就是空间超出限制 然后动态规划的方法就是：使用一个 dp 数组然后在这个 dp 数组记录的内容就是党目前为止的最长的子序列 1234567891011121314151617181920212223242526272829303132333435363738package LeetCode;import org.junit.jupiter.api.Test;import java.util.Arrays;public class LongestIncreasingSubsequence &#123; public int lengthOfLIS(int[] nums) &#123; if (nums.length == 0) &#123; return 0; &#125; int[] dp = new int[nums.length]; Arrays.fill(dp,0); dp[0] = 1; int maxans = 1; for (int i = 1; i &lt; dp.length; i++) &#123; int maxval = 0; for (int j = 0; j &lt; i; j++) &#123; if (nums[i] &gt; nums[j]) &#123; maxval = Math.max(maxval, dp[j]); &#125; &#125; dp[i] = maxval + 1; maxans = Math.max(maxans, dp[i]); &#125; System.out.println(LeetcodeUtils.integerArrayToString(dp));; return maxans; &#125; @Test public void fun()&#123; lengthOfLIS(new int[]&#123;4,10,4,3,8,9&#125;); &#125;&#125;","categories":[],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://lwenxu.coding.me/tags/动态规划/"}]},{"title":"烦躁","slug":"Life/烦躁","date":"2017-09-25T07:44:25.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/25/Life/烦躁/","link":"","permalink":"http://lwenxu.coding.me/2017/09/25/Life/烦躁/","excerpt":"​ 下午两点过一点，从宿舍走出来，外面还是淅淅沥沥下着小雨。心里不是很舒服，一直不喜欢下雨，阴冷的天气，总是让人觉得不适，什么都不适合，不适合上课不适合看书，就想让人躺在床上。躺在床上就不经意间会回忆到以前，想到种种。","text":"​ 下午两点过一点，从宿舍走出来，外面还是淅淅沥沥下着小雨。心里不是很舒服，一直不喜欢下雨，阴冷的天气，总是让人觉得不适，什么都不适合，不适合上课不适合看书，就想让人躺在床上。躺在床上就不经意间会回忆到以前，想到种种。 ​ 算了不管了，还是去实验室一个人清净一会，这里就我一个人。拉上窗帘根本看不到外面在下雨，就好像一个晴天的夜晚。 ​ 打开电脑准备看看 Coursera 上面的算法，可是静不下心来，真的静不下心来！我尽力让自己平静，关掉了窗口，算了！刷题吧，连续点开了三道中档题，没有一个有思路的，题目太长，看到题目的第一眼我就觉得我没有办法再看下去了…. ​ QQ 上好像有消息，成绩和对的表格。排名并不好看，六级没加分，没参加任何比赛，没有任何团体活动。之后随随便便看了几个人的就关掉了。为什么突然心里落差这么大？ ​ 再次回到 leetcode 这次更加烦躁了，突然想到是不是自己太差劲了，好像没什么值得自己或者能让自己感到骄傲的，反而失败的地方好像更多！","categories":[],"tags":[]},{"title":"刷题列表","slug":"Leet Code/刷题列表","date":"2017-09-25T07:21:33.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/25/Leet Code/刷题列表/","link":"","permalink":"http://lwenxu.coding.me/2017/09/25/Leet Code/刷题列表/","excerpt":"","text":"动态规划 Longest Increasing Subsequence Best Time to Buy and Sell Stock with Cooldown ​","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"1-d range","slug":"Algorithm/1-d-range","date":"2017-09-25T07:02:37.000Z","updated":"2019-03-14T23:15:14.000Z","comments":true,"path":"2017/09/25/Algorithm/1-d-range/","link":"","permalink":"http://lwenxu.coding.me/2017/09/25/Algorithm/1-d-range/","excerpt":"​ 1d range 的问题主要就是讨论，在某两个符号之间存在多少个其他的符号。首先这里用到了二叉排序树，然后我们利用了二叉排序树的 rank 操作就能直接得到两个符号之间的 range 数","text":"​ 1d range 的问题主要就是讨论，在某两个符号之间存在多少个其他的符号。首先这里用到了二叉排序树，然后我们利用了二叉排序树的 rank 操作就能直接得到两个符号之间的 range 数","categories":[{"name":"-数据结构与算法","slug":"数据结构与算法","permalink":"http://lwenxu.coding.me/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/tags/数据结构/"}]},{"title":"平衡搜索树","slug":"Algorithm/平衡搜索树","date":"2017-09-24T11:13:44.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/09/24/Algorithm/平衡搜索树/","link":"","permalink":"http://lwenxu.coding.me/2017/09/24/Algorithm/平衡搜索树/","excerpt":"2-3树​ 其实仔细来看2-3树好像是 B 树的一个特例，它规定了一个节点要么有一个 key 要么有两个 key。 如果有一个 key 那么他就有两个子节点，左边小于这个 key 右边大于这个 key 如果有两个 key 那么他就有三个子节点，左边小于，中间处于两者之间，右边大于","text":"2-3树​ 其实仔细来看2-3树好像是 B 树的一个特例，它规定了一个节点要么有一个 key 要么有两个 key。 如果有一个 key 那么他就有两个子节点，左边小于这个 key 右边大于这个 key 如果有两个 key 那么他就有三个子节点，左边小于，中间处于两者之间，右边大于 ​ 这样一来就会发现他其实也会处在插入的时候出现分裂的情况，当一个节点需要插入的时候我们先让他插入，这时候可能出现一个节点有三个 key 的情况，我们就打出四个分支，然后我们把中间的那个 key 分裂到父节点，然后左右的 key 分别作为左右子节点。 ​ 这时候我们能够发现当且仅当我们的根节点分裂的时候我们的 2-3 树的高度才会真正的加一。这也是和 B 树的性质相似的。 ​ 2-3 树最好情况就是当所有的节点都是 3 key 节点的时候，这时候我们的树高度最小，而最坏情况自然也就是一个二叉树的时候。 红黑树红黑树我们可以把它看做为 2-3 树的变种，也就是说我们可以在 2-3 上进行一些改造生成对应的红黑树。一般来说我们就是将那些具有三个子节点的节点拆分成两个节点，key 大的那个作为根，小的那个作为左子节点，然后他们之间使用红色连接起来（用红色连接的意思就是父节点是黑的，子节点是红的），也就可以看出红黑树更偏向于左边。下面是一个具体的例子： 红黑树的三个基本操作：左旋转​ 从第一个图到第二个，这个在什么情况下需要呢？当我们插入一个新节点的时候我们发现插入后就是图一的情况，这时候我们还原到 2-3 树我们发现因为 s 节点更大，所以 s 节点应该是根节点， e 节点应该是 s 节点的子节点才对。所以产生了这样的操作！ ​ 所以说，当我们插入一个节点的时候我们发现插入到了右边的节点了我们就需要左旋转进行调整。 右旋转右旋转刚和和左旋转相反。 颜色翻转颜色翻转就是 当红黑树是这种情况的时候我们会发现他对应的 2-3 树是有问题的，需要进行分裂，所以说这里的颜色翻转就是把他的子节点都表示为黑色，自己变成红色。 红黑树的插入操作上面看到了关于红黑树的三个基本操作，这三个操作其实在我们插入的时候都是用的上的，并且重要的是在 AVL 树我们也可以仿照这种思想去完成平衡操作。 上面一般就是我们进行插入的时候会遇到的所有需要处理的情况。 首先看第一个，就是在插入的时候 C 被插入到了左节点，这时候根据 2-3 树的规定我们是需要进行旋转的，把 C 作为根节点，就类似于把 C 提起来，然后 A 节点随着重力到达左节点。也就是左旋转 第二种情况就是左右节点都是红节点的时候我们就需要进行颜色翻转，让左右子节点都变黑，根节点边城红节点 第三种情况一开始属于有两个连续的红节点在左边，这时候我们仅仅需要进行一次右旋转就变成了第二种情况了 第四种情况我们可以看到首先进行一次左旋转，然后右旋转又再次回到了第二种情况，也就是颜色翻转 所以说无论怎么变化我们只需要这三个基本操作我们就可以保证红黑树的性质不被破坏。 所以最终的代码就是 ​ 我们的 AVL 树完全可以按照这个套路在接着写。","categories":[{"name":"-数据结构与算法","slug":"数据结构与算法","permalink":"http://lwenxu.coding.me/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/tags/数据结构/"}]},{"title":"优先队列","slug":"Algorithm/优先队列","date":"2017-09-24T02:23:12.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/09/24/Algorithm/优先队列/","link":"","permalink":"http://lwenxu.coding.me/2017/09/24/Algorithm/优先队列/","excerpt":"优先队列基本介绍​ 优先队列又叫做堆，他是一种比较特殊的完全二叉树。所谓完全二叉树就是一层层的堆叠，本层不满就不能堆放下一层。并且优先队列还有一个特点就是如果他是大根堆那么父节点不小于子节点，如果是小根堆父节点不大于子节点。这也是一个递归定义。","text":"优先队列基本介绍​ 优先队列又叫做堆，他是一种比较特殊的完全二叉树。所谓完全二叉树就是一层层的堆叠，本层不满就不能堆放下一层。并且优先队列还有一个特点就是如果他是大根堆那么父节点不小于子节点，如果是小根堆父节点不大于子节点。这也是一个递归定义。 为什么要是用优先队列？ 首先如果我们需要查找一个第 k 大的数字，毫无疑问这个是最方便的 他的插入操作和删除操作都是 logn 的复杂度，所以说他是最经济的方式 优先队列的常用操作插入插入的时候我们一般采用的方式就是上滤，也就是把要插入的元素放在最后面，然后比较让这个元素向上冒，知道正确的位置。 123456789101112131415161718192021//插入 public void insert(int x) &#123; if (size &gt; ele.length - 1) &#123; return; &#125; //不使用0号元素 ele[++size] = x; swim(size); &#125; //上滤操作 private void swim(int index) &#123; while (index / 2 &gt; 0) &#123; if (ele[index] &gt; ele[index / 2]) &#123; int tep = ele[index]; ele[index] = ele[index / 2]; ele[index / 2] = tep; &#125; index = index / 2; &#125; &#125; 删除操作​ 在删除的时候我们再删除了最上面的元素之后我们还需要调整堆的平衡，这个时候我们采取的策略就是下滤，首先用最后一个元素代替要删除的那个元素，然后对该元素进行下滤，直到平衡。 123456789101112131415161718192021222324252627//删除元素 public int deleteMax()&#123; int max = ele[1]; ele[1] = ele[size--]; sink(1); return max; &#125; //下滤 private void sink(int i) &#123; int index = i; int tmp = ele[i]; while (i * 2 &lt; size) &#123; int next = i * 2; if (ele[next + 1] &gt; ele[next]) &#123; ++next; &#125; if (ele[next] &gt; tmp) &#123; // int temp = ele[index]; ele[index] = ele[next]; // ele[next] = temp; index = next; &#125; i = next; &#125; ele[index] = tmp; &#125; 堆排序​ 优先队列的很好的一个使用就是堆排序，他有比较好的性能，和优点。 堆排序分为两个步骤： 首先我们需要把一个无序的数组构建成一个优先队列，这个过程我们是从下往上进行的，也就是从它有两个孩子的节点开始依次向上上滤操作。 这样我们就建立了一个完整的优先队列了，接下来就是类似于删除最大元素最小元素的问题了。 然后我们只需要把最大或者最小的元素同最后一个元素交换，然后再次下滤就可以了。这一步就类似于删除顶点元素，的步骤。 这样我们就完成了整个的堆排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class HeapSort &#123; //下滤操作 public void sink(int[] arr,int i,int end) &#123; int index = i; int tmp = arr[i]; while (i * 2 &lt;= end) &#123; int n = i * 2; if (n+1&lt;=end&amp;&amp;arr[n] &gt; arr[n + 1]) &#123; ++n; &#125; if (arr[n] &lt; tmp) &#123; arr[index] = arr[n]; index = n; &#125; i = n; &#125; arr[index] = tmp; &#125; public void sort(int[] arr) &#123; //构建堆 for (int i = arr.length / 2; i &gt; 0; i--) &#123; sink(arr, i, arr.length - 1); &#125; //从堆序生成顺序 int size = arr.length - 1; while (size &gt; 0) &#123; int tmp = arr[1]; arr[1] = arr[size]; arr[size] = tmp; --size; sink(arr, 1, size); &#125; &#125; @Test public void fun()&#123; int[] arr = new int[]&#123;0, 7, 2, 5, 8, 3, 9&#125;; sort(arr); System.out.println(arr); &#125;&#125; ​ 三大排序的分析三大排序就是快排，堆排序，归并排序。 堆排序的优势在于它能够在最坏的情况下使用 NLogN 的复杂度，并且在不借助辅助空间的情况下完成排序 归并当然也是最坏的情况为 NLogN 时间复杂度，但是他需要借助线性的辅助空间 快排虽然不需要借助空间，但是时间复杂度没有让人满意，最坏情况快排的复杂度到了平方级别。 看起来貌似堆排序是最完美的排序算法，但是其实不是的，下面就是一些缺点： 他的内部循环的次数要高于快排 在现代计算机上我们主存其实也不是很大的问题，这个时候归并其实也没什么不好 他是不稳定的排序算法 常见排序算法的复杂度","categories":[{"name":"-数据结构与算法","slug":"数据结构与算法","permalink":"http://lwenxu.coding.me/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/tags/数据结构/"}]},{"title":"排序算法","slug":"Algorithm/排序算法","date":"2017-09-23T07:35:56.000Z","updated":"2019-01-30T22:10:30.000Z","comments":true,"path":"2017/09/23/Algorithm/排序算法/","link":"","permalink":"http://lwenxu.coding.me/2017/09/23/Algorithm/排序算法/","excerpt":"选择排序：​ 选择排序一般来说就是，我们 始终从中右边的序列中找出那些最小的元素，放在左侧，这样我们就能保证左边始终有序。 ​ 但是这个算法的复杂度比较高，为$$n^2/2$$​ 那为什么是这个值，假若我们放一张 n x n 的表格，然后我们在排序的过程中用灰色表示不变的元素，然后用黑色表示变化的元素。这样一来我们会发现这个表格是一个以对角线分隔的一个矩阵。很统一看到我们进行了二分之一的 n^2 扫描。","text":"选择排序：​ 选择排序一般来说就是，我们 始终从中右边的序列中找出那些最小的元素，放在左侧，这样我们就能保证左边始终有序。 ​ 但是这个算法的复杂度比较高，为$$n^2/2$$​ 那为什么是这个值，假若我们放一张 n x n 的表格，然后我们在排序的过程中用灰色表示不变的元素，然后用黑色表示变化的元素。这样一来我们会发现这个表格是一个以对角线分隔的一个矩阵。很统一看到我们进行了二分之一的 n^2 扫描。 ​ 这个算法的另外一个问题就是无论我们的序列本来是否有序，我们都需要不停地扫描，所以说这个不存在最好情况和最坏情况，一直都效率不高。 插入排序：​ 插入排序的算法过程和选择排序类似，这是这个地方我们始终让左边的序列保持有序，然后把剩下的那些无序的元素一个个插入到有序序列之中。或许你已经明白了整整比较消耗时间的就是插入操作，我们又需要不停地移动着数组。但是这就有一个好处就是当我们序列比较有序的时候我们所做的操作非常少，甚至当序列完全有序的时候我们只需要进行 n 次比较而已。他的算法复杂度比上面的要好一点,为$$n^2/4$$同样的我们可以画一个矩阵，最终我们会发现有黑色全部在对角线下面，而且对角线下面只有一半是黑色的，因此就是 1/4 希尔排序：​ 希尔排序事实上可以看做插入排序的一个变种，他是首先进行了分组，然后在组内进行了插入排序，这样改造后的性能提高了很多。重点就在于如何进行分组的问题，希尔自己提出的方法就是使用 n/3 也就是每一次步长减少 n/3 归并排序：​ 归并排序是比较有名的排序，这个排序的思想就是归和并，所谓的归就是递归，递归的去求左右子序列。而并就是最后需要合并这些子序列。这个算法一般需要一个辅助数组来支撑，也就是把两个子序列合并成一个新的数组的时候，需要这个辅助数组，最后还需要把他拷贝回去。下面是归并的流程图。 ​ ​ 除了这种使用递归的方式我们还可以从下到上的进行合并操作，也就是我们合并操作不变，但是把递归改成循环了，这里就用到了双循环，首先两两排序，然后两两合并。有点类似于希尔排序了。但是这种方式的算法复杂度并没有改变依然就是 nlogn ​ 对于这种比较高级的排序我们可以做一定的优化让他们支持所中情况下的排序。首先这个归并排序并不适合于少量的数据，少量的数据的时候我们使用分治循环是很不划算的，我们可以在归并排序前面添加一些判断条件，当数组的容量少于多少的时候我们可以采用插入排序，这样算法更具有通用性。 ​","categories":[{"name":"-数据结构与算法","slug":"数据结构与算法","permalink":"http://lwenxu.coding.me/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/tags/数据结构/"}]},{"title":"并查集","slug":"Algorithm/并查集","date":"2017-09-23T01:07:18.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/09/23/Algorithm/并查集/","link":"","permalink":"http://lwenxu.coding.me/2017/09/23/Algorithm/并查集/","excerpt":"​ 在我们需要判断某一些事物之间是否存在一定的关系的时候，我们最好的办法不是使用图而是使用并查集。因为我们关心的是他们之间是否有关系，而不是关心的他们到底存在怎样的关系。 ​ 并查集，简单来说就是 n 个集合，我们通过 union 操作来建立两个节点之间的关系。通过 connected 来判断两个节点之间的关系。那么现在我们知道了 并查集的基本操作就是 union 和 connected 。","text":"​ 在我们需要判断某一些事物之间是否存在一定的关系的时候，我们最好的办法不是使用图而是使用并查集。因为我们关心的是他们之间是否有关系，而不是关心的他们到底存在怎样的关系。 ​ 并查集，简单来说就是 n 个集合，我们通过 union 操作来建立两个节点之间的关系。通过 connected 来判断两个节点之间的关系。那么现在我们知道了 并查集的基本操作就是 union 和 connected 。 逻辑结构：并查集一开始我们初始化都是初始化 n 个不相关的独立集合。然后我们在做 union 操作的时候也就是让两个集合进行合并，所谓的合并操作就是让 connected 操作在应用于这两个元素的时候能返回同一个集合我们就逻辑上认为他们处于同一个集合内。 物理结构:现在我们大致对逻辑结构有了了解，就是集合的合并，以及判断两个元素是否在同一个集合。对于这种问题我们可以使用一个数组来对元素进行存储。这里我们维护一个 id 数组，一开始我们数组存放的就都是自己的下标，这个时候我们认为他们相互独立，当我们需要进行合并操作的时候我们只需要把一个集合的元素 id 值改成另外一个集合的元素的下标即可。这时也许你已经想到了那么 connected 操作就是判断这个 id 内容是否相等就可以了。这里确实也如此！ 代码实现的第一个版本：​ 此时大概了解他们的物理结构和逻辑结构以后我们就可以开始写代码了。 123456789101112131415161718192021222324252627public class QuickFindUF &#123; private int[] id; QuickFindUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; id.length; i++) &#123; id[i] = i; &#125; &#125; public boolean connected(int p, int q) &#123; return id[p] == id[q]; &#125; public void union(int p, int q) &#123; int pid = id[p]; int qid = id[q]; if (pid == qid) &#123; return; &#125; for (int i = 0; i &lt; id.length; i++) &#123; if (id[i] == pid) &#123; id[i] = qid; &#125; &#125; &#125;&#125; ​ 可以看到以上的代码我们就是维护了一个 id 数组，然后我们根据这个 id 数组进行判断是否联通，以及使用它进行合并操作，也许你已经发现了这个代码的 connected 操作的时间复杂度是常数，但是 union 操作的代价却是 n平方（为什么是 n 平方而不是 n，因为每一次合并的代价是 n 而一般我们最坏情况需要进行 n 次的合并所以就是 n 平方数量级），所以说当我们在处理很大数据量的时候这个复杂大是完全不可以接受的，一般10亿数据在 n 平方的复杂度下面需要的时间大概是 30 年，而 n 复杂度可能就是几秒钟的事情，所以我们说 n 平方是不可接受的慢。 代码实现的第二个版本：​ 好了上面我们已经分析了第一个版本的代码对于 union 操作的代价太高，所以我们不得不想办法对其进行优化，否则这个算法面对大量的数据是无法使用的。上面的第一个版本我们可以称之为 快速查找 因为他只用了常数的时间完成了操作。 ​ 接下来需要看一个快速合并的例子，来改进上述的代码。 12345678910111213141516171819202122232425262728public class QuickUnionUF &#123; private int[] id; QuickUnionUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; id.length; i++) &#123; id[i] = i; &#125; &#125; private int root(int x) &#123; while (x != id[x]) &#123; x = id[x]; &#125; return x; &#125; public boolean connected(int p, int q) &#123; return root(p) == root(q); &#125; public void union(int p, int q) &#123; if (connected(p, q)) &#123; return; &#125; id[p] = q; &#125;&#125; ​ 这里我们改进的思想就是让这个集合成为一棵树，然后我们在合并的时候只需要调整一次根节点就好了，这样复杂度瞬间就降低了，但是有一个问题就是查找的复杂度变高了，因为此时我们存放的不是一个同一个根节点，而是有可能是一些中间节点，我们为了能够查找我们必须去寻找这个节点的根节点。如下图。无偶一我们需要一个 root 方法帮我们找到他们的根节点。 ​ 现在合并只需要线性的时间，但是我们查找则需要 n 最坏的情况就是我们要找的节点刚好就一个子树的最下面的节点，而且这个树根只有一个子节点。也就是极左或者极右的那种。 代码实现的第三个版本：​ 现在看起来这个数据结构已经比较完美了，合并和查找的时间都比较短，但是仔细想想在上面进行合并的时候我们并没有规定怎么合并，我们只是说了合并就是把一个树的根作为另外一棵树的子树。也许你已经想到了，有时候我们把一颗大的树作为小的树子树会导致树高度变高。这样显然是不明智的，比较好的做法就是把小树作为大树的子树。这里我们采用了权重，我们所说的权重就是树的大小 注意是树的大小而不是树的高度，这样我们就只需要再维护一个权重的数组就可以了，每次在合并的时候只需要进行一下判断就能避免树高度大幅度增加，导致不必要的查找开销。 123456789101112131415161718192021222324252627282930313233343536373839public class QuickUnionWeightImprove &#123; private int[] id; private int[] size; QuickUnionWeightImprove(int N) &#123; id = new int[N]; size = new int[N]; for (int i = 0; i &lt; id.length; i++) &#123; id[i] = i; size[i] = 1; &#125; &#125; private int root(int x) &#123; while (x != id[x]) &#123; x = id[x]; &#125; return x; &#125; public boolean connected(int p, int q) &#123; return root(p) == root(q); &#125; public void union(int p, int q) &#123; int rootP = root(p); int rootQ = root(q); if (connected(p, q)) &#123; return; &#125; if (size[p] &gt; size[q]) &#123; id[rootQ] = rootP; size[p] += size[q]; &#125; else &#123; id[rootP] = rootQ; size[q] += size[p]; &#125; &#125;&#125; ​ 好了这里需要注意的是：在进行了树的合并以后不要忘记修改根节点的树的大小（权重） 代码实现的第四个版本：​ 上面的代码其实还可以再进行优化，这里提出的优化方案就是路径压缩。简单来说我们进行查找的时候我们可以把这个节点挂到祖父节点下面这样树的高度明显变低，查找起来很方便。然而这一切我们只需要一行代码就能搞定，并且不影响查找的正确性。 123456789101112131415161718192021222324252627282930313233343536373839public class QuickUnionWeightCompressImprove &#123; private int[] id; private int[] size; QuickUnionWeightCompressImprove(int N) &#123; id = new int[N]; size = new int[N]; for (int i = 0; i &lt; id.length; i++) &#123; id[i] = i; size[i] = 1; &#125; &#125; private int root(int x)&#123; while (x!=id[x])&#123; //路径压缩只需要一行,这一行就是把节点向上移动一层 id[x]=id[id[x]]; x=id[x]; &#125; return x; &#125; public boolean connected(int p,int q)&#123; return root(p) == root(q); &#125; public void union(int p, int q) &#123; int root_p = root(p); int root_q = root(q); if (root_p == root_q) &#123; return; &#125; if (size[root_p] &gt; size[root_q]) &#123; id[root_q] = root_p; &#125;else &#123; id[root_p] = root_q; &#125; &#125;&#125; ​ 好了现在代码看起来会比较完美了，该用的技巧我们都已经用上了，现在合并操作的时间复杂度是常数，而查找操作的复杂度则是 n+nlogn 应用：​ 接下来一个并查集的小应用的例子，就是迷宫是否有解，我们就可以使用并查集来找最上面，和最下面一行之间是不是有联通的节点，如果有的话我们就能找到迷宫的解。 ​ 但是这样一来复杂度又上去了，因为我们最上面一层的 n 个节点和最下面一层 n 个节点都要进行 connected 操作，这样我们时间复杂度毫无疑问的成为了 n 平方 又是那个不可接受的慢，这里有一个技巧就是我们为最上面一行，最下面一行的 n 个节点分别建立一个父节点，这样一来我们只需要进行一次 connected 操作即可。","categories":[{"name":"-数据结构与算法","slug":"数据结构与算法","permalink":"http://lwenxu.coding.me/categories/数据结构与算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/tags/数据结构/"}]},{"title":"吐槽关于许鹏飞","slug":"Life/吐槽关于许鹏飞","date":"2017-09-18T08:05:39.000Z","updated":"2019-04-14T17:50:16.000Z","comments":true,"path":"2017/09/18/Life/吐槽关于许鹏飞/","link":"","permalink":"http://lwenxu.coding.me/2017/09/18/Life/吐槽关于许鹏飞/","excerpt":"​ 今年的微机原理的老师竟然叫许鹏飞，这个我也没什么好吐槽的。本来上学期以来对伟明哥教的计算机组成原理还是蛮感兴趣的，最后成绩也还不错。没想到今年又学一点计算机的基本原理和体系结构能丰富一下自己对计算机的理解增长一点见识。不过到目前为止计算机的知识我都是没增长多少，对这个老师的态度真的不是很好。首先他说他是经管院的考研考到计算机专业的，当时还是挺佩服的。","text":"​ 今年的微机原理的老师竟然叫许鹏飞，这个我也没什么好吐槽的。本来上学期以来对伟明哥教的计算机组成原理还是蛮感兴趣的，最后成绩也还不错。没想到今年又学一点计算机的基本原理和体系结构能丰富一下自己对计算机的理解增长一点见识。不过到目前为止计算机的知识我都是没增长多少，对这个老师的态度真的不是很好。首先他说他是经管院的考研考到计算机专业的，当时还是挺佩服的。 ​ 然而他后来的种种举措导致我对他的影响非常不好： 文科生+理科生的教学方式，自己理解的不是很透彻的就硬背，程序硬背，cup 总线结构硬背。我觉得既然教的是计算机就应该用like 的方式探讨为什么要这样设计，作用是什么，流程是什么 而不是一味的去背，真没啥用 超级愤青，仇视社会。上课没办法调动大家的积极性，然后就各种抱怨，各种不爽，说什么我们不努力什么的。这些话完全是废话，都是二十多岁的人人家该怎么走他不清楚吗，而且重要的是有时候听你在这废话不如自己看书来的快 最后一点也是让我最不爽的一点就是每节课都会点名点到我，让我起来回答问题。就因为我们名字一样吗？我就呵呵了，自己教的一塌糊涂，全靠自己背，还说我们不认真去背。 ​ 今天又在学汇编，说实话这种东西很少会去在用了，除非你是做硬件的不然学这个真的浪费时间，没有任何学习的价值，首先汇编基本就是记流水账，先背会各个寄存器作用，中断什么的，记这些可能有用对理解操作系统什么的还行。主要是这个就是简单的堆砌，顶多能耍小聪明，没有任何的设计可言，没有设计模式，没有异常，代码不可维护，不可扩展 这样的语言除了在底层硬件上需要，难道我们还真的需要这样的语言去做设计做开发吗。 ​ 然后就是看到了一个外行人的写得非常烂的代码，虽然说那些教授写得代码可能不多，但是我觉得这个人的代码完全就是一个外行的随便拼凑的代码片段。所以说外行人真的还是和行内有区别的，理论多，背的多，但是你别忘了计算机就是一个应用性的学科，生来就是为了服务，不是为了背那些条条框框。","categories":[{"name":"-小记","slug":"小记","permalink":"http://lwenxu.coding.me/categories/小记/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://lwenxu.coding.me/tags/生活/"}]},{"title":"二叉树","slug":"Algorithm/二叉树","date":"2017-09-11T12:01:05.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/09/11/Algorithm/二叉树/","link":"","permalink":"http://lwenxu.coding.me/2017/09/11/Algorithm/二叉树/","excerpt":"1.二叉树的性质1.具有 n 个节点的二叉树第 n 层最多2的 n-1 次方个节点2.具有 n 个节点的二叉树最多有 2 的 n 次方减 1 个节点3.度为 0 的节点数等于度为 2 的节点数加 1","text":"1.二叉树的性质1.具有 n 个节点的二叉树第 n 层最多2的 n-1 次方个节点2.具有 n 个节点的二叉树最多有 2 的 n 次方减 1 个节点3.度为 0 的节点数等于度为 2 的节点数加 1 节点度的关系 n=n0+n1+n2边的条数就是 n-1 ,也就是节点的关系的个数 另外一方面就是从父亲的方面来看就是利用度来计算 n0*0+n1*1+n2*2也就是从不同的角度来理解这个东西获得一个等式从而得到的 2.两个小概念：满二叉树：所有的节点排满了完全二叉树:按顺序从左向右排放可以不满 3.线索化1.中序线索化rtag=0 右子树最左边的节点rtag=1 rchild 指向 ltag=0 左子树的最右边节点ltag=1 lchild 指向 4.树任何一棵树我们如果使用孩子兄弟表示法的话 我们自然就会把这个树转化成一个二叉树 当然也可以使用双亲表示法，就是用map 然后记录双亲的位置也可以使用孩子表示法就是使用一个索引链表也可以把上面两个方法结合起来就是使用双亲孩子表示法 5.层序遍历就是先把根节点放在队列里面，然后只要这个队列不空的话，就访问这个节点然后出队，然后分别把这个节点的左右节点分别入队列 6.中序和先序遍历的非递归的算法使用一个栈，中序的话就是第二次经过这个节点的时候我们访问，先序就是第一次经过这个节点的时候去访问这个节点因为一般来说我们知道他会进过两次，但是什么时候第三次经过我们并不知道。我们可以每个节点设置一个 mark 如果是第三次访问的时候我们就访问","categories":[{"name":"-数据结构","slug":"数据结构","permalink":"http://lwenxu.coding.me/categories/数据结构/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://lwenxu.coding.me/tags/二叉树/"}]},{"title":"HouseRobber","slug":"Leet Code/HouseRobber","date":"2017-09-07T13:29:06.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/07/Leet Code/HouseRobber/","link":"","permalink":"http://lwenxu.coding.me/2017/09/07/Leet Code/HouseRobber/","excerpt":"","text":"You are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night.Given a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police. 题目的意思大概就是有一个数组，数组里面装的就是正整数，你要去访问各个数组，但是这些数组相邻元素不可同时访问，从而获取最大的和 思路还是 dp 动态规划 ：我们首先就想当前是头还是不偷，从而推断下一步，不管别的 1234567891011121314151617181920public class HouseRobber &#123; public int rob(int[] nums) &#123; int no=0; int yes=0; for (int num : nums) &#123; int lastNo=no; no=Math.max(yes,no); yes=lastNo+num; &#125; return Math.max(yes, no); &#125; public int rob1(int[] nums) &#123; int[][] dp=new int[nums.length+1][2]; for (int i = 1; i &lt; nums.length; i++) &#123; dp[i][0]=Math.max(dp[i-1][0],dp[i-1][1]); dp[i][1]=dp[i-1][0]+nums[i]; &#125; return Math.max(dp[nums.length][0],dp[nums.length][1]); &#125;&#125;","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://lwenxu.coding.me/tags/动态规划/"}]},{"title":"IntersectionOfTwoLinkedLists","slug":"Leet Code/IntersectionOfTwoLinkedLists","date":"2017-09-07T12:44:02.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/07/Leet Code/IntersectionOfTwoLinkedLists/","link":"","permalink":"http://lwenxu.coding.me/2017/09/07/Leet Code/IntersectionOfTwoLinkedLists/","excerpt":"","text":"Write a program to find the node at which the intersection of two singly linked lists begins. For example, the following two linked lists: A: a1 → a2 ↘ c1 → c2 → c3 ↗ B: b1 → b2 → b3 begin to intersect at node c1. Notes: If the two linked lists have no intersection at all, return null. The linked lists must retain their original structure after the function returns. You may assume there are no cycles anywhere in the entire linked structure. Your code should preferably run in O(n) time and use only O(1) memory. Credits: Special thanks to @stellari for adding this problem and creating all test cases. 两个思路:一个就是把链表转化成一个有环链表 这样的话我们就可以当做那个有环的求入点问题了 但是人家说了不能修改链表的结构很抱歉没办法使用第二个思路就是既然是这个入点是重复的那么我们就找出重复元素即可 这样自然想到了 hash 表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import java.util.HashSet;import java.util.Set;class IntersectionOfTwoLinkedLists_1 &#123; public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; if (headA==null||headB==null)&#123; return null; &#125; ListNode circle=headA; ListNode fast=headB; ListNode slow=headB; while (circle.next!=null)&#123; circle=circle.next; &#125; circle.next=headA; while (fast!=null&amp;&amp;slow!=null)&#123; if (fast.next!=null&amp;&amp;fast.next.next!=null)&#123; fast=fast.next.next; &#125;else &#123; return null; &#125; if (slow.next!=null)&#123; slow=slow.next; &#125;else &#123; return null; &#125; if (fast==slow)&#123; ListNode x=fast; ListNode y=headB; while(x!=null&amp;&amp;y!=null)&#123; x=x.next; y=y.next; if (x==y)&#123; return x; &#125; &#125; &#125; &#125; return null; &#125;&#125;class IntersectionOfTwoLinkedLists &#123; public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; if (headA==null||headB==null)&#123; return null; &#125; Set&lt;ListNode&gt; nodes=new HashSet&lt;&gt;(); ListNode listA=headA; ListNode listB=headB; while (listA!=null)&#123; nodes.add(listA); listA=listA.next; &#125; while (listB!=null)&#123; if (!nodes.add(listB))&#123; return listB; &#125; listB=listB.next; &#125; return null; &#125;&#125;","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://lwenxu.coding.me/tags/链表/"}]},{"title":"归并排序","slug":"Algorithm/归并排序","date":"2017-09-05T09:17:39.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/09/05/Algorithm/归并排序/","link":"","permalink":"http://lwenxu.coding.me/2017/09/05/Algorithm/归并排序/","excerpt":"归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 首先考虑下如何将将二个有序数列合并。","text":"归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。 首先考虑下如何将将二个有序数列合并。这个非常简单，只要从比较二个数列的第一个数，谁小就先取谁，取了后就在对应数列中删除这个数。然后再进行比较，如果有数列为空，那直接将另一个数列的数据依次取出即可。 1234567891011121314151617181920//将有序数组a[]和b[]合并到c[]中 void MemeryArray(int a[], int n, int b[], int m, int c[]) &#123; int i, j, k; i = j = k = 0; while (i &lt; n &amp;&amp; j &lt; m) &#123; if (a[i] &lt; b[j]) c[k++] = a[i++]; else c[k++] = b[j++]; &#125; while (i &lt; n) c[k++] = a[i++]; while (j &lt; m) c[k++] = b[j++]; &#125; 可以看出合并有序数列的效率是比较高的，可以达到O(n)。 解决了上面的合并有序数列问题，再来看归并排序，其的基本思路就是将数组分成二组A，B，如果这二组组内的数据都是有序的，那么就可以很方便的将这二组数据进行排序。如何让这二组组内数据有序了？ 可以将A，B组各自再分成二组。依次类推，当分出来的小组只有一个数据时，可以认为这个小组组内已经达到了有序，然后再合并相邻的二个小组就可以了。这样通过先递归的分解数列，再合并数列就完成了归并排序。 1234567891011121314151617181920212223242526272829303132333435363738394041424344//将有二个有序数列a[first...mid]和a[mid...last]合并。 void mergearray(int a[], int first, int mid, int last, int temp[]) &#123; int i = first, j = mid + 1; int m = mid, n = last; int k = 0; while (i &lt;= m &amp;&amp; j &lt;= n) &#123; if (a[i] &lt;= a[j]) temp[k++] = a[i++]; else temp[k++] = a[j++]; &#125; while (i &lt;= m) temp[k++] = a[i++]; while (j &lt;= n) temp[k++] = a[j++]; for (i = 0; i &lt; k; i++) a[first + i] = temp[i]; &#125; void mergesort(int a[], int first, int last, int temp[]) &#123; if (first &lt; last) &#123; int mid = (first + last) / 2; mergesort(a, first, mid, temp); //左边有序 mergesort(a, mid + 1, last, temp); //右边有序 mergearray(a, first, mid, last, temp); //再将二个有序数列合并 &#125; &#125; bool MergeSort(int a[], int n) &#123; int *p = new int[n]; if (p == NULL) return false; mergesort(a, 0, n - 1, p); delete[] p; return true; &#125; 归并排序的效率是比较高的，设数列长为N，将数列分开成小数列一共要logN步，每步都是一个合并有序数列的过程，时间复杂度可以记为O(N)，故一共为O(NlogN)。因为归并排序每次都是在相邻的数据中进行操作，所以归并排序在O(NlogN)的几种排序方法（快速排序，归并排序，希尔排序，堆排序）也是效率比较高的。","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"排序","slug":"排序","permalink":"http://lwenxu.coding.me/tags/排序/"}]},{"title":"LinkedListCycle","slug":"Leet Code/LinkedListCycle","date":"2017-09-04T13:54:37.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/04/Leet Code/LinkedListCycle/","link":"","permalink":"http://lwenxu.coding.me/2017/09/04/Leet Code/LinkedListCycle/","excerpt":"","text":"Given a linked list, determine if it has a cycle in it. Follow up: Can you solve it without using extra space? 分析 一开始使用了复杂度O(n^2)的方法，使用两个指针a, b。a从表头开始一步一步往前走，遇到null则说明没有环，返回false；a每走一步，b从头开始走，如果遇到b==a.next，则说明有环true，如果遇到b==a，则说明暂时没有环，继续循环。 后来找到了复杂度O(n)的方法，使用两个指针slow,fast。两个指针都从表头开始走，slow每次走一步，fast每次走两步，如果fast遇到null，则说明没有环，返回false；如果slow==fast，说明有环，并且此时fast超了slow一圈，返回true。 为什么有环的情况下二者一定会相遇呢？因为fast先进入环，在slow进入之后，如果把slow看作在前面，fast在后面每次循环都向slow靠近1，所以一定会相遇，而不会出现fast直接跳过slow的情况。 扩展问题在网上搜集了一下这个问题相关的一些问题，思路开阔了不少，总结如下： 环的长度是多少？ 如何找到环中第一个节点（即Linked List Cycle II）？ 如何将有环的链表变成单链表（解除环）？ 如何判断两个单链表是否有交点？如何找到第一个相交的节点？ 首先我们看下面这张图： 设：链表头是X，环的第一个节点是Y，slow和fast第一次的交点是Z。各段的长度分别是a,b,c，如图所示。环的长度是L。slow和fast的速度分别是qs,qf。 下面我们来挨个问题分析。 方法一（网上都是这个答案）： 第一次相遇后，让slow,fast继续走，记录到下次相遇时循环了几次。因为当fast第二次到达Z点时，fast走了一圈，slow走了半圈，而当fast第三次到达Z点时，fast走了两圈，slow走了一圈，正好还在Z点相遇。 方法二： 第一次相遇后，让fast停着不走了，slow继续走，记录到下次相遇时循环了几次。 方法三（最简单）： 第一次相遇时slow走过的距离：a+b，fast走过的距离：a+b+c+b。 因为fast的速度是slow的两倍，所以fast走的距离是slow的两倍，有 2(a+b) = a+b+c+b，可以得到a=c（这个结论很重要！）。 我们发现L=b+c=a+b，也就是说，从一开始到二者第一次相遇，循环的次数就等于环的长度。 我们已经得到了结论a=c，那么让两个指针分别从X和Z开始走，每次走一步，那么正好会在Y相遇！也就是环的第一个节点。 在上一个问题的最后，将c段中Y点之前的那个节点与Y的链接切断即可。 如何判断两个单链表是否有交点？先判断两个链表是否有环，如果一个有环一个没环，肯定不相交；如果两个都没有环，判断两个列表的尾部是否相等；如果两个都有环，判断一个链表上的Z点是否在另一个链表上。 如何找到第一个相交的节点？求出两个链表的长度L1,L2（如果有环，则将Y点当做尾节点来算），假设L1&lt;L2，用两个指针分别从两个链表的头部开始走，长度为L2的链表先走(L2-L1)步，然后两个一起走，直到二者相遇。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import org.junit.jupiter.api.Test;public class LinkedListCycle &#123; public boolean hasCycle(ListNode head) &#123; if (head==null||head.next==null)&#123; return false; &#125; ListNode outer=head; int outCount=0; while (outer.next!=null)&#123; outer=outer.next; ListNode current=outer; outCount++; ListNode inner=head; int inCount=0; while (inCount&lt;outCount)&#123; if (inner==current)&#123; return true; &#125; inner=inner.next; inCount++; &#125; &#125; return false; &#125; public boolean hasCycle_1(ListNode head) &#123; if (head==null||head.next==null)&#123; return false; &#125; ListNode fast=head; ListNode slow=head; while (fast!=null||fast.next!=null)&#123; fast=fast.next; if (fast==null)&#123; return false; &#125; fast=fast.next; if (fast==null)&#123; return false; &#125; slow=slow.next; if (fast==slow)&#123; return true; &#125; &#125; return false; &#125; @Test void test()&#123; ListNode n1=new ListNode(1); ListNode n2=new ListNode(2); n1.next=n2; n2.next=null; System.out.println(hasCycle_1(n1)); &#125;&#125;","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://lwenxu.coding.me/tags/链表/"}]},{"title":"WordBreak","slug":"Leet Code/WordBreak","date":"2017-09-04T12:52:16.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/04/Leet Code/WordBreak/","link":"","permalink":"http://lwenxu.coding.me/2017/09/04/Leet Code/WordBreak/","excerpt":"","text":"Given a non-empty string s and a dictionary wordDict containing a list of non-empty words, determine if s can be segmented into a space-separated sequence of one or more dictionary words. You may assume the dictionary does not contain duplicate words. For example, given s = \"leetcode\", dict = [\"leet\", \"code\"]. Return true because \"leetcode\" can be segmented as \"leet code\". 这道题的思路是这样的，首先设置一个比字符串长一的数组，这个数组里面多的那个一就是存放空格的位置假设我们空格在某个位置，然后这个数组的空格前一个位置表示空格之前的数组是字典里面的内容，然后空格后面的字串被包含在字典里那么就说明在这个字串就是字典里面的内容 这道题说白了也是一个动态规划的问题，这类问题的思想就是存储上一步骤的东西，然后根据上一步骤的东西推算出下一步骤的结论这里的存储的上一步骤的东西就是那个布尔数组，然后根据递推公式也就是 if 判断里面的东西得出本步骤的结论 12345678910111213141516171819202122import java.util.List;public class WordBreak &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; if (s.length() == 0) &#123; return true; &#125; boolean[] res = new boolean[s.length() + 1]; res[0] = true; for (int i = 0; i &lt; s.length(); i++) &#123; StringBuilder stringBuilder = new StringBuilder(s.substring(0, i + 1)); for (int j = 0; j &lt;= i; j++) &#123; if (res[j] &amp;&amp; wordDict.contains(stringBuilder.toString())) &#123; res[i + 1] = true; break; &#125; stringBuilder.deleteCharAt(0); &#125; &#125; return res[s.length()]; &#125;&#125;","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"动态规划","slug":"动态规划","permalink":"http://lwenxu.coding.me/tags/动态规划/"}]},{"title":"BinaryTreeLevelOrderTraversal树的层序遍历","slug":"Leet Code/BinaryTreeLevelOrderTraversal树的层序遍历","date":"2017-09-03T02:57:46.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/03/Leet Code/BinaryTreeLevelOrderTraversal树的层序遍历/","link":"","permalink":"http://lwenxu.coding.me/2017/09/03/Leet Code/BinaryTreeLevelOrderTraversal树的层序遍历/","excerpt":"","text":"Given a binary tree, return the level order traversal of its nodes' values. (ie, from left to right, level by level). For example: Given binary tree [3,9,20,null,null,15,7], 3 / \\ 9 20 / \\ 15 7 return its level order traversal as: [ [3], [9,20], [15,7] ] 基本思想就是每一次遍历的时候看当前的层数是不是大于已有的 list 集合数，不大于则需要拓展否则就把获取当前层的 list 集合，然后王进放元素即可。这里需要注意的就是在这个种递归问题中我们最重要的是考虑当前的问题，而不要考虑到下一层，否则会越来越乱。 123456789101112131415161718192021222324252627282930import org.junit.jupiter.api.Test;import java.util.ArrayList;import java.util.List;public class BinaryTreeLevelOrderTraversal &#123; public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; result=new ArrayList&lt;&gt;(); levelOrder(root,result,0); return result; &#125; private void levelOrder(TreeNode root, List&lt;List&lt;Integer&gt;&gt; result, int level)&#123; if (root==null)&#123; return; &#125; if (level&gt;result.size()-1)&#123; result.add(new ArrayList&lt;&gt;()); &#125; List&lt;Integer&gt; list=result.get(level); if (root!=null)&#123; list.add(root.val); &#125; levelOrder(root.left,result,level+1); levelOrder(root.right,result,level+1); &#125;&#125;","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"SymmetricTree","slug":"Leet Code/SymmetricTree","date":"2017-09-03T01:40:50.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/03/Leet Code/SymmetricTree/","link":"","permalink":"http://lwenxu.coding.me/2017/09/03/Leet Code/SymmetricTree/","excerpt":"","text":"Given a binary tree, check whether it is a mirror of itself (ie, symmetric around its center). For example, this binary tree [1,2,2,3,4,4,3] is symmetric: 1 / \\ 2 2 / \\ / \\ 3 4 4 3 But the following [1,2,2,null,3,null,3] is not: 1 / \\ 2 2 \\ \\ 3 3 错误的解法，就是遇到多个 null 值的时候就会出问题，也就是在有的时候虽然他不对称，但是终须遍历的结果表明他就是对称的 123456789101112131415161718192021222324252627282930313233343536import org.junit.jupiter.api.Test;import java.util.ArrayList;import java.util.List;public class SymmetricTree &#123; public boolean isSymmetric(TreeNode root) &#123; List&lt;TreeNode&gt; list = new ArrayList&lt;&gt;(); inOrderTraversal(root, list); int center = list.size() / 2; return compare(list, center); &#125; public boolean compare(List&lt;TreeNode&gt; list, int center) &#123; for (int i = 0, j = list.size() - 1; i &lt; center; i++, j--) &#123; if (list.get(i).val != list.get(j).val) &#123; return false; &#125; &#125; return true; &#125; public void inOrderTraversal(TreeNode root, List&lt;TreeNode&gt; list) &#123; if (root == null) &#123; return; &#125; inOrderTraversal(root.left, list); list.add(root); inOrderTraversal(root.right, list); &#125; @Test void test() &#123; &#125;&#125; 好的解法就是使用递归，所谓对称简单来说就是 root 的左孩子和右孩子要一样才行","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"ValidateBinarySearchTree","slug":"Leet Code/ValidateBinarySearchTree","date":"2017-09-02T03:16:10.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/02/Leet Code/ValidateBinarySearchTree/","link":"","permalink":"http://lwenxu.coding.me/2017/09/02/Leet Code/ValidateBinarySearchTree/","excerpt":"","text":"import org.junit.jupiter.api.Test;import org.omg.CORBA.INTERNAL; Given a binary tree, determine if it is a valid binary search tree (BST). Assume a BST is defined as follows: The left subtree of a node contains only nodes with keys less than the node's key. The right subtree of a node contains only nodes with keys greater than the node's key. Both the left and right subtrees must also be binary search trees. Example 1: 2 / \\ 1 3 Binary tree [2,1,3], return true. Example 2: 1 / \\ 2 3 Binary tree [1,2,3], return false. 错误解法，只判断了每一个小的子树是搜索二叉树，而忽略了整个 root 的情况 123456789101112131415161718192021222324252627public class ValidateBinarySearchTree &#123; public boolean isValidBST(TreeNode root) &#123; if (root==null)&#123; return true; &#125; if (root.left==null&amp;&amp;root.right==null)&#123; return true; &#125; int leftValue=(root.left==null)?Integer.MIN_VALUE:root.left.val; int rightValue=(root.right==null)? Integer.MAX_VALUE:root.right.val; if(leftValue&lt;root.val&amp;&amp;rightValue&gt;root.val)&#123; return isValidBST(root.left)&amp;&amp;isValidBST(root.right); &#125; return false; &#125; @Test void test()&#123; TreeNode root=new TreeNode(0); TreeNode left=new TreeNode(-1); TreeNode right=new TreeNode(3); root.left=left; // root.right=right; System.out.println(isValidBST(root)); &#125;&#125; 通过的代码就是使用的搜索二叉树的中序遍历，他的终须遍历的话刚好出来结果就是左边的树必须小于右边的数，这样就能很轻松的判断出来是否合法 1234567891011121314151617181920212223242526272829303132333435363738public class ValidateBinarySearchTree &#123; public boolean isValidBST(TreeNode root) &#123; if (root==null)&#123; return true; &#125; if (root.left==null&amp;&amp;root.right==null)&#123; return true; &#125; List&lt;TreeNode&gt; list=new ArrayList&lt;&gt;(); inOrderTraversal(root,list); for (int i = 1; i &lt; list.size(); i++) &#123; if (list.get(i).val &lt;= list.get(i - 1).val)&#123; return false; &#125; &#125; return true; &#125; public void inOrderTraversal(TreeNode root,List&lt;TreeNode&gt; list)&#123; if (root==null)&#123; return ; &#125; inOrderTraversal(root.left,list); list.add(root); inOrderTraversal(root.right,list); &#125; @Test void test()&#123; TreeNode root=new TreeNode(0); TreeNode left=new TreeNode(-1); TreeNode right=new TreeNode(3); root.left=left; // root.right=right; System.out.println(isValidBST(root)); &#125;&#125; 以及终须遍历衍生出来的新方法，也就是不使用一个 list 集合来存储前后之间的关系 12345678910111213141516171819202122232425262728293031class ValidateBinarySearchTree2 &#123; TreeNode pre=null; public boolean isValidBST(TreeNode root) &#123; //这是一个中序遍历。然后我们在每次遍历的时候都存储了前一个元素，避免了使用一个 list 集合 if (root!=null)&#123; //首先遍历左子树，左子树出问题直接 false if (!isValidBST(root.left))&#123; return false; &#125; //核心判断条件，是不是前面的数大于后面的数 if (pre!=null&amp;&amp;pre.val&gt;=root.val)&#123; return false; &#125; //最后就是右子树，右子树由于是最后一道所以可以直接返回他的结果 return isValidBST(root.right); &#125; return true; &#125; @Test void test()&#123; TreeNode root=new TreeNode(0); TreeNode left=new TreeNode(-1); TreeNode right=new TreeNode(3); root.left=left; // root.right=right; System.out.println(isValidBST(root)); &#125;&#125;","categories":[],"tags":[]},{"title":"UniqueBinarySearchTreesII","slug":"Leet Code/UniqueBinarySearchTreesII","date":"2017-09-02T02:25:20.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/02/Leet Code/UniqueBinarySearchTreesII/","link":"","permalink":"http://lwenxu.coding.me/2017/09/02/Leet Code/UniqueBinarySearchTreesII/","excerpt":"","text":"import org.junit.jupiter.api.Test; 题目的描述如下 * Given n, how many structurally unique BST's (binary search trees) that store values 1...n? For example, Given n = 3, there are a total of 5 unique BST's. 1 3 3 2 1 \\ / / / \\ \\ 3 2 1 1 3 2 / / \\ \\ 2 1 2 3 也就是让生成搜索二叉树的所有可能情况，用一种遍历方式放在 list 集合中展示出来 这个地方的基本思路就是把这个问题分解成子问题，也就是先找出一个 root 节点，然后分别对左右的子树进行同样的查找操作，这里的代码比较巧妙的一点就是他一开始存放的并不是已经遍历过的树，而是只存放了这个根结点，根结点的左右子树都放在了根结点的内部了，所以最后才会有一个双重循环说白了就是循环的是当选这个 root 节点的时候左右子树的所有情况 123456789101112131415161718192021222324252627282930313233343536373839404142434445class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode(int x) &#123; val = x; &#125;&#125;public class UniqueBinarySearchTreesII &#123; public List&lt;TreeNode&gt; generateTrees(int n) &#123; if (n &lt; 1) &#123; return new ArrayList&lt;TreeNode&gt;(); &#125; return generate(1, n); &#125; public List&lt;TreeNode&gt; generate(int start, int end) &#123; List&lt;TreeNode&gt; lists = new ArrayList&lt;&gt;(); if (start &gt; end) &#123; lists.add(null); return lists; &#125; for (int i = start; i &lt;= end; i++) &#123; List&lt;TreeNode&gt; leftTree = generate(start, i - 1); //里面的存储结构其实就是只存了一个子树的 root 节点然后，root 节点里面带的有左右子节点的关系 List&lt;TreeNode&gt; rightTree = generate(i+1, end); for (TreeNode leftNode : leftTree) &#123; for (TreeNode rightNode : rightTree) &#123; TreeNode root = new TreeNode(i); root.left = leftNode; root.right = rightNode; lists.add(root); &#125; &#125; &#125; return lists; &#125; @Test void fun() &#123; // generateTrees(3); System.out.println(Arrays.toString(generateTrees(3).toArray())); &#125;&#125;","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"卡塔兰数列[UniqueBinarySearchTrees]","slug":"Leet Code/卡塔兰数列[UniqueBinarySearchTrees]","date":"2017-09-01T14:17:57.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/09/01/Leet Code/卡塔兰数列[UniqueBinarySearchTrees]/","link":"","permalink":"http://lwenxu.coding.me/2017/09/01/Leet Code/卡塔兰数列[UniqueBinarySearchTrees]/","excerpt":"","text":"Given n, how many structurally unique BST’s (binary search trees) that store values 1…n? For example,Given n = 3, there are a total of 5 unique BST’s. 1 3 3 2 1 \\ / / / \\ \\ 3 2 1 1 3 2 / / \\ \\ 2 1 2 3 这道题实际上是 Catalan Number卡塔兰数的一个例子，我们先来看当 n = 1的情况，只能形成唯一的一棵二叉搜索树，n分别为1,2,3的情况如下所示： 1 n = 1 2 1 n = 2 / \\ 1 2 1 3 3 2 1 n = 3 \\ / / / \\ \\ 3 2 1 1 3 2 / / \\ \\ 2 1 2 3 就跟斐波那契数列一样，我们把n = 0 时赋为1，因为空树也算一种二叉搜索树，那么n = 1时的情况可以看做是其左子树个数乘以右子树的个数，左右字数都是空树，所以1乘1还是1。那么n = 2时，由于1和2都可以为跟，分别算出来，再把它们加起来即可。n = 2的情况可由下面式子算出： dp[2] = dp[0] * dp[1] (1为根的情况) + dp[1] * dp[0] (2为根的情况) 同理可写出 n = 3 的计算方法： dp[3] = dp[0] * dp[2] (1为根的情况) + dp[1] * dp[1] (2为根的情况) + dp[2] * dp[0] (3为根的情况) 由此可以得出卡塔兰数列的递推式为： c[0]=1 ; c[n+1] = sum(c[i]*c[n-i]) 最后代码实现为： 1234567891011121314151617public class UniqueBinarySearchTrees &#123; public int numTrees(int n) &#123; int[] dp=new int[n+1]; dp[0]=dp[1]=1; for (int i = 2; i &lt;=n; i++) &#123; for (int j = 0; j &lt; i; j++) &#123; dp[i]+=dp[j]*dp[i-j-1]; &#125; &#125; return dp[n]; &#125; @Test void fun()&#123; System.out.println(numTrees(3)); &#125;&#125;","categories":[{"name":"-LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/categories/LeetCode/"}],"tags":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://lwenxu.coding.me/tags/LeetCode/"}]},{"title":"命令行常用参数","slug":"Linux/命令行常用参数","date":"2017-09-01T13:43:10.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/09/01/Linux/命令行常用参数/","link":"","permalink":"http://lwenxu.coding.me/2017/09/01/Linux/命令行常用参数/","excerpt":"","text":"1.命令行中1.上一条命令的最后一个参数 ： !$2.上一条命令的第 n 个参数 ： !:n3.上一条命令的名称 ： !4.上一条命令的内容 ： !!5.上n条命令的内容 ： n!!2.shell 脚本中1.上一条命令的名称 ： $02.上一条命令的第 n 个参数 ：$n3.上一条命令的执行情况 ： 0 正常退出 非0不正常","categories":[{"name":"-Linux","slug":"Linux","permalink":"http://lwenxu.coding.me/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://lwenxu.coding.me/tags/Linux/"}]},{"title":"三大框架整合","slug":"Java Web/三大框架整合","date":"2017-08-23T11:45:42.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/23/Java Web/三大框架整合/","link":"","permalink":"http://lwenxu.coding.me/2017/08/23/Java Web/三大框架整合/","excerpt":"1.整合思想 web 层 -&gt; struts2 service 层 -&gt; Spring dao 层 -&gt; Hibernate整合就是两两整合，struts 和 spring 整合，然后 spring 和 hibernate 整合。 struts 和 spring 整合就是 action 需要的 service 直接通过 spring 实例化并且注入到 action 中 spring 和 hibernate 整合就是把 sessionFactory 放在 spring 中管理，然后把 dao 注入到 service 中","text":"1.整合思想 web 层 -&gt; struts2 service 层 -&gt; Spring dao 层 -&gt; Hibernate整合就是两两整合，struts 和 spring 整合，然后 spring 和 hibernate 整合。 struts 和 spring 整合就是 action 需要的 service 直接通过 spring 实例化并且注入到 action 中 spring 和 hibernate 整合就是把 sessionFactory 放在 spring 中管理，然后把 dao 注入到 service 中","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/tags/JAVA/"}]},{"title":"Spring笔记(三)","slug":"Java Web/Spring笔记-三","date":"2017-08-23T09:37:03.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/23/Java Web/Spring笔记-三/","link":"","permalink":"http://lwenxu.coding.me/2017/08/23/Java Web/Spring笔记-三/","excerpt":"","text":"1.使用注解实现 aop 配置 xml12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd \"&gt; &lt;!--开启 aop 操作--&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;bean id=\"user\" class=\"aop1.User\"/&gt; &lt;bean id=\"improve\" class=\"aop1.Improve\"/&gt;&lt;/beans&gt;```&lt;!--more--&gt;* 在增强类中注解```javapackage aop1;import org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint;import org.springframework.context.annotation.EnableAspectJAutoProxy;@Aspectpublic class Improve &#123; @Before(value=\"execution(* aop1.User.say(..))\") public void before_say()&#123; System.out.println(\"before\"); &#125; public void after_say()&#123; System.out.println(\"after\"); &#125; public void around_say(MethodInvocationProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println(\"before\"); joinPoint.proceed(); System.out.println(\"after\"); &#125;&#125; 2.JdbcTemplate1.增1234567891011//配置 dataSource DriverManagerDataSource dataSource=new DriverManagerDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql:///JAVA\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"12345678\"); //设置模板 JdbcTemplate jdbcTemplate=new JdbcTemplate(dataSource); //操作 String sql=\"insert into user values(?,?)\"; jdbcTemplate.update(sql,1,\"lwen\"); 2.删还是 update 操作只是 sql 不一样 3.改同增加 4.查类似于 QueryRunner 也是使用接口的实例，不过这里没有准备好的实现类，实现类需要我们自己书写。 1.查询单值123456789101112131415161718192021222324252627282930313233343536373839404142@Test void fun2()&#123; //配置 dataSource DriverManagerDataSource dataSource=new DriverManagerDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql:///JAVA\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"12345678\"); //设置模板 JdbcTemplate jdbcTemplate=new JdbcTemplate(dataSource); //操作 String sql=\"select count(*) from user\"; Object object=jdbcTemplate.queryForObject(sql,Integer.class); System.out.println(object); &#125; class MyRowMapper implements RowMapper&#123; public Object mapRow(ResultSet resultSet, int i) throws SQLException &#123; User user=new User(); user.setId(resultSet.getInt(\"id\")); user.setName(resultSet.getString(\"name\")); return user; &#125; &#125; @Test void fun3()&#123; //配置 dataSource DriverManagerDataSource dataSource=new DriverManagerDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql:///JAVA\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"12345678\"); //设置模板 JdbcTemplate jdbcTemplate=new JdbcTemplate(dataSource); //操作 String sql=\"select * from user where name=?\"; Object object=jdbcTemplate.queryForObject(sql, new MyRowMapper(),\"lwen\"); System.out.println(object); &#125; 2.多值查询123456789101112131415161718192021222324class MyRowMapper1 implements RowMapper&#123; public Object mapRow(ResultSet resultSet, int i) throws SQLException &#123; User user=new User(); user.setId(resultSet.getInt(\"id\")); user.setName(resultSet.getString(\"name\")); return user; &#125; &#125; @Test void fun4()&#123; //配置 dataSource DriverManagerDataSource dataSource=new DriverManagerDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql:///JAVA\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"12345678\"); //设置模板 JdbcTemplate jdbcTemplate=new JdbcTemplate(dataSource); //操作 String sql=\"select * from user\"; List&lt;User&gt; users=jdbcTemplate.query(sql,new MyRowMapper1()); System.out.println(users); &#125; 2.事务管理1.xml方式配置12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd \"&gt; &lt;!--jdbcTemplate--&gt; &lt;bean id=\"jdbc\" class=\"org.springframework.jdbc.core.JdbcTemplate\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置事务管理器--&gt; &lt;bean id=\"txManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!--注入 dataSource--&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!--配置事务的增强--&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"txManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"add\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!--配置切面--&gt; &lt;aop:config&gt; &lt;!--切入点--&gt; &lt;aop:pointcut id=\"point1\" expression=\"execution(* com.lwen.Service.add(..))\"/&gt; &lt;!--切面--&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"point1\"/&gt; &lt;/aop:config&gt;&lt;/beans&gt; 2.注解方式 开启注解 12&lt;!-- 开启注解 --&gt;&lt;tx:annotation-driven transaction-manager=\"transactionManager\"/&gt; 在事务类上面写注解@Transactional","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lwenxu.coding.me/tags/Spring/"}]},{"title":"Spring笔记(二)","slug":"Java Web/Spring笔记-二","date":"2017-08-23T08:05:53.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/23/Java Web/Spring笔记-二/","link":"","permalink":"http://lwenxu.coding.me/2017/08/23/Java Web/Spring笔记-二/","excerpt":"1.注解ioc1.开启注解扫描123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--开启注解扫描--&gt; &lt;context:component-scan base-package=\"domain1\"/&gt;&lt;/beans&gt;","text":"1.注解ioc1.开启注解扫描123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--开启注解扫描--&gt; &lt;context:component-scan base-package=\"domain1\"/&gt;&lt;/beans&gt; 2.在类上面做注解：12@Component(value = \"user\")@Scope(value=\"singleton\") 注解有四个，但是却别都不大： Component Service Controller Repository 3.注入属性注解的时候 set 方法也无需生成，直接注解就能搞定。直接在属性上面写@Autowired或者@Resource(name = “”)第一种方式我们不用去指定对象的 id 值，而第二个需要些 id 值。主要用的就是第二个，因为他更加的严谨。 2.AOP1.基本介绍aop 也叫做面向切面编程，或者面向方面编程。他的主要方式就是横向抽取，与以前的继承方式的纵向抽取不同。这里就主要说说横向抽取，aop 主要还是用了动态代理的方式来拓展对象的功能。而动态代理分为两种： jdk 的动态代理这种动态代理就是一个接口，然后我们需要使用 aop 来增强这个接口的实现类的对象的功能，那么这个动态代理方式就是新建一个类，然后这个类实现那个接口，也就是创建一个与被增强的类的平级的一个类，所以称之为横向抽取。之后只需要再次类中进行方法的增强即可，但是这个地方就是用了动态代理的方式而不是切切实实的写一个类，我们代理原来的需要被增强的类，然后在他的基础上做一些拓展。 gclib 动态代理方式这种动态代理是针对的没有接口的代理。主要就是通过集成需要被增强的类，然后进行动态代理。 2.相关定义 连接点：类中的哪些类可以被增强的方法就称之为连接点。 切入点：我们实际增强了的方法。 增强：我们增强的功能。分为前置增强（方法之前），后置增强（方法之后），异常增强（抛出异常执行），最终增强（后置之后），环绕增强（之前之后都执行） 切面：把增强应用到方法上的过程。 目标对象：代理的目标对象 3.xml 配置方式增强类： 12345678910111213141516171819package aop;import org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint;public class Improve &#123; public void before_say()&#123; System.out.println(\"before\"); &#125; public void after_say()&#123; System.out.println(\"after\"); &#125; public void around_say(MethodInvocationProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println(\"before\"); joinPoint.proceed(); System.out.println(\"after\"); &#125;&#125; 被增强类 1234567package aop;public class User &#123; public void say()&#123; System.out.println(\"hello\"); &#125;&#125; 配置文件 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd \"&gt; &lt;bean id=\"improve\" class=\"aop.Improve\"/&gt; &lt;aop:config&gt; &lt;!--配置切入点 方法--&gt; &lt;aop:pointcut id=\"point1\" expression=\"execution(* aop.User.say(..))\"/&gt; &lt;!--配置切面 应用增强--&gt; &lt;aop:aspect ref=\"improve\"&gt; &lt;aop:before method=\"before_say\" pointcut-ref=\"point1\"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; &lt;bean id=\"user\" class=\"aop.User\"/&gt;&lt;/beans&gt; 2.log4j导包： log4j common-loging配置文件： src/log4j.properties","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lwenxu.coding.me/tags/Spring/"}]},{"title":"Spring笔记(一)","slug":"Java Web/Spring笔记-一","date":"2017-08-23T07:12:40.000Z","updated":"2019-03-11T23:18:34.000Z","comments":true,"path":"2017/08/23/Java Web/Spring笔记-一/","link":"","permalink":"http://lwenxu.coding.me/2017/08/23/Java Web/Spring笔记-一/","excerpt":"1.基本介绍spring 是一个一站式框架，也就是有了它 web 层，service 层还有 dao 层都能直接搞定而不需使用其他的框架。这三层分别就是： SpringMVC ioc JdbcTemplate","text":"1.基本介绍spring 是一个一站式框架，也就是有了它 web 层，service 层还有 dao 层都能直接搞定而不需使用其他的框架。这三层分别就是： SpringMVC ioc JdbcTemplate 2.ioc基本原理ioc 原理就是使用配置文件解析到需要创建的类的 class 然后使用工厂类的静态方法获取这个类的对象。 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean id=\"user\" class=\"domain.User\"/&gt;&lt;/beans&gt; 123456@Test void fun1()&#123; ApplicationContext context= new ClassPathXmlApplicationContext(\"user.xml\"); User user= (User) context.getBean(\"user\"); user.say(); &#125; 3.spring 差UN感觉爱你对象的三种方式1.ioc无参构造也就是上面的那个方法，首先配置 bean 然后读取配置文件，根据 id 获取类的对象，这个实例化的时候都是使用该类的默认构造函数。默认构造函数是无参的，当我们使用有参的构造函数覆盖了以后就会报错。这个方法也是最常用的一种方法。 2.静态工厂首先创建一个静态工厂的类，这个类里面需要有静态方法，静态方法返回类的实例，最后配置 xml 文件，也和上面一样，但是这里的 class 值写得是静态工厂的类，还有一个 factory-method 属性，就写那个静态方法。 3.实例工厂实例工厂和上面的静态工厂不同的方式就是这个工厂需要实例化，然后实例化就交给 ioc 来解决其他的和静态工厂一样。 4.bean 标签的常用属性1.idid 值就类似于对像的名字 2.class需要创建的类的全路径 3.name和 id 属性一样，获取对象也是 getBean 方法，他和 id 的不同的在于他可以写一些特殊符号。 4.scope singleton 单例对象，默认值 prototype 多例 request 创建的对象都放在了request 域 session 创建对象放在 session 域 5.ioc 属性注入1.构造函数注入1234&lt;bean id=\"user\" class=\"domain.User\"&gt; &lt;constructor-arg name=\"id\" value=\"1\"/&gt; &lt;constructor-arg name=\"name\" value=\"lwen\"/&gt;&lt;/bean&gt; 2.set 方法1234&lt;bean id=\"user1\" class=\"domain.User\"&gt; &lt;property name=\"id\" value=\"1\"/&gt; &lt;property name=\"name\" value=\"lwen\"/&gt;&lt;/bean&gt; 3.注入对象属于 set 方法的一种 ，但是他和注入普通的字符串还是不一样的。 123&lt;bean id=\"user1\" class=\"domain.User\"&gt; &lt;property name=\"userDao\" ref=\"Dao 的 id 值\"/&gt;&lt;/bean&gt; 4.复杂类型的注入还是使用 set 方法 数组类型 list map properties12345678910111213141516171819202122232425262728293031&lt;bean id=\"user2\" class=\"domain.User\"&gt; &lt;!--数组--&gt; &lt;property name=\"array\"&gt; &lt;list&gt; &lt;value&gt;1&lt;/value&gt; &lt;value&gt;1&lt;/value&gt; &lt;value&gt;1&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!--list--&gt; &lt;property name=\"list\"&gt; &lt;list&gt; &lt;value&gt;hello&lt;/value&gt; &lt;value&gt;hello&lt;/value&gt; &lt;value&gt;hello&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!--map--&gt; &lt;property name=\"map\"&gt; &lt;map&gt; &lt;entry key=\"a\" value=\"a\"/&gt; &lt;entry key=\"b\" value=\"b\"/&gt; &lt;/map&gt; &lt;/property&gt; &lt;!--properties--&gt; &lt;property name=\"properties\"&gt; &lt;props&gt; &lt;prop key=\"url\"&gt;jdbc:mysql:///java&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt; 5.配置文件自动加载在服务器创建的时候会创建一个 ServletContext 对象，这个对象有一个监听器，监听他什么时候创建。我们可以在这个对象创建的时候把配置文件给加载，再把加载的文件对象放在 ServletContext 域中。这个监听器就叫做 ServletContextListener 。这个东西目前 spring 已经封装好了，我们只需要进行 xml 的配置即可。 contextConfigLocation classpath:aop.xml org..web.context.ContextLoaderListener","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://lwenxu.coding.me/tags/Spring/"}]},{"title":"Struts2笔记(三)","slug":"Java Web/Struts2笔记-三","date":"2017-08-23T02:39:26.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/23/Java Web/Struts2笔记-三/","link":"","permalink":"http://lwenxu.coding.me/2017/08/23/Java Web/Struts2笔记-三/","excerpt":"拦截器，struts2方庄了很多功能，这些功能都是使用拦截器来实现的。一般的拦截器只是执行默认的拦截器，就是在struts-core这个包里面，然后李 main 有一个struts-default.xml这个文件李爱你就定义了很多默认的拦截器，interceptor-strck这个标签里面就是默认的拦截器。例如里面有ModelDriven。 1.拦截器执行的时机拦截器执行的时机就是action创建完成之后在action调用的方法之前调用。 2.底层原理1.aop思想aop就是面向切面编程。如果我们需要扩展一个类的功能，一般来说我们会写一个父类，","text":"拦截器，struts2方庄了很多功能，这些功能都是使用拦截器来实现的。一般的拦截器只是执行默认的拦截器，就是在struts-core这个包里面，然后李 main 有一个struts-default.xml这个文件李爱你就定义了很多默认的拦截器，interceptor-strck这个标签里面就是默认的拦截器。例如里面有ModelDriven。 1.拦截器执行的时机拦截器执行的时机就是action创建完成之后在action调用的方法之前调用。 2.底层原理1.aop思想aop就是面向切面编程。如果我们需要扩展一个类的功能，一般来说我们会写一个父类，让子类继承父类这样子类的功能就能获得拓展。这就是纵向编程，而所谓的横向的切面编程就在这个类的某个方法之前我们执行某些操作，或者在某个方法之后执行某些操作。蕾丝与thinkphp中的before()或者after()。 2.责任链模式责任链就类似于过滤链，过滤链就需要首先方形才能够继续进行。也就是如果我们需要进行一系列的操作的话，首先操作一然后必须放行才能进行下一个操作。再多拦截器的时候就需要责任链模式。 3.原理概述首先需要创建 action 的代理对象，所谓代理对象就不是真正的对象，而是一个具有被代理的对象的全部功能的对象，然后在代理对象执行 action 的方法之前，做了一个 aop 的操作也就是执行各种默认的拦截器，在每一个拦截器执行完毕以后需要在执行放行操作执行下一个拦截器，最后才执行那个被调用的方法。 3.过滤器与拦截器过滤器是服务器启动的时候创建，然后能过滤所有的内容，只要有路径就可以拦截。但是拦截器虽然叫做拦截器，他只能拦截action 4.自定义拦截器1.写逻辑的类首先需要继承 AbstractInterceptor 类，然后里面有三个方法，分别就是 init 初始化的操作，destroy 销毁的操作，interceptor 拦截的操作。实际在开发的时候尽量继承的 MethodFilterInterceptor 类，重写里面的拦截方法。最后注册拦截器，配置拦截器和 action 的关系。 1234567891011public class MyInterceptor extends MethodFilterInterceptor&#123; @Override protected String doIntercept(ActionInvocation actionInvocation) throws Exception &#123; //逻辑 //if 成功 -&gt;放行操作 actionInvocation.invoke(); //if fail -&gt; 返回一个字符串，就回到 result 中找这个结果就和 action 一样 return \"fail\"; &#125;&#125; 在 action 中的所在的包配置拦截器的声明。 123&lt;interceptors&gt; &lt;interceptor name=\"MyInterecpot\" class=\"demo2.MyInterceptor\"/&gt;&lt;/interceptors&gt; 再具体的 action 标签里面使用配置的拦截器 1234&lt;action name=\"hello\" class=\"demo01.Hello\"&gt; &lt;interceptor-ref name=\"MyInterecpot\"/&gt; &lt;result name=\"success\"&gt;/index.jsp&lt;/result&gt;&lt;/action&gt; 把默认拦截器写上，不然默认拦截器会失效。 1&lt;interceptor-ref name=\"defaultStack\"/&gt; 不拦截某个方法 &lt;interceptor-ref name=\"MyInterecpot\"&gt; &lt;param name=\"excludeMethods\"&gt;login,add&lt;/param&gt; &lt;/interceptor-ref&gt;","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"struts2","slug":"struts2","permalink":"http://lwenxu.coding.me/tags/struts2/"}]},{"title":"Struts2笔记(二)","slug":"Java Web/Struts2笔记-二","date":"2017-08-22T10:52:11.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/22/Java Web/Struts2笔记-二/","link":"","permalink":"http://lwenxu.coding.me/2017/08/22/Java Web/Struts2笔记-二/","excerpt":"1.结果页面1.全局结果页面当一些方法的返回值一样的时候并且需要跳转的页面也一样的时候就可以使用全局结果页面。 12345678&lt;package name=\"struts\" extends=\"struts-default\" namespace=\"/\"&gt; &lt;global-results&gt; &lt;result name=\"done\"&gt;index.jsp&lt;/result&gt; &lt;/global-results&gt; &lt;action name=\"hello\" class=\"demo01.Hello\"&gt; &lt;result name=\"success\"&gt;/index.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; 注意他只是太某一个package中，而不是整个项目","text":"1.结果页面1.全局结果页面当一些方法的返回值一样的时候并且需要跳转的页面也一样的时候就可以使用全局结果页面。 12345678&lt;package name=\"struts\" extends=\"struts-default\" namespace=\"/\"&gt; &lt;global-results&gt; &lt;result name=\"done\"&gt;index.jsp&lt;/result&gt; &lt;/global-results&gt; &lt;action name=\"hello\" class=\"demo01.Hello\"&gt; &lt;result name=\"success\"&gt;/index.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; 注意他只是太某一个package中，而不是整个项目 2.局部结果页面全局页面和局部页面同事存在并且冲突的时候是以局部的为准。 2.action获取表单数据。1.使用ActionContext对象在action中没办法调用request对象，所以我们智力只能使用actionContext对象获取。首先需要获取actionContext对象，然后这个对象不能new，而是通过他自己的一个静态方法获取的，名字就叫做getContext(),最后使用getParamters方法就能获取到表单的数据。 12ActionContext actionContext=ActionContext.getContext();Map&lt;String, Object&gt; map = actionContext.getParameters(); 2.ServletActionContext对象里面的方法大多数都是静态的，我们直接可以调用方法。我们可以获取HttpServletRequest对象也可以获取ActionContext对象。 123//获取request对象HttpServletRequest request= ServletActionContext.getRequest();request.getParameter(\"name\"); 3.接口注入让action实现ServletRequestAware接口，然后实现接口的方法，这个方法其实会有一个参数，这个参数就是我们需要的request对象，这样tomcat注入以后我们就可以保存起来直接使用。 3.action操作域对象其实action更像是一个servlet，这里action中可以操作的域对象和servlet一样也是三个。 request 使用ServletActionContext对象的getRequest方法获取 session 使用request对象的getSession获取 ServletContext 使用ServletActionContext的getServletContext方法获取 4.表单数据自动注入1.属性封装直接把要提交的属性的name值放在action的属性中，然后生成属性的set方法这样就能完表单数据属性的自动注入 2.模型驱动封装模型驱动封装就可以直接把这个表单的数据直接封装到一个实体类中首先需要实现ModelDriven接口，这个借口需要传入一个对象类型，这个对象就是实体类的类型。然后我们在这个action中必须要有一个实体类的对象，必须要new出来。然后需要实现这个接口的方法，getModel方法，返回值返回的就是我们创建的实体类的对象。属性封装和模型驱动不能同时使用，到时候只有模型驱动起作用，属性封装获取的都是null。 3.表达式封装 声明实体类，不实例化。 生成变量的set和get方法 在表单name中使用表达式 user.username 就是这个属性。通过get方法获取user，设置完属性以后set方法更新值。 5.值栈值栈就类似于一个域对象 1.存储位置每一个action都只有一个值栈区，每一次访问的时候action都会被重新创建，也就是action多例的。 2.获取值栈的对象使用ActionContext对象 1actionContext.getValueStack(); 3.值栈的结构值栈主要分为两部分，root和context。root是List集合而context是一个map集合。context中存放了三大域对象。而我们主要使用的空间就是root，在root中默认的栈顶元素就是当前的action对象。 4.向值栈中存数据 调用值栈对象的set方法 调用push方法 在action定义属性，然后生成get方法，最后再调用的方法中设置这个属性的值，这样这个值就被放到了值栈中。 5.获取值栈中的数据 字符串 &lt;s:property value=”username”/&gt; 直接根据名称获取值 对象 &lt;s:property value=”user.username”/&gt; user中的username属性 list集合 方案一 ： &lt;s:property value=”list[0].username”/&gt; 方案二 ： 123&lt;s:iterator value=\"list\"&gt; &lt;s:property value=\"username\"/&gt;&lt;/s:iterator&gt; 方案三 ：使用var的时候每次遍历的user对象的引用放在了值栈中的context中了，但是我们要取值栈中的context中的内容需要使用#，所以就有以下的表达式。 123&lt;s:iterator value=\"list\" var=\"user\"&gt; &lt;s:property value=\"#user.username\"/&gt;&lt;/s:iterator&gt; 获取set方法放的数据 &lt;s:property value=”username”/&gt; 获取push方法放的数据 &lt;s:property value=”[0].top”/&gt; push是放在了一个栈中了，这个就是一个数组，取数组的第一个元素 使用EL表达式也是可以获取值栈的数据。他的原理就是如果能在域对象中得到变量的时候就是域对象中的，获取不到的时候就去值栈查找，然后再放到域对象中。而这些操作能执行的原因就是在filter中给域对象做了增强也就是用了一个装饰设计模式。 6.OGNL表达式以及struts2标签库ognl表达式类似于el表达式，他的主要用途就是操作值栈里面的内容。struts2标签库的使用必须要导入他的标签库。 1.调用方法获取字符串hello的长度 1&lt;s:property value=\"'hello'.lenth()\"/&gt; 2.两个特殊符号的使用 这个就是获取context中的数据。 &lt;s:property value=”#request.username”/&gt; 获取域对象中的username % 表示在struts标签中使用ognl表达式，不识别，我们为了让他识别使用% 例如 &lt;s:textarea value=”%#request.username”/&gt;","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"struts2","slug":"struts2","permalink":"http://lwenxu.coding.me/tags/struts2/"}]},{"title":"Struts2笔记(一)","slug":"Java Web/Struts2笔记-一","date":"2017-08-22T10:52:06.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/22/Java Web/Struts2笔记-一/","link":"","permalink":"http://lwenxu.coding.me/2017/08/22/Java Web/Struts2笔记-一/","excerpt":"1.创建Action创建action需要继承ActionSupport类，然后就会有一些常量以及一些方法。struts2的action默认执行的方法就是execute()方法","text":"1.创建Action创建action需要继承ActionSupport类，然后就会有一些常量以及一些方法。struts2的action默认执行的方法就是execute()方法 123456789package demo01;import com.opensymphony.xwork2.ActionSupport;public class Hello extends ActionSupport&#123; public String execute()&#123; return SUCCESS; &#125;&#125; 2.配置核心配置文件12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE struts PUBLIC \"-//Apache Software Foundation//DTD Struts Configuration 2.3//EN\" \"http://struts.apache.org/dtds/struts-2.3.dtd\"&gt;&lt;struts&gt; &lt;!-- name随便配 extends就只能是这个 namespace是将来要访问的路径的前缀 --&gt; &lt;package name=\"struts\" extends=\"struts-default\" namespace=\"/\"&gt; &lt;!-- name以后和namespace合并形成访问的url class就是具体的action的类 --&gt; &lt;action name=\"hello\" class=\"demo01.Hello\"&gt; &lt;!-- 看返回的值是什么然后转发到对应的页面 --&gt; &lt;result name=\"success\"&gt;/index.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 1.package就相当于java中的包，为了区分不同的action。 name和功能无关，name值不能重复 extends 他的值是固定的，是继承了struts，只有这样类才有action的特性 namespace 和name构成访问路径 不写默认就是斜杠2.action name就是访问路径 class action的class路径 method 这个就是要执行的方法3.result name 回去返回值 type 就是跳转还是转发4.配置常量123&lt;constant name=\"\" value=\"\"/&gt;&lt;!-- 例如 --&gt;&lt;constant name=\"struts.i18n.encoding\" value=\"UTF-8\"/&gt; 3.配置web.xml过滤器我们的web服务器并不知道我们访问的是一个action而不是一个Servlet，所以我们要使用一个Struts2的过滤器来处率action的请求。 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" version=\"3.1\"&gt; &lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 4.struts2基本原理1.过滤器加载配置文件在web服务器启动的时候，过滤器就会创建，然后在init方法就会加载struts2的核心配置文件，以及它自带的jar包中的配置文件 2.访问action执行方法在访问的时候都被过滤器拦截到，然后转发到对应的类，让这些类的对应方法执行 5.配置文件的拆分可以拆分配置文件，但是子配置文件还是需要dtd，struts标签，然后主配置文件也是如此。然后在主配置文件中的struts标签中写include标签。 主配置文件： 123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE struts PUBLIC \"-//Apache Software Foundation//DTD Struts Configuration 2.3//EN\" \"http://struts.apache.org/dtds/struts-2.3.dtd\"&gt;&lt;struts&gt; &lt;constant name=\"struts.i18n.encoding\" value=\"UTF-8\"/&gt; &lt;include file=\"struts.xml\"/&gt;&lt;/struts&gt; 子配置文件： 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE struts PUBLIC \"-//Apache Software Foundation//DTD Struts Configuration 2.3//EN\" \"http://struts.apache.org/dtds/struts-2.3.dtd\"&gt;&lt;struts&gt; &lt;constant name=\"struts.i18n.encoding\" value=\"UTF-8\"/&gt; &lt;package name=\"struts\" extends=\"struts-default\" namespace=\"/\"&gt; &lt;action name=\"hello\" class=\"demo01.Hello\"&gt; &lt;result name=\"success\"&gt;/index.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt;","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"Struts2","slug":"Struts2","permalink":"http://lwenxu.coding.me/tags/Struts2/"}]},{"title":"Hibernate笔记(三)","slug":"Java Web/Hibernate笔记-三","date":"2017-08-21T08:01:03.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/21/Java Web/Hibernate笔记-三/","link":"","permalink":"http://lwenxu.coding.me/2017/08/21/Java Web/Hibernate笔记-三/","excerpt":"1.对象导航查询两个相关的对象 2.OID查询用id查出对象 3.hql查询Query对象","text":"1.对象导航查询两个相关的对象 2.OID查询用id查出对象 3.hql查询Query对象 1.hql 查询所有 from entity 条件查询 from entity where name=? setParameter(index,arg) 设置参数值 模糊查询 from entity where name like ?； 排序 from entity order by name desc 分页 setFirstResult()开始位置 setMaxResults()每页数 投影 select property from entity property不能是* 聚集函数 count select count(* ) from entity query.uniqueResult() 其他的类似 多表查询 内连接 form entity inner join entity.set 最后返回的是数组 迫切内连接 form entity inner join fetch entity.set 最后返回的是list 外连接 form entity left outer join entity.set 最后返回的是数组 迫切左外连接 form entity left outer join fetch entity.set 最后返回的是list 4.QBC查询Criteria对象createCriteria(entity.class) 查询所有 list() 条件查询 add(Restrictions.eq/like/(“property”,”value”)) -&gt; list() 排序 addOrder(Order.asc(“property”)) 分页 setFirstResult()开始位置 setMaxResults()每页数 统计查询 setProjection(Projetions.rowCount(10)); 离线查询 DetachCriteria deCriteria=DetachCriteria.forClass(entity.class)Criteria criteria=deCriteria.getExectueableCriteria(); 与session无关5.本地sql查询SQLQuery对象 6.Hibernate的查询策略1.立即查询get方法就是立即查询，方法执行立即发送语句 get(entity.Class,id) 2.延时查询load方法是延时查询，方法调用不会立即发送语句，只有当我们获取返回的对象中的非id字段的值得时候才会发语句。 1.类级别的延迟例如根据id的查询，最后查的是一个类的某个对象 2.关联级别的延迟当表之间是有关系的，然后我们进行延迟查询","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"Hibernate","slug":"Hibernate","permalink":"http://lwenxu.coding.me/tags/Hibernate/"}]},{"title":"Hibernate笔记(二)","slug":"Java Web/Hibernate笔记-二","date":"2017-08-21T08:00:58.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/21/Java Web/Hibernate笔记-二/","link":"","permalink":"http://lwenxu.coding.me/2017/08/21/Java Web/Hibernate笔记-二/","excerpt":"1.一对多的关系映射对于一的一方：","text":"1.一对多的关系映射对于一的一方： 1234567891011121314151617181920212223242526272829303132333435package domain;import java.util.HashSet;import java.util.Set;public class Customer &#123; private int cid; private String name; //表示多个联系人 private Set&lt;Person&gt; people=new HashSet&lt;&gt;(); public Set&lt;Person&gt; getPeople() &#123; return people; &#125; public void setPeople(Set&lt;Person&gt; people) &#123; this.people = people; &#125; public int getCid() &#123; return cid; &#125; public void setCid(int cid) &#123; this.cid = cid; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 对于多的一方 1234567891011121314151617181920212223242526272829303132package domain;public class Person &#123; private int uid; private String name; //表示客户 private Customer customer; public Customer getCustomer() &#123; return customer; &#125; public void setCustomer(Customer customer) &#123; this.customer = customer; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getUid() &#123; return uid; &#125; public void setUid(int uid) &#123; this.uid = uid; &#125;&#125; 他们的mapping文件分别就是：一的一方 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;class name=\"domain.Customer\" table=\"customer\"&gt; &lt;id name=\"cid\" column=\"id\"&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;property name=\"name\" column=\"name\"/&gt; &lt;!-- 单方面的维护关系 --&gt; &lt;set name=\"people\" inverse=\"true\"&gt; &lt;key column=\"cpid\"/&gt; &lt;one-to-many class=\"domain.Person\"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 多的一方 12345678910111213&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;class name=\"domain.Person\" table=\"people\"&gt; &lt;id name=\"uid\" column=\"id\"&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;property name=\"name\" column=\"name\"/&gt; &lt;many-to-one name=\"customer\" class=\"domain.Customer\" column=\"clid\"/&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 2.一对多的级联操作首先在一的一方的配置文件的set标签中写一个属性 cascade=”save-update,delete” 这个就是级联配置，然后我们在写具体的代码的时候我们只需要把多的一方设置到一的一方的对象set中就可了，此时直接操作了一的一方就能把多的一方顺便就操作了。 3.多对多的配置1234567891011121314151617181920212223242526272829303132333435package domain1;import java.util.HashSet;import java.util.Set;public class User &#123; private int cid; private String name; //表示多个联系人 private Set&lt;Role&gt; roles=new HashSet&lt;&gt;(); public Set&lt;Role&gt; getRoles() &#123; return roles; &#125; public void setRoles(Set&lt;Role&gt; roles) &#123; this.roles = roles; &#125; public int getCid() &#123; return cid; &#125; public void setCid(int cid) &#123; this.cid = cid; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536package domain1;import java.util.HashSet;import java.util.Set;public class Role &#123; private int cid; private String name; //表示多个联系人 private Set&lt;User&gt; users=new HashSet&lt;&gt;(); public Set&lt;User&gt; getUsers() &#123; return users; &#125; public void setUsers(Set&lt;User&gt; users) &#123; this.users = users; &#125; public int getCid() &#123; return cid; &#125; public void setCid(int cid) &#123; this.cid = cid; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;class name=\"domain1.Role\" table=\"role\"&gt; &lt;id name=\"uid\" column=\"id\"&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;property name=\"name\" column=\"name\"/&gt; &lt;set name=\"users\" table=\"user_role\" cascade=\"save-update,delete\"&gt; &lt;key column=\"rid\"/&gt; &lt;many-to-many class=\"domain1.User\" column=\"uid\"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;class name=\"domain1.User\" table=\"user\"&gt; &lt;id name=\"cid\" column=\"id\"&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;property name=\"name\" column=\"name\"/&gt; &lt;set name=\"roles\" table=\"user_role\"&gt; &lt;key column=\"uid\"/&gt; &lt;many-to-many class=\"domain1.Role\" column=\"rid\"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt;","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"Hibernate","slug":"Hibernate","permalink":"http://lwenxu.coding.me/tags/Hibernate/"}]},{"title":"Hibernate笔记(一)","slug":"Java Web/Hibernate笔记-一","date":"2017-08-21T08:00:52.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/21/Java Web/Hibernate笔记-一/","link":"","permalink":"http://lwenxu.coding.me/2017/08/21/Java Web/Hibernate笔记-一/","excerpt":"","text":"1.导入jar包jar包主要需要导入的有两个文件夹下面的jar包 required 必须要导入的核心包 jpa 实体规范的包2.写一个实体类实体类必须要有一个唯一的id值，对应于表中的主键。其他的就是字段值，字段值不一定和数据库的字段一样，而是可以不一样，然后在配置文件中进行映射。然后生成对应的get与set方法。3.写映射配置文件一般位置就是放在该实体类的位置，名字后缀最好是hbm.xml,然后导入dtd的约束。这个约束是mapping的约束注意不要导错了。 123456789&lt;class name=\"类路径\" table=\"表名\"&gt; &lt;id name=\"实体字段\" column=\"表字段\"&gt; &lt;!-- 主键的生成策略，常用的就是native自增长，还有就是uuid使用128位的uuid算法产生uuid --&gt; &lt;generter&gt;native&lt;/gengrter&gt; &lt;/id&gt; &lt;property name=\"\" column=\"\"/&gt; &lt;property name=\"\" column=\"\"/&gt; &lt;property name=\"\" column=\"\"/&gt;&lt;/class&gt; 4. 写Hibernate的核心配置文件12345678910111213141516171819202122&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC \"-//Hibernate/Hibernate Configuration DTD//EN\" \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!--DB base config--&gt; &lt;property name=\"connection.url\"/&gt; &lt;property name=\"connection.driver_class\"/&gt; &lt;property name=\"connection.username\"/&gt; &lt;property name=\"connection.password\"/&gt; &lt;!--DB schema will be updated if needed--&gt; &lt;property name=\"hbm2ddl.auto\"&gt;update&lt;/property&gt; &lt;property name=\"hibernate.show_sql\"&gt;true&lt;/property&gt; &lt;property name=\"hibernate.format_sql\"&gt;true&lt;/property&gt; &lt;property name=\"hibernate.dialect\"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!--DB Mapping--&gt; &lt;mapping resource=\"\"/&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 4.Hibernate代码12345678910111213141516171819202122232425262728293031323334353637public class Main &#123; private static final SessionFactory ourSessionFactory; //由于创建sessionFactory的时候他会去创建表，非常耗资源，所以一个项目之创建一个SessionFactory //所以我们写一个工具类，在静态代码快中，只被加载一次 static &#123; try &#123; Configuration configuration = new Configuration(); configuration.configure(); ourSessionFactory = configuration.buildSessionFactory(); &#125; catch (Throwable ex) &#123; throw new ExceptionInInitializerError(ex); &#125; &#125; public static Session getSession() throws HibernateException &#123; return ourSessionFactory.openSession(); &#125; public static void main(final String[] args) throws Exception &#123; //session是单例的，不可多线程公用，也就是一个session只能被一个线程使用。我们可以使用threadLocal来把session和本地线程绑定。 final Session session = getSession(); try &#123; System.out.println(\"querying all the managed entities...\"); final Map metadataMap = session.getSessionFactory().getAllClassMetadata(); for (Object key : metadataMap.keySet()) &#123; final ClassMetadata classMetadata = (ClassMetadata) metadataMap.get(key); final String entityName = classMetadata.getEntityName(); final Query query = session.createQuery(\"from \" + entityName); for (Object o : query.list()) &#123; System.out.println(\" \" + o); &#125; &#125; &#125; finally &#123; session.close(); &#125; &#125;&#125; 5.实体类编写规范 属性为私有的 必须有一个唯一的值一般都是id或者uid 属性一般都是使用包装类型，不要使用基本数据类型，就是防止出现null类型的。 6.CRUD操作1.增加首先需要一个对象，这个也就是实体类的对象，然后设置字段的值，最后只需要调用session.save(user)即可插入一条数据。 2.查询根据id查询，直接使用session.get(User.class,id) 第一个参数就是类，第二个是id值。最后返回的不是数组或者list什么的，而是一个实体类的对象。 3.修改首先就需要进行查询，然后修改实体的属性，最后再使用update方法保存即可。save方法也可以，但是如果记录不存在他就会添加。 4.删除还是先查到该对象，然后在调用delete方法。 7.一级缓存Hibernate的一级缓存默认是开启的，他的范围是在session开启导session关闭之间的，一级缓存的存放的对象只能就是持久太的数据。一级缓存一个简单的例子就是，我们第一次查询一条数据的时候这条数据就被被放在内存中，而第二次再次查询此数据的时候他不会取数据库获取数据，而是直接从内存中取到这条数据。Hibernate也是有耳机缓存的，但是现在基本不再使用，而是通过一些NoSQL数据库来完成，存放类似于SessionFactory对象之类的东西。 8.session和本地线程绑定因为session是单例的不可以多个线程同时访问，我们可以使用threadLocal来绑定session和Thread，但是这样比较麻烦，我们Hibernate已经提供了session和thread绑定的方法。首先需要配置核心配置文件thread然后SessionFactory.getCurrentSession()就是获得的与本地线程绑定的线程。线程结束以后session自动被销毁，不需要我们自己关闭session，否则会报错。 9.Hibernate三个查询对象 Query 执行hql语句，调用对应的方法获取结果 12Query query=session.createQuery(\"hql\"); //执行hqlquery.list(); //获取一个list集合 Criteria 无需执行hql，直接调用方法获取结果 12Criteria criteria=session.createCriteria(User.class); //实体类的classcriteria.list(); SQLQuery 调用底层sql 12SQLQuery sql=session.createSQLQuery(\"sql\");//执行sqlsql.list() //每一条记录是一个数组","categories":[{"name":"-Java Web","slug":"Java-Web","permalink":"http://lwenxu.coding.me/categories/Java-Web/"}],"tags":[{"name":"Hibernate","slug":"Hibernate","permalink":"http://lwenxu.coding.me/tags/Hibernate/"}]},{"title":"jsp指令和EL表达式","slug":"Java Web/jsp指令和EL表达式","date":"2017-08-21T03:22:27.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/21/Java Web/jsp指令和EL表达式/","link":"","permalink":"http://lwenxu.coding.me/2017/08/21/Java Web/jsp指令和EL表达式/","excerpt":"1.page指令1.pageEncoding指定jsp的编码 2.contextType设置响应头这两个东西其实使用任意一个即可。","text":"1.page指令1.pageEncoding指定jsp的编码 2.contextType设置响应头这两个东西其实使用任意一个即可。 3.errorPage如果这个页面抛出异常以后重定向到哪一个页面。 2.静态包含 include他是静态包含和RequestDispatcher类似，但是就是包含的时期不一样。静态包含就是在jsp编译成java的时候形成的，也就是最终是两个文件合并成了一个class，最后形成一个class文件RequestDispatcher则是动态包含，他们在显示之前始终是两个java文件，两个class，在最后需要显示的时候才把内容整合发送给客户端。 3.导入标签库 importprefix制定标签库的前缀，uri就是标签库的位置。 4.九大内置对象 out jsp的输出流，向浏览器输出数据 page 当前的jsp对象，也就是在编译成大java中有page=this config 对应的servletConfig对象 pageContext 包含其他的所有 域对象之一 request response exception session HttpSession application servletContext 5.四大对象作用范围 ServletContext 一个应用 Session 一个会话 Request 一个请求 pageContext 一个jsp页面 ，一般用来jsp标签的数据传输 6.pageContext作用 代理其他的三大域对象pageContext.setAttribute(“key”,”value”,pageContext.SESSION_SCOPE); 存放在session中代理了session 全域查找pageContext.findAttribute(“key”) 在这四大域对象中依次查找 获取其他的jsp八大内置对象 7.JSP动作标签 &lt;jsp:forward page=””/&gt; 转发 &lt;jsp:include page=””/&gt; 包含 &lt;jsp:param name=”” value=””/&gt; 为其他的标签传递参数 8.EL表达式EL表达式主要就是用来代替JSP中的 &lt;%= %&gt; 这个标签的，他可以简单的用于输出语句 输出四大域对象中的内容${key} 这样就可以全域查找到四大域对象中的key变量 如果key是一个对象的话，我们希望获取这个对象里面的某个get方法的返回值，我们只需要key.key1 key1就是getKey1()这个方法的返回值。 精确的四大域对象查找${pageScope.key}${requestScope.key}${sessionScope.key}${applicationScope.key} 其他7个内置对象 param paramValue header headerValue cookie pageContext 他可以获取其他所有的10个对象，因为它里面有其他十个对象的get方法。 EL 函数库导入对应的库，然后使用标签调用函数库 9.JSTLJSTL是EL的扩展，因为EL只是进行输出而已，但是有一些判断，遍历等等，这些操作就是JSTL。他需要引入jstl.jar他有四大库，但是常用的只有两个一个是core另外一个就是formate标签库注意导入的时候uri是jsp/core 或者 jsp/formate 1.core标签库(c标签) out 输出标签 value就是要输出的变量 set 设置某个变量的值 var变量名 value变量值 url url格式化的标签 value 自动添加上项目名 里面如果加param标签那么就可以传递参数 name/value remove 删除域变量 var变量名 scope域范围，不写的话删除全域的对象中的此值 if if语句 test 判断的条件 ${not empty key} 如果key不是空 forEach 计数方式 var循环变量 begin循环变量从几开始 end到几结束 step设置步长 用来遍历 items需要迭代的变量 var每一次迭代的变量 choose/when 多分支 123456&lt;c:choose&gt; &lt;c:when test&gt;&lt;/c:when&gt; &lt;c:when test&gt;&lt;/c:when&gt; &lt;c:when test&gt;&lt;/c:when&gt; &lt;c:when test&gt;&lt;/c:when&gt;&lt;/c:choose&gt; 2.formate标签库 formateDate value需要格式化的变量 pattern yyyy-MM-dd HH:mm:ss formateNumber value变量 pattern 0.00 需要小数点两位 四舍五入","categories":[{"name":"-JAVA","slug":"JAVA","permalink":"http://lwenxu.coding.me/categories/JAVA/"}],"tags":[{"name":"java","slug":"java","permalink":"http://lwenxu.coding.me/tags/java/"}]},{"title":"JavaWeb基础二:JSP","slug":"Java Web/JavaW_eb基础三_ JSP","date":"2017-08-21T02:26:18.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/21/Java Web/JavaW_eb基础三_ JSP/","link":"","permalink":"http://lwenxu.coding.me/2017/08/21/Java Web/JavaW_eb基础三_ JSP/","excerpt":"","text":"1. JSP 标签我们常用的 jsp 标签有两种，实际上有三种 jsp 标签。 &lt;% %&gt; 这种就是可以放 java 代码 &lt;%= %&gt; 这种就是输出语句，类似 PHP 中的简写语法 &lt;%! %&gt; 放各种生命代码，基本不用。 其实JSP最终还是一个Servlet，主要他的优点在于，可以在一个Servlet中直接写html代码，防止我们去写很多 out.print(“html代码”) ，或者说我们可以在html中写 java 脚本。但是并不是说我们使用了jsp 就不再使用Servlet，他们之间是有区别的，分工不一样。 jsp主要就用来显示表单，显示数据结果 Servlet就是用来处理数据，返回给jsp2. JSP 原理服务器启动后的第一次访问时，服务器会把这个文件转化为java文件，并且这个java文件是实现了servlet接口的一个类然后再把此java文件，转化成一个class文件，实例化对象，然后调用service方法。而在第二次访问的时候就是直接调用service方法。这也就是第一次惩戒。jsp被编译成的java放在了tomcat的work目录下面。具体的看一下jsp编译出来的文件的时候就会发现里面是有六个private对象，还有两个分别就是request和response被tomcat传入。也就是有8个对象 ，还有一个exception没在这。所以这里就知道了jsp的九大内置对象。 3. JSP指令1. page指令1. pageEncoding指定jsp的编码 2. contextType设置响应头这两个东西其实使用任意一个即可。 3. errorPage如果这个页面抛出异常以后重定向到哪一个页面。 4. IsErrorPage=true标记这个页面可使用 expection 对象，其他页面不行。 5. session=”true”当前页可使用 session 对象 2. 静态包含 include他是静态包含和RequestDispatcher类似，但是就是包含的时期不一样。 静态包含就是在jsp编译成java的时候形成的，也就是最终是两个文件合并成了一个class，最后形成一个class文件。RequestDispatcher则是动态包含，他们在显示之前始终是两个java文件，两个class，在最后需要显示的时候才把内容整合发送给客户端。 3. 导入标签库 importprefix制定标签库的前缀，uri就是标签库的位置。 4.九大内置对象 out jsp的输出流，向浏览器输出数据 page 当前的jsp对象，也就是在编译成大java中有page=this config 对应的servletConfig对象 pageContext 代理其他的所有域对象，在标签之间传数据。 request response exception session （HttpSession） application （servletContext） 5.四大对象作用范围 ServletContext 一个应用 Session 一个会话 Request 一个请求 pageContext 一个jsp页面 ，一般用来jsp标签的数据传输 6.pageContext作用 代理其他的三大域对象pageContext.setAttribute(“key”,”value”,pageContext.SESSION_SCOPE); 存放在session中代理了session 全域查找pageContext.findAttribute(“key”) 在这四大域对象中依次查找 获取其他的jsp八大内置对象 7.JSP动作标签 &lt;jsp:forward page=””/&gt; 转发 &lt;jsp:include page=””/&gt; 包含 &lt;jsp:param name=”” value=””/&gt; 为其他的标签传递参数 8.EL表达式EL表达式主要就是用来代替JSP中的 &lt;%= %&gt; 这个标签的，他可以简单的用于输出语句 输出四大域对象中的内容${key} 这样就可以全域查找到四大域对象中的key变量 如果key是一个对象的话，我们希望获取这个对象里面的某个get方法的返回值，我们只需要key.key1 key1就是getKey1()这个方法的返回值。 精确的四大域对象查找${pageScope.key}${requestScope.key}${sessionScope.key}${applicationScope.key} 其他7个内置对象 param paramValue header headerValue cookie pageContext 他可以获取其他所有的10个对象，因为它里面有其他十个对象的get方法。 EL 函数库导入对应的库，然后使用标签调用函数库 9.JSTLJSTL是EL的扩展，因为EL只是进行输出而已，但是有一些判断，遍历等等，这些操作就是JSTL。他需要引入jstl.jar他有四大库，但是常用的只有两个一个是core另外一个就是formate标签库注意导入的时候uri是jsp/core 或者 jsp/formate 1.core标签库(c标签) out 输出标签 value就是要输出的变量 set 设置某个变量的值 var变量名 value变量值 url url格式化的标签 value 自动添加上项目名 里面如果加param标签那么就可以传递参数 name/value remove 删除域变量 var变量名 scope域范围，不写的话删除全域的对象中的此值 if if语句 test 判断的条件 ${not empty key} 如果key不是空 forEach 计数方式 var循环变量 begin循环变量从几开始 end到几结束 step设置步长 用来遍历 items需要迭代的变量 var每一次迭代的变量 choose/when 多分支 123456&lt;c:choose&gt; &lt;c:when test&gt;&lt;/c:when&gt; &lt;c:when test&gt;&lt;/c:when&gt; &lt;c:when test&gt;&lt;/c:when&gt; &lt;c:when test&gt;&lt;/c:when&gt;&lt;/c:choose&gt; 2.formate标签库 formateDate value需要格式化的变量 pattern yyyy-MM-dd HH:mm:ss formateNumber value变量 pattern 0.00 需要小数点两位 四舍五入","categories":[{"name":"-Java Web","slug":"Java-Web","permalink":"http://lwenxu.coding.me/categories/Java-Web/"}],"tags":[{"name":"Java Web","slug":"Java-Web","permalink":"http://lwenxu.coding.me/tags/Java-Web/"}]},{"title":"Java8新特性","slug":"Java SE/Java8新特性","date":"2017-08-19T02:49:28.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/19/Java SE/Java8新特性/","link":"","permalink":"http://lwenxu.coding.me/2017/08/19/Java SE/Java8新特性/","excerpt":"1.HashMap首先就是对 java 的 HashMap 进行了修改，以前是通过 hashCode 方法来判断他们的地址值是否一样，如果相同的话再使用 equals 方法比对他们的 equals 返回的结果是否一样，是则不存入否则的话就形成一个链表直接挂在原有元素的后面。这个地方就有一个比较大的问题就是使用 hashCode 方法的时候组字坏的情况时需要和每一个元素比对 hashCode 比较的次数就变多了。 这里后来提出了一种解决方案，就相当于一个数组，然后数组的元素就是一个 entry","text":"1.HashMap首先就是对 java 的 HashMap 进行了修改，以前是通过 hashCode 方法来判断他们的地址值是否一样，如果相同的话再使用 equals 方法比对他们的 equals 返回的结果是否一样，是则不存入否则的话就形成一个链表直接挂在原有元素的后面。这个地方就有一个比较大的问题就是使用 hashCode 方法的时候组字坏的情况时需要和每一个元素比对 hashCode 比较的次数就变多了。 这里后来提出了一种解决方案，就相当于一个数组，然后数组的元素就是一个 entry这样的话 hashCode 值只需要成为数组的下标即可，可以直接取出数据，然后再调用 equals 方法，这里还需要注意的是，这个数组一开始是 16 个，但是当容量达到总容量的 75% 的时候就进行扩容，而不可以等到 100% 原因就是防止有一些元素始终在某个位置插入而其他的位置始终为空。这就是新特性对于 hashCode 方法这一块的优化方案。然后对于后面的 equals 方法形成的链表，java8也进行了优化，具体就是当元素的总个数超过 64 链表的长度超过 8 的时候把链表元素形成红黑树，红黑树也是二叉树的一种，可以简单的理解为若元素大于根元素放左边小于放右边。这样以来再链表查询的时候就可以快速定位。 2.CurrentHashMap这里使用了 CAS 算法，从而实现了无锁添加元素，因为 CAS 算法是受底层的操作系统的支持的，所以效率很高。 3.永久区 PremGen以前堆内存中是有一块内存称之为永久区，这个区主要存放的就是类的加载信息，尤其是核心类库。但是这个区一般很少被垃圾回收机制所回收。在 java8 中彻底的把这个区去掉了，二天了一个元空间区 Matespace 他是用的物理内存，而不是从系统申请来的。 4.Lambda 表达式java8 中的 Lambda 表达式就是一种语法糖，简化书写用的。例如我们需要对一个员工集合里面的元素进行筛选，筛选出工资大于 5000 的员工，然后我们还需要筛选出年龄小于 50 的员工，这样的话我们就会发现这两个函数功能虽然不一样其实很多东西就是重复的，这里可以使用一个设计模式就是策略设计模式，这个设计模式主要的实现方式就是定义一个接口，然后只用写一个方法，在这个方法的参数列表中使用这个接口，使用这个接口的方法来处理我们的需求。类似于所说的回调函数。当我们调用方法的时候我们需要传入这个接口的实际对象，这时候这根 函数就会因为我们传入的对象不同从而执行不同的方法。这个需要传入的对象，我们可以使用匿名内部类来实现，这个时候我们发现这个匿名内部类最重要的就是实现的接口的那个函数的方法体。我们这里就是可使用 Lambda 表达式来代替匿名内部类。 5. Lambda 表达式的语法Lambda 表达式的语法很简单，左侧就是需要实现接口的函数的参数，然后这个东西当参数只有一个的时候圆括号可以不写，然后这里面的参数都不用带类型，当然带上也没问题，主要是 java8 的新特新中有一个就是类型推断，例如说在写泛型的时候 new 对象的时候我们并没有写泛型的名称。而是 java 自动推断出来的。其右侧就是正宗的方法体，这个方法体如果有多行代码的时候呢我们需要时使用大括号包含起来。否则就可以直接是用一行代码即可。当只有一行代码的时候我们返回值的 return 语句都可以不用写，直接写表达式即可。但是注意这个地方我们的 Lambda 表达式只实现了接口中的一个方法，那如果接口中有多个方法，表达式就不知道需要实现哪一个，所以这里就有一个约定就是接口必须是函数式接口，所谓函数是借口就是接口中只有一个函数，然后我们可以使用 @FunctionalInterface 这个注解来声明他就是一个函数式接口。 6. 四大核心接口1. Consumer 消费接口 传一个参数没有返回值 T accept(T t) 2. Supplier 供给接口 不传参数，返回一个东西 T get() 3. Funtion 函数接口 传进去一个T，返回一个M M apply(T t) 4. Pridecate 断言接口 boolean test(T t)","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://lwenxu.coding.me/tags/Java8/"}]},{"title":"Java多线程JUC","slug":"Java SE/Java多线程JUC","date":"2017-08-19T02:49:28.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/19/Java SE/Java多线程JUC/","link":"","permalink":"http://lwenxu.coding.me/2017/08/19/Java SE/Java多线程JUC/","excerpt":"1. volatile 关键字多线程访问的时候，一个比较严重的问题就是内存不可见，其实在内存访问的时候每一个线程都有一个自己的缓冲区，每次在做修改的时候都是从主存取到数据，然后放到自己的缓冲区中，在做完修改之后放回主存。这样每一个线程之间的变量是不可见的。造成读到的数据可能始终就是错误的，因此有一个关键字可以使得这个共享变量称为透明的。就好像所有的操作就直接是在内存中操作一样，因为他一直不停的去同步主存的数据。","text":"1. volatile 关键字多线程访问的时候，一个比较严重的问题就是内存不可见，其实在内存访问的时候每一个线程都有一个自己的缓冲区，每次在做修改的时候都是从主存取到数据，然后放到自己的缓冲区中，在做完修改之后放回主存。这样每一个线程之间的变量是不可见的。造成读到的数据可能始终就是错误的，因此有一个关键字可以使得这个共享变量称为透明的。就好像所有的操作就直接是在内存中操作一样，因为他一直不停的去同步主存的数据。 2.原子性i++ 这个运算，其实在底层低用的就是临时变量的方式，这样的话虽然是一个表达式，但是在多线程的时候就会出现安全问题。 12345678910111213141516171819202122232425262728package atomic;/** * @Author: lwen * @Date: Created in 2017/8/19 15:26 * @Description: */class Test implements Runnable&#123; private volatile int i=0; @Override public void run() &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(i++); &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Test t=new Test(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(t).start(); &#125; &#125;&#125; 最后运行的结果，显然就是 volatile 这个关键字他只是让变量课件也就是都是在主存中操作，但是他没有互斥的作用简单来说没有锁来控制，他们都及时的从主存里面拿到了数据，但是他们拿到最新的数据了，正在运算的时候有人提交了结果，所以导致重复元素。最根本原因是 i++ 有三步操作，读，运算，写 1320476588Process finished with exit code 0 java 底层提供了一些原子性的变量，例如 AtomicInteger 这些东西他们既然是源自的首先就是可见的。这些东西的底层主要是使用了 CAS ( CompareAndSet ) 算法，CAS 算法主要是操作系统在硬件上提供的支持。这个算法有三个重要的参数：第一个就是 V 就是运算前从内存读取的值 A 写入前从内存中读取的值 B 最终需要写入的值。在写入前做一次判断当且仅当 V == A 时才会写入 B 否则什么操作也不做。 3.ConcurrentHahsMap 安全的 HashMap这是一个线程安全的 HashMap ，说道线程安全的 HahsMap 自然就有 HashTable 但是这个效率非常的低，主要就是因为他的封锁粒度太大，他锁的是整个 HashTable 也就是两个不相干的 HashTable 也是互斥访问的，在 jdk1.5 以后使用的就是 ConcurrentHahsMap 这个东西那个时候主要使用的锁分段机制，也就是在原来的基础上把 HashTable 分16段，每一段对应一个 HashMap 这样的话两个互不相干的 HashMap 是可以同步访问的。 4.CountDownLatch 闭锁所谓的闭锁说白了就是该线程会等到洽谈所有线程的代码都运行结束了才开始运行，他的底层实现就是维护一个变量，这个变量就是当前存活的线程的数量，当他减成0了也就是其他的线程都运行完了，此时这个闭锁线程可以开始。例如说我们开十个线程做某一件事情，我们在主线程中统计这十个线程的总的运行时间。 12345678910111213141516171819202122232425262728293031323334353637383940414243package latch;import com.sun.javafx.sg.prism.web.NGWebView;import java.util.concurrent.CountDownLatch;/** * @Author: lwen * @Date: Created in 2017/8/19 16:06 * @Description: */class Latch implements Runnable&#123; private CountDownLatch latch; public Latch(CountDownLatch latch) &#123; this.latch = latch; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread()); try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; latch.countDown(); //线程结束以后，需要给维护的变量减一 &#125;&#125;public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; int start= (int) System.currentTimeMillis(); CountDownLatch downLatch= new CountDownLatch(10); //定义十个线程 Latch latch=new Latch(downLatch); for (int i = 0; i &lt; 10; i++) &#123; new Thread(latch).start(); &#125; downLatch.await(); //当线程没有完全结束的时候，主线程需要等待 int end= (int) System.currentTimeMillis(); System.out.println(end-start); &#125;&#125; 4.线程的第三种创建方式一般我们创建线程我们使用的都是继承 Thread 类，或者实现 Runnable 接口，但是还是主要使用的是实现 Runnable 接口，但是注意这两个方式他们嗾使没有返回值的东西。也就是我么不能多线程没有办法返回一些结果。这里就出现了创建线程的第三种方式，也就是可以得到返回值的方式，就是使用 Callable 接口，这个接口的使用需要使用 FutureTask 类，而这个类实现了 Runnable 和 Future 接口，他的具体的使用方式和 Runnable 接口还是有一点不一样的。 12345678910111213141516171819202122232425262728293031323334package future;import org.omg.PortableInterceptor.INACTIVE;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;/** * @Author: lwen * @Date: Created in 2017/8/19 16:23 * @Description: */class Future implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; int sum=0; for (int i = 0; i &lt; 1000; i++) &#123; sum+=i; &#125; return sum; &#125;&#125;public class Main &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; Future future=new Future(); FutureTask&lt;Integer&gt; task=new FutureTask&lt;Integer&gt;(future); new Thread(task).start(); System.out.println(task.get());;//获取最终的返回值，但是注意这个地方的这个方法其实就是一个闭锁，前面的那个县城没有执行完，这个地方是不会执行的 &#125;&#125; 5.高级同步解决同步问题总共就有三种方式，分别就是同步代码块，同步函数，和同步锁。也就是手动的声明 lock 加锁，然后使用 unlock 释放锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344package lock;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * @Author: lwen * @Date: Created in 2017/8/19 16:33 * @Description: */class Ticket implements Runnable&#123; private int ticket=100; Lock lock=new ReentrantLock(); @Override public void run() &#123; while (true) &#123; lock.lock(); try &#123; if (ticket != 0) &#123; try &#123; Thread.sleep(20); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; ticket--; System.out.println(Thread.currentThread().getName() + \":\" + ticket); &#125; &#125;finally &#123; lock.unlock(); //解锁必须放在finally里面保证能够执行到 &#125; &#125; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Ticket t=new Ticket(); new Thread(t,\"窗口一\").start(); new Thread(t,\"窗口二\").start(); new Thread(t,\"窗口三\").start(); &#125;&#125; 6.生产者和消费者的线程同步问题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package product;import java.util.logging.Level;/** * @Author: lwen * @Date: Created in 2017/8/19 16:57 * @Description: */class Clerk &#123; private int production=0; public synchronized void get() throws InterruptedException &#123; while (production&gt;=1)&#123; //notifyAll 可能会形成假唤醒问题，所以说必须要使用while一直判断而不能使用if System.out.println(\"已满\"); this.wait(); &#125; System.out.println(Thread.currentThread().getName()+\":\"+ ++production); this.notifyAll(); &#125; public synchronized void sale() throws InterruptedException &#123; while (production&lt;=0)&#123; System.out.println(\"卖完\"); this.wait(); &#125; System.out.println(Thread.currentThread().getName()+\":\"+ --production); this.notifyAll(); &#125;&#125;class Product implements Runnable&#123; private Clerk clerk; public Product(Clerk clerk) &#123; this.clerk = clerk; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 20; i++) &#123; try &#123; Thread.sleep(20); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; clerk.get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class Consumer implements Runnable&#123; private Clerk clerk; public Consumer(Clerk clerk) &#123; this.clerk = clerk; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 20; i++) &#123; try &#123; Thread.sleep(20); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; clerk.sale(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Clerk clerk=new Clerk(); Product p=new Product(clerk); Consumer consumer=new Consumer(clerk); new Thread(p,\"生产者1\").start(); new Thread(p,\"生产者2\").start(); new Thread(consumer,\"消费者1\").start(); new Thread(consumer,\"消费者2\").start(); &#125;&#125; 7.读写锁排斥写写和读写同时进行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package readandwrite;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantReadWriteLock;/** * @Author: lwen * @Date: Created in 2017/8/19 17:29 * @Description: */class ReadWriteLockDemo &#123; private int number=0; private ReadWriteLock lock=new ReentrantReadWriteLock(); public void read()&#123; lock.readLock().lock(); try &#123; System.out.println(Thread.currentThread().getName()+\":\"+number); &#125;finally &#123; lock.readLock().unlock(); &#125; &#125; public void write(int number) throws InterruptedException &#123; lock.writeLock().lock(); Thread.sleep(20); try &#123; this.number=number; System.out.println(\"write\"); &#125;finally &#123; lock.writeLock().unlock(); &#125; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; ReadWriteLockDemo readWriteLockDemo=new ReadWriteLockDemo(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; readWriteLockDemo.write(20); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); for (int i = 0; i &lt; 20; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; readWriteLockDemo.read(); &#125; &#125;).start(); &#125; &#125;&#125; 4.线程池1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package pool;import java.util.concurrent.*;/** * @Author: lwen * @Date: Created in 2017/8/19 17:56 * @Description: */class Test implements Runnable&#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125;&#125;class Test1 implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; int sum=0; for (int i = 0; i &lt;= 100; i++) &#123; sum+=i; &#125; return sum; &#125;&#125;public class Main &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; //注意线程池里面装的都是线程，这些线程到时候再次使用的时候不需要再次创建，也就是代表操作系统不需要再次分配资源，分配pid等等 //而不是说里面装的是任务，这里仅仅就是线程而已 ExecutorService executor= Executors.newFixedThreadPool(10); //固定大小的线程池 ExecutorService executor1=Executors.newSingleThreadExecutor(); //一个线程的线程池 ExecutorService executor2=Executors.newCachedThreadPool(); //动态变化的线程池 for (int i = 0; i &lt; 20; i++) &#123; executor.submit(new Test()); &#125; Future&lt;Integer&gt; future=executor1.submit(new Test1()); System.out.println(future.get()); executor.shutdown(); //只有当线程池关闭的时候 程序才会停止 executor1.shutdown(); executor2.shutdown(); &#125;&#125; 8.线程调度：线程调度可以决定在多久之后执行什么操作。 1234567891011121314151617181920212223242526272829package schedule;import java.util.Random;import java.util.concurrent.*;/** * @Author: lwen * @Date: Created in 2017/8/19 18:11 * @Description: */public class Main &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ScheduledExecutorService service= Executors.newScheduledThreadPool(5); for (int i = 0; i &lt; 5; i++) &#123; Future&lt;Integer&gt; future=service.schedule(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int random=new Random().nextInt(100); System.out.println(Thread.currentThread().getName()+\":\"+random); return random; &#125; &#125;,1, TimeUnit.SECONDS); System.out.println(future.get()); &#125; service.shutdown(); &#125;&#125;","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://lwenxu.coding.me/tags/多线程/"}]},{"title":"内部类的作用","slug":"Java SE/内部类的作用","date":"2017-08-19T02:49:28.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/19/Java SE/内部类的作用/","link":"","permalink":"http://lwenxu.coding.me/2017/08/19/Java SE/内部类的作用/","excerpt":"一、 作用 内部类可以很好的实现隐藏，一般的非内部类，是不允许有 private 与protected权限的，但内部类可以加上这几个修饰词。 内部类拥有外围类的所有元素的访问权限，可以直接访问外部类的私有属性及方法 可以间接实现多重继承，多个内部类继承不同的类形成了一个类中复用了多个类的方法。 可以避免在继承一个父类和一个接口的时候导致的方法重复定义。","text":"一、 作用 内部类可以很好的实现隐藏，一般的非内部类，是不允许有 private 与protected权限的，但内部类可以加上这几个修饰词。 内部类拥有外围类的所有元素的访问权限，可以直接访问外部类的私有属性及方法 可以间接实现多重继承，多个内部类继承不同的类形成了一个类中复用了多个类的方法。 可以避免在继承一个父类和一个接口的时候导致的方法重复定义。 二、详解1.实现隐藏12345678910111213141516171819public class Example &#123; //private 修饰词 private class InsideClass implements InterfaceTest &#123; public void test() &#123; System.out.println(\"这是一个测试\"); &#125; &#125;&#125; 2.可以无条件地访问外围类的所有元素12345678public class TagBean &#123; private String name=\"lwen\"; private class InTest&#123; public InTest()&#123; System.out.println(name); &#125; &#125;&#125; 3.可以间接实现多重继承​ 个特点非常重要，个人认为它是内部类存在的最大理由之一。正是由于他的存在使得Java的继承机制更加完善。大家都知道Java只能继承一个类，它的多重继承在我们没有学习内部类之前是用接口来实现的。但使用接口有时候有很多不方便的地方。比如我们实现一个接口就必须实现它里面的所有方法。而有了内部类就不一样了。它可以使我们的类继承多个具体类或抽象类。大家看下面的例子。 12345678class Test&#123; class A extends C &#123; &#125; class B extends D&#123; &#125;&#125; 四、 避免同名方法的冲突。 如果你的类要继承一个类，还要实现一个接口，可是你发觉你继承的类和接口里面有两个同名的方法怎么办？你怎么区分它们？？这就需要我们的内部类了。看下面的代码 123456789101112131415public interface Incrementable &#123; void increment();&#125;public class Test&#123; public void increment() &#123; System.out.println(\"Other increment()\"); &#125;&#125;public class Callee2 extends MyIncrement implements Incrementable &#123; public void increment() &#123; &#125;&#125; increment()这个方法是属于覆盖MyIncrement这里的方法呢？还是Incrementable这里的方法。我怎么能调到MyIncrement这里的方法？显然这是重复定义。","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://lwenxu.coding.me/tags/Java8/"}]},{"title":"静态内部类","slug":"Java SE/静态内部类","date":"2017-08-19T02:49:28.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/19/Java SE/静态内部类/","link":"","permalink":"http://lwenxu.coding.me/2017/08/19/Java SE/静态内部类/","excerpt":"定义：静态内部类，定义在类中，任何方法外，用static定义；静态内部类只能访问外部类的静态成员。","text":"定义：静态内部类，定义在类中，任何方法外，用static定义；静态内部类只能访问外部类的静态成员。 注意点： 一般情况下，如果一个内部类不是被定义成静态内部类，那么在定义成员变量或者成员方法的时候，是不能够被定义成静态成员变量与静态成员方法的。也就是说，在非静态内部类中不可以声明静态成员。 一般非静态外部类可以随意访问其外部类的成员变量以及方法（包括声明为private的方法），但是如果一个内部类被声明为static，则其在访问包括自身的外部类会有诸多的限制。静态内部类不能访问其外部类的非静态成员变量和方法。 在一个类中创建非静态成员内部类的时候，有一个强制性的规定，即内部类的实例一定要绑定在外部类的实例中，也就是在编译时期，编译器会给外部类江上一个字段就叫做 OuterClassName.this 而如果是静态内部类，外部类就不存在这个属性。也就是要引用内部类首先得 new 出外部类。如果要在一个类中定义一个静态的内部类，不需要利用关键字new来创建外部类的实例。即在创建静态类内部对象时，不需要其外部类的对象存在。","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"http://lwenxu.coding.me/tags/Java8/"}]},{"title":"JavaIO","slug":"Java SE/JavaIO","date":"2017-08-09T07:49:28.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/JavaIO/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/JavaIO/","excerpt":"1.在IO有两种数据传输格式一个是字符流还一个是字节流但是字符流就会涉及到编码的问题 一开始美国使用的自己的编码表就是ASCII表 中国的字符需要被识别也需要编码表于是就有了GB2312 但是由于中国的子很多，还有少数名族等等后来又进行了优化扩容就出现了GBK 最后国际标准组织制定了一个包含所有国家所有地区的码表就是Unicode 之后对Unicode进行了优化也就是以前是所有的字符都是两个字节表示，但是现在就可以一个字节或者三个字节，具体看情况的UTF_8字符流一般都包含了编码表，也就是在传输的时候你可以指定编码方式然后IO流帮你转换","text":"1.在IO有两种数据传输格式一个是字符流还一个是字节流但是字符流就会涉及到编码的问题 一开始美国使用的自己的编码表就是ASCII表 中国的字符需要被识别也需要编码表于是就有了GB2312 但是由于中国的子很多，还有少数名族等等后来又进行了优化扩容就出现了GBK 最后国际标准组织制定了一个包含所有国家所有地区的码表就是Unicode 之后对Unicode进行了优化也就是以前是所有的字符都是两个字节表示，但是现在就可以一个字节或者三个字节，具体看情况的UTF_8字符流一般都包含了编码表，也就是在传输的时候你可以指定编码方式然后IO流帮你转换 在IO流里面就是有四个抽象的顶层接口 字节流的： InputStream OutputStream 字符流： Reader Writer 3.装饰设计模式： 也就是基于原理已经有的对象，在此对象的基础上提供更强大的功能，也就是能达到不修源码的情况下扩展原来的类的功能 用于增强的的类称为装饰类，这个类一般都是用构造函数来接受需要被装饰的类的对象就例如BufferedRead()内部就调用了 FileReader的read方法 一说到功能扩展自然就会想到继承，这里就要说一下有时候为什么还需要装饰模式。 假如说有以下类层次结构： —ReadText —ReadMedia —ReadData 那么我们要用缓冲区读的话我们就会有以下的类层次结构： —ReadText |–BufferedReadText —ReadMedia |–BufferedReadMedia —ReadData |–BufferedReadData 类层级就非常臃肿 所以我们想到就用装饰者模式： 假如有以下装饰类： 1234567891011class BufferedReader&#123; BufferedReader(ReadText readText)&#123; &#125; BufferedReader(ReadMedia readMedia)&#123; &#125; BufferedReader(ReadData readData)&#123; &#125;&#125; 这样虽然可以，但是我们要拓展Read的子类这个装饰类必须要修改，拓展性很差 所以我们直接就用多态性质 123456789101112131415class BufferedReader extends Read&#123; private Read read; BufferedReader(Read read)&#123; &#125; public int read(char cbuf[], int off, int len)&#123; return read.read( cbuf[], off, len);//这里我们必须要复写Read里面的抽象方法，但是我们不知道这个read怎么实现，所以我们直接调用传进来的子类的对象的read方法 &#125; public boolean close()&#123; return read.close(); //同上 &#125;&#125; 这样一来类层级结构就是： —Read |—ReadText |—ReadMedia |—ReadData |—BufferedRead 注意装饰类是Read的子类，并且他和被装饰类是同一个层次，因为他是更强的被装饰类，所以他们是同一个层级 4.字节流的处理 InputStream |–FileInputStream OutputStream |–FileOutputStream 这两个类的处理方式和上面的字符流完全一样，唯一一点的不同就是，它里面读取的时候还有一个avaliable方法可以确定文件中字节大小，还有就是他是以字节为单位的​ 123456789101112131415161718192021222324252627282930313233343536373839public class FileInputStreamDemo &#123; public static void main(String[] args) throws IOException&#123; FileInputStream fileInputStream=new FileInputStream(\"a.txt\"); read_3(fileInputStream); &#125; public static void read_1(FileInputStream fileInputStream)throws IOException&#123; byte by; while ((by= (byte) fileInputStream.read())!=-1)&#123; System.out.print((char) by); &#125; &#125; public static void read_2(FileInputStream fileInputStream)throws IOException&#123; byte[] buffer=new byte[1024]; char[] buf=new char[1024]; int num=0; StringBuilder builder=new StringBuilder(); while ((num=fileInputStream.read(buffer))!=-1)&#123; // TODO: 2017/7/16 转数组为字符串的问题 尤其是基本类型转字符串的问题 是不是还有什么好的对象去做这件事 for (byte b:buffer)&#123; builder.append((char) b); &#125; &#125; System.out.println(builder); &#125; public static void read_3(FileInputStream fileInputStream) throws IOException&#123; byte[] by=new byte[fileInputStream.available()]; //这个函数就可以确定字节个数 不过只能用于较小的文件 大文件开辟太大的缓冲区会出问题 fileInputStream.read(by); StringBuilder stringBuilder=new StringBuilder(); for (byte bys:by)&#123; // TODO: 2017/7/16 转数组为字符串的问题 尤其是基本类型转字符串的问题 是不是还有什么好的对象去做这件事 stringBuilder.append((char)bys); &#125; System.out.println(stringBuilder); &#125;&#125; 5.当然也是有BufferedInputStream和BufferedOutputStream这两个装饰类 注意这个和前面的一模一样 6.流对象的使用，流对象的使用它们的类别太多，这里为了区分使用哪一个流对象我们就具体分析一下： 1.明确源和目的： 源的话我们就是用InputStream和Reader 目的则是OutputStream和Writer 2.之后就是确定是否为纯文本： 是：字符流 否：字节流 3.确定具体的对象： 通过设备来区分：硬盘，控制台，内存等等 分别使用合适的子类 然后根据是否需要更强的功能，更快的速度使用Buffered包装类","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"IO","slug":"IO","permalink":"http://lwenxu.coding.me/tags/IO/"}]},{"title":"Java多线程","slug":"Java SE/Java多线程","date":"2017-08-09T07:49:28.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java多线程/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java多线程/","excerpt":"1.复写run方法的目的在于，把要运行的代码放到run方法里面，也就是新的线程要跑什么内容这也就是第一种多线程的方法，其主要的步骤如下： 继承Thread类 复写run方法 创建对象 start","text":"1.复写run方法的目的在于，把要运行的代码放到run方法里面，也就是新的线程要跑什么内容这也就是第一种多线程的方法，其主要的步骤如下： 继承Thread类 复写run方法 创建对象 start 任何一个程序至少有一个线程就是主线程，主线程也是main方法的线程，这个线程是由jvm启动的，当我们自己创建新的线程的时候实际上是在主线程之外另开的新的线程和主线程并行工作12345678910111213141516171819class DemoRun extends Thread&#123; @Override public void run() &#123; for (int i = 0; i &lt; 60; i++) &#123; System.out.println(\"thread---\"+i); &#125; &#125;&#125;public class ThreadDemo &#123; public static void main(String[] args) &#123; DemoRun demoRun=new DemoRun(); //创建线程 demoRun.start();//start方法有两个作用，一个是启动线程，第二个就是调用run方法 //如果仅仅是使用run方法的话，也就仅仅调用了run方法里面的代码，而并没有开启多线程，run方法的线程还是在主线程 for (int i = 0; i &lt; 60; i++) &#123; System.out.println(\"main---\"+i); &#125; &#125;&#125; 3.第一种创建线程的方式其实会有很大的局限性，例如说，我们说java是单继承的语言，那么也就会出现一个class继承了父类，无法在继承Thread类 而java却是多实现的，我们就可以继承runnable接口完成。但是注意，runnable接口并不是一个Thread类的对象，说白了他不是一个线程，那么我们 就不知道我们多线程到底要运行哪的代码，不明确run方法。所以我们就先建立Thread的对象，然后把runnable接口的对象传递给Thread类，这样一来Thread类就明确了 run方法的位置，也就是多线程要运行的代码的位置。 12345678910111213141516171819class RunnableTest implements Runnable&#123; @Override public void run() &#123; for (int i = 0; i &lt; 60; i++) &#123; System.out.println(Thread.currentThread().getName()+\"-----\"+i); &#125; &#125;&#125;public class RunnableDemo &#123; public static void main(String[] args) &#123; RunnableTest runnableTest=new RunnableTest(); Thread run=new Thread(runnableTest); Thread run1=new Thread(runnableTest); run.start(); //注意如果实现的runnable接口的话一个线程可以启动多次，相当于多个线程，里面的属性可以当做共享变量来使用，因为是同一个对象 run1.start(); &#125;&#125; 4.在说完多线程的创建以后最重要的就是线程的安全问题，主要就是共享变量的问题。例如上面的说到的实现runnable接口的时候，我们的属性就可以是共享变量 一般来说就是使用进程同步代码块来搞定，安全问题。当如具体我们要同步哪一个代码块就看我们那个块使用了共享 123456789101112131415161718192021222324252627282930313233class TestDemo implements Runnable&#123; private int num; Object obj=new Object(); TestDemo()&#123; num=100; &#125; @Override public void run() &#123; while (true)&#123; synchronized (obj) &#123; //这个地方可以随便放一个对象，但是注意如果是同一个对象就是同一个锁否则就基本没有同步功能 if (num &gt; 0) &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"=====\" + num); num--; &#125; &#125; &#125; &#125;&#125;public class SyncDemo &#123; public static void main(String[] args) &#123; TestDemo testDemo=new TestDemo(); new Thread(testDemo).start(); new Thread(testDemo).start(); new Thread(testDemo).start(); &#125;&#125; 5.同步函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Bank&#123; public int sum; Bank()&#123; sum=0; &#125; public void add(int n)&#123; sum+=n; &#125;&#125;class TestDemo_01 implements Runnable&#123; private Bank bank=new Bank(); @Override //1.首先要明确哪些代码是多线程代码，这里显然就是run里面的，然后run里面调用了add函数，所以add方法也是多线程 //2.之后就是哪些是共享变量，这里就是sum，bank //3.这样我们同步的代码就知道是哪些了既可以笼统的把run里面的操作bank的同步起来 //这样的话我们就同步了一个函数，函数里面的那些局部变量就被同步了，这样和单线程没却别 //所以我们同步add方法里面的内容 //或者说我们可以直接同步add方法 就在方法的前面添加synchronized即可 //也就是说我们的代码同步有两种方法一个就是同步代码块，一个就是同步函数 public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; synchronized (bank) &#123; bank.add(100); try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(bank.sum); &#125; &#125; &#125;&#125;public class SyncFunction &#123; public static void main(String[] args) &#123; TestDemo_01 testDemo_01=new TestDemo_01(); new Thread(testDemo_01).start(); new Thread(testDemo_01).start(); &#125;&#125; 6.如果在我们进行了代码同步以后，代码还挂了那就说明我们的代码没有满足两个前提： 第一个就是必须是两个及两个以上的线程 第二个就是使用的必须是同一个锁 这里顺带说同步函数使用的锁其实就是this然后如果是静态同步函数的话，我们知道静态函数不可能使用this，因为他不属于对象而是属于类这里也就是类的字解码文件 类名.class 就是这个 7.线程通讯同步，所谓线程同步通讯就是，在多个线程同时对同一个资源进行操作的时候我们使用同步代码让他们同步，但是这样可能会造成两个线程各自执行到底 而非交替执行，为了交替执行我们使用同步，一个执行完了以后就睡眠唤醒另外一个，但是还是要注意这两个线程称一定要使用同一把锁，两个线程的代码都要同步 具体方法就是： wait(),notify(),notifyAll()这几个函数都是使用在同步中的，因为他们需要对有监视器（锁）的对象进行操作 所以只有在同步中他们才有锁、 这些方法在操作线程的时候必须要标识他们所操作的锁，也就是说被某个锁同步的代码只能由此锁的wait，notify操作不可以对不同的锁的对象进行等待唤醒 由于锁是任意对象所以说这些方法都被定义在Object中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class Resource&#123; private int count; public boolean flag; Resource()&#123; count=0; flag=true; &#125; public synchronized void in()&#123; if (flag) &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"in===\" + count++); flag=true; notify(); &#125; public synchronized void out()&#123; if (!flag)&#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"out------------\"+count); flag=false; notify(); &#125;&#125;class Producer implements Runnable&#123; private Resource resource; public Producer(Resource resource) &#123; this.resource = resource; &#125; @Override public void run() &#123; while (true)&#123; resource.in(); &#125; &#125;&#125;class Consumer implements Runnable&#123; private Resource resource; public Consumer(Resource resource) &#123; this.resource = resource; &#125; @Override public void run() &#123; resource.out(); &#125;&#125;public class ProducerAndConsumer &#123; public static void main(String[] args) &#123; Resource resource=new Resource(); Producer producer=new Producer(resource); Consumer consumer=new Consumer(resource); new Thread(producer).start(); new Thread(producer).start(); new Thread(consumer).start(); new Thread(consumer).start(); &#125;&#125;","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://lwenxu.coding.me/tags/多线程/"}]},{"title":"Java泛型","slug":"Java SE/Java范型","date":"2017-08-09T07:49:28.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java范型/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java范型/","excerpt":"1.java泛型及就是在jdk1.5之后出现的一个新的安全机制 我们发现在集合框架中我们可以放入任何的元素，然而这样做并没有任何意义，绝大多时候我们是默认我们 知道这个容器需要存放什么样的内容，但是用户的输入是不安全的如果他们输入了各种类型然后我们只对某些类型 进行了处理显然到时候运行时必然报错 所以为了解决这个问题，类似于数组的解决方式给集合限定了类型使用尖括号来限定，当然包括Iterator 他的好处就是安全","text":"1.java泛型及就是在jdk1.5之后出现的一个新的安全机制 我们发现在集合框架中我们可以放入任何的元素，然而这样做并没有任何意义，绝大多时候我们是默认我们 知道这个容器需要存放什么样的内容，但是用户的输入是不安全的如果他们输入了各种类型然后我们只对某些类型 进行了处理显然到时候运行时必然报错 所以为了解决这个问题，类似于数组的解决方式给集合限定了类型使用尖括号来限定，当然包括Iterator 他的好处就是安全 2.comparable接口和comparator都可以使用泛型，在使用泛型以后里面的内容就无需在强转直接写泛型的类型即可 3.泛型不仅仅是安全这一说，还有就是以前我们在不确定一个函数的具体接受对象的类型的时候我们都是使用object对象 来接受，然后向下转型。但是如果有了泛型我们就可以直接定义泛型类或者泛型方法。 1）.泛型类就是把泛型定义在类上面这样的话类中只要引用了泛型的地方他们的类型都一致例如集合框架，写在类名后类似于接受参数 泛型的确定就是在类实例化的时候 2）.当然有时候类中的函数想操作的独享并不是类上定义的那个类型我们可以把泛型定义在函数上，写在返回值的前面 类似于参数一样，但是静态方法是无法使用定义在类上面的泛型因为类的泛型在确定类型的时候都是在类的实例化 而函数的泛型则是自动识别无需程序员做任何操作 3）.接口也可以定义泛型，然后类在实例化的时候可以明确泛型也可以不指定泛型然后还是一个泛型类 三个知识点的代码分别如下： 12345678910111213141516171819202122232425262728293031/** * Author: lwen * Date: 2017/07/12 * Description:定义在类上面的泛型 */class Worker&#123;&#125;class Student&#123;&#125;class Tool&lt;T&gt;&#123; private T t; public T getT() &#123; return t; &#125; public void setT(T t)&#123; this.t=t; &#125;&#125;public class GenericDemo01 &#123; public static void main(String[] args) &#123; Tool&lt;Worker&gt; tool=new Tool&lt;&gt;(); tool.getT(); &#125;&#125; 12345678910111213141516171819202122232425/** * Author: lwen * Date: 2017/07/12 * Description:定义在函数上的泛型 */class Out&lt;T&gt;&#123; &lt;M&gt; void show(M m)&#123; System.out.println(m); &#125; void print(T t)&#123; System.out.println(t); &#125; static &lt;O&gt; void prints(O o)&#123; System.out.println(o); &#125;&#125;public class GenericDemo02 &#123; public static void main(String[] args) &#123; Out&lt;String&gt; out=new Out&lt;&gt;(); out.print(\"string\"); //只能传入string因为这个是类上面的泛型 out.show(3); //任意类型的因为这个事函数上面的泛型 &#125;&#125; 12345678910111213141516171819202122232425262728/** * Author: lwen * Date: 2017/07/12 * Description: 定义在接口上的泛型 */interface Inter &lt;T&gt;&#123; void print(T t);&#125;class InterImp implements Inter&lt;String&gt;&#123; @Override public void print(String s) &#123; System.out.println(s); &#125;&#125;class InterImp1&lt;T&gt; implements Inter&lt;T&gt;&#123; @Override public void print(T t) &#123; &#125;&#125;public class GenericDemo03 &#123; public static void main(String[] args) &#123; &#125;&#125; 4.泛型的高级应用就是泛型限定： 泛型限定： 1）.当我们要传入的某个参数不确定的时候我们可以使用定义在函数上的泛型，当然还有一种更方便的方法就是 使用？占位符 2）.我们会发现？占位符能接受的类型的范围太大，无论是什么都可以接受，但是我们希望我们只能接受 某一类对象的子对象或者某对象的父类对象 有向下类型限定和向上类型限定： 向上： ? extends className 向下: ? super className 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * Author: lwen * Date: 2017/07/12 * Description: 向下限定也就是在comparator接口中他的泛型限定其实就是 ？ super T 这个T就是TreeSet的T * 那么也就是说comparator中可以放T的父类 * * 显然如果说我们要给TreeSet传入比较器的话我们肯定需要给每一个特定的类型的TreeSet给一个比较器 * 但是由于在定义比较器接口的时候人家给的就是某个类型的父类这样的话我们构造一个父类的比较器就能搞定 * */class Person&#123; private int age; Person(int age)&#123; this.age=age; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125;class Students extends Person&#123; Students(int age)&#123; super(age); &#125;&#125;class Workers extends Person&#123; Workers(int age)&#123; super(age); &#125;&#125;public class GenericDemo04 &#123; public static void main(String[] args) &#123; TreeSet&lt;Workers&gt; ts1=new TreeSet&lt;&gt;(new Comp()); ts1.add(new Workers(12)); ts1.add(new Workers(13)); ts1.add(new Workers(10)); for (Workers ws : ts1) &#123; System.out.println(\"ws--------\"+ws.getAge()); &#125; TreeSet&lt;Students&gt; ts2=new TreeSet&lt;&gt;(new Comp()); ts2.add(new Students(12)); ts2.add(new Students(9)); ts2.add(new Students(17)); for (Students stu : ts2) &#123; System.out.println(\"student---\"+stu.getAge()); &#125; &#125;&#125;class Comp implements Comparator&lt;Person&gt;&#123; @Override public int compare(Person o1, Person o2) &#123; return new Integer(o1.getAge()).compareTo(o2.getAge()); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * Author: lwen * Date: 2017/07/12 * Description: */class A&#123;&#125;class B extends A&#123;&#125;class C extends B&#123;&#125;public class GenericDemo05 &#123; public static void main(String[] args) &#123; A a=new A(); B b=new B(); C c=new C(); ArrayList&lt;A&gt; ala=new ArrayList&lt;&gt;(); ala.add(a); ArrayList&lt;B&gt; alb=new ArrayList&lt;&gt;(); alb.add(b); ArrayList&lt;C&gt; alc=new ArrayList&lt;&gt;(); alc.add(c); print(ala);// printSub(ala); error printSup(ala); printSup(alb);// printSup(alc); error printSub(alc); printSub(alb); &#125; public static void print(ArrayList&lt;?&gt; al)&#123; Iterator&lt;?&gt; it=al.iterator(); while (it.hasNext())&#123; System.out.println(it.next());; &#125; &#125; public static void printSub(ArrayList&lt;? extends B&gt; al)&#123; Iterator&lt;?&gt; it=al.iterator(); while (it.hasNext())&#123; System.out.println(it.next());; &#125; &#125; public static void printSup(ArrayList&lt;? super B&gt; al)&#123; Iterator&lt;?&gt; it=al.iterator(); while (it.hasNext())&#123; System.out.println(it.next());; &#125; &#125;&#125;","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"范型","slug":"范型","permalink":"http://lwenxu.coding.me/tags/范型/"}]},{"title":"JDBC","slug":"Java Web/JDBC","date":"2017-08-09T07:49:28.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/09/Java Web/JDBC/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java Web/JDBC/","excerpt":"1.普通的 JDBC 链接12345678910111213141516171819202122232425262728293031public class JdbcConnect &#123; @Test public void connect() throws ClassNotFoundException, SQLException &#123; /** * 准备四大参数： driver url username password * 加载驱动类 * 得到连接 * 创建statement * 调用statement的查询或者更新方法 * 关闭资源（必须关闭）倒关 */ Class.forName(\"com.mysql.jdbc.Driver\"); java.sql.Connection con= DriverManager.getConnection(\"jdbc:mysql://localhost:3306/Java\",\"root\",\"\"); Statement statement=con.createStatement(); int effectRow=statement.executeUpdate(\"INSERT INTO `user` VALUES (1,'lwen',20,'lwen')\"); System.out.println(effectRow); ResultSet resultSet=statement.executeQuery(\"SELECT * FROM `user`\"); while (resultSet.next())&#123; System.out.println(resultSet.getInt(1)); //或者使用列名称来获取 System.out.println(resultSet.getString(2)); System.out.println(resultSet.getInt(3)); System.out.println(resultSet.getString(4)); &#125; //倒关 resultSet.close(); statement.close(); con.close(); &#125;&#125;","text":"1.普通的 JDBC 链接12345678910111213141516171819202122232425262728293031public class JdbcConnect &#123; @Test public void connect() throws ClassNotFoundException, SQLException &#123; /** * 准备四大参数： driver url username password * 加载驱动类 * 得到连接 * 创建statement * 调用statement的查询或者更新方法 * 关闭资源（必须关闭）倒关 */ Class.forName(\"com.mysql.jdbc.Driver\"); java.sql.Connection con= DriverManager.getConnection(\"jdbc:mysql://localhost:3306/Java\",\"root\",\"\"); Statement statement=con.createStatement(); int effectRow=statement.executeUpdate(\"INSERT INTO `user` VALUES (1,'lwen',20,'lwen')\"); System.out.println(effectRow); ResultSet resultSet=statement.executeQuery(\"SELECT * FROM `user`\"); while (resultSet.next())&#123; System.out.println(resultSet.getInt(1)); //或者使用列名称来获取 System.out.println(resultSet.getString(2)); System.out.println(resultSet.getInt(3)); System.out.println(resultSet.getString(4)); &#125; //倒关 resultSet.close(); statement.close(); con.close(); &#125;&#125; 2. 数据库连接池：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 数据库连接池 * 就是为了连接课重用，由于创建销毁比较麻烦，所以放在一个map里面也就是一个池，下次要用的时候直接从里面取 * 而不用平凡的销毁和创建 * * 常用的就是dbcp连接池 这个也说commons里面的东西 */public class JdbcConnections &#123; /** * 1.池参数 * 2.四大连接参数 * 3.实现javax.sql.DataSource接口 */ @Test public void dbcp() throws SQLException &#123; BasicDataSource dataSource=new BasicDataSource(); dataSource.setDriverClassName(\"com.mysql.jdbc.Driver\"); dataSource.setUrl(\"jdbc:mysql://localhost/Java\"); dataSource.setUsername(\"root\"); dataSource.setPassword(\"\"); dataSource.setMaxTotal(20);//设置最大的连接数 dataSource.setMaxWaitMillis(1000);//设置最大等待时间 Connection connection=dataSource.getConnection();//此时获得的connection不是以前的那个了而是在以前的mysql的连接上的增强 //也就是说他是装饰者模式，装饰的部分就是close方法，因为此时的close方法不是关闭连接而是将连接归还的操作// 下面的操作就和一般的sql连接一模一样了// 然后注意一般来说上面的哪些创建连接池的操作我们只进行一次。然后整个项目就是用这一个连接池 &#125; /** * 现在dbcp用的更少了 主要用的就是c3p0 */ @Test public void c3p0() throws PropertyVetoException, SQLException &#123; ComboPooledDataSource dataSource=new ComboPooledDataSource(); dataSource.setDriverClass(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://localhost/Java\"); dataSource.setUser(\"root\"); dataSource.setPassword(\"\"); dataSource.setMaxPoolSize(20); dataSource.setMinPoolSize(2); dataSource.setInitialPoolSize(20); dataSource.setAcquireIncrement(5); Connection connection=dataSource.getConnection(); System.out.println(connection); //返回的是代理连接 而不是装饰者模式 他比装饰者模式更加的灵活 connection.close(); &#125;&#125; 3. c 组件中的数据库操作类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class JdbcDbUtils &#123; /** * 测试beanHandler 对于单行的javaBean * @throws SQLException */ @Test public void fun1() throws SQLException, PropertyVetoException &#123; ComboPooledDataSource dataSource=new ComboPooledDataSource(); dataSource.setMaxPoolSize(20); dataSource.setAcquireIncrement(4); dataSource.setMinPoolSize(5); dataSource.setInitialPoolSize(10); dataSource.setDriverClass(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://localhost/java\"); dataSource.setUser(\"root\"); dataSource.setPassword(\"\"); QueryRunner qr=new QueryRunner(dataSource); String sql=\"select * from user where id = ?\"; Object[] params=&#123;1&#125;; final Object query = qr.query(sql, new BeanHandler&lt;UserBean&gt;(UserBean.class), params); System.out.println(query); &#125; @Test public void fun2() throws SQLException, PropertyVetoException &#123; ComboPooledDataSource dataSource=new ComboPooledDataSource(); dataSource.setMaxPoolSize(20); dataSource.setAcquireIncrement(4); dataSource.setMinPoolSize(5); dataSource.setInitialPoolSize(10); dataSource.setDriverClass(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://localhost/java\"); dataSource.setUser(\"root\"); dataSource.setPassword(\"\"); QueryRunner qr=new QueryRunner(dataSource); String sql=\"select * from user\"; final Object query = qr.query(sql, new BeanListHandler&lt;UserBean&gt;(UserBean.class)); System.out.println(query); &#125; @Test public void fun3() throws SQLException, PropertyVetoException &#123; ComboPooledDataSource dataSource=new ComboPooledDataSource(); dataSource.setMaxPoolSize(20); dataSource.setAcquireIncrement(4); dataSource.setMinPoolSize(5); dataSource.setInitialPoolSize(10); dataSource.setDriverClass(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://localhost/java\"); dataSource.setUser(\"root\"); dataSource.setPassword(\"\"); QueryRunner qr=new QueryRunner(dataSource); String sql=\"select * from user where id = ?\"; Object[] params=&#123;1&#125;; final Object query = qr.query(sql, new MapHandler(), params); System.out.println(query); &#125; @Test public void fun4() throws SQLException, PropertyVetoException &#123; ComboPooledDataSource dataSource=new ComboPooledDataSource(); dataSource.setMaxPoolSize(20); dataSource.setAcquireIncrement(4); dataSource.setMinPoolSize(5); dataSource.setInitialPoolSize(10); dataSource.setDriverClass(\"com.mysql.jdbc.Driver\"); dataSource.setJdbcUrl(\"jdbc:mysql://localhost/java\"); dataSource.setUser(\"root\"); dataSource.setPassword(\"\"); QueryRunner qr=new QueryRunner(dataSource); String sql=\"select * from user \"; Object[] params=&#123;1&#125;; final Object query = qr.query(sql, new MapListHandler()); System.out.println(query); &#125;&#125;","categories":[{"name":"-JavaWeb","slug":"JavaWeb","permalink":"http://lwenxu.coding.me/categories/JavaWeb/"}],"tags":[{"name":"JDBC","slug":"JDBC","permalink":"http://lwenxu.coding.me/tags/JDBC/"}]},{"title":"JavaWeb基础","slug":"Java Web/JavaWeb总结","date":"2017-08-09T07:49:28.000Z","updated":"2018-12-19T18:44:50.000Z","comments":true,"path":"2017/08/09/Java Web/JavaWeb总结/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java Web/JavaWeb总结/","excerpt":"1. XML xml一般就用来存放少量的数据，或者是作为配置文件。 xml的声明 必须放在首行的首列（也就是顶头写） 有且仅有一个根标签，其他的都是他的子标签 xml中的换行和空格都当做内容来解析，所以对于缩进来说一定要注意。 xml中的内容区分大小写，不能以数字和下划线开始,不能以xml开始，里面不能包含空格和冒号","text":"1. XML xml一般就用来存放少量的数据，或者是作为配置文件。 xml的声明 必须放在首行的首列（也就是顶头写） 有且仅有一个根标签，其他的都是他的子标签 xml中的换行和空格都当做内容来解析，所以对于缩进来说一定要注意。 xml中的内容区分大小写，不能以数字和下划线开始,不能以xml开始，里面不能包含空格和冒号 一个元素可以有多个属性，名字自定义，属性不能冲突 对于一些特殊字符需要转义，使用实体来表示，就和html里面的一样 CDATA区就是里面的内容无需转义 对于xml的内容的约束有两个 dtd和scheme两种 –dtd：1.创建一个dtd文件 2.有几个元素就写几个&lt;!ELEMENT&gt; 3.看元素分别是简单元素还是复杂元素，就是嵌套否 --简单元素&lt;!ELEMENT 元素名 (#PCDATA) &gt; --复杂&lt;!ELEMENT 元素名 (子元素，逗号隔开) &gt; 4.在xml中引入dtd &lt;!DOCTYPE 根元素名 SYSTEM &quot;dtd文件路径&quot;&gt; xml的解析方法有两个分别就是dom和sax （dom说白了就是构建dom树，这个方便的就是增删操作，但是文件过大可能造成内存溢出；sax则是从上往下读，一行行的解析，然后返回对象，但是不可以增删改，但是方便查询） 三个常用的xml的解析器 ：dom4j(重要) jaxp jdom 2. HTTP 基础： 请求头： 请求行（GET /hello/index.html HTTP/1.1 ） 请求头 （多个键值对，其中有一个Keep-Alive这个东西是由于http无状态协议，所以说一个网站加载的时候肯定不止一次请求，像图片等等的东西，我们为了一次请求就让他多连接一会） （Content-Type:application-x-www-from-urlencoded ->表示表单的数据会使用url编码） 一个空行 请求体 （只有POST才有请求体，GET没有） 响应头： 响应行 （HTTP/1.1 200 OK） 2开头的都是成功 3开头的重定向 4开头的客户端错误 5开头的服务器错误 请求头 （Content-Type:text/html ;charset=ISO-8859-1 文本的话必须要有编码，像图片之类的可以不要） 空行 响应正文 Reference 显示的从哪个网站过来的一般的作用就是防盗链和统计广告 重定向就是当客户端给服务器发送求以后，服务器返回了一个带有新的地址的返回，然后客户端去请求这个新的地址（302），而转发则是直接接通到新的服务器客户端不须在请求 304就是缓存 首先浏览器发了一个Last-Modify头 然后服务器比对Last-Modify-Since 如果一样那么返回304 没有请求体 Tomcat是支持java web而不支持java ee 因为java ee范围很广泛 主要就是不支持java ee的JEB（企业级的java 应用） 但是我们有ssh可以代替 3. Servlet Servlet的创建有三种方式，分别就是实现Servlet接口，继承GenericServlet和继承HttpServlet类12345678910111213141516171819202122public class AHttpServlet extends HttpServlet&#123; /** * Http servlet首先就是继承的是GenericServlet，它里面有更丰富的方法，但是说到底还是要运行service方法，但是这个类里面的service方法其实有两个 * 第一个是从上面继承下来的，另一个是自己的实际要用的，他们的不同就在于参数，自己的那个参数是与Http协议相关的，也就是说这个东西绑定了Http协议 * 但是以前的那个参数是与协议无关的，但是最终tomcat要调用的是父类里面的service方法，所以说在继承的service方法中首先把参数都强转成http类型的参数 * 也就是自己的service方法的参数，然后去调用自己的service方法，自己的service方法里面会判断来自客户端的请求究竟是post还是get然后调用doPost或者doget * 方法，所以说最终我们只需要复写doGet或者doPost即可 * HttpServlet这个类是抽象的，但是里面的方法没有一个是抽象的，doGet和doPost默认都是给客户端返回一个405也就是不支持的请求类型，所以如果不复写 * 这两个方法就会出问题405 * */ @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(\"doGet\"); &#125; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; System.out.println(\"doPost\"); &#125;&#125; 仿写的 GenericServelt 的代码 1234567891011121314151617181920212223242526272829303132333435363738394041public class SrcGenericServlet implements Servlet&#123; private ServletConfig servletConfig; //很重要的一个对象，里面有五个方法，前面已经说了两个方法就是关于初始化配置的两个 //还有就是Context,以及getServletName()获取Servlet的名字 @Override public void init(ServletConfig servletConfig) throws ServletException &#123; this.servletConfig=servletConfig; //这个就是钩子，如果我们写好的这个类然后有别人去继承，那么如果他想在init方法里面添加一些自己的功能 //这个init有参数的如果被覆盖的话，子类中的servletConfig就会指向空指针，因为没有初始化。 //所以为了拓展，子类能够写自己的代码我们写了一个新的函数，子类只需要覆盖这个函数就可以到到目的 //不过还有一个方式就是在子类中我们先写自己的代码，然后使用super.init()也是能够搞定的 init(); &#125; public void init()&#123; &#125; public ServletContext getServletContext()&#123; return this.servletConfig.getServletContext(); &#125; @Override public ServletConfig getServletConfig() &#123; return this.servletConfig; &#125; @Override public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException &#123; &#125; @Override public String getServletInfo() &#123; return \"hello\"; &#125; @Override public void destroy() &#123; &#125;&#125; 首先说Servlet接口，这个接口里面总共有五个抽象方法需要进行复写，其中有三个声明周期方法init【在第一次访问这个Servlet的时候】 server【其他每一次访问的时候】 destroy【tomcat关闭的时候】这个是单例的，一个类只有一个对象而且这个是线程不安全的，所以效率高 Servlet要被浏览器访问必须要配置一下 web.xml 让 tomcat 能够调用这个 Servlet 具体就有两块分别就是Servlet的配置也就是配置Servlet的名字和类第二个就是配置浏览器访问的路径，和对应的Servlet的名称 12345678&lt;servlet&gt; &lt;servlet-name&gt;AServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;Servlet.AServlet&lt;/servlet-class&gt;&lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;AServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/AServlet&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 或者直接在 Servlet 的类上面写 @WebServlet( name=””, url-pattern=”” ) 而不用写 web.xml 的配置 由于Servlet是线程不安全的，所以说最好不要创建一些成员，而一般的创建局部变量。或者是无状态成员（一个类里面没有属性，然后这个类对象作为自己类成员），或者只读的成员，只有get没有set 一个Servlet一般的就是第一请求的时候创建，也可以在tomcat启动的时候创建Servlet。就是在Servlet标签里面load-on-startup标签，里面是一个序号，不要重复 web.xml的继承，其实每一个项目都有一个web.xml，但是要注意每一个web.xml都是继承了tomcat的conf下的web.xml这个xml里面主要定义了三个东西。第一个就是默认Servlet这个默认的Servlet是匹配所有的页面，当我们访问一个页面的时候没有Servlet响应就轮到defaultServlet，他处理的方法也很简单就是返回一个404然后就是一个JSPServlet这个Servlet是用来处理所有的jsp页面的请求的，还有定义了很多的MIME类型 ServletConfig是javaWeb四大域对象之一，他们的功能就是在Servlet中传递数据，这个对象就是存取属性用于Servlet交互。getAttribute() setAttribute() removeAttribute() 设置公共的初始化配置在Servlet标签外面写context-param 获取的ServletConfig对象里面的getRealPath(“/index.jsp)这个就是获取他在服务器上得真是位置，然后需要转化为流对象的话我们可以使用getResourceAsStream()直接返回的流对象 4. ServletContext 对象&emsp;&emsp; 这个对象其实就是我们整个的项目，所以一般我们把它称之为 application ，他在整个项目中只有一个，并且他的生命周期和 Tomcat 一模一样。一般用它来做多个 Servlet 之间的数据传递。&emsp;&emsp; 可以使用 ServletConfig 获取这个对象。或者使用 getServletContext() 直接获取 。我们还可以使用 HttpSession 获得这个对象。还能使用 ServletContextEvent 获取这个对象。&emsp;&emsp; 可以获取 Web 根目录下的资源路径，也就是 webapps 下面的项目下的 web 目录，getRealPath() 、getResourceAsStream() ，同样的我们也可以使用 class 和 classloader 来获取类路径下的资源。className.class.getClassLoader().getResourceAsStream() 或者 className.class.getResourceAsStream() 。 5. Servlet 四大域对象首先说一下域对象的功能，简单来说就是一个用来在多个 Servlet 之间传递数据的对象，类似于一个 Map 容器。 PageContext ServletRequest HttpSession ServletContext 他们都有 set/get/removeAttribute(“”,obj) 方法来存取数据。 4.反射： 获取class，有三种方法： 类名.class 对象.getClass() Class.forName(“具体路径（包名）”) 对于一个类如果我们不使用new我们可以使用class来获取 12345Class clazz=Class.forName(\"cn.lwen.Person\");Person p=(Person) clazz.newInstance(); //p就是person的实例，这个显然也就是无参数的构造方法来实现的然后对于有参数的构造方法则是使用getConstructor来获取这个实例Class clazz=Class.forName(\"cn.lwen.Person\");Constructor cs=clazz.getConstructor(类型的class（如：String.class）由于这个地方是可变参数，所以说参数的个说可以有多个)Person p=new (Person) cs.newInstance(\"lwen\"); 操作类的属性：类的属性是由一个叫做getDeclaredField()的方法获得的，得到的类型是Field类型，然后可以使用返回的类型的set方法类设置，第一个参数是；类的实例，第二个就是属性的内容但是这里只允许操作公共的变量，私有变量是不允许的，filed上面的一个setAccessible(true)则表示可以直接操作底油属性 对于方法的操作就是和上面的属性很类似，首先使用getDeclaredMethod(“”,parm)获得方法然后返回的Method类型的，如果是私有的则和上面执行一样的操作，然后使用返回的Method对象的invoke(obj,parmar)执行函数 5. 两大重要对象：1. 在service这个方法中有两个很重要的对象response和request这两个，现在主要就说说这两个东西怎么给客户端请求以及响应response 首先就有一个发送状态信息的方法：response.sendError(404,”访问的页面存在但是不给你看”);//发送一个错误的返回信息 然后就是设置头信息，头信息就是键值对这里有三个常用的设置头信息的方法： 123setHeader(\"\",\"\")setIntHeader(\"\",int)setDateHeader(\"\",second) 然后这个方法把set改成add就是一个键多个值设置重定向setRedirect(“URL”) 快捷的方法 也可使用设置头来做. setHeader(&quot;Location&quot;,&quot;index.jsp&quot;) 、 setStatus(302,&quot;ss&quot;) response里面的两个流，字符流和字节流，但是这两个流 不能同时存在否则会抛异常 getOutputStream() getWriter() 设置浏览器的缓存 request 获取客户端的信息，获取客户端的url信息 获取客户端的请求的参数，无论是get还是post对于单值的属性都可以使用getParameter(“name”) 然后对于多值则是getParameterValues()返回数组 getParameterNames()获取所有的键名，是枚举类型 请求转发和请求包含。 请求转发：如果我们访问A，然后A做了请求转发到B，那么最终返回给客户端的就是保留了A的请求头和B的请求体（留头不留体）这次过程中url不变 请求包含：同上，只是这次包含A的头和体还有B的体 他们与重定向是不同的，浏览器不知道A请求了B，这始终就是一个请求 123456request.getRequestDispatcher(\"/AServlet\").forward(request,response); //请求转发 request.getRequestDispatcher(\"/AServlet\").include(request,response); //请求包含 //request域 在Servlet中有三大域对象，在javaweb中有四个 //分别就是request,session,application,Context //他们的生命周期就和这个对象的生命周期相同 //他们都用相同的方法setAttribute() getAttribute() removeAttribute() 然后供其他的Servlet使用这些存在这些对象的信息 2. 编码问题：编码分为响应编码和请求编码 响应编码：就是服务器向客户端发送的数据的编码，我们首先要自己发送的是utf-8并且还要浏览器用utf-8去解析，我们采用的就是http头信息 setHeader(&quot;Content-Type:text/html;charset:utf-8&quot;) 或者直接一个简单的方法就是setContentType(&quot;text/html;charset:utf-8&quot;) 请求编码：则是服务器接受客户端过来的请求，进行编码，客户端默认使用的是iso，我们需要转成utf-8，而且这个地方是区分post和get请求方式的 post就直接使用setCharacterEncoding(&quot;utf-8&quot;)而get就需要先转化成byte数组然后使用string转成utf-8 byte[] by str.getBytes(&quot;ISO-8859-1&quot;); string =new String(byte,&quot;utf-8&quot;)6. JSP1. JSP三大指令 ： page include taglib一个jsp页面可以使用多个指令，不一定放在第一行 —page：pageEncoding 设置页面的编码 在服务器把jsp编译成java时使用这个属性 contentType 设置返回响应头 就和setContentType()方法一样 以上两个属性只要设置了一个属性另一个属性可以不设置 如果都不设置就是iso8859-1 import 导包 可以用逗号隔开 errorPage 当前页面如果抛出异常要转发到哪个页面，不是跳转 状态码200 isErrorPage 设置当前页面是否为处理错误的页面 只有这个页面可以使使用9大内置对象的exception（当标签的内容为true） 状态码为500 isELignore 是否忽略el表达式—include 静态包含他是在编译成java文件的时候完成的 他们共同编译成一个java文件 然后生成一个class 他和ResponseDispatcher的include作用类似 只是他是动态包含 编译成两个不一样的文件class 最后运行的时候才合并 动态合并 静态包含的作用就是页面分解—taglib引入标签库 prefix引入前缀 uri 标签的地址 &lt;%@ page …..%&gt; 在web.xml中配置errorPage 123456789101112&lt;error-page&gt; &lt;error-code&gt;404&lt;/error-code&gt; &lt;localtion&gt;/error.jsp&lt;/localtion&gt;&lt;/error-page&gt;&lt;error-page&gt; &lt;error-code&gt;500&lt;/error-code&gt; &lt;localtion&gt;/error.jsp&lt;/localtion&gt;&lt;/error-page&gt;&lt;error-page&gt; &lt;exception-type&gt;java.lang.RuntimeException&lt;/exception-type&gt; //页面抛出任何异常都会显示500 有事为了更加细致的分 我们可以定异常来处理 &lt;localtion&gt;/error.jsp&lt;/localtion&gt;&lt;/error-page&gt; 2. JSP 九大内置对象和四大域对象： out 就是response.getWriter 用于想浏览器输出 config ServletConfig 就是xml中的内容 page 当前jsp对象 引用类型就是Object Object page=this pageContext 一个顶9个 response HttpServletResponse request HttpServletRequest exception 异常 session application 整个tomcat存活期有效 ServletContext Servlet三大jsp四大域对象 ServletContext 整个应用 session 整个会话 request 一个请求 ——————-jsp专有 pageContext 一个jsp页面 用于jsp标签中的数据传递 代理其他域可以其他的域查找设置pageContext.setAttribute(“”,””,PageContext.SESSION_SCOPE) 就是设置到session中全域查找 findAttribute(&quot;xx&quot;) 从小到大（域范围），依次查找 3.JSP的动作标签：jsp:forward 他和RequestDispatcher中的forward一样 就是一个在Servlet中使用一个在jsp中使用jsp:include 同上 include方法一样jsp:param 用来作为前两个的子标签 用来给包含的或者转发的页面传递参数 4.JavaBean： 必须要为成员提供get和set方法 必须要有默认构造器 某个属性有get和set方法但是没有该属性 也是可以的 boolean的属性get方法可以直接就是is。。 5.EL表达式： $(pageScope.xxx) 获取并输入该域中的xxx字段 $(requestScope.xxx) $(sessionScope.xxx) $(applicationScope.xxx)如果不写那么就是全域查找 EL表达式就是用来输出的 用来代替&lt;%= %&gt; EL的11个内置对象：其中只有pageContext不是map类型 因为她就是pageContext类型其他的都是map类型 在El表达式中 Map的值访问可以使用点 或者数组方式 map[‘key’] map.key上面已经有4个就是pageScope….然后就是param key为参数名value为参数值 和getParam方法一样 适用于单值的paramValues 适用于多值的 和上面的一样 value是一个数组header:headerValues:这两个同上initParam 获取里面的参数cookie value是cookie对象 所以在获得cookie对象以后必须要使用value才能获得值pageContext 例如${pageContext.request.contextPage} 获取request域中的contextPage内容 4.EL的函数库（由JSTL提供）首先需要导入JSTL的函数库${fn:substring(“123123”,1,2)} 5.自定义函数库： 写一个java类 类中的方法可多个 但是必须为 public static 然后写tld文件,ide可以生成在xml下 8. JSTL ：1. 回顾： jsp： 三大指令 include page taglib 九个内置对象 response cookie out page pageContext request Exception config application 动作标签 forward include param javaBean： 默认构造器 set，get方法 EL表达式： 基本语法 11个内置对象pageScope...Header，headerValuers,initParam,cookie,pageContext,param,paramValues 函数库 2.JSTL标签库：四大标签库：core核心库（重要），fmt（格式化），sql，xml（后两个过时） 导入标签，使用taglib指令–core：【C标签】 out &lt;c:out value=”aaa”&gt;字符常量 &lt;c:out value=”${aaa}”&gt;全域查找 default表示默认的值 escapeXml是否转义特殊字符 默认true set &lt;c:set var=”” value=”” scope=””&gt; var变量名 value可以是EL表达式 scope域 默认page remove &lt;c:remove var=”” scope=””&gt; 给出scope就删指定的 不然就是所有域 url &lt;c:url value=”” &gt; 在路径前面自动加项目名 但是value一斜杠开头 &lt;c:param name=”” value=””&gt; 子标签用于传参，并对参数进行url编码 var参数用来保存生成的url而不进行输出，否则就直接输出 if &lt;c:if test=${not empty a}/&gt; 判断a不是空就输出 在全域内查找 test中放bool类型 choose &lt;c:choose /&gt; 表示if….elseif()..else 这个标签主要用于容纳when标签 when标签里面有test属性 forEach &lt;c:forEach var=”” begin=”” end=”” step=””&gt; 包含头也包含尾 items 需要遍历的对象(这里一定不要有空格) var 迭代到这个变量上循环状态变量 vsStatus=“vs” vs.index vs.count vs.first vs.last vs.current –fmt标签：【格式化标签】&lt;fmt:formatData value=&quot;&quot; pattern=&quot;&quot;&gt; 例如 yyyy-MM-DD &lt;fmt:formatNumber value=&quot;&quot; pattern=&quot;&quot;&gt; 例如0.00 两位小数 四舍五入 3.JSTL自定义标签1. 步骤： * 标签处理类 实现SimpleTag接口 或者继承simpleTagSupport他做了很多处理 tomcat传 给simpleTag的参数都被保存了 * tld文件（xml）标签和类相关联 都放在WEB-INF中 防止别人直接访问 * 在页面中引入 2. 标签处理类 * 这些方法都是有tomcat调用 最后调用的是doTag方法 和Servlet非常类似 * doTag 执行标签的时候调用 * getParent 获得父标签 * setParent 设置父标签 * setJspBody 设置标签体 * setJSPContext 设置pageContext 3. 跳过某部分 直接在处理类中抛出一个跳过页面异常，最终编译的代码就是一个标签一个函数，由于这个函数也是直接抛出异常，所以该标签后面的内容就不执行了 而是跑到调用该函数的try块中的catch中执行响应的方法，这个catch对SkipPageException特别的照顾了一下，然后就结束了 4. 自定义标签属性： 1. 在处理类中创建属性 2. 在tld文件中定义 4.三层架构mvc是bs架构的公共的东西而三层架构则是java web的东西： web层 与web相关的 Servlet jsp 业务层 功能【登陆，注册，转账 等等…】(service) 数据层（dao 【data access Object】）(dao)","categories":[{"name":"-JavaWeb","slug":"JavaWeb","permalink":"http://lwenxu.coding.me/categories/JavaWeb/"}],"tags":[{"name":"Web","slug":"Web","permalink":"http://lwenxu.coding.me/tags/Web/"}]},{"title":"Java集合框架Map","slug":"Java SE/Java集合框架Map","date":"2017-08-09T06:38:12.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java集合框架Map/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java集合框架Map/","excerpt":"","text":"map集合是一对一对的存放，而且要保证键名的唯一性。 map的共性方法： 1.添加： put(K key,V value) putAll(K key,V value) 2.删除： clear() remove(Object key) &lt;!--more--&gt; 3.判断： isEmpty() constrainKey(object key) constrainValue(object value) 4.获取： get(Object key) size() values() 1234567891011121314151617181920public class MapDemo01 &#123; public static void main(String[] args) &#123; HashMap&lt;String,String&gt; hashMap=new HashMap&lt;&gt;(); //当第一次存放元素的时候这个键不存在所以返回的是null //第二次再存放同一个键的值的时候不会报错而是返回的改建原有的值这个和Set以及collection是不一样的 System.out.println(hashMap.put(\"01\",\"zhansgan01\")); System.out.println(hashMap.put(\"01\",\"zhansgan02\")); hashMap.put(\"03\",\"zhansgan03\"); hashMap.put(\"04\",\"zhansgan04\"); System.out.println(hashMap.get(\"01\")); Collection&lt;String&gt; collection=hashMap.values(); System.out.println(collection); System.out.println(hashMap.containsKey(\"02\")); System.out.println(hashMap.containsValue(\"zhansgan03\")); //remove返回的value System.out.println(hashMap.remove(\"03\")); &#125;&#125; 3.Map的三个常用的小弟： hashTable 底层是hash表不可以使用null作为键或者值，线程同步 jdk1.0 hashMap 底层是hash表可以使用null作为键或者值，线程不同步 jdk1.2 效率 更高 TreeMap 底层是二叉树，可对map的键进行排序其实set的底层都是Map 4.两个特别重要的函数keySet和entrySet 首先是keySet，其实在Map集合中里面的结构是双列结构也就是；两个Set构成的，里面分别存放 键值的引用，而keySet就是只把键取出来，类似于values取出所有的值，当吧所有的键都取出来的时候就意味着我们 具备了所有的值，这时候我们就可以遍历Map了，map本身没有遍历的方法 12345678910111213141516public class KeyMapDemo &#123; public static void main(String[] args) &#123; HashMap&lt;String,String&gt; hashMap=new HashMap&lt;&gt;(); hashMap.put(\"1\",\"zs1\"); hashMap.put(\"2\",\"zs2\"); hashMap.put(\"3\",\"zs3\"); hashMap.put(\"4\",\"zs4\"); Set&lt;String&gt; keySet =hashMap.keySet(); Iterator&lt;String&gt; it=keySet.iterator(); for (;it.hasNext();)&#123; String key=it.next(); System.out.println(hashMap.get(key)); &#125; &#125;&#125; 5.entrySet则是直接返回了这个Map的映射关系，仅仅是关系而不是元组。 这个关系的类型是Map.Entry类型的里面有getValue和getKey方法 Entry其实是Map接口的内部接口就像是内部类一样，这是内部接口 并且这个接口是静态的 12345678910111213141516171819202122public class EntrySet &#123; public static void main(String[] args) &#123; Map&lt;String,String&gt; map=new HashMap&lt;&gt;(); map.put(\"1\",\"s1\"); map.put(\"2\",\"s2\"); map.put(\"3\",\"s3\"); //返回的还是set集合只里面的类型是Map.Entry类型的 Set&lt;Map.Entry&lt;String, String&gt;&gt; mapEntry=map.entrySet(); for (Map.Entry me : mapEntry) &#123; System.out.println(me.getKey()+\"--------\"+me.getValue()); &#125; &#125;&#125;//类似于种东西interface Map&#123; static interface Entry&#123; abstract Object getKey(); abstract Object getValue(); &#125;&#125; 5.一个小demo 12345678910111213141516171819202122232425262728293031/** * Created by lwen on 2017/7/13. * 把一个字符串里面的字符的数目统计一下，，并且按照字符的顺序显示 */public class MapDemo03 &#123; public static void main(String[] args) &#123; String str=charCount(\"aasdfasadcl\"); System.out.println(str); &#125; static String charCount(String str)&#123; char[] chs=str.toCharArray(); TreeMap&lt;Character,Integer&gt; treeMap=new TreeMap&lt;&gt;(); int count=0; for (char ch:chs)&#123; if (treeMap.get(ch)!=null)&#123; count=treeMap.get(ch); &#125; count++; treeMap.put(ch,count); count=0; &#125; StringBuilder sb=new StringBuilder(); Set&lt;Map.Entry&lt;Character,Integer&gt;&gt; set=treeMap.entrySet(); for (Map.Entry&lt;Character,Integer&gt; em:set)&#123; sb.append(em.getKey()).append(\"(\").append(em.getValue()).append(\")\"); &#125; return sb.toString(); &#125;&#125; 7.集合框架总共有两大部分分别就是： ---Collection |--List ArrayList LinkedList |--Set HashSet TreeSet ---Map |--HashTable |--HashMap |--TreeMap另外还有两个常用的类就是两个工具类Collections,Collections里面提供了: 1) 一个sort方法他是专门对Collection排序的 2)还有，max方法用法和sort方法一模一样 3）binarySearch就是二分法查找元素可以自己实现一个试试 5) replaceAll(list,oldEle,newEle) 6)reverseOrder()强行翻转一个比较器，当不传入参数的时候强行逆转默认的自然排序，传入一个比较器则是逆转比较器 还有一个工具类就是Arrays这个类里面的方法主要就是为了操作数组的： 1）sort 2）fill 全部替换 3）shuflle 乱序 4）asList 把数组转化为List集合，但是注意这个list集合不能进行增删操作否则异常，还有就是如果数组是一个对象类型的数组，转化为list最后就是对象的list而数组时基本数据类型则会把数组当做一个list元素 集合变数组，集合变数组使用的就是Collection接口里面的共性方法，toArray(type [collection.size()]) 一般转过来的数组的长度最好就是集合的长度否则他会再开辟一个数组，而小于等于的情况会直接使用原来的数组 数组变成集合是为了扩展数组的操作让数组作为集合来处理例如contains数组要判断元素是否存在必须遍历而集合就不用 把集合变成数组是为了限制操作，也就是让数组无法操作，例如再返回的时候最好返回数组 可变参数的方法，就是在函数声明或者定义的时候使用一个数组当做参数，但是我们传参的时候传入的并不是一个数组而是一般状况的传值，个数不限 但是这个函数的固定参数必须放在可变参数的前面 void fun(string str,int... arr) 后面就是可变参数个数不限但是类型有限制12345678910111213141516171819202122232425262728293031class StrLenComparator implements Comparator&lt;String&gt;&#123; public int compare(String s1,String s2)&#123; if (s1.length()&gt;s2.length())&#123; return 1; &#125;else if(s1.length()&lt;s2.length())&#123; return -1; &#125; return s1.compareTo(s2); &#125;&#125;public class CollectionsDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list=new ArrayList&lt;&gt;(); list.add(\"aaa\"); list.add(\"ab\"); list.add(\"adc\"); list.add(\"dd\"); list.add(\"cd\"); list.add(\"efcasdc\"); Collections.sort(list); for (String string:list)&#123; System.out.println(string); &#125; Collections.sort(list,new StrLenComparator()); for (String string:list)&#123; System.out.println(string); &#125; &#125;&#125; 10，静态导入： 当一般的我们import一个包的时候我们导入的是包中的类 而我们使用静态导入的时候import static则是导入类中的所有的静态成员，无论是属性还是方法 123456789101112131415import static java.util.Arrays.*;import static java.util.Collections.*;public class StaticImport &#123; public static void main(String[] args) &#123; int[] arr=new int[11]; for (int i=10,j=0;i&gt;0;i--,j++)&#123; arr[j]=i; &#125; sort(arr); //可以直接使用Arrays中的方法而不用写Arrays.sort但是如果同一个类中名字冲突的话需要加上 for (int ele:arr)&#123; System.out.println(ele); &#125; &#125;&#125; 9.HashMap与HashTable的区别： 1）hashmap不是线程同步的，而hashtable则是线程同步的，也就是前者效率较高后者效率较低，安全性相反 2）hashmap他是Map的子类。而hashtable则是dictionary的子类 3）hashMap的键值均可以为null，hashtable的键值均不可为null10.hashTable的使用。 一般来说hashtable使用的很少，这里也有一个常用的子类就是hashTable的常用子类Properties 类，这个类的作用主要就是读，写，加载配置文件，这个容器里面只允许存放字符串，不论是键值均如此 存放的键值可以转化为普通的配置文件也可以转化为xml文件，之后下一次还可以使用load进行加载 1234567891011121314public class HashTableDemo &#123; public static void main(String[] args) throws IOException&#123; Properties properties=new Properties(); properties.setProperty(\"user\",\"lwen\"); properties.setProperty(\"pwd\",\"123\"); properties.store(new FileWriter(\"info.properties\"),\"用户配置文件\"); properties.store(new FileOutputStream(\"info_1.properties\"),\"用户配置文件\"); //可以字符流也可以字节流 properties.storeToXML(new FileOutputStream(\"info.xml\"),\"xml\"); //这个只能使用字节流对象 xml没有编码 System.out.println(properties.getProperty(\"user\",\"not this \")); //如果找不到这个属性，则会返回默认值 properties.load(new FileReader(\"info.properties\")); //加载配置文件是直接加载到这个对象里面，而不是打印 &#125;&#125; 11.内存的中的变量一般分为4种，这四种对于垃圾回收机制来说是不一样的： 强引用：无论什么时候都不会被gc回收 软引用：可能会被gc回收，只有在jvm内存不足的时候才会被回收 弱引用：当gc运行的时候就被回收 虚引用：类似于无引用，主要跟踪对象被回收的状态，不能单独使用，一般和引用队列一起使用 这里重点说一下强和弱引用，所谓强引用一般来说就是一些字符串常量，他们长期驻留在内存，用于共享 当我们在一个hashMap中存放了很多内容的时候，有时候我们需要清除一些没用的数据，我们就可以运行gc 因此就诞生了WeakHashMap这样的话，这里面的弱类型的就会被干掉 1234567891011121314151617181920212223242526272829public class WeakHashMapDemo &#123; public static void main(String[] args) &#123; WeakHashMap&lt;String,String&gt; weakHashMap=new WeakHashMap&lt;&gt;(); //这两个事在常量池中的常量，所以放到weakmap中也不会被gc weakHashMap.put(\"zhangsan0\",\"122\"); weakHashMap.put(\"zhangsan1\",\"123\"); //这两个则是两个对象在堆内存中，放到这里了以后，肯定被gc weakHashMap.put(new String(\"zhangsan2\"),\"102\"); weakHashMap.put(new String(\"zhangsan3\"),\"1245\"); //运行垃圾回收机制之前 Set&lt;Map.Entry&lt;String,String&gt;&gt; me=weakHashMap.entrySet(); for (Map.Entry&lt;String, String&gt; stringStringEntry : me) &#123; System.out.println(stringStringEntry.getKey()); System.out.println(stringStringEntry.getValue()); &#125; //运行垃圾回收机制 System.gc(); System.runFinalization(); //垃圾回收之后 System.out.println(\"=========================\"); Set&lt;Map.Entry&lt;String,String&gt;&gt; me1=weakHashMap.entrySet(); for (Map.Entry&lt;String, String&gt; stringStringEntry : me1) &#123; System.out.println(stringStringEntry.getKey()); System.out.println(stringStringEntry.getValue()); &#125; &#125;&#125; 12.IdentityHashMap这个容器是以键的地址作为比较的对象 注意是地址而不是其他的，例如说如果是一个字符串常量，显然这个只要内容相同就重复了，而如果是字符串对象就是不同的地址值，哪怕他们的内容一样 123456789101112public class IdentifiedHashMapDemo &#123; public static void main(String[] args) &#123; IdentityHashMap identityHashMap=new IdentityHashMap(); //前两个是字符串常量，在常量池中，地址是一样的 identityHashMap.put(\"a\",\"21\"); identityHashMap.put(\"a\",\"22\"); //后面两个是不同的对象，因此他们都被存入 identityHashMap.put(new String(\"a\"),\"23\"); identityHashMap.put(new String(\"a\"),\"24\"); System.out.println(identityHashMap.size()); &#125;&#125; 13.对于集合框架中有时候遇到多线程，我们又需要使用那些非同步的集合的时候我们必须手动的去同步这些集合，以及希望集合不可修改的时候也需要加一些限定 1234567891011public class SyncDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list=new ArrayList&lt;&gt;(); List&lt;String&gt; list1=Collections.synchronizedList(list);// 这样一来list1就是一个同步的arraylist// 其他的几个容器类似 List&lt;String&gt; list2=Collections.unmodifiableList(list1); //这样一来list2就是一个不可修改的容器也就是此时的容器不再支持增删操作 &#125;&#125;","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"集合框架","slug":"集合框架","permalink":"http://lwenxu.coding.me/tags/集合框架/"}]},{"title":"Java集合框架Collections","slug":"Java SE/Java集合框架Collections","date":"2017-08-09T06:38:06.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java集合框架Collections/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java集合框架Collections/","excerpt":"1.基本介绍： 集合就是存放对象的，他比数组好的一点就是他一开始不清楚自己长度 容器一般是分为很多种的，很多的容器在一起然后进过断的抽象和抽取就成了一个体系，我们称之为集合框架 我们看体系首先是看顶层的容器，他是底层的容器都有的特性，然后在逐步求精 最顶层的我们称之为collection 在util包中的","text":"1.基本介绍： 集合就是存放对象的，他比数组好的一点就是他一开始不清楚自己长度 容器一般是分为很多种的，很多的容器在一起然后进过断的抽象和抽取就成了一个体系，我们称之为集合框架 我们看体系首先是看顶层的容器，他是底层的容器都有的特性，然后在逐步求精 最顶层的我们称之为collection 在util包中的 在collection中分为两个比较常用的子接口分别是list和set。list是类似于数组的那种，也就是集合元素可重复，有序有脚标。set则为无序的，所以集合元素不可重复，不可脚标查找以下是List的通用方法： 添加元素：add(index,data) 删除元素：remove(index) 修改元素：set(index,data) 获取元素：get(index) 配合for循环 迭代器indexOf（data）subList（start,end） 在list中有一个特殊的迭代器，其他的集合都没有只是list有叫做ListIterater这个迭代器比一般的迭代器会多非常多的功能 另外注意的一点就是在使用iterater进行list迭代的时候，不能够使用集合的方法对集合进行增删改查的操作否则就会出现一个运行时异常，主要原因就是同时操作一个集合导致不合法，类似于同时IO同一块数据块因此在迭代的过程中只能使用迭代器提供的操作集合的方法或者不使用迭代器，直接使用原生的for循环，然后直接就可以使用迭代器的方法进行对集合的操作 add方法接受的参数类型为object以便于接受任意类型的参数集合中存放的是对象的地址而不是对象本身对象可以直接被打印 List可以分为三种，但是常用的只有两种，他们之间的主要区别就是底层的数据及结构不一样。 ArrayList 底层的实现使用的是数组，也就是说类似于数组构成的线性表，查询快增删慢，而且他是不同步的 LinkedList 底层使用的是链表，那么就会出现查询慢，增删快 Vector 底层和ArrayList完全一样，只不过vector就是jdk1.0出现的那时候还没有集合框架，后来有了集合框架被分到List里面，目前被ArrayList代替因为他是同步的速度慢，我们都是用Arraylist然后自己写锁来手动同步 arraylist和vector之间区别还有就是他们们的迭代方式可以有不同，由于vector是最先出来的，所以说他一开始用的并不是iterator迭代器而是枚举enumeration他和迭代器很相似，目前由于枚举不好记就用iterator。另外arraylist和vector使用的是变长数组，也就是本来都是固定长度10个元素，然后如果查过十个以后ArrayList使用的是50%的增长也就是会变成15个，二vector则是直接100%增长20个枚举的代码如下： 123456789101112public class Enmu &#123; public static void main(String[] args) &#123; Vector v=new Vector(); v.add(\"1\"); v.add(\"2\"); v.add(\"3\"); Enumeration e=v.elements(); //定义枚举 while (e.hasMoreElements())&#123; //循环遍历 System.out.println(e.nextElement()); &#125; &#125;&#125; LinkedList中除了一般的List的通用方法还有他自己特有的方法，而且比较重要 addFirst addLast getFirst 获取元素但是不删除元素 getLast removeFirst 获取元素而且删除元素，但是如果给的是一个空的链表列表使用此方法会产生异常因此有了以下替代方法 removeLast offerFirst 添加 offerLast peekFirst 获取 peekLast pollFirst 删除 pollLast 空链表列表也不会有异常而是直接返回null 代码如下： 123456789101112131415161718public class LinkedList_5 &#123; public static void main(String[] args) &#123; LinkedList list=new LinkedList(); list.addFirst(\"1\"); list.addFirst(\"2\"); list.addFirst(\"3\"); System.out.println(list.getFirst()); System.out.println(list.removeFirst()); LinkedList list1=new LinkedList(); list1.offerFirst(\"1\"); list1.offerFirst(\"2\"); list1.offerFirst(\"3\"); System.out.println(list1.peekFirst()); System.out.println(list1.pollFirst()); &#125;&#125; 7.使用LinkedList实现堆栈和队列结构也就是他所特有的addFirst addLast 以及remove方法的使用 只是要注意在LinkedList里面添加和删除的元素都是object而不是一般的对象，应该说 所有的集合框架里面的东西都是接受object对象的 所以在写具体的函数的时候注意一下 8.使用ArrayList写几个小程序，第一个就是使用ArrayList去处重复元素，其中的元素就是字符串，而第二个则是去除的某些自定义对象。第二个程序也揭示了对于List集合中的元素的比较的接口就是contains他底层是调用的对象的equals方法，对于remove也是底层调用了equals方法从而进行比较和删除。所以说重点在于重写equals方法。另外在迭代器中每使用一次next方法必须要进行一次hasNext的判断否则很有可能出现找不到元素的情况例如一个hasNext里面有两个next方法，而元素又为奇数个时候会抛异常 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Person&#123; private String name; private int age; Person(String name,int age)&#123; this.name=name; this.age=age; &#125; String getName()&#123; return this.name; &#125; private int getAge()&#123; return this.age; &#125; public boolean equals(Object object)&#123; if (!(object instanceof Person))&#123; return false; &#125; Person person=(Person)object; //注意这个地方必须要强转否则会出现下面的person无法调用方法 return this.name.equals(person.getName()) &amp;&amp; this.age==person.getAge(); &#125;&#125;public class ArrayList_7 &#123; private static ArrayList&lt;Person&gt; singleElement(List&lt;Person&gt; al)&#123; ArrayList&lt;Person&gt; newAl=new ArrayList&lt;Person&gt;(); Iterator&lt;Person&gt; it=al.iterator(); while (it.hasNext())&#123; Person tmp= it.next(); //iterator返回的是object所以必须要强转 if (!newAl.contains(tmp))&#123; newAl.add(tmp); &#125; &#125; return newAl; &#125; public static void main(String[] args) &#123; ArrayList&lt;Person&gt; al=new ArrayList&lt;&gt;(); al.add(new Person(\"zhang01\",1)); al.add(new Person(\"zhang02\",2)); al.add(new Person(\"zhang03\",1)); al.add(new Person(\"zhang03\",1)); al=singleElement(al); for (Person per : al) &#123; //可以使用这种更好的语言结构来实现迭代省去了iterator迭代 也不用考虑向下类型转换 System.out.println(per.getName()); &#125; &#125;&#125; 9.Set中存放的元素都是无序的并且里面的元素都是不可重复的，显然如果只存放字符串的话很容易就知道是否重复 也就无序我们自己去判断是否重复了。 set中的公共方法就是集合框架中共有的方法，重要的还是他的子类，这里有两个就是hashSet和TreeSet 而存放一般的自定义对象的时候我们发现如果想要某些属性一致的对象作为重复对象 的话hashSet自身是做不到的，所以我们需要了解hashSet的底层层放原理，hashSet底层就是hash表，在存放元素的时候 首先来判断存放的元素的hashCode值是否一样也就是调用他们的hashCode方法，注意hashCode是object对象的方法，所以 所有的对象都有此方法，另外如果他们的hashCode是一样的然后就调用他们的equals方法.不一样则就存进去一样则被踢出去 那么说白了hashSet底层判断是否为重复元素做了两件事第一个就是判断他们的hashCode第二个就是equals方法 如果要自定义对象如何存放就要重写这两个方法，但是重写的时候一定要注意他们的参数列表否则肯定不会生效，hashCode 一般来说也尽量不要让不同的对象的hashCode一致造成多余的比较 对于元素判断是否存在和删除元素都是hashCode和equals方法 下面是hashSet的代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142class People&#123; private String name; private int age; People(String name,int age)&#123; this.name=name; this.age=age; &#125; String getName()&#123; return this.name; &#125; private int getAge()&#123; return this.age; &#125; public int hashCode()&#123; return name.hashCode()+age; &#125; public boolean equals(Object object)&#123; if (!(object instanceof People))&#123; return false; &#125; People person=(People)object; //注意这个地方必须要强转否则会出现下面的person无法调用方法 return this.name.equals(person.getName()) &amp;&amp; this.age==person.getAge(); &#125;&#125;public class HashSet_8 &#123; public static void main(String[] args) &#123; HashSet&lt;People&gt; hs=new HashSet&lt;People&gt;(); hs.add(new People(\"1\",11)); hs.add(new People(\"2\",11)); hs.add(new People(\"1\",11)); for (People pe:hs)&#123; System.out.println(pe.getName()); &#125; &#125;&#125; 10.treeSet是在集合中的元素会自动排序，如果是字符串什么的他们都可以自动比较，因为字符串是已经实现了Compareable接口 但是如果要存放一般的元素对象的时候注意一定要让改类实现compareable接口，因为此接口会让类强制具有比较性 然后复写此接口中的compareTo方法，大于返回正数等于为零小于则为负，这里要注意如果有多个排序元素的话然后在比较 的时候相等条件判断要注意对其他排序元素的判断，否则会造成某个条件相等但是并不是同一个元素而无法存入 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Student implements Comparable&#123; private String name; private int age; Student(String name,int age)&#123; this.name=name; this.age=age; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125; @Override public int compareTo(Object o) &#123; if (!(o instanceof Student))&#123; throw new RuntimeException(\"not same type\"); &#125; if (this.age&gt;((Student) o).age)&#123; return 1; &#125;else if (this.age==((Student) o).age)&#123; return this.name.compareTo(((Student) o).name); //注意多重判断，要是age一样的话他们就会被当成相同元素而无法插入 string类已经实现了comparable接口 //其实java中很多类都实现了comparable接口，让类具有可比性 &#125; return -1; &#125;&#125;public class TreeSet_9 &#123; public static void main(String[] args) &#123; TreeSet&lt;Student&gt; ts=new TreeSet&lt;&gt;(); ts.add(new Student(\"ab\",1)); ts.add(new Student(\"kb\",3)); ts.add(new Student(\"mb\",3)); ts.add(new Student(\"am\",7)); for (Student stu : ts) &#123; System.out.println(stu.getName()+\"--------\"+stu.getAge()); &#125; &#125;&#125; 11.TreeSet底层的数据结构就是二叉树，元素的排列方式就是第一个进入的元素作为根节点然后按照compareTo方法 返回的值来判定是左孩子还是右孩子，这里就是如果说compareTo方法返回的正数则右孩子,负数为左孩子相等就说明 是同一个元素不用再比较。 所以说决定了TreeSet中的元素的重复与否就是compareTo函数的返回值 那么这样的话我们也可以规定一个TreeSet按照放进去的顺序取出来 或者倒序取出来就是compareTo全部返回1 或者-1即可，当然如果返回的始终为0那么最后集合中只有一个元素就是第一个元素 12.在TreeSet中除了实现comparable接口复写compareTo方法以外还有一种排序方法就是比较器，前面的comparable 接口是让元素具有了比较性而比较器则是让集合具有了比较性这个优先级跟高，具体的方法就是在集合实例化的时候传入一个 自定义的比较器，也就是构造方法传入一个比较器对象，这个比较器也是一个接口要实例化的话需要实现他的compare方法 比较器也是更加常用的 123456789101112131415161718192021222324252627class MyComparator implements Comparator&#123; public int compare(Object o1,Object o2)&#123; Student obj1=(Student)o1; Student obj2=(Student)o2; int num=obj1.getName().compareTo(obj2.getName()); if (num==0)&#123; return new Integer(obj1.getAge()).compareTo(obj2.getAge()); &#125; return num; &#125;&#125;public class TreeSet_10 &#123; public static void main(String[] args) &#123; TreeSet&lt;Student&gt; ts=new TreeSet&lt;Student&gt;(new MyComparator()); ts.add(new Student(\"dsf\",11)); ts.add(new Student(\"dmf\",12)); ts.add(new Student(\"ddf\",13)); ts.add(new Student(\"jf\",14)); for (Student stu : ts) &#123; System.out.println(stu.getName()+\"----------\"+stu.getAge()); &#125; &#125;&#125;","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"集合框架","slug":"集合框架","permalink":"http://lwenxu.coding.me/tags/集合框架/"}]},{"title":"Java之StringBuffer","slug":"Java SE/Java之StringBuffer","date":"2017-08-09T06:33:06.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java之StringBuffer/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java之StringBuffer/","excerpt":"1.存储： append(data) 添加在最后 insert(index,data) 在制定位置添加2.删除： delete(start,end) 删除某一段字符串 deleteCharAt(index) 删除置顶字符","text":"1.存储： append(data) 添加在最后 insert(index,data) 在制定位置添加2.删除： delete(start,end) 删除某一段字符串 deleteCharAt(index) 删除置顶字符 3.获取： charAt(index) indexOf(data) lastIndexOf(data) length() subString(start,end)4.修改： replace(start,end,data) setCharAt(index,data)5.翻转： reverse()6.获取缓冲区的制定数据放在指定字符串中 getChars(start,end,dstChar,dstIndex) 还有一个容器叫做 StringBuilder 其实一般来说这个用的更加频繁，因为 StringBuilder 他是线程不安全的，速度会更快。","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"Java面向对象基础(二)","slug":"Java SE/Java面向对象基础-二","date":"2017-08-09T03:14:38.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java面向对象基础-二/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java面向对象基础-二/","excerpt":"1.构造器： 构造函数在一个类没有写任何的构造函数的时候，系统会生成一个默认的空参数构造函数，这个构造函数的修饰符就是类的修饰符，当我们定义了一个构造函数，默认的构造函数就不存在了而不会出现重载 构造函数是没有返回值的，他没有返回值不是指他就是void，因为void指的是函数的返回值为void类型，他是有返回值的。而没有返回值则是说明根本不用写，这两个有很大区别。","text":"1.构造器： 构造函数在一个类没有写任何的构造函数的时候，系统会生成一个默认的空参数构造函数，这个构造函数的修饰符就是类的修饰符，当我们定义了一个构造函数，默认的构造函数就不存在了而不会出现重载 构造函数是没有返回值的，他没有返回值不是指他就是void，因为void指的是函数的返回值为void类型，他是有返回值的。而没有返回值则是说明根本不用写，这两个有很大区别。 没有return语句 函数的名字只能和类名完全一样 构造函数是可以用私用的，但是当所有的构造函数的修饰符都是私有的话对象就无法创建了，其实在看 Java 文档的时候我们也会发现有些类的构造器真的就是私有的，这也就代表了我们没办法使用 new 关键字调用这个类的构造函数，因为他的构造函数对我们来说是透明的，而且既然他自己定义了构造函数那么默认构造函数也不会生成，哪怕他是私有的。再仔细我们会发现他必然会提供一个静态方法让我们获取这个类的实例，类似于单例模式的样子，对外提供一个接口。 对象一建立构造函数就会被调用 构造函数的作用主要就是给对象做初始化 在类中有一种特殊的代码块叫做构造代码块，和一般的代码一样，只是在要执行的代码上添加一个花括号就行。&nbsp;&nbsp;&nbsp;&nbsp;这个构造代码块也是在每次构造对象的时候执行，看起来和构造函数非常类似，但是注意他和构造函数是有很大区别的&nbsp;&nbsp;&nbsp;&nbsp;首先按照执行顺序来说，构造代码块要是中先于构造函数执行。&nbsp;&nbsp;&nbsp;&nbsp;另外对于功能来说构造代码块是针对类的所有对象，而构造函数则是针对类的不同对象。因为构造函数是可以重载的而代码块则是无脑执行。12345678910111213141516171819class PersonDemo&#123; private String name; &#123; System.out.println(\"this is construct code block !\"); &#125; PersonDemo()&#123; this.name=\"zhangsan\"; &#125; PersonDemo(String name)&#123; this.name=name; &#125; public void say()&#123; System.out.println(\"name :\"+this.name); &#125;&#125; 2. Final 关键字： final可以修饰类，函数，变量 被final修饰的类无法再次进行继承，也就是为了避免功能被覆盖，保护封装性 被final修饰的方法无法被复写 被final修饰的变量只能赋值一次，就是一个常量 3. 内部类： 内部类就是在一个类中定义了另外一个类 内部类可以直接访问外部类中的成员和方法，包括私有的成员与方法 其原因在于内部类存在一个指向外部类的引用 ：就叫做 外部类类名.this 内部类是可以私有的 在私有了以后在别处无法直接创建内部类的对象 只能通过外部类来访问 内部类可以是静态static的，也可用public，default，protected和private修饰。（而外部顶级类即类名和文件名相同的只能使用public和default）。 内部类是一个编译时的概念，一旦编译成功，就会成为完全不同的两类。对于一个名为outer的外部类和其内部定义的名为inner的内部类。编译完成后出现outer.class和outer$inner.class两类。所以内部类的成员变量/方法名可以和外部类的相同。 内部类分为以下几种： 成员内部类：因为成员内部类需要先创建了外部类，才能创建它自己的 12345678910111213141516171819 class Outer&#123; private int x; public Outer(int x) &#123; this.x = x; &#125; class Inner&#123; public void method()&#123; System.out.println(x); System.out.println(Outer.this.x); &#125; &#125; public void getInner()&#123; Inner in=new Inner(); in.method(); &#125;&#125; 局部内部类：就可以在函数作用域类创建内部类 嵌套内部类 嵌套内部类，就是修饰为static的内部类。声明为static的内部类，不需要内部类对象和外部类对象之间的联系，就是说我们可以直接引用outer.inner，即不需要创建外部类，也不需要创建内部类。 匿名内部类有时候我为了免去给内部类命名，便倾向于使用匿名内部类，因为它没有名字。例如： 12345678910 public void onClick(View v) &#123; new Thread() &#123; @Override public void run() &#123; &#125; &#125;.start();&#125; 4. 抽象类与抽象方法： 抽象方法就是没有方法体 有抽象方法的类必须声明为抽象类 抽象类没有办法实例化 当子类继承了抽象类，必须把抽象类的所有抽象方法都重写了才能实例化，否则他还是抽象类。 5.接口： 当一个类中的方法都是抽象方法的时候可以把抽象类修改成接口 接口中一般只能定义抽象方法和静态常量，当然如果不写这些修饰符的话java会自动给加上 接口可以被类多实现，也就是说一个类可以实现多个接口 也就是前面所说的多实现 java中的接口是可以多继承的，也就是说如果说java支持多继承的话那么一定给加上限定条件，就是他只在接口中可以 6. Static 关键字： 静态static可以修饰方法，修饰属性当成员被static修饰的时候，这个成员就相当于被类的所有对象共享了，所有对象都可以访问修改 静态成员并不是存放在堆栈中的而是存放在一块特殊的内存叫做『方法区』或者『数据区』，『共享区』等，并且这个地方分的很细，对象的方法也是存放在这个地方 静态成员在调用的时候不仅仅是使用对象来调用还可以使用类名调用，因为静态成员就是属于类的而不是单单属于某个对象 静态成员的生命周期是与类的生命周期相同 静态成员是先于对象加载入内存，也就是静态属性先存在然后才有的对象 1.实例变量和类变量的区别： 存储位置： 类变量存放在方法区中，而实例变量存放在堆内存中 生命周期： 类变量的生命周期是和类一样，但是实例变量的生命周期则是与实例相同 2.使用static的注意事项： 静态方法只能访问静态成员和静态方法。（静态的是独立于对象的，而非静态的则是依赖于对象存在的。另外静态的是先于对象载入内存） 非静态方法即可以访问静态也可以访问非静态成员和方法 静态方法中不可以出现this，super因为静态成员先于对象存在 3.那什么时候使用static： 对于静态方法就是当这个方法中不存在关于对象的成员的时候就把该方法修改成静态的 对于变量则当该变量需要共享的时候就要把属性变成static 4.主函数为什么是静态的？主函数是一个特殊的函数，作为程序的入口，可被jvm调用public：代表访问权限是最大的static：代表主函数是独立于类存在的，并且该函数是在类的加载的时候被加载void：不用呗jvm返回一个参数String[] args :jvm需要的参数 注意这个main函数除了args是可以改的以外其他都不可改，不然不可以被jvm识别同时main是可以被重载的，但是只有仅仅满足以上格式的才能被jvm执行，string[] 这个参数其实就是命令行传的参数 4.静态代码块1234//静态代码块 static &#123; //static code block &#125; 他是随着类的加载而加载，并且仅仅执行一次，因为类进入内存以后再次new对象的时候类不会再次加载 他可以先于main函数执行 它的作用是给类初始化 但是注意当用一个类定义一个变量的时候不加载类7.编译小问题在java编译的时候如果在某个类中调用了其他的类，那么jvm则会在当前目录或者指定目录（classpath）寻找该类的class文件（编译过后的），没找到则找java文件都没找到肯定报错在堆内存中的变量都是有初始值的，而在站内存中的变量在不初始化的情况下是无法参与运算的，对内存中可以 8.单例设计模式单例设计模式一般来说就有两种方式，一个是懒汉式，一个是饿汉式。其中懒汉式使用的类的延时加载，但是会出现安全问题，需要使用同步代码块包裹返回的对象，并且做双重判断才可以。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package learn;/** * 单例模式的第一种实现方式，也是最常用的一种叫做饿汉式 * 他是先初始化对象 */class SingleHunger&#123; private String name; private int age; private static SingleHunger s=new SingleHunger(\"lwen\",19); private SingleHunger(String name,int age)&#123; this.name=name; this.age=age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public static SingleHunger getSingle() &#123; return s; &#125;&#125;/** * 这个又成为懒汉式也叫做对象的延时加载，他则使用的比较少，因为在进行new新对象的时候可能会有两个线程同时进入临界区导致对相爱那个不唯一 * 多一需要做同步操作，但是同步的时候又会消耗时间，下面的方式要稍微好一点一般只做了一次同步操作，还有一种解决方案就是直接在class后面添加同步关键字 * 每次都要判断非常耗时 */class SingleLazy&#123; private String name; private int age; private static SingleLazy s=null; /** * 使用private限定词是为了防止外部的方法直接调用本类中的构造方法生成新的对象 * @param name * @param age */ private SingleLazy(String name,int age)&#123; this.age=age; this.name=name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public static SingleLazy getSingle()&#123; /* 同步机制加双重判断，防止意外情况发生 */ if (s==null)&#123; synchronized (SingleLazy.class)&#123; if (s==null) &#123; s = new SingleLazy(\"lwen\", 19); &#125; &#125; &#125; return s; &#125;&#125;public class SingleModel &#123; public static void main(String[] args)&#123; SingleHunger s1=SingleHunger.getSingle(); s1.setAge(20); s1.setName(\"lwenxu\"); SingleHunger s2=SingleHunger.getSingle(); System.out.println(s2.getName()); &#125;&#125; 9.模板设计模式模板设计模式,就是在一段确定的方法中调用了一些不确定的方法。那么就把这些不确定的方法定义成抽象的方法，并且把这些不确定的方法的接口给暴露出去 12345678910111213141516171819202122232425abstract class codeTime&#123; final public long getTime()&#123; long start=System.currentTimeMillis(); runCode(); long end=System.currentTimeMillis(); return end-start; &#125; abstract void runCode();&#125;class ACodeTime extends codeTime&#123; void runCode()&#123; for (int i=0;i&lt;1000;i++)&#123; System.out.println(i); &#125; &#125;&#125;public class Template &#123; public static void main(String[] args) &#123; ACodeTime time=new ACodeTime(); System.out.println(\"time is :\"+time.getTime()); &#125;&#125;","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"面向对象","slug":"面向对象","permalink":"http://lwenxu.coding.me/tags/面向对象/"}]},{"title":"ConcurrentHashMap","slug":"Java SE/ConcurrentHashMap","date":"2017-08-09T02:27:50.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/ConcurrentHashMap/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/ConcurrentHashMap/","excerpt":"","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ConcurrentHashMap值得注意的点 不能使用 null 做为键或者是值 他和 HashTable 一样的 ​","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"JDK 源码","slug":"JDK-源码","permalink":"http://lwenxu.coding.me/tags/JDK-源码/"}]},{"title":"Java面向对象基础","slug":"Java SE/Java面向对象基础","date":"2017-08-09T02:27:50.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java面向对象基础/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java面向对象基础/","excerpt":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;面向对象一直是一种很流行的思想，他的精髓也就在于他的三大特性：封装，继承和多态。本文就在这三个方面简单的谈一谈Java的面向对象基础。 1.封装：&nbsp;&nbsp;&nbsp;&nbsp;封装顾名思义，就是将一些对象的属性和方法隐藏于本类之中，其他的类无法访问本类的这些被封装的属性和方法。也就是这些方法和属性仅仅是为了本类服务的。除了为本类服务之外封装还可以只暴露自己想给别人提供的服务，而对于一些特殊的底层的服务不希望别人能看到，或者调用。","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;面向对象一直是一种很流行的思想，他的精髓也就在于他的三大特性：封装，继承和多态。本文就在这三个方面简单的谈一谈Java的面向对象基础。 1.封装：&nbsp;&nbsp;&nbsp;&nbsp;封装顾名思义，就是将一些对象的属性和方法隐藏于本类之中，其他的类无法访问本类的这些被封装的属性和方法。也就是这些方法和属性仅仅是为了本类服务的。除了为本类服务之外封装还可以只暴露自己想给别人提供的服务，而对于一些特殊的底层的服务不希望别人能看到，或者调用。 总的来说封装有以下作用或者好处： 为本类提供服务 对外暴露部分接口 屏蔽类底层的实现细节 防止别人破坏类内部的核心结构，例如直接继承，然后覆盖核心方法，或者装饰者模式，造成违背作则意愿的修改。 2.继承：&nbsp;&nbsp;&nbsp;&nbsp;继承这个名词也很形象，就是子类去获得父类的共有的或者保护的属性以及方法，然后再次基础上进行扩充进一步完善类代码和功能。继承一把来说在直观上是为我们节省了代码量，父类中已有的方法和属性我们无需再次书写，但是继承并非为了节省代码量而被提出的，而是因为他展示了类与类之间的联系。一般两个类有间接或直接的关系我们才会去继承，而不是单单为了节省代码量。 1.他的主要功能： 展现类之间的关系 节省代码量 提高了代码的重用性 因为有了继承才有的多态 2.另外还有一些需要注意的地方：&nbsp;&nbsp;&nbsp;&nbsp;java只支持单继承，不支持多继承，多继承会导致功能紊乱&nbsp;&nbsp;&nbsp;&nbsp;例如多个父类中有相同的方法，但是同时继承就会产生不知道继承哪一个方法的问题但是java还是保留了C++的这种多继承的机制，叫做多实现，也就是在接口上支持多继承( 实现 )。&nbsp;&nbsp;&nbsp;&nbsp;但是继承的时候要注意他们是is a的关系也就是每一个子类对象都是一个父类对象。 子类对象 is a 一个父类对象。 3.继承中的 super 和 this1.super指针指向的就是父类的对象 变量：如果子类中出现了父类中的非私有的同名变量要访问子类中变量直接this或者不写，要访问父类中的变量使用super 函数：覆盖：保留父类的方法的功能定义，重写功能内容；子类的覆盖的函数权限必须大于父类的函数的权限，对于没有权限限定的就是默认权限，他是介于公有与私有之间的一种权限子类中只能使用静态方法覆盖静态方法 注意： 重写：他们的参数列表与返回值都必须一样 重载：他们的参数列表一定不一样，返回值无所谓 2. this 代表的是所在函数所属对象简单来说就是this在哪个函数，这个函数是哪个对象的，this指的就是哪个对象但是注意，this他并不是当前对象而是指向当前对象，他类似于一个指针this的应用： 就是当前对象的方法需要引用当前对象的时候我们才使用this this的第二个应用就是，在构造函数中使用类似于函数的方式来调用该类中的其他构造函数，注意他也只能出现在构造函数的互相调用之中123456789101112131415161718class PersonDemo2&#123; private int age; private String name; private PersonDemo2()&#123; System.out.println(\"no params \"); &#125; private PersonDemo2(String name)&#123; this(); this.name=name; &#125; PersonDemo2(String name,int age)&#123; this(name); this.age=age; &#125;&#125; this在构造函数中的互相调用不允许一直互相反复调用会造成死循环 3.多态：&nbsp;&nbsp;&nbsp;&nbsp;多态算是面向对象里面比较复杂的一个功能也是一个极其好用的功能。一句话来概括多态的话可以说，” 一个接口，多个实现 “。就是同一种事物表现出的多种形态。&nbsp;&nbsp;&nbsp;&nbsp;多态允许将子类的对象当作父类的对象使用，某父类型的引用指向其子类型的对象,调用的方法是该子类型的方法。这里引用和调用方法的代码编译前就已经决定了,而引用所指向的对象可以在运行期间动态绑定。 1.他的具体体现就是： 父类的引用指向子类的对象 父类的引用可以接受子类的对象作为参数 &nbsp;&nbsp;&nbsp;&nbsp;这里父类的引用指向了子类的实例，那么这里会发生一个自动的向上类型转换，就是自动的把子类的对象提升为父类的对象，但是这样会造成精度的损失，也就是子类的特性被销毁了子类独有的方法和属性无法再调用了。&nbsp;&nbsp;&nbsp;&nbsp;但是既然可以向上类型转换必然就存在向下类型转换，也就是把父类对象转为子类对象。只不过这种转换仅仅可以出现在父类对象是因为向上类型转换的对象，而不能平白无故的把一个父类对象，转为子类对象。 2.多态的前提： 必须要有继承或者接口的实现 必须存在方法的覆盖 3.参数的动态绑定：1.在多态中（也就是在父类的引用指向子类的时候）对成员函数来说： 在编译期间：看引用的成员函数，是否存在如果不存在编译不通过。（编译期间就是看的是类型的声明，声明里有就编译通过没有就失败） 在运行期间：看实际对象的函数，运行实际的对象的方法。（运行使用的是对象运行里面的this指的就是new 哪个类方法就被绑定在哪个对象上） &nbsp;&nbsp;&nbsp;&nbsp;简单来说就是编译看右边，运行看左边（儿子充当父亲，人家编译的时候看的你是一个父亲那么就看你父亲是不是有这个方法，而运行的时候儿子会做什么就做什么而不是按照父亲的做），总之一句话：“ 编译声明检查，运行动态绑定 ” 2.再多态中，成员变量的特点：&nbsp;&nbsp;&nbsp;&nbsp;变量始终与引用类型看齐（向左看齐）无论是静态变量还是非静态 静态就好说与类绑定自然就看引用 说白了成员变量没有方法那种动态绑定 3.静态方法：&nbsp;&nbsp;&nbsp;&nbsp;始终与引用类型看齐 因为是静态绑定 静态方法与类绑定","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"面向对象","slug":"面向对象","permalink":"http://lwenxu.coding.me/tags/面向对象/"}]},{"title":"Java基本包装类型","slug":"Java SE/Java基本包装类型","date":"2017-08-09T02:14:07.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java基本包装类型/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java基本包装类型/","excerpt":"基本类型的对象包装，也就是将常用的基本数据类型包装成对象 byte Byte short Short int Integer long Long boolean Boolean float Float double Double char Character","text":"基本类型的对象包装，也就是将常用的基本数据类型包装成对象 byte Byte short Short int Integer long Long boolean Boolean float Float double Double char Character 最常用的作用就是基本数据类型与字符串的转换1. 基本数据类型转字符串：基本数据类型+””基本数据类型类.toString(基本类型的数值)2.字符串转成基本数据类型：Integer.parseInt()Long.parseLog()对character不用转就是string3.进制转换：向十进制转：toHexString（）向其他进制转换：parseInt(“”,radax) radax指的是字符串的进制4.自动拆箱和装箱： 1.5版本 的新特性，自动装箱与拆箱以前要这么写： 12Integer x=new Integer(1) Integer x=new Integer(\"1\") 现在可以自动装箱： 12Integer x=5; //自动装箱x=x+2 //先拆箱后和装箱 拆箱原理就是x.intValue() 1.5后对于在byte范围（-128~+127）内的数 如果一个数已经存在 则不会重新开辟新空间,也就是 12Integer x=127,y=127; //x===yInteger m=128,n=128; //m!==n 还有一点需要注意的就是 new String 和普通的 String = “” 这两个差别很大前者属于一个对象放在了堆内存中，而后者则是直接就在常量池中，不仅仅是字符串，其他都如此。","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"Java位操作","slug":"Java SE/Java位操作","date":"2017-08-09T01:34:32.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/08/09/Java SE/Java位操作/","link":"","permalink":"http://lwenxu.coding.me/2017/08/09/Java SE/Java位操作/","excerpt":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无论说是在哪一门计算机语言，位操作运算对于计算机来说肯定是最高效的，因为计算机的底层是按就是二进制，而位操作就是为了节省开销，加快程序的执行速度，以及真正的实现对数的二进制操作。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用位操作，很多代码看起来会很简洁，并且执行速度也会随之提高。在大多数编程语言中都会有 &lt;&lt; 和 &gt;&gt;这两个符号向左的就是左移，反之则是右移这个符号的左边就是需要操作的数，而右边就代表了对这个数移动多少位。","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无论说是在哪一门计算机语言，位操作运算对于计算机来说肯定是最高效的，因为计算机的底层是按就是二进制，而位操作就是为了节省开销，加快程序的执行速度，以及真正的实现对数的二进制操作。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用位操作，很多代码看起来会很简洁，并且执行速度也会随之提高。在大多数编程语言中都会有 &lt;&lt; 和 &gt;&gt;这两个符号向左的就是左移，反之则是右移这个符号的左边就是需要操作的数，而右边就代表了对这个数移动多少位。 1.具体位操作 左移( &lt;&lt; )：左移几位就是将这个数再乘以2的几次方，例如说 4 &lt;&lt; 2 其结果就是16，也就是将这个数化作为2进制的数然后向左移动两位，最右边的空位就补0. 右移( &gt;&gt; )：右移就刚好相反，但是也不是完全一样，他是向右移动 n 位，如果说这个数本来就是正的，那么和左移刚好相反就直接除以 2 的 n 次方位，但是如果是负数的话在这个数向右移动 n 位后我们在前面的空位补的是 0 。也就是右移的话是与数相关的问题。右移一个很明显的应用就是在二分法的时候我们就可以直接右移一位，显然速度会提高。 超级右移( &gt;&gt;&gt; )：刚刚说了右移其实还是需要按照情况来的，有时候就不一定是正数，我们就可能补 1 ，但是我们期望结果就是这个数除以 2 的 n 次方，我们就可以使用这个无视正负号的右移操作 &gt;&gt;&gt; ，也就是说他是在任何情况下都是给最高位添加 0 。 与操作( &amp; ):与操作就是把两个数转化为二进制的数，然后再把这两个数，从最低位每位对其，同 1 结果为 1 否则全为 0。 或操作( | ):操作同上只是这个是同 0 为 0，其他都是1。 取反操作( ~ ):二进制的0 变 1 ， 1 变 0。 异或( ^ ):异或有一条很重要的性质，用的非常多就是一个数异或同一个数两次结果还是那个数。 上面的与或操作会发现他们有单符号的还有双符号的，不要搞混了单符号的不仅仅就是位操作，他们还是逻辑操作，而双符号的仅仅就是逻辑操作。并且他们有区别例如 &amp; 和 &amp;&amp; 当他们都作为逻辑操作的，前者就是对一个表达式一直判断完毕才会出现他的值，而后者则是判断一半如果知道为假或真他就不再判断了，这也就是我们看到的大多数的 if 判断中是用的双与，而非单与。 2.实际应用： 第一个就是两个数交换，这个一般有三种方式：第一个：临时变量 1234int i=3,j=8,temp=0;temp=i;i=j;j=temp; 第二个：使用加减法 1234int i=3,j=8;i=j+i;j=i-j;i=i-j; 第三个：位操作 1234int i=3,j=8;i=i^j;j=i^j;i=i^j; 这个地方就是用了异或的重要性质 第二个就是进制转换了：基本思路就是先把数转为二进制的数，然后如果要 16 进制那么就4位取，8进制3位取，但是又怎么取这个4位或者3位呢，这里与操作就能派上用场取四位我们可以直接与上 15 ，三位就是 7 了，例如：12345int num=60;int n1=num &amp; 15;int tmp=num &gt;&gt;&gt; 4;int n2=tmp &amp; 15;System.out.println(\"n1: \"+n1+\" n2 \"+n2);","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://lwenxu.coding.me/tags/Java/"}]},{"title":"proxifier配合ss，实现全局代理","slug":"Tools/proxifier配合ss，实现全局代理","date":"2017-07-30T13:05:34.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2017/07/30/Tools/proxifier配合ss，实现全局代理/","link":"","permalink":"http://lwenxu.coding.me/2017/07/30/Tools/proxifier配合ss，实现全局代理/","excerpt":"","text":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;proxfixer配合ss的话，基本可以实现全局代理，分应用代理，或者玩外服的游戏（一般的游戏默认不走代理，本软件可以强制应用代理）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于ss使用的是sockets5代理，一般情况下只有浏览器支持，可以实现科学上网。但很多用户希望自己的应用软件，像outlook或游戏之类的软件也实现科学上网。这就需要proxifier的配合。软件可以在官网下载，https://www.proxifier.com/官网无法下载的也可在如下百度网盘下载，链接: https://pan.baidu.com/s/1c11bs8C 密码: 44qj目前仅支持windows和mac os，不支持手机。此软件为收费软件，这里提供两个注册码, 软件分为Standard Edition和Portable Edition版本，注册码不通用，注册用户名任意。 123L6Z8A-XY2J4-BTZ3P-ZZ7DF-A2Q9C（Portable Edition）5EZ8G-C3WL5-B56YG-SCXM9-6QZAP（Standard Edition）P427L-9Y552-5433E-8DSR3-58Z68（MAC） 1.打开软件，首先配置代理服务器。如下图，添加地址127.0.0.1，以及ss里配置的本地端口，默认为1080，选择socks version 5在配置完成之后需要测试一下，看配置的是否有问题。 2.接下来就要添加规则，来确定哪些软件是走代理的，哪些不用按如图所示的添加，这里有个default规则，如果default旁边的action里边选择的时proxy socks5…则本机所有软件都会走代理。一般default会选direct，然后把你需要走代理的软件选成proxy socks5…","categories":[{"name":"-工具类","slug":"工具类","permalink":"http://lwenxu.coding.me/categories/工具类/"}],"tags":[{"name":"shadowsocks","slug":"shadowsocks","permalink":"http://lwenxu.coding.me/tags/shadowsocks/"}]},{"title":"Redis数据类型","slug":"DataBase/Redis数据类型","date":"2017-07-28T09:54:41.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/07/28/DataBase/Redis数据类型/","link":"","permalink":"http://lwenxu.coding.me/2017/07/28/DataBase/Redis数据类型/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Redis基本入门","slug":"DataBase/Redis基本入门","date":"2017-07-28T08:56:49.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/07/28/DataBase/Redis基本入门/","link":"","permalink":"http://lwenxu.coding.me/2017/07/28/DataBase/Redis基本入门/","excerpt":"1.Redis简介&nbsp;&nbsp;&nbsp;&nbsp;Redis 是一种基于内存亦可持久化的日志型，Key-Value 数据库。可持久在于他的部分数据是存放在内存上，而当数据库重启以后他的数据不会立刻丢失，而是会存放在磁盘上，通过日志去加载磁盘上的数据文件。所以说它不仅仅是一种内存型键值数据库。&nbsp;&nbsp;&nbsp;&nbsp;另外 Redis 所支持的数据结构也非常丰富，不仅仅就是一种简单的 NoSql ，而是被称作为数据结构服务器。他所支持的数据结构有：字符串（string），哈希（Map），列表（List），集合（Set），有序集合（ZSet），BitMap，HyperLogLog（超小内存唯一值计数），GEO（地理信息位置）。以上所说的均是值所支持的数据结构，键必然为字符串。","text":"1.Redis简介&nbsp;&nbsp;&nbsp;&nbsp;Redis 是一种基于内存亦可持久化的日志型，Key-Value 数据库。可持久在于他的部分数据是存放在内存上，而当数据库重启以后他的数据不会立刻丢失，而是会存放在磁盘上，通过日志去加载磁盘上的数据文件。所以说它不仅仅是一种内存型键值数据库。&nbsp;&nbsp;&nbsp;&nbsp;另外 Redis 所支持的数据结构也非常丰富，不仅仅就是一种简单的 NoSql ，而是被称作为数据结构服务器。他所支持的数据结构有：字符串（string），哈希（Map），列表（List），集合（Set），有序集合（ZSet），BitMap，HyperLogLog（超小内存唯一值计数），GEO（地理信息位置）。以上所说的均是值所支持的数据结构，键必然为字符串。 2.Redis安装&nbsp;&nbsp;&nbsp;&nbsp; Redis 最初是由标准 C 写的，但是后来社区非常的活跃，所以现在什么版本的 Redis 都是有的，所以说这个数据库是可以跑在任何平台的，这里主要就说 Windows 下的安装， Linux 与 Mac 下安装很简单，只需要一个命令就能搞定。&nbsp;&nbsp;&nbsp;&nbsp;下载好Redis的二进制文件后，使用 cmd 切到 Redis 安装目录下，然后运行 1redis-server.exe redis.conf 就能跑起一个 Redis 的服务端程序，然后不要关闭这个程序。另开一个 cmd 依然切换到安装目录执行 1redis-cli.exe -h 127.0.0.1 -p 6379 这样就开启了一个客户端。 3.Redis的配置我们有三种启动 redis 的方式： 最简启动，无需配置文件 redis-server 加载配置文件 redis-server configpath 动态参数的配置 客户端的连接方式： redis-cli -h ip -p port &nbsp;&nbsp;&nbsp;&nbsp;Redis 可以使用客户端进行配置也可以使用配置文件，Redis 的配置文件位于 Redis 安装目录下，文件名为 redis.conf。使用客户端基本格式如下： 1CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE 这样的好处在于配置起来方便，但是缺点显然就是服务器重启，配置将不再生效，也就是说现在的配置放在了内存中，然后需要重启还生效的东西必须放在永久存储介质上，一般来说就是磁盘。这个规则不仅仅适用于 Redis ，对于 Linux 以及其他数据库也是如此。&nbsp;&nbsp;&nbsp;&nbsp;接下来主要说一下配置文件里面的重要选项： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351. Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no2. 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid3. 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字 port 63794. 绑定的主机地址 bind 127.0.0.15.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 3006. 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose loglevel verbose7. 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null logfile stdout/filename8. 设置数据库的数量，默认数据库为0，可以使用SELECT &lt;dbid&gt;命令在连接上指定数据库id databases 169. 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save &lt;seconds&gt; &lt;changes&gt; Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。10. 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes11. 指定本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb12. 指定本地数据库,以及存放目录 dir ./13. 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 slaveof &lt;masterip&gt; &lt;masterport&gt;14. 当master服务设置了密码保护时，slav服务连接master的密码 masterauth &lt;master-password&gt;15. 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH &lt;password&gt;命令提供密码，默认关闭 requirepass foobared16. 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 maxclients 12817. 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory &lt;bytes&gt;18. 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no appendonly no19. 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof20. 指定更新日志条件，共有3个可选值： no：表示等操作系统进行数据缓存同步到磁盘（快） always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） everysec：表示每秒同步一次（折衷，默认值） appendfsync everysec21. 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制） vm-enabled no22. 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap23. 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-max-memory 024. Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 vm-page-size 3225. 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 vm-pages 13421772826. 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 vm-max-threads 427. 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 glueoutputbuf yes28. 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 51229. 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍） activerehashing yes30. 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件 include /path/to/local.conf 4. 通用命令 keys 所有的键 O(n) dbsize 复杂度为O(1) exists key del key expire key second type key ttl/persist key 存活时间，让他一直存活 时间复杂度 5. 字符串最大是512M，主要用于缓存、计数器、分布式锁。 1.API get/set/del Incr/decr/incrby/decrby Set/setnx/set .. xx Mget/mset … 批量操作原子的 getset key newvalue Append key value Strlen key 6. Hash1.API Hget/hset/hdel Hexits/hlen field 数 hmget/hmset 同上 7. List lpush/lpop/rpush/rpop Linsert key before/after lrem key count value 根据count值，从列表中删除所有value相等的项 (1) count &gt;0，从左到右，删除最多count个value相等的项(2) count&lt;0,从右到左，删除最多Math.abs(count)个value相等的项(3) count=0,删除所有value相等的项lrem listkey 0 a Itrim key start end 按照索引范围修剪列表,删除不在范围之内的 lrange key start end (包含end) 获取列表指定索引|范围所有item lindex key index 获取列表指定位置的值 len key 长度 lset key index val blpop/brpop key timeout 阻塞直到部位空返回 8. set sadd/sdel/srem scrad/sismember/srandmember/spop/smembers sdiff user:1:follow user:2:follow = music his #差集 sinter user:1:follow user:2:follow = it sports #交集 sunion user:1:follow user:2:follow = it music his sports news ent #并集 sdifflsinterlsuion + store destkey..#将差集、交集、并集结果保存在destkey中 SADD= Tagging SPOP/SRANDMEMBER = Random item SADD + SINTER = Social Graph 9. zset zadd key score element(可以是多对)添加score和element zrem key element zsrore key ele zincrby key increscore element增加或减少元素的分数 Zrank 排名 zrange key start end zrangebyscore zrembyscore zrevarank 反向的排序 10. 发布订阅11.RDB RDB是Redis内存到硬盘的快照，用于持久化。 save通常会阻塞Redis。 bgsave不会阻塞Redis,但是会fork新进程。 save自动配置满足任一就会被执行。 有些触发机制不容忽视","categories":[{"name":"-数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/categories/数据库/"}],"tags":[{"name":"Redis NoSql 数据库","slug":"Redis-NoSql-数据库","permalink":"http://lwenxu.coding.me/tags/Redis-NoSql-数据库/"}]},{"title":"Java异常","slug":"Java SE/Java异常","date":"2017-07-10T00:25:29.000Z","updated":"2018-12-19T18:44:48.000Z","comments":true,"path":"2017/07/10/Java SE/Java异常/","link":"","permalink":"http://lwenxu.coding.me/2017/07/10/Java SE/Java异常/","excerpt":"从今天开始就要好好的写日志了，每天一篇，把工作中学习中遇到的问题，学习的新知识都放在这个博客里面，有空了就过来回顾一下，记录一下成长。","text":"从今天开始就要好好的写日志了，每天一篇，把工作中学习中遇到的问题，学习的新知识都放在这个博客里面，有空了就过来回顾一下，记录一下成长。","categories":[{"name":"-Java","slug":"Java","permalink":"http://lwenxu.coding.me/categories/Java/"}],"tags":[{"name":"Java学习","slug":"Java学习","permalink":"http://lwenxu.coding.me/tags/Java学习/"}]},{"title":"杂记","slug":"Life/杂记","date":"2017-06-05T15:43:55.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/06/05/Life/杂记/","link":"","permalink":"http://lwenxu.coding.me/2017/06/05/Life/杂记/","excerpt":"好久好久没有写过东西了，最近说事很多其实也不是很多，反正还是一堆杂事，然后加上贪玩，恶补了几部动漫。","text":"好久好久没有写过东西了，最近说事很多其实也不是很多，反正还是一堆杂事，然后加上贪玩，恶补了几部动漫。 今天脑子一热把手机上的娱乐性app全给删了，感觉最近还是太过浮躁。学习没有学习，玩没有认真玩，技术也没有认真做。总之感觉状态一直很差吧。或者说自己突然变得很怠惰。目前的计划算是基本确定了，最近把大数据平台的需求分析搞定，暂时不做这方面的技术吧，毕竟马上又要期末考试了。虽然感觉不像去年学的那么烂，但是也没感觉自己学的有多好，所以这段时间的复习还是至关重要的！尽量多把心思放在考试复习上面，嘉木还有大数据平台先搁置一下。之后学长他们旅游回来了，我想大家再聚一次，毕竟以后的机会真的很少很少了啊，还有从那以后技术必须要以自己能看到的速度成长才行，不然自己说的什么都是空话而已！暑假，还是和去年差不多。只是换了一个地方，我想这段时间一定一定要把java和php以及算法和数据结构中的至少两个搞得通透，时间真的不多了，而且这样的整体的时间更是越来越少了。这段时间还是尽量尽量不要受任何人的影响，这样只会让自己想的更多更浮躁。目前的目标只有两个搞定就好了，不多想！","categories":[{"name":"-杂记","slug":"杂记","permalink":"http://lwenxu.coding.me/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"http://lwenxu.coding.me/tags/杂记/"}]},{"title":"Mac配置sshd","slug":"Mac/Mac配置sshd","date":"2017-05-12T22:53:23.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/05/13/Mac/Mac配置sshd/","link":"","permalink":"http://lwenxu.coding.me/2017/05/13/Mac/Mac配置sshd/","excerpt":"","text":"修改sshd_config文件把password验证方式打开修改这个文件要用sudo PasswordAuthentication yes 12345sudo ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_keysudo ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_keysudo ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_keysudo ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_keysudo /usr/sbin/sshd","categories":[{"name":"-Mac","slug":"Mac","permalink":"http://lwenxu.coding.me/categories/Mac/"}],"tags":[]},{"title":"数据库Exists关键字举例","slug":"DataBase/数据库Exists关键字举例","date":"2017-05-11T23:30:00.000Z","updated":"2018-12-19T18:44:46.000Z","comments":true,"path":"2017/05/12/DataBase/数据库Exists关键字举例/","link":"","permalink":"http://lwenxu.coding.me/2017/05/12/DataBase/数据库Exists关键字举例/","excerpt":"一.问题描述： 查询所有未选择03号课程的学生的姓名规定使用存在量词","text":"一.问题描述： 查询所有未选择03号课程的学生的姓名规定使用存在量词 student表： grade表： 二.思路：既然是存在量词那么也就是Exists和Not Exists两个存在两次来做判断条件。那么就可以想： 1.选出所有学生然后除去那些选了03号课程的同学2.直接选出那些没有选择03号课程的同学三.开始写Sql：1.尝试首先按照第一种思路就是先连接student和grade（或者不连接）然后除掉grade中有03课程记录的学生，那么我们会写出以下Sql: 1234567SELECT DISTINCT sname from Student,Grade WHERE NOT exists( SELECT * FROM Grade WHERE cno='03');或者SELECT DISTINCT sname from Student WHERE NOT exists( SELECT * FROM Grade WHERE cno='03'); 执行以后我们发现我们得到的结果是空 接下来我们看看student表中到底有多少人：执行以下语句： 1SELECT DISTINCT sno,sname FROM Student GROUP BY sno; 这里我们发现这条语句根本没有进行筛选，这是因为Exists不知道使用什么条件去筛选数据，前面是一个结果集后面为另一个结果集数据库不清楚按照哪个字段来判断前面的某条记录是否存在与后面的集合中。 2.修正错误：这里在两个表之间显然只有sno字段是相关的，所以在最后添加判断条件： 12345Grade.sno=Student.sno也就是SELECT DISTINCT sname from Student WHERE NOT exists( SELECT * FROM Grade,Student WHERE cno='03' AND Grade.sno=Student.sno); 此时出现了10条记录经过比对发现是正确的。 3.接下来用sql语句验证结论：12SELECT DISTINCT sno,sname FROM Student GROUP BY sno;SELECT sno FROM Grade WHERE cno='03'; 第一条语句就是找到student表中的所有人，第二条语句就是看看哪些人选择了03号课程，结果如下。 发现结论正确，但是这两个语句貌似可以拼接成一条新的sql来完成这道题： 1234SELECT DISTINCT snameFROM Student where sno NOT IN ( SELECT sno FROM Grade WHERE cno='03'); 结果同上。 4.反向思维：既然not Exists是可以的那么是不是可以把那条语句修改成exists语句然后把where里面的条件再非一下，执行以下语句： 1234SELECT sname FROM Student WHERE exists( SELECT DISTINCT Student.sno FROM Grade WHERE Grade.sno=Student.sno AND cno!='03'); 但是结论是只有七条数据，显然差距比较大。也就是子查询是有问题的，查表以后发现在student表中是有十二个同学，但是grade表中选课的同学总数并不是十二个，也就是说有很多人根本没有选课。并且另外一个问题就是有的人选了不止一门课可能某个同学既选了03又选了别的课程，而在使用exits判断的时候只要有满足条件的就返回，自然是没等判断到选了03就能返回真。所以这个方法行不通。 5.修改：上面出现问题，说明使用exists思路没问题只是子查询错误,试试运用course表看能不能写出其他语句： 12345SELECT sname FROM Student WHERE exists( SELECT cno FROM Course WHERE sno NOT IN ( SELECT sno FROM Grade WHERE cno='03' )); 把exits换成IN 123456SELECT DISTINCT snoFROM Student where sno IN ( SELECT sno FROM Course WHERE sno NOT IN ( SELECT sno FROM Grade WHERE cno='03' )); 看以下的句子： 12345SELECT sname FROM Student WHERE exists( SELECT dno FROM Department WHERE sno NOT IN ( SELECT sno FROM Grade WHERE cno='03' )); 仔细看就会发现其实上面的句子其实就是： 1234SELECT DISTINCT snameFROM Student where sno NOT IN ( SELECT sno FROM Grade WHERE cno='03'); 只是中间添加了一些毫无逻辑的语句，但是对结果没有任何影响。","categories":[{"name":"-数据库","slug":"数据库","permalink":"http://lwenxu.coding.me/categories/数据库/"}],"tags":[]},{"title":"Mac配置PHP7环境","slug":"PHP/Mac配置PHP7环境","date":"2017-05-07T13:40:24.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/05/07/PHP/Mac配置PHP7环境/","link":"","permalink":"http://lwenxu.coding.me/2017/05/07/PHP/Mac配置PHP7环境/","excerpt":"","text":"在Mac下面本来就安装有Apache2和PHP5.5.3这里为了配置更新的环境就稍微折腾了一下，主要配置的就是MySQL和PHP，Apache就使用自带的就行。 配置MySQL：MySQL在MySQL的官网上直接下载dmg包之后安转就行了。这里Mac版本的MySQL下载地址是 https://dev.mysql.com/downloads/file/?id=461365 下载之后在安装完成以后注意他会提示有一个默认的密码，一定要给记下来，一会改密码用的上。再安装完成了，打开偏好设置，最下面有一个MySQL的控制面板，在里面开启MySQL然后在终端中修改MySQL的密码 1234ln -s /usr/local/mysql/bin/mysql /usr/local/binmysql -uroot -p #输入刚才提示的密码，登录以后开始修改密码set password for root@localhost=password('password');exit 配置PHP7环境添加PHP7的源 123456brew tap homebrew/dupes brew tap homebrew/versions brew tap homebrew/homebrew-php brew install php70 brew unlink php55brew link php70 --with-httpd24 需要等待比较久的时间，因为是直接去官方下载。 配置Apache直接vim Apache的配置文件，记得使用sudo，否则没权限写入。当然不用sudo也可以，在修改完成以后执行 :w !sudo tee %然后就可以使用管理员权限写入了。然后打开Apache的配置文件主要得目的就是修改DocumentRoot和PHP模块文件 1sudo vim /etc/apache2/httpd.conf 找到DocumentRoot改成你想要的目录，但是这个目录必须要有权限，一般给个777绝对ok并且找到下面的地方，把PHP5的模块改成下面的内容： 12#Enable PHP 7 module LoadModule php7_module /usr/local/opt/php70/libexec/apache2/libphp7.so","categories":[{"name":"-Mac","slug":"Mac","permalink":"http://lwenxu.coding.me/categories/Mac/"}],"tags":[]},{"title":"关于PHP的回调函数","slug":"PHP/关于PHP的回调函数","date":"2017-05-07T11:49:31.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/05/07/PHP/关于PHP的回调函数/","link":"","permalink":"http://lwenxu.coding.me/2017/05/07/PHP/关于PHP的回调函数/","excerpt":"","text":"普通函数的定义及调用与js相似,这个定义方式无需返回值,哪怕是有返回值在声明的时候也无需添加 再后来的PHP版本中是添加了一向很有用的功能就是可在函数定义之前进行调用 123456789101112echo add(1,2);echo &quot;&lt;/br&gt;&quot;;function add($a,$b)&#123; return $a+$b;&#125;function sub($a,$b)&#123; return $a-$b;&#125;echo add(23,12);echo &quot;&lt;/br&gt;&quot;;echo sub(23,22);echo &quot;&lt;/br&gt;&quot;; 下面是一个非常有用的功能就是变量函数,顾名思义就是将函数作为一个变量。 其优点在于用同一个变量可以调用不同的函数,非常类似于函数的多态调用。 123456$var=&quot;add&quot;;echo $var(4,2);echo &quot;&lt;/br&gt;&quot;;$var=&quot;sub&quot;;echo $var(4,2);echo &quot;&lt;/br&gt;&quot;; 回调函数就是在给一个函数传入一个简单的参数无法解决问题的时候给他传入一个过程,从而达到目的 在函数调用时给他传入一个函数作为参数就是函数回调。 123$arr=array(2,3,5,4,1,6,7,9,8);var_dump($arr);echo &quot;&lt;/br&gt;&quot;; 12345678910111213141516//这里是自定义回调函数,返回-1是指将两个元素交换,0和1是不发生改变。function myrule($a,$b)&#123; if ($a&gt;$b)&#123; return 1; &#125; elseif ($a&lt;$b)&#123; return -1; &#125; else&#123; return 0; &#125;&#125;//usort就是系统函数,但是他的第二个参数是回调函数,这个函数参数就是排序规则usort($arr,&quot;myrule&quot;);var_dump($arr);echo &quot;&lt;/br&gt;&quot;; 自己写回调函数,使用变量函数以及回调完成一个简单的过滤条件,如果需多个条件同时满足给一个&amp;&amp;关系即可。 其中使用的变量函数可以使用系统中的一个叫做call_user_func_array()的函数进行调用,他有两个参数分别是回调函数名称,以及参数数组 call_user_func_array(“demo”,array(1,3));其优点在于array中的参数的数量可以比原函数的少,既有默认缺省参数的时候。 12345678910111213141516171819202122232425262728293031323334//rule1除去数组中是三的倍数的数function rule1($a)&#123; if ($a%3==0)&#123; return true; &#125;else&#123; return false; &#125;&#125;//rule2是除去数组中的回文数（从左边读与从右边读是一样的）function rule2($a)&#123; if ($a==strrev($a))&#123; return true; &#125;else&#123; return false; &#125;&#125;function demo($n,$var)&#123; for ($i=0;$i&lt;$n;$i++)&#123; if (call_user_func_array($var,array(23))) //if ($var($i)) &#123; continue; &#125;else&#123; echo $i.&quot;&lt;br&gt;&quot;; &#125; &#125;&#125;$var=&quot;rule1&quot;;demo(100,$var);echo &quot;&lt;/br&gt;&quot;;echo &quot;&lt;hr&gt;&quot;;$var=&quot;rule2&quot;;demo(200,$var);echo &quot;&lt;/br&gt;&quot;; 注意在调用对象里面的方法时我们需要传入一个匿名对象,后面指定函数名 而在调用类中的静态方法时只需指定类名即可。 以上两种情况都不能完全使用变量函数只能用系统的回调call_user_func_array(),只是变量函数来传参而不调用 12345678class A&#123; function one()&#123; &#125; static function two()&#123; &#125;&#125;demo(200,array(new A,&quot;one&quot;));demo(200,array(&quot;A&quot;,&quot;two&quot;));","categories":[{"name":"-PHP","slug":"PHP","permalink":"http://lwenxu.coding.me/categories/PHP/"}],"tags":[]},{"title":"VirtualEnv","slug":"Python/pip 的阿里源","date":"2017-05-06T15:18:33.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/05/06/Python/pip 的阿里源/","link":"","permalink":"http://lwenxu.coding.me/2017/05/06/Python/pip 的阿里源/","excerpt":"","text":"修改配置文件1）检查pip.conf文件是否存在 123&gt;&gt; cd ~&gt;&gt; mkdir .pip&gt;&gt; ls ~/.pip 2）直接编辑pip.conf 1sudo vi ~/.pip/pip.conf 修改成如下的格式 1234[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host = mirrors.aliyun.com 临时作用的方式1pip3 install 包名 -i https://mirrors.aliyun.com/pypi/simple/","categories":[{"name":"-Mac","slug":"Mac","permalink":"http://lwenxu.coding.me/categories/Mac/"}],"tags":[]},{"title":"Mac安装包版本的Python","slug":"Python/Mac安装包版本的Python","date":"2017-05-06T15:18:33.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/05/06/Python/Mac安装包版本的Python/","link":"","permalink":"http://lwenxu.coding.me/2017/05/06/Python/Mac安装包版本的Python/","excerpt":"","text":"安装配置Python版本管理器pyenv brew install pyenv 查看已经安装了哪些版本的Python pyenv versions其中版本号前面有*号的就是当前生效的版本,查看当前生效的版本也可以用pyenv version 安装指定版本的Python pyenv install 3.7-dev 安装完成后必须rehashpyenv rehash 切换和使用指定的版本Python版本有3种方法 系统全局用系统默认的Python比较好，不建议直接对其操作pyenv global system用local进行指定版本切换，一般开发环境使用。pyenv local 2.7.10对当前用户的临时设定Python版本，退出后失效pyenv shell 3.7-dev取消某版本切换pyenv local 3.5.0 –unset优先级关系：shell——local——global 另外最重要的一点，当执行了pyenv shell/local/global 命令后，一定要执行 source ~/.zshrc ，不然切换版本就不会生效。 最后执行 123456➜ ~ pyenv versions system* 3.7-dev➜ ~➜ ~ python -VPython 3.7-dev","categories":[{"name":"-Mac","slug":"Mac","permalink":"http://lwenxu.coding.me/categories/Mac/"}],"tags":[]},{"title":"两个 python 的虚拟管理工具","slug":"Python/virtualenv配置","date":"2017-05-06T15:18:33.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/05/06/Python/virtualenv配置/","link":"","permalink":"http://lwenxu.coding.me/2017/05/06/Python/virtualenv配置/","excerpt":"","text":"两个 python 的虚拟管理工具 virtualenv安装 virtualenv1sudo apt-get install python-virtualenv 创建 env1virtualenv ENV 启动 env12cd ENVsource ./bin/activate 退出虚拟环境1deactivate virtualenv 的加强版 virtualenvwrapper优点： 将所有虚拟环境整合在一个目录下 管理（新增，删除，复制）虚拟环境 切换虚拟环境 安装：1sudo easy_install virtualenvwrapper 此时还不能使用virtualenvwrapper，默认virtualenvwrapper安装在/usr/local/bin下面，实际上你需要运行virtualenvwrapper.sh文件才行，先别急，打开这个文件看看,里面有安装步骤，我们照着操作把环境设置好。 创建目录用来存放虚拟环境1mkdir $HOME/.virtualenvs 配置脚本文件在 bashrc 文件中进行如下操作 1234 export WORKON_HOME=$HOME/.virtualenvs source /usr/local/bin/virtualenvwrapper.sh source ~/.bashrc​` 此时virtualenvwrapper就可以使用了。 基本操作 列出基本环境 1workon/lsvirtualenv 新建虚拟环境 1mkvirtualenv [虚拟环境名称] 启动/切换虚拟环 1workon [虚拟环境名称] 删除虚拟环境 1rmvirtualenv [虚拟环境名称] 离开虚拟环境 1deactivate ```","categories":[{"name":"-Mac","slug":"Mac","permalink":"http://lwenxu.coding.me/categories/Mac/"}],"tags":[]},{"title":"打造酷炫终端","slug":"Mac/打造酷炫终端","date":"2017-05-06T14:24:56.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/05/06/Mac/打造酷炫终端/","link":"","permalink":"http://lwenxu.coding.me/2017/05/06/Mac/打造酷炫终端/","excerpt":"1.安装iTerm2iTerm2官方下载地址 http://www.iterm2.com/downloads.html 2.安装Oh My Bash1.使用brew安装zsh：1brew install zsh","text":"1.安装iTerm2iTerm2官方下载地址 http://www.iterm2.com/downloads.html 2.安装Oh My Bash1.使用brew安装zsh：1brew install zsh 2.通过echo $SHELL命令可以查看我们当前正在使用的shell； Mac系统中默认的shell为bash shell/bin/bash 3.如果当前的shell不是zsh，我们可以通过chsh -s /bin/zsh命令可以将shell切换为shell之zsh，终端重启之后即可生效。4.将shell切换为zsh之后，我们就可以安装Oh My ZSH了官方推荐的安装方法为： 1sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" 3.配置agnoster主题1.Oh My Zsh提供的所有主题在线预览：https://github.com/robbyrussell/oh-my-zsh/wiki/Themes 安装成功之后，我们可以通过vi ~/.zshrc，设置ZSH_THEME=”agnoster”对主题进行修改。 注意，agnoster主题能否设置成功，还依赖于以下东西： 2.Solarized Dark配色方案下载完成之后解压，在iTerm2的Preferences——Profiles——colors——Load Presets——Solarized Dark即可设置终端配色 3.特殊字体安装将字体克隆到本地，并使用install.sh安装 12git clone https://github.com/powerline/fontsinstall.sh 安装完成以后，在iTerm2的Preferences——Profiles——Text中同时将Regular Font和Non—ASCII Font设置为Meslo LG M DZ Regular for Powerline即可","categories":[{"name":"-Mac","slug":"Mac","permalink":"http://lwenxu.coding.me/categories/Mac/"}],"tags":[]},{"title":"DSDT GUIDE","slug":"Mac/dsdt guide","date":"2017-05-05T05:09:40.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/05/05/Mac/dsdt guide/","link":"","permalink":"http://lwenxu.coding.me/2017/05/05/Mac/dsdt guide/","excerpt":"Overview In order to make many OS X features work well on a laptop, you will always need a properly patched DSDT (and SSDTs). The purpose of this guide is to provide a foundation for proper patching of your OEM DSDT/SSDTs. Advanced users may wish to implement hotpatching via Clover. See guide here: http://www.tonymacx86.com/threads/guide-using-clover-to-hotpatch-acpi.200137/ Although you may be tempted to use a DSDT from another computer, it will almost always end in failure. You simply cannot be certain it is valid to use ACPI files from another computer. Even minor differences in hardware configuration (BIOS version, amount of memory installed, BIOS options selected, and other hardware differences such as which WiFi card is installed) can make for differences that cause instability and weird bugs if you use foreign ACPI files. Differences such as BIOS version, amount of memory installed, BIOS options selected, and other hardware differences such as which WiFi card is installed, can make various OperationRegion addresses different, which makes a patched DSDT for one system incompatible with another. It is also not uncommon for the same laptop model to be produced in different runs with different motherboards, and potentially incompatible ACPI files.","text":"Overview In order to make many OS X features work well on a laptop, you will always need a properly patched DSDT (and SSDTs). The purpose of this guide is to provide a foundation for proper patching of your OEM DSDT/SSDTs. Advanced users may wish to implement hotpatching via Clover. See guide here: http://www.tonymacx86.com/threads/guide-using-clover-to-hotpatch-acpi.200137/ Although you may be tempted to use a DSDT from another computer, it will almost always end in failure. You simply cannot be certain it is valid to use ACPI files from another computer. Even minor differences in hardware configuration (BIOS version, amount of memory installed, BIOS options selected, and other hardware differences such as which WiFi card is installed) can make for differences that cause instability and weird bugs if you use foreign ACPI files. Differences such as BIOS version, amount of memory installed, BIOS options selected, and other hardware differences such as which WiFi card is installed, can make various OperationRegion addresses different, which makes a patched DSDT for one system incompatible with another. It is also not uncommon for the same laptop model to be produced in different runs with different motherboards, and potentially incompatible ACPI files. The process of patching involves several steps: extracting native files disassembling the native files analyzing and filtering the native files patching saving (compiling) and installing Extracting native ACPI files All BIOS implementations provide ACPI files to the OS. So, on any OS, you can extract them for patching later. Extraction can therefore be done on Linux, OS X, Windows, or even in the Clover bootloader. Native files extracted are generally identical, although because of the software used to extract, they may be named differently. This guide will focus on three methods of extraction: Using patchmatic in OS X, using F4 with Clover, or using Linux. Extracting with ‘patchmatic’: If you’ve already installed OS X, provided you’re not currently booting with any patched ACPI files, you can extract your native DSDT/SSDT with patchmatic. Download the patchmatic binary here: https://github.com/RehabMan/OS-X-MaciASL-patchmatic (be sure to read the README as the download location is linked from it). For ease of use in Terminal, you should copy the binary (inside the ZIP) to /usr/bin. After installing patchmatic, you can invoke it in Terminal, as such: Code (Text): cd ~/Desktopmkdir extractcd extractpatchmatic -extract The patchmatic binary will extract all loaded ACPI files and place them in the current directory. If you’re using any options in the bootloader that affect the injected DSDT/SSDT, you will not get native ACPI files, so be sure you’re not using those options. For example, if you’re using (Chameleon) DropSSDT=Yes, or (Clover) DropOem=true, the native SSDTs are being dropped before OS X can load them, so you’ll be missing them in the patchmatic output. Same goes for any Clover DSDT “Fixes” – those fixes are patching the native DSDT, and to do your own DSDT patching, you don’t want that. Options such as GeneratePStates/GenerateCStates=Yes, or with Clover /ACPI/SSDT/Generate/CStates /ACPI/SSDT/Generate/PStates will inject extra SSDTs which can cause complications with disassembly. It is for all those reasons, it is often easier to extract via Linux or using Clover F4. Note: Using ‘patchmatic -extract’ to confirm you’re patching DSDT/SSDTs as you expect is a useful diagnostic tool. Extracting with Clover F4 (recommended): Extracting with Clover F4 is recommended, due to ease of extraction, and due to ease of comparison between ACPI/origin and ACPI/patched (for troubleshooting). At the main Clover bootloader screen, you can press F4 and Clover will dump the native ACPI files to EFI/Clover/ACPI/origin. You can then access them after you boot OS X to disassemble them and patch. Note that some BIOS implementations reverse the function of Fn+F4 with F4, so when in doubt, press both Fn+F4 and F4. There is no feedback during or after the dump, just a slight delay as the files are written. The delay is more noticeable if they are being written to USB, as would be the case when booting from a Clover USB. Sometimes, Clover F4 will write duplicate SSDTs. These duplicates will cause problems during disassembly. If you run into issues (duplicate definitions) during disassembly, you will need to analyse all SSDTs to eliminate the files which are duplicate. It is easy to see which are duplicates by looking at the file sizes. Files with equal size are likely duplicates. You can see file sizes in bytes of all SSDTs in Terminal:Code (Text): ls -l SSDT*.aml Extracting with Linux: In Linux, the native ACPI files are available directly from the file system. You can find them at /sys/firmware/acpi/tables and /sys/firmware/acpi/tables/dynamic. It is possible to copy the entire set with a single command in Terminal. It is not necessary to install Linux. Simply run it from USB: http://www.ubuntu.com/download/desktop/create-a-usb-stick-on-windows. In Linux Terminal:Code (Text): substitute DEST with the mountpoint of a FAT32 formatted USB sticksudo cp -R /sys/firmware/acpi/tables DEST You should copy the files to a FAT32 formatted USB. Using FAT32 avoids permissions issues as FAT32 has no file permissions. The value of DEST for an auto-mounted USB will depend on the version of Linux you’re using and how you booted it. You can see the mount-point by typing ‘mount’ in Terminal, or hover your mouse over the volume name in the Linux file explorer. Preparing tools for disassembly To properly disassemble your extracted files, you need the iasl compiler, which is run from Terminal. You will need a recent build of iasl to disassemble them properly. There is an appropriate version available here: https://bitbucket.org/RehabMan/acpica/downloads/. It is a good idea to copy the iasl binary to your path (eg. /usr/bin), so it is easily accessed from Terminal. For example, if you downloaded it to ~/Downloads/iasl.zip, you can extract and copy it in Terminal:Code (Text): cd ~/Downloadsunzip iasl.zipsudo cp iasl /usr/bin Building the latest iasl from github You can also build the latest version of my iasl from my github. Assuming you have Xcode installed:Code (Text): mkdir ~/Projects &amp;&amp; cd ~/Projectsgit clone https://github.com/RehabMan/Intel-iasl.git iasl.gitcd iasl.git The latest version always tends to have experimental and not well tested code. For example, the new code Intel added to disassemble If/Else blocks as Switch/Case is full of bugs (I have not had time to report them to Intel). I recommend using the version prior to that change:Code (Text): git checkout b9c6c2b Note: The b9c6c2b version is the one currently available from bitbucket. Then build it:Code (Text): make At that point, you can install it with:Code (Text): sudo make install And assuming you have MaciASL.app installed to /Applications, you can use the new version (that you just built and installed to /usr/bin) in MaciASL as well:Code (Text): sudo cp /usr/bin/iasl /Applications/MaciASL.app/Contents/MacOS/iasl61 The newer version of iasl will eventually be available at the bitbucket link, but for those who want to be on the “bleeding edge”… Disassembling ACPI files Although the extracted native files can be opened directly in MaciASL, it is not recommended. Opening an AML file directly in MaciASL will cause MaciASL to disassemble the file (with iasl) standalone, and if the AML has complex references to other AMLs, it will not disassemble it correctly. You’ll be left with many hard to fix errors. As a result, it is better to disassemble all files as a group using iasl in Terminal. To prepare, place all DSDT and SSDT files in a single directory (DO NOT copy ACPI files that don’t begin with DSDT or SSDT), and change the names such that they have an .aml extension. Then disassemble in OS X Terminal:Code (Text): cd “to directory where you placed all SSDT/DSDT”iasl -da -dl DSDT.aml SSDT*.aml Note: Do NOT attempt to disassemble other ACPI files with the -da option. It will not work. Note: Also read the section below regarding refs.txt. Using refs.txt takes little effort, but can eliminate many common errors. From this point onward, you will work exclusively with the resulting *.dsl files using MaciASL. Of course, to use them you must save as “ACPI Machine Language Binary” with an extension .aml and place them where they will be loaded by the bootloader. But keep your patched .dsl files in case you need to apply more patches in the future. Let me state it quite simply (because this comes up a lot): If you are opening an AML file directly in MaciASL and clicking Compile, you are doing it WRONG. Let that soak into the gray matter between your ears for a minute. Note: The new tools with ACPI 6.1 are much more robust when dealing with AML files that have been compiled with the new version of iasl. ACPI 6.1 adds a feature to the compiler where opcodes for External references are added to the AML binary. ACPI interpreters ignore this data, but the data is useful to the disassembler (also only ACPI 6.1 version of iasl) to create a better disassembly from a standalone AML. As a result, you might find that AML files that have been recompiled with the latest tools may open directly more reliably. Of course, existing OEM ACPI DSDT and SSDTs are not using the new tools at this point, so you still must disassemble initially with all DSDT/SSDT with option -da, as described in this guide. Note regarding Snow Leopard ACPI implementation: Unfortunately, the 10.6.8 ACPI is old enough that it chokes on AMLs with the external opcode. If you are planning to use your ACPI files with Snow Leopard use the undocumented “-oe” switch to iasl when you compile your AML files. This option is not set when you compile (Save As) from MaciASL, so you will need to compile your files in Terminal. The “-oe” option disables generation of the external opcode in the output AML files. Disassembly with refs.txt Sometimes there are additional unresolved externals (symbols not defined in any file). The iasl disassembler will attempt to guess the number of arguments, but often it guesses poorly. You can correct it, by providing the External declarations in a text file. Some common unresolved symbols are SGPO, ECRD, ECWT, and MMTB. The following refs.txt content has some common (and not so common) missing symbols (as reported by users in this thread) that the disassembler tends to be confused by. First create refs.txt in the directory where your DSDT/SSDT files are:Code (Text): External(MDBG, MethodObj, 1)External(_GPE.MMTB, MethodObj, 0)External(_SB.PCI0.LPCB.H_EC.ECWT, MethodObj, 2)External(_SB.PCI0.LPCB.H_EC.ECRD, MethodObj, 1)External(_SB.PCI0.LPCB.H_EC.ECMD, MethodObj, 1)External(_SB.PCI0.PEG0.PEGP.SGPO, MethodObj, 2)External(_SB.PCI0.GFX0.DD02._BCM, MethodObj, 1)External(_SB.PCI0.SAT0.SDSM, MethodObj, 4)External(_GPE.VHOV, MethodObj, 3)External(_SB.PCI0.XHC.RHUB.TPLD, MethodObj, 2) Note: A handy way to create refs.txt is to use pbpaste in Terminal. Copy the text above to the clipboard (I’m assuming you know how to do that), then:Code (Text): pbpaste&gt;refs.txt That will create refs.txt in your current working directory. Then use it during disassembly:Code (Text): iasl -da -dl -fe refs.txt DSDT.aml SSDT*.aml Older versions of the iasl disassembler will place these External declarations before all the other External declarations. This, also, is a poor choice. Most of the time, you’ll need to move them so they follow the other External declarations instead of preceding them. It will be obvious as you’ll get errors from the External declarations that follow those inserted from refs.txt. In the current iasl supporting ACPI 6.1, this bug has been fixed. Filtering ACPI files For older computers (Sandy Bridge and prior), the SSDTs related to CPU can cause problems. If this is the case (you already had to use the alternate DropTables, or DropOem=true, or DropSSDT=Yes), then you should not include such SSDTs in ACPI/patched. I like to include all SSDTs, in their original order, patched appropriately, unless they are known to cause a problem. Keep in mind that an SSDT that doesn’t need any patches, does not need to be recompiled. You can simply use the original AML file unmodified. Note: The ‘x’ SSDTs from a Clover dump and likewise the SSDTs in the dynamic subdirectory from a Linux dump are loaded dynamically and are never included in ACPI/patched (they are SSDTs loaded on-demand with ACPI Load from SystemMemory). After you successfully disassemble your files, look at each one in an attempt to determine the SSDT’s purpose. If it is CPU related and is known to cause a problem, set it aside, and don’t include it in your final set for injection via the bootloader. For the most part, SSDTs with objects declared in Scope _PR.CPUx are likely CPU related. Here are some typical SSDTs you’ll find: CPU related: already discussed above. Include unless known to cause a problem. SATA: Can be excluded or included… your choice. PTID: Usually this file is useless for OS X and contains many errors. In rare cases, it may provide clues for how to read fan speed, temperature, or other system status. IAOE: If this SSDT is present, it is usually accessed from DSDT in _PTS and _WAK. Sleep may not work properly without it. GFX0: Usually the SSDT with ‘Device GFX0’ will be for integrated graphics. This is the SSDT you patch for backlight control. With older laptops, GFX0 is usually defined in DSDT. With newer Haswell laptops, it is usually defined in SSDT (although it can also be in DSDT). PEGP: PEGP usually corresponds to the discrete card in a switched dual-GPU configuration. There can be more than one, and usually you will need to include all of them as a group in order to accomplish any meaningful patching. These SSDTs should be patched if you wish to disable the discrete card when running OS X. It is a good idea to keep notes on what the purpose of each SSDT is and which ones you plan to “drop”, which ones you plan to keep unmodified, and those that you plan to patch. Fixing Errors Even by disassembling all at once (iasl with -da option), the native files can still have errors. The disassembled files have errors due to changes in iasl over time, imperfections in iasl itself, and differences in the compilation environment between our laptops and the OEM. A common cause of errors (my theory), for example, is that some of the methods referenced are actually inside Windows (MMTB and MDBG for example). There is also clearly cases where bugs are in the code or code was written uninitentionally (sometimes hard to tell the difference). So.. after determining which files you need, you must patch them so they compile without errors. There are many common patches for such errors in my laptop patch repository for MaciASL. MaciASL: https://github.com/RehabMan/OS-X-MaciASL-patchmaticLaptop Patches: https://github.com/RehabMan/Laptop-DSDT-Patch Note: I do not test my patches with DSDT Editor. It has too many bugs and a very old version of iasl. Please do not ask me about it. Be certain to always read the README, in order to download from the correct location and in order to setup MaciASL correctly. The patches for syntax/error problems begin with “[syn]” in the name. Common examples for older DSDTs are “Fix _PLD Buffer/Package Error”, “Fix TNOT Error”, and “Fix FPED Parse Error”. In order to determine which patch you need, you can look at the error message coming from the iasl compiler and the code at the line the error was detected. You can also attempt to apply a patch just to see if it makes changes as shown in the Preview window in MaciASL. If you’re not familiar with each type of error, it can take some experimentation and trial/error. For some errors, you can simply remove the line of code causing the error. But, it depends on whether the line is necessary for proper operation of the code or not. For example, errors caused by ‘External’ declarations can generally be removed to fix the error. If you wish, you can create automated patches of your own to remove these lines. It helps to have some experience with the ACPI spec and some programming experience. Your goal is to get each .dsl file to compile without errors (warnings/remarks/optimizations are ok). Once you have files that compile without errors, you can move on to patching them to fix issues you may have with your OS X installation. Common Patches Generally, a DSDT patch should only be applied after finding a need for that specific fix. But there are several patches that are commonly needed and that have only a small chance of causing a problem. They are in my laptop repo and are listed here:“Fix _WAK Arg0 v2”“HPET Fix”“SMBUS Fix”“IRQ Fix”“RTC Fix”“OS Check Fix”“Fix Mutex with non-zero SyncLevel”“Fix PNOT/PPNT” (use only if you’re dropping CPU related SSDTs)“Add IMEI” (do not use if your DSDT or SSDTs already have IMEI/HECI/MEI device) Note: The OS Check Fix patch you use has nothing to do with the version of Windows the laptop came with, nor with the version of Windows you’re currently using. Note: Do not use the “Fix PNOT/PPNT” patch if you’re including all OEM SSDTs. It is intended only for the case you omit the OEM CPU related SSDTs. The USB patches can be used to fix “instant wake” where the laptop will not sleep without waking up seconds after sleep begins. Apply the patch appropriate for your hardware:“6-series USB”“7-series/8-series USB” The USB3 Mutliplex patch can assist in using AppleUSBXHCI.kext instead of GenericUSBXCHI.kext. It is based on information published by Mieze. Most DSDTs will need modifications to use it. The ProBook, for example, uses a modified version of this patch. And the Lenovo u310/u410 can use it as-is:“7-series USB3 Multiplex” If you’re using GenericUSBXHCI.kext on Yosemite, make sure you’re using one built for Yosemite. Also, to avoid instant wake you may need kernel flag -gux_defer_usb2. An alternate solution for “instant wake” using AppleUSBXHCI.kext is to use “USB _PRW 0x6D (instant wake)”. You should examine your DSDT to determine what the relevant _PRW methods return to be certain the patch is appropriate for your DSDT. Also provided in the repo is “USB _PRW 0x0D (instant wake)” (0x0D and 0x6D are both common values for XHC/EHC/HDEF return from _PRW). If you have a Haswell CPU/8-series chipset, and AppleLPC.kext is not loading, you should use this patch to inject a compatible ID that will allow it to load:“Haswell LPC” If you have a Skylake CPU/100-series chipset, and AppleLPC.kext is not loading, you should use this patch to inject a compatible ID that will allow it to load:“Skylake LPC” Note regarding renames: Renames must be “balanced.” It is common to rename objects to better match what OS X expects (example “Rename GFX0 to IGPU” for proper IGPU power management). In such cases, all DSDT/SSDTs with references to that name must also be renamed. Note regarding duplicate identifiers: You must be sure that your patched files do not contain duplicate identifiers. A common case would be adding a _DSM method to a given path in one SSDT, where the OEM has defined a _DSM at the same path in another SSDT. To avoid this problem, you can use the “Remove _DSM methods” patch as one of the first patches you do to all DSDT/SSDTs. Also, “Rename _DSM methods to XDSM” is an alternative (sometimes “Remove _DSM methods” exposes a bug in MaciASL). Problem specific patching Battery status: http://www.tonymacx86.com/yosemite-...de-how-patch-dsdt-working-battery-status.html Backlight control: http://www.tonymacx86.com/yosemite-...ching-dsdt-ssdt-laptop-backlight-control.html Disabling nVidia/Radeon discrete graphics: http://www.tonymacx86.com/yosemite-...bling-discrete-graphics-dual-gpu-laptops.html When following a guide for a specific laptop, it may instruct you to apply a patch that is provided in the post itself. You will recognize it as the syntax used will look similar to other patches you’ve seen in the repository (eg. ‘into_all method label FOO code_regex xxyy removeall_matched;’). These patches are intended to be pasted directly into the patch window in MaciASL so they can be applied. If you’re interested in writing your own patches, read the documentation on MaciASL patch grammar: http://sourceforge.net/p/maciasl/wiki/Patching Syntax Grammar/ Note: In many cases, DSDT patches are used in conjunction with additional kexts, patched kexts, or Clover config.plist patches that patch the system kexts as they are loaded. Patches for using patched AppleHDA With patched AppleHDA, there are two patches that are needed in conjunction with the kext:“Audio Layout 12” (change the layout-id from 12 to the one used by your DSDT)“IRQ Fix” Note that you must have an AppleHDA that matches your codec, and must determine which layout-id was chosen. The layout-id is an arbitrary choice by the creator of the patched AppleHDA. To determine the layout-id used by a particular patched AppleHDA: First you need to know your codec id in decimal (eg. 0x10ec0269 = 283902569). Then look in the Info.plist for AppleHDAHardwareConfigDriver.kext (at AppleHDA.kext/Contents/PlugIns/AppleHDAHardwareConfigDriver.kext/Contents/Info.plist), find your codec id under HDAConfigDefault (there may be many entries in a sloppy patched AppleHDA or only one). The LayoutID that matches your codec id is the layout id you need. It is possible that a patched AppleHDA contains more than one layout-id for a given codec. In that case, choose the one you want to use. Saving files for loading by the bootloader In order to use your patched DSDT/SSDTs, you must save them where the bootloader can load them. Each bootloader location is unique and has different requirements for naming. Files must be saved in “ACPI Machine Language Binary” (MaciASL-&gt;Save As). Saving a text file (dsl) with an AML extension will likely cause panic or very strange behavior in OS X. Clover: Files should be placed on the Clover bootloader partition (usually the EFI partition), in EFI/Clover/ACPI/patched. DSDT.aml, if present, will automatically replace the OEM DSDT. For versions of Clover prior to v3062, SSDTs must be named SSDT-x or SSDT-xx, where ‘x’ is a digit (up to SSDT-19). Clover allows gaps in the numbering (eg. SSDT-1.aml, SSDT-5.aml, SSDT-6.aml is allowed). Clover version v3062+ will load all *.aml files present in ACPI/patched, with no restrictions on the name. Keep in mind that SSDT loading order is important. The original order of the SSDTs must be maintained in the patched set. Note regarding Clover v3062+: A change in the way SSDTs are loaded from ACPI/patched makes the order non-deterministic. You should specify the order explicitly with config.plist/ACPI/SortedOrder. The SortedOrder option is implemented in Clover v3088+. The config.plist files linked from my Clover guide have a good default for SortedOrder: http://www.tonymacx86.com/yosemite-...de-booting-os-x-installer-laptops-clover.html Chameleon(or Chimera): Files should be placed in /Extra on the system volume (or wherever your bootloader /Extra configuration is located). DSDT.aml, if present, will automatically replace the OEM DSDT. Chameleon requires there are no gaps in the names of SSDTs. It will load SSDT.aml, SSDT-1.aml, SSDT-2.aml, SSDT-3.aml, and so-on from /Extra until it does not find the file in the sequence. So, if you have SSDT.aml, SSDT-1.aml, SSDT-4.aml, SSDT-5.aml, only SSDT.aml and SSDT-1.aml will be loaded. SSDT-4.aml and SSDT-5.aml will be ignored. Finally, keep in mind you cannot provide patched SSDTs without dropping the OEM SSDTs that they replace. The easiest way is to use DropSSDT=Yes (Chameleon) or ACPI/SSDT/DropOem=true (Clover) to drop all the SSDTs, then provide the patched (and unpatched) files for loading by the bootloader. Floating regions In ACPI, an OperationRegion can define a MMIO region, SystemMemory region, EmbeddedControl region, etc. These regions usually have fixed addresses dependent only on the machine configuration, BIOS version, or BIOS options. Sometimes, these regions can change randomly or unexpectedly. This is referred to as “floating regions”. Since by patching DSDT and/or SSDTs, we are providing a snapshot of these addresses at a given point in time, they may not match up should the BIOS decide to place such regions at a different address. If this is the case, you may notice that certain features are intermittently working, or other stability issues that appear to be random. As a result, it is a good idea to use Clover and its FixRegions feature. You can find the details in the Clover Wiki. All of the config.plist files in the Clover laptop guide use this feature. Note: Only floating regions in DSDT can be fixed by FixRegions. Floating regions in SSDTs are problematic and there is no good solution other than to not provide patched SSDTs for SSDTs subject to randomly floating regions. Working around floating regions in patched SSDTs is beyond the scope of this guide. Resources MaciASL (RehabMan fork): https://github.com/RehabMan/OS-X-MaciASL-patchmaticpatchmatic: https://github.com/RehabMan/OS-X-MaciASL-patchmaticiasl (RehabMan fork): https://bitbucket.org/RehabMan/acpica/downloadsACPI spec: http://acpi.info/spec.htm RehabMan github: https://github.com/RehabMan?tab=repositories Clover laptop guide: http://www.tonymacx86.com/yosemite-...oting-os-x-installer-laptops-clover-uefi.htmlClover config.plist files for laptops: https://github.com/RehabMan/OS-X-Clover-Laptop-Config Clover thread: http://www.insanelymac.com/forum/topic/284656-clover-general-discussion/Clover changes: http://www.insanelymac.com/forum/topic/304530-clover-change-explanations/ Providing Feedback Do not treat this thread as your private troubleshooting thread. If you have a specific problem with your specific laptop, open a separate thread. If you see something here that is in error, or wish to make a contribution, please reply to this thread. Problem Reporting Please read above “Providing Feedback”. It is best to open a separate thread. In that separate thread, describe you problem clearly. And provide relevant data… Download patchmatic: https://bitbucket.org/RehabMan/os-x-maciasl-patchmatic/downloads/RehabMan-patchmatic-2015-0107.zipExtract the ‘patchmatic’ binary from the ZIP. Copy it to /usr/bin, such that you have the binary at /usr/bin/patchmatic. In terminal,Code (Text): if [ -d ~/Downloads/RehabMan ]; then rm -R ~/Downloads/RehabMan; fimkdir ~/Downloads/RehabMancd ~/Downloads/RehabManpatchmatic -extract Note: It is easier if you use copy/paste instead of typing the commands manually. Attach contents of Downloads/RehabMan directory as ZIP. Attach ioreg as ZIP: http://www.tonymacx86.com/audio/58368-guide-how-make-copy-ioreg.html. Please, use the IORegistryExplorer v2.1 attached to the post! DO NOT reply with an ioreg from any other version of IORegistryExplorer.app. Provide output (in Terminal):Code (Text): kextstat|grep -y acpiplatkextstat|grep -y appleintelcpukextstat|grep -y applelpckextstat|grep -y applehda Attach EFI/Clover folder as ZIP (press F4 at main Clover screen before collecting). Please eliminate ‘themes’ directory. Provide only EFI/Clover, not the entire EFI folder. Attach output of (in Terminal):Code (Text): sudo touch /System/Library/Extensions &amp;&amp; sudo kextcache -u / Compress all files as ZIP. Do not use external links. Attach all files using site attachments only. If you cannot boot, attach photo of panic/hang and the EFI/Clover that causes it (as ZIP, without themes).","categories":[{"name":"-MacOS","slug":"MacOS","permalink":"http://lwenxu.coding.me/categories/MacOS/"}],"tags":[{"name":"-MacOS","slug":"MacOS","permalink":"http://lwenxu.coding.me/tags/MacOS/"}]},{"title":"Idea使用技巧","slug":"Tools/Idea使用技巧","date":"2017-05-05T05:09:40.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2017/05/05/Tools/Idea使用技巧/","link":"","permalink":"http://lwenxu.coding.me/2017/05/05/Tools/Idea使用技巧/","excerpt":"【编辑】souf:System.out.printf(“”); sout:System.out.println();","text":"【编辑】souf:System.out.printf(“”); sout:System.out.println(); soutm:System.out.println(“demo.main”); soutp:System.out.println(“args = [“ + args + “]”); soutv:System.out.println(“true = “ + true); Shift+Click，可以关闭文件 Ctrl+[ / ]，可以跑到大括号的开头与结尾 Ctrl+N，可以快速打开类 Ctrl+Shift+N，可以快速打开文件 Ctrl+Q，可以看到当前方法的声明 Ctrl+Shift+Insert，可以选择剪贴板内容并插入 Alt+Insert，可以生成构造器/Getter/Setter等 Ctrl+Enter，导入包，自动修正 Ctrl+Alt+L，格式化代码 Ctrl+Alt+I，将选中的代码进行自动缩进编排，这个功能在编辑 JSP 文件时也可以工作 Ctrl+R，替换文本 Ctrl+F，查找文本 Ctrl+Shift+Space，自动补全代码 Shift+F6，重构 – 重命名 Ctrl+X，删除行 Ctrl+D，复制行 Ctrl+/或Ctrl+Shift+/，注释（//或者） Ctrl+J，自动代码（例如：serr） Ctrl+Alt+J，用动态模板环绕 Ctrl+H，显示类结构图（类的继承层次） Ctrl+Alt+left/right，返回至上次浏览的位置 Alt+Up/Down，在方法间快速移动定位 F2 或 Shift+F2，高亮错误或警告快速定位 Alt+F3，逐个往下查找相同文本，并高亮显示 Ctrl+O，重写方法 Ctrl+Shift+J，整合两行 Alt+F8，计算变量值 Shift+Esc，不仅可以把焦点移到编辑器上，而且还可以隐藏当前（或最后活动的）工具窗口 Ctrl+Y，删除当前行 Ctrl+Shift+F，全局查找 Ctrl+U，转到父类 Ctrl+G，定位行 Ctrl+Backspace，按单词删除 Ctrl+”+/-”，当前方法展开、折叠 Ctrl+Shift+”+/-”，全部展开、折叠 【调试部分、编译】Ctrl+F2，停止Alt+Shift+F9，选择 DebugAlt+Shift+F10，选择 RunCtrl+Shift+F9，编译Ctrl+Shift+F10，运行Ctrl+Shift+F8，查看断点F8，步过F7，步入Shift+F7，智能步入Shift+F8，步出Alt+Shift+F8，强制步过Alt+Shift+F7，强制步入Alt+F9，运行至光标处Ctrl+Alt+F9，强制运行至光标处F9，恢复程序Alt+F10，定位到断点Ctrl+F8，切换行断点Ctrl+F9，生成项目Alt+1，项目Alt+2，收藏Alt+6，TODOAlt+7，结构Ctrl+Shift+C，复制路径Ctrl+Alt+Shift+C，复制引用，必须选择类名Ctrl+Alt+Y，同步Ctrl+~，快速切换方案（界面外观、代码风格、快捷键映射等菜单）Shift+F12，还原默认布局Ctrl+Shift+F12，隐藏/恢复所有窗口Ctrl+F4，关闭Ctrl+Shift+F4，关闭活动选项卡Ctrl+Tab，转到下一个拆分器Ctrl+Shift+Tab，转到上一个拆分器 ##【重构】Ctrl+Alt+Shift+T，弹出重构菜单Shift+F6，重命名F6，移动F5，复制Alt+Delete，安全删除Ctrl+Alt+N，内联ctrl+shift+alt+j 列操作 ##【查找】Ctrl+F，查找Ctrl+R，替换F3，查找下一个Shift+F3，查找上一个Ctrl+Shift+F，在路径中查找Ctrl+Shift+R，在路径中替换Ctrl+Shift+S，搜索结构Ctrl+Shift+M，替换结构Alt+F7，查找用法Ctrl+Alt+F7，显示用法Ctrl+F7，在文件中查找用法Ctrl+Shift+F7，在文件中高亮显示用法 1. 跳转1.上次编辑的位置 2.上次查看的位置 3.书签跳转使用Ctrl+F11可以输入一个带有数字字母标记的书签，比如我们使用的标签名是1则我们使用Ctrl+1/N可以跳转到对应的位置。 另外我们可以在Favorite中找到对应的书签 4.收藏类或者方法把光标移动到类里面或者上面，使用add to favorite 添加到对应的收藏夹，如果放到方法里面则是添加方法。 5.使用macsIdea插件进行跳转在keymap中配置AceJumpWords的快捷键为alt+j 按下alt+j 然后输入我们需要跳转的字母则会生成字母对应位置的一个快捷键，我们就可以跳转过去。 6.vim分屏:sp / :vsp ctrl+w -&gt; h/l 左右 ctrl+w -&gt; j/k上下 ctrl+w -&gt; c 关闭 ctrl+w &gt;-&gt;+/-/= 尺寸 2.列操作 3.posfix 1. for100.fori 生成100 的for循环 2. sout“hello”.sout 3.fieldname.field 直接创建字段并且在构造方法中赋值 4.returnname.return 5.nn不空 name.nn 4.自动修复alt+enter 这个是一个多功能的快捷键，根据不同场景有不同效果。 自动创建函数，当函数没有创建的时候 代码优化 string的format和builder 接口的实现，subclass 单词拼写 导包 5.重构1. shift+f6当前的方法名或者变量名都会被选中，然后我们只需要修改一个地方就可以完成整个的修改 2.ctrl+f6在函数名字上使用这个快捷键就可以进行函数签名的重构。 3.抽取变量 6. 调试1. ctrl+f8 添加断点2.shift+f9 调试程序3.f8 单步运行4.resume 调到下个断点没有断点结束程序5.ctrl+shift+f8 按两次哦 ，查看所有断点6.mute breakpoints 禁止所有断点7.ctrl+shift+f8条件断点8.alt+f8表达式求值9.alt+f9 运行到执行行10.f2修改值所有的导包，以及优化 ctrl+shift+o 查看所有的实现 Ctrl+H","categories":[{"name":"-开发工具","slug":"开发工具","permalink":"http://lwenxu.coding.me/categories/开发工具/"}],"tags":[]},{"title":"Atom使用技巧","slug":"Tools/Atom使用技巧","date":"2017-05-05T04:32:34.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2017/05/05/Tools/Atom使用技巧/","link":"","permalink":"http://lwenxu.coding.me/2017/05/05/Tools/Atom使用技巧/","excerpt":"","text":"打开项目1ctrl + o 模糊查找文件12ctrl + t / ctrl + pctrl + b 仅仅查找已经打开的文件 命令模式1ctrl + shift +p 另存为1ctrl + shift + s gmerge-conflicts1在使用 Git 进行合并和 rebase 的时候可以用 alt-m d 来激活这个插件，它会列出所有冲突的文件，将每一处冲突高亮，同时有按钮和快捷键供你快速选用某个版本，在你解决所有冲突后会提示你进行 Commit. 有了这个插件再也不同担心出冲突的时候看瞎眼了。","categories":[{"name":"-Atom","slug":"Atom","permalink":"http://lwenxu.coding.me/categories/Atom/"}],"tags":[]},{"title":"Linux常用技巧","slug":"Linux/Linux常用技巧","date":"2017-05-04T13:08:52.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/05/04/Linux/Linux常用技巧/","link":"","permalink":"http://lwenxu.coding.me/2017/05/04/Linux/Linux常用技巧/","excerpt":"","text":"使用ls显示一个文件的绝路径：1ls file |sed \"s:^:`pwd`/:\" 创建一个程序的启动器：使用Desktop Entery的格式，首先需要进入相应目录建立文件，在文件中写入程序相关信息： 12cd /usr/share/applications/sudo vim application.desktop 开始写入文件信息,格式如下： 1234567[Desktop Entery]Version=1.0Name=AppNameExec=/application/pathIcon=/application/icon.pngTerminal=falseType=Application vim中选定内容：命令模式下使用vi命令变为可视之后即可选中，使用d就可以删除 快速处理某个被包含的内容：以下命令可以对标点内的内容进行操作。 ci’、ci”、ci(、ci[、ci{、ci&lt; - 分别更改这些配对标点符号中的文本内容di’、di”、di(或dib、di[、di{或diB、di&lt; - 分别删除这些配对标点符号中的文本内容yi’、yi”、yi(、yi[、yi{、yi&lt; - 分别复制这些配对标点符号中的文本内容vi’、vi”、vi(、vi[、vi{、vi&lt; - 分别选中这些配对标点符号中的文本内容 另外如果把上面的i改成a可以连配对标点一起操作。举个例子：比如要操作的文本如下：111”222”333将光标移到”222”的任何一个字符处输入命令 di” ,文本会变成： 111””333若输入命令 da” ,文本会变成： 111333","categories":[{"name":"-Linux","slug":"Linux","permalink":"http://lwenxu.coding.me/categories/Linux/"}],"tags":[]},{"title":"Linux下安装shadowsocks","slug":"Linux/Linux下安装shadowsocks","date":"2017-05-04T12:04:20.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/05/04/Linux/Linux下安装shadowsocks/","link":"","permalink":"http://lwenxu.coding.me/2017/05/04/Linux/Linux下安装shadowsocks/","excerpt":"Fedora/Red Hat Enterprise Linux使用dnf安装: 123sudo dnf copr enable librehat/shadowsockssudo dnf updatesudo dnf install shadowsocks-qt5 如果你要使用copr repo可能还需要安装下面这个插件：","text":"Fedora/Red Hat Enterprise Linux使用dnf安装: 123sudo dnf copr enable librehat/shadowsockssudo dnf updatesudo dnf install shadowsocks-qt5 如果你要使用copr repo可能还需要安装下面这个插件： 1sudo dnf install dnf-plugins-core 当然你的Linux版本不是特别高的话可能用的不是dnf，这时候用yum就行： 12sudo yum updatesudo yum install shadowsocks-qt5 Ubuntu PPA is for Ubuntu &gt;= 14.04. 123sudo add-apt-repository ppa:hzwhuang/ss-qt5sudo apt-get updatesudo apt-get install shadowsocks-qt5 Debian首先需要安装一系列的ss-qt5的依赖： 1sudo apt-get install qt5-qmake qtbase5-dev libqrencode-dev libqtshadowsocks-dev libappindicator-dev libzbar-dev libbotan1.10-dev 然后执行下面的命令，就能得到一个Deb包 1dpkg-buildpackage -uc -us -b 之后直接使用dpkg安装即可： 1sudo dpkg -i shadowsocks-qt5-&lt;VER_ARCH_ETC&gt;.deb.","categories":[{"name":"-Linux","slug":"Linux","permalink":"http://lwenxu.coding.me/categories/Linux/"}],"tags":[]},{"title":"Linux下安装Node.js","slug":"Linux/Linux下安装Node-js","date":"2017-05-04T09:51:37.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/05/04/Linux/Linux下安装Node-js/","link":"","permalink":"http://lwenxu.coding.me/2017/05/04/Linux/Linux下安装Node-js/","excerpt":"手动二进制包的安装方法一般来说我们在Node的官网上是找不到Linux的Deb包，或者是Rpm包的，他针对Windows和mac都有二进制的安装包，但是Linux只有一个tar.xz这个包下载下来虽然也是一个二进制的包，类似于Windows中的绿色软件，也非常好配置，仅仅使用 1tar -xvf package.tar.xz 即可完成解压，然后使用软连接，把node与npm文件链接到/usr/local/bin下面","text":"手动二进制包的安装方法一般来说我们在Node的官网上是找不到Linux的Deb包，或者是Rpm包的，他针对Windows和mac都有二进制的安装包，但是Linux只有一个tar.xz这个包下载下来虽然也是一个二进制的包，类似于Windows中的绿色软件，也非常好配置，仅仅使用 1tar -xvf package.tar.xz 即可完成解压，然后使用软连接，把node与npm文件链接到/usr/local/bin下面 12ln -s /opt/nodejs/bin/node /usr/local/bin/nodeln -s /opt/nodejs/bin/npm /usr/local/bin/npm 这样以来然后可以看看node的版本，从而来判断node是否安装上了，并且看看版本是不是我们需要的版本。 1node -v 假如出现了类似与以下的信息就说明安装完成 v6.10.3 使用nvm管理node版本安装nvm复制以下代码，放到一个shell脚本中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795#!/usr/bin/env bash&#123; # this ensures the entire script is downloaded #nvm_has() &#123; type \"$1\" &gt; /dev/null 2&gt;&amp;1&#125;nvm_install_dir() &#123; printf %s \"$&#123;NVM_DIR:-\"$HOME/.nvm\"&#125;\"&#125;nvm_latest_version() &#123; echo \"v0.33.2\"&#125;nvm_profile_is_bash_or_zsh() &#123; local TEST_PROFILE TEST_PROFILE=\"$&#123;1-&#125;\" case \"$&#123;TEST_PROFILE-&#125;\" in *\"/.bashrc\" | *\"/.bash_profile\" | *\"/.zshrc\") return ;; *) return 1 ;; esac&#125;## Outputs the location to NVM depending on:# * The availability of $NVM_SOURCE# * The method used (\"script\" or \"git\" in the script, defaults to \"git\")# NVM_SOURCE always takes precedence unless the method is \"script-nvm-exec\"#nvm_source() &#123; local NVM_METHOD NVM_METHOD=\"$1\" local NVM_SOURCE_URL NVM_SOURCE_URL=\"$NVM_SOURCE\" if [ \"_$NVM_METHOD\" = \"_script-nvm-exec\" ]; then NVM_SOURCE_URL=\"https://raw.githubusercontent.com/creationix/nvm/$(nvm_latest_version)/nvm-exec\" elif [ -z \"$NVM_SOURCE_URL\" ]; then if [ \"_$NVM_METHOD\" = \"_script\" ]; then NVM_SOURCE_URL=\"https://raw.githubusercontent.com/creationix/nvm/$(nvm_latest_version)/nvm.sh\" elif [ \"_$NVM_METHOD\" = \"_git\" ] || [ -z \"$NVM_METHOD\" ]; then NVM_SOURCE_URL=\"https://github.com/creationix/nvm.git\" else echo &gt;&amp;2 \"Unexpected value \\\"$NVM_METHOD\\\" for \\$NVM_METHOD\" return 1 fi fi echo \"$NVM_SOURCE_URL\"&#125;## Node.js version to install#nvm_node_version() &#123; echo \"$NODE_VERSION\"&#125;nvm_download() &#123; if nvm_has \"curl\"; then curl --compressed -q \"$@\" elif nvm_has \"wget\"; then # Emulate curl with wget ARGS=$(echo \"$*\" | command sed -e 's/--progress-bar /--progress=bar /' \\ -e 's/-L //' \\ -e 's/--compressed //' \\ -e 's/-I /--server-response /' \\ -e 's/-s /-q /' \\ -e 's/-o /-O /' \\ -e 's/-C - /-c /') # shellcheck disable=SC2086 eval wget $ARGS fi&#125;install_nvm_from_git() &#123; local INSTALL_DIR INSTALL_DIR=\"$(nvm_install_dir)\" if [ -d \"$INSTALL_DIR/.git\" ]; then echo \"=&gt; nvm is already installed in $INSTALL_DIR, trying to update using git\" command printf \"\\r=&gt; \" command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" fetch 2&gt; /dev/null || &#123; echo &gt;&amp;2 \"Failed to update nvm, run 'git fetch' in $INSTALL_DIR yourself.\" exit 1 &#125; else # Cloning to $INSTALL_DIR echo \"=&gt; Downloading nvm from git to '$INSTALL_DIR'\" command printf \"\\r=&gt; \" mkdir -p \"$&#123;INSTALL_DIR&#125;\" if [ \"$(ls -A \"$&#123;INSTALL_DIR&#125;\")\" ]; then command git init \"$&#123;INSTALL_DIR&#125;\" || &#123; echo &gt;&amp;2 'Failed to initialize nvm repo. Please report this!' exit 2 &#125; command git --git-dir=\"$&#123;INSTALL_DIR&#125;/.git\" remote add origin \"$(nvm_source)\" 2&gt; /dev/null \\ || command git --git-dir=\"$&#123;INSTALL_DIR&#125;/.git\" remote set-url origin \"$(nvm_source)\" || &#123; echo &gt;&amp;2 'Failed to add remote \"origin\" (or set the URL). Please report this!' exit 2 &#125; command git --git-dir=\"$&#123;INSTALL_DIR&#125;/.git\" fetch origin --tags || &#123; echo &gt;&amp;2 'Failed to fetch origin with tags. Please report this!' exit 2 &#125; else command git clone \"$(nvm_source)\" \"$&#123;INSTALL_DIR&#125;\" || &#123; echo &gt;&amp;2 'Failed to clone nvm repo. Please report this!' exit 2 &#125; fi fi command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" checkout -f --quiet \"$(nvm_latest_version)\" if [ ! -z \"$(command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" show-ref refs/heads/master)\" ]; then if command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" branch --quiet 2&gt;/dev/null; then command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" branch --quiet -D master &gt;/dev/null 2&gt;&amp;1 else echo &gt;&amp;2 \"Your version of git is out of date. Please update it!\" command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" branch -D master &gt;/dev/null 2&gt;&amp;1 fi fi echo \"=&gt; Compressing and cleaning up git repository\" if ! command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" gc --aggressive --prune=now ; then echo &gt;&amp;2 \"Your version of git is out of date. Please update it!\" fi return&#125;## Automatically install Node.js#nvm_install_node() &#123; local NODE_VERSION NODE_VERSION=\"$(nvm_node_version)\" if [ -z \"$NODE_VERSION\" ]; then return 0 fi echo \"=&gt; Installing Node.js version $NODE_VERSION\" nvm install \"$NODE_VERSION\" local CURRENT_NVM_NODE CURRENT_NVM_NODE=\"$(nvm_version current)\" if [ \"$(nvm_version \"$NODE_VERSION\")\" == \"$CURRENT_NVM_NODE\" ]; then echo \"=&gt; Node.js version $NODE_VERSION has been successfully installed\" else echo &gt;&amp;2 \"Failed to install Node.js $NODE_VERSION\" fi&#125;install_nvm_as_script() &#123; local INSTALL_DIR INSTALL_DIR=\"$(nvm_install_dir)\" local NVM_SOURCE_LOCAL NVM_SOURCE_LOCAL=$(nvm_source script) local NVM_EXEC_SOURCE NVM_EXEC_SOURCE=$(nvm_source script-nvm-exec) # Downloading to $INSTALL_DIR mkdir -p \"$INSTALL_DIR\" if [ -f \"$INSTALL_DIR/nvm.sh\" ]; then echo \"=&gt; nvm is already installed in $INSTALL_DIR, trying to update the script\" else echo \"=&gt; Downloading nvm as script to '$INSTALL_DIR'\" fi nvm_download -s \"$NVM_SOURCE_LOCAL\" -o \"$INSTALL_DIR/nvm.sh\" || &#123; echo &gt;&amp;2 \"Failed to download '$NVM_SOURCE_LOCAL'\" return 1 &#125; &amp; nvm_download -s \"$NVM_EXEC_SOURCE\" -o \"$INSTALL_DIR/nvm-exec\" || &#123; echo &gt;&amp;2 \"Failed to download '$NVM_EXEC_SOURCE'\" return 2 &#125; &amp; for job in $(jobs -p | sort) do wait \"$job\" || return $? done chmod a+x \"$INSTALL_DIR/nvm-exec\" || &#123; echo &gt;&amp;2 \"Failed to mark '$INSTALL_DIR/nvm-exec' as executable\" return 3 &#125;&#125;nvm_try_profile() &#123; if [ -z \"$&#123;1-&#125;\" ] || [ ! -f \"$&#123;1&#125;\" ]; then return 1 fi echo \"$&#123;1&#125;\"&#125;## Detect profile file if not specified as environment variable# (eg: PROFILE=~/.myprofile)# The echo'ed path is guaranteed to be an existing file# Otherwise, an empty string is returned#nvm_detect_profile() &#123; if [ -n \"$&#123;PROFILE&#125;\" ] &amp;&amp; [ -f \"$&#123;PROFILE&#125;\" ]; then echo \"$&#123;PROFILE&#125;\" return fi local DETECTED_PROFILE DETECTED_PROFILE='' local SHELLTYPE SHELLTYPE=\"$(basename \"/$SHELL\")\" if [ \"$SHELLTYPE\" = \"bash\" ]; then if [ -f \"$HOME/.bashrc\" ]; then DETECTED_PROFILE=\"$HOME/.bashrc\" elif [ -f \"$HOME/.bash_profile\" ]; then DETECTED_PROFILE=\"$HOME/.bash_profile\" fi elif [ \"$SHELLTYPE\" = \"zsh\" ]; then DETECTED_PROFILE=\"$HOME/.zshrc\" fi if [ -z \"$DETECTED_PROFILE\" ]; then for EACH_PROFILE in \".profile\" \".bashrc\" \".bash_profile\" \".zshrc\" do if DETECTED_PROFILE=\"$(nvm_try_profile \"$&#123;HOME&#125;/$&#123;EACH_PROFILE&#125;\")\"; then break fi done fi if [ ! -z \"$DETECTED_PROFILE\" ]; then echo \"$DETECTED_PROFILE\" fi&#125;## Check whether the user has any globally-installed npm modules in their system# Node, and warn them if so.#nvm_check_global_modules() &#123; command -v npm &gt;/dev/null 2&gt;&amp;1 || return 0 local NPM_VERSION NPM_VERSION=\"$(npm --version)\" NPM_VERSION=\"$&#123;NPM_VERSION:--1&#125;\" [ \"$&#123;NPM_VERSION%%[!-0-9]*&#125;\" -gt 0 ] || return 0 local NPM_GLOBAL_MODULES NPM_GLOBAL_MODULES=\"$( npm list -g --depth=0 | command sed -e '/ npm@/d' -e '/ (empty)$/d' )\" local MODULE_COUNT MODULE_COUNT=\"$( command printf %s\\\\n \"$NPM_GLOBAL_MODULES\" | command sed -ne '1!p' | # Remove the first line wc -l | tr -d ' ' # Count entries )\" if [ \"$&#123;MODULE_COUNT&#125;\" != '0' ]; then # shellcheck disable=SC2016 echo '=&gt; You currently have modules installed globally with `npm`. These will no' # shellcheck disable=SC2016 echo '=&gt; longer be linked to the active version of Node when you install a new node' # shellcheck disable=SC2016 echo '=&gt; with `nvm`; and they may (depending on how you construct your `$PATH`)' # shellcheck disable=SC2016 echo '=&gt; override the binaries of modules installed with `nvm`:' echo command printf %s\\\\n \"$NPM_GLOBAL_MODULES\" echo '=&gt; If you wish to uninstall them at a later point (or re-install them under your' # shellcheck disable=SC2016 echo '=&gt; `nvm` Nodes), you can remove them from the system Node as follows:' echo echo ' $ nvm use system' echo ' $ npm uninstall -g a_module' echo fi&#125;nvm_do_install() &#123; if [ -z \"$&#123;METHOD&#125;\" ]; then # Autodetect install method if nvm_has git; then install_nvm_from_git elif nvm_has nvm_download; then install_nvm_as_script else echo &gt;&amp;2 'You need git, curl, or wget to install nvm' exit 1 fi elif [ \"$&#123;METHOD&#125;\" = 'git' ]; then if ! nvm_has git; then echo &gt;&amp;2 \"You need git to install nvm\" exit 1 fi install_nvm_from_git elif [ \"$&#123;METHOD&#125;\" = 'script' ]; then if ! nvm_has nvm_download; then echo &gt;&amp;2 \"You need curl or wget to install nvm\" exit 1 fi install_nvm_as_script fi echo local NVM_PROFILE NVM_PROFILE=\"$(nvm_detect_profile)\" local PROFILE_INSTALL_DIR PROFILE_INSTALL_DIR=\"$(nvm_install_dir| sed \"s:^$HOME:\\$HOME:\")\" SOURCE_STR=\"\\nexport NVM_DIR=\\\"$&#123;PROFILE_INSTALL_DIR&#125;\\\"\\n[ -s \\\"\\$NVM_DIR/nvm.sh\\\" ] &amp;&amp; \\\\. \\\"\\$NVM_DIR/nvm.sh\\\" # This loads nvm\\n\" COMPLETION_STR=\"[ -s \\\"\\$NVM_DIR/bash_completion\\\" ] &amp;&amp; \\\\. \\\"\\$NVM_DIR/bash_completion\\\" # This loads nvm bash_completion\\n\" BASH_OR_ZSH=false if [ -z \"$&#123;NVM_PROFILE-&#125;\" ] ; then echo \"=&gt; Profile not found. Tried $&#123;NVM_PROFILE&#125; (as defined in \\$PROFILE), ~/.bashrc, ~/.bash_profile, ~/.zshrc, and ~/.profile.\" echo \"=&gt; Create one of them and run this script again\" echo \"=&gt; Create it (touch $&#123;NVM_PROFILE&#125;) and run this script again\" echo \" OR\" echo \"=&gt; Append the following lines to the correct file yourself:\" command printf \"$&#123;SOURCE_STR&#125;\" else if nvm_profile_is_bash_or_zsh \"$&#123;NVM_PROFILE-&#125;\"; then BASH_OR_ZSH=true fi if ! command grep -qc '/nvm.sh' \"$NVM_PROFILE\"; then echo \"=&gt; Appending nvm source string to $NVM_PROFILE\" command printf \"$&#123;SOURCE_STR&#125;\" &gt;&gt; \"$NVM_PROFILE\" else echo \"=&gt; nvm source string already in $&#123;NVM_PROFILE&#125;\" fi # shellcheck disable=SC2016 if $&#123;BASH_OR_ZSH&#125; &amp;&amp; ! command grep -qc '$NVM_DIR/bash_completion' \"$NVM_PROFILE\"; then echo \"=&gt; Appending bash_completion source string to $NVM_PROFILE\" command printf \"$COMPLETION_STR\" &gt;&gt; \"$NVM_PROFILE\" else echo \"=&gt; bash_completion source string already in $&#123;NVM_PROFILE&#125;\" fi fi if $&#123;BASH_OR_ZSH&#125; &amp;&amp; [ -z \"$&#123;NVM_PROFILE-&#125;\" ] ; then echo \"=&gt; Please also append the following lines to the if you are using bash/zsh shell:\" command printf \"$&#123;COMPLETION_STR&#125;\" fi # Source nvm # shellcheck source=/dev/null \\. \"$(nvm_install_dir)/nvm.sh\" nvm_check_global_modules nvm_install_node nvm_reset echo \"=&gt; Close and reopen your terminal to start using nvm or run the following to use it now:\" command printf \"$&#123;SOURCE_STR&#125;\" if $&#123;BASH_OR_ZSH&#125; ; theLinux下安装Node-js.md Previewtitle date tags categoriesLinux下安装Node.jsFri May 05 2017 01:51:37 GMT+0800 (CST)null-Linux手动二进制包的安装方法一般来说我们在Node的官网上是找不到Linux的Deb包，或者是Rpm包的，他针对Windows和mac都有二进制的安装包，但是Linux只有一个tar.xz这个包下载下来虽然也是一个二进制的包，类似于Windows中的绿色软件，也非常好配置，仅仅使用￼tar -xvf package.tar.xz即可完成解压，然后使用软连接，把node与npm文件链接到/usr/local/bin下面￼ln -s /opt/nodejs/bin/node /usr/local/bin/nodeln -s /opt/nodejs/bin/npm /usr/local/bin/npm这样以来然后可以看看node的版本，从而来判断node是否安装上了，并且看看版本是不是我们需要的版本。￼node -v假如出现了类似与以下的信息就说明安装完成v6.10.3使用nvm管理node版本安装nvm复制以下代码，放到一个shell脚本中。￼#!/usr/bin/env bash&#123; # this ensures the entire script is downloaded #nvm_has() &#123; type \"$1\" &gt; /dev/null 2&gt;&amp;1&#125;nvm_install_dir() &#123; printf %s \"$&#123;NVM_DIR:-\"$HOME/.nvm\"&#125;\"&#125;nvm_latest_version() &#123; echo \"v0.33.2\"&#125;nvm_profile_is_bash_or_zsh() &#123; local TEST_PROFILE TEST_PROFILE=\"$&#123;1-&#125;\" case \"$&#123;TEST_PROFILE-&#125;\" in *\"/.bashrc\" | *\"/.bash_profile\" | *\"/.zshrc\") return ;; *) return 1 ;; esac&#125;## Outputs the location to NVM depending on:# * The availability of $NVM_SOURCE# * The method used (\"script\" or \"git\" in the script, defaults to \"git\")# NVM_SOURCE always takes precedence unless the method is \"script-nvm-exec\"#nvm_source() &#123; local NVM_METHOD NVM_METHOD=\"$1\" local NVM_SOURCE_URL NVM_SOURCE_URL=\"$NVM_SOURCE\" if [ \"_$NVM_METHOD\" = \"_script-nvm-exec\" ]; then NVM_SOURCE_URL=\"https://raw.githubusercontent.com/creationix/nvm/$(nvm_latest_version)/nvm-exec\" elif [ -z \"$NVM_SOURCE_URL\" ]; then if [ \"_$NVM_METHOD\" = \"_script\" ]; then NVM_SOURCE_URL=\"https://raw.githubusercontent.com/creationix/nvm/$(nvm_latest_version)/nvm.sh\" elif [ \"_$NVM_METHOD\" = \"_git\" ] || [ -z \"$NVM_METHOD\" ]; then NVM_SOURCE_URL=\"https://github.com/creationix/nvm.git\" else echo &gt;&amp;2 \"Unexpected value \\\"$NVM_METHOD\\\" for \\$NVM_METHOD\" return 1 fi fi echo \"$NVM_SOURCE_URL\"&#125;## Node.js version to install#nvm_node_version() &#123; echo \"$NODE_VERSION\"&#125;nvm_download() &#123; if nvm_has \"curl\"; then curl --compressed -q \"$@\" elif nvm_has \"wget\"; then # Emulate curl with wget ARGS=$(echo \"$*\" | command sed -e 's/--progress-bar /--progress=bar /' \\ -e 's/-L //' \\ -e 's/--compressed //' \\ -e 's/-I /--server-response /' \\ -e 's/-s /-q /' \\ -e 's/-o /-O /' \\ -e 's/-C - /-c /') # shellcheck disable=SC2086 eval wget $ARGS fi&#125;install_nvm_from_git() &#123; local INSTALL_DIR INSTALL_DIR=\"$(nvm_install_dir)\" if [ -d \"$INSTALL_DIR/.git\" ]; then echo \"=&gt; nvm is already installed in $INSTALL_DIR, trying to update using git\" command printf \"\\r=&gt; \" command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" fetch 2&gt; /dev/null || &#123; echo &gt;&amp;2 \"Failed to update nvm, run 'git fetch' in $INSTALL_DIR yourself.\" exit 1 &#125; else # Cloning to $INSTALL_DIR echo \"=&gt; Downloading nvm from git to '$INSTALL_DIR'\" command printf \"\\r=&gt; \" mkdir -p \"$&#123;INSTALL_DIR&#125;\" if [ \"$(ls -A \"$&#123;INSTALL_DIR&#125;\")\" ]; then command git init \"$&#123;INSTALL_DIR&#125;\" || &#123; echo &gt;&amp;2 'Failed to initialize nvm repo. Please report this!' exit 2 &#125; command git --git-dir=\"$&#123;INSTALL_DIR&#125;/.git\" remote add origin \"$(nvm_source)\" 2&gt; /dev/null \\ || command git --git-dir=\"$&#123;INSTALL_DIR&#125;/.git\" remote set-url origin \"$(nvm_source)\" || &#123; echo &gt;&amp;2 'Failed to add remote \"origin\" (or set the URL). Please report this!' exit 2 &#125; command git --git-dir=\"$&#123;INSTALL_DIR&#125;/.git\" fetch origin --tags || &#123; echo &gt;&amp;2 'Failed to fetch origin with tags. Please report this!' exit 2 &#125; else command git clone \"$(nvm_source)\" \"$&#123;INSTALL_DIR&#125;\" || &#123; echo &gt;&amp;2 'Failed to clone nvm repo. Please report this!' exit 2 &#125; fi fi command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" checkout -f --quiet \"$(nvm_latest_version)\" if [ ! -z \"$(command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" show-ref refs/heads/master)\" ]; then if command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" branch --quiet 2&gt;/dev/null; then command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" branch --quiet -D master &gt;/dev/null 2&gt;&amp;1 else echo &gt;&amp;2 \"Your version of git is out of date. Please update it!\" command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" branch -D master &gt;/dev/null 2&gt;&amp;1 fi fi echo \"=&gt; Compressing and cleaning up git repository\" if ! command git --git-dir=\"$INSTALL_DIR\"/.git --work-tree=\"$INSTALL_DIR\" gc --aggressive --prune=now ; then echo &gt;&amp;2 \"Your version of git is out of date. Please update it!\" fi return&#125;## Automatically install Node.js#nvm_install_node() &#123; local NODE_VERSION NODE_VERSION=\"$(nvm_node_version)\" if [ -z \"$NODE_VERSION\" ]; then return 0 fi echo \"=&gt; Installing Node.js version $NODE_VERSION\" nvm install \"$NODE_VERSION\" local CURRENT_NVM_NODE CURRENT_NVM_NODE=\"$(nvm_version current)\" if [ \"$(nvm_version \"$NODE_VERSION\")\" == \"$CURRENT_NVM_NODE\" ]; then echo \"=&gt; Node.js version $NODE_VERSION has been successfully installed\" else echo &gt;&amp;2 \"Failed to install Node.js $NODE_VERSION\" fi&#125;install_nvm_as_script() &#123; local INSTALL_DIR INSTALL_DIR=\"$(nvm_install_dir)\" local NVM_SOURCE_LOCAL NVM_SOURCE_LOCAL=$(nvm_source script) local NVM_EXEC_SOURCE NVM_EXEC_SOURCE=$(nvm_source script-nvm-exec) # Downloading to $INSTALL_DIR mkdir -p \"$INSTALL_DIR\" if [ -f \"$INSTALL_DIR/nvm.sh\" ]; then echo \"=&gt; nvm is already installed in $INSTALL_DIR, trying to update the script\" else echo \"=&gt; Downloading nvm as script to '$INSTALL_DIR'\" fi nvm_download -s \"$NVM_SOURCE_LOCAL\" -o \"$INSTALL_DIR/nvm.sh\" || &#123; echo &gt;&amp;2 \"Failed to download '$NVM_SOURCE_LOCAL'\" return 1 &#125; &amp; nvm_download -s \"$NVM_EXEC_SOURCE\" -o \"$INSTALL_DIR/nvm-exec\" || &#123; echo &gt;&amp;2 \"Failed to download '$NVM_EXEC_SOURCE'\" return 2 &#125; &amp; for job in $(jobs -p | sort) do wait \"$job\" || return $? done chmod a+x \"$INSTALL_DIR/nvm-exec\" || &#123; echo &gt;&amp;2 \"Failed to mark '$INSTALL_DIR/nvm-exec' as executable\" return 3 &#125;&#125;nvm_try_profile() &#123; if [ -z \"$&#123;1-&#125;\" ] || [ ! -f \"$&#123;1&#125;\" ]; then return 1 fi echo \"$&#123;1&#125;\"&#125;## Detect profile file if not specified as environment variable# (eg: PROFILE=~/.myprofile)# The echo'ed path is guaranteed to be an existing file# Otherwise, an empty string is returned#nvm_detect_profile() &#123; if [ -n \"$&#123;PROFILE&#125;\" ] &amp;&amp; [ -f \"$&#123;PROFILE&#125;\" ]; then echo \"$&#123;PROFILE&#125;\" return fi local DETECTED_PROFILE DETECTED_PROFILE='' local SHELLTYPE SHELLTYPE=\"$(basename \"/$SHELL\")\" if [ \"$SHELLTYPE\" = \"bash\" ]; then if [ -f \"$HOME/.bashrc\" ]; then DETECTED_PROFILE=\"$HOME/.bashrc\" elif [ -f \"$HOME/.bash_profile\" ]; then DETECTED_PROFILE=\"$HOME/.bash_profile\" fi elif [ \"$SHELLTYPE\" = \"zsh\" ]; then DETECTED_PROFILE=\"$HOME/.zshrc\" fi if [ -z \"$DETECTED_PROFILE\" ]; then for EACH_PROFILE in \".profile\" \".bashrc\" \".bash_profile\" \".zshrc\" do if DETECTED_PROFILE=\"$(nvm_try_profile \"$&#123;HOME&#125;/$&#123;EACH_PROFILE&#125;\")\"; then break fi done fi if [ ! -z \"$DETECTED_PROFILE\" ]; then echo \"$DETECTED_PROFILE\" fi&#125;## Check whether the user has any globally-installed npm modules in their system# Node, and warn them if so.#nvm_check_global_modules() &#123; command -v npm &gt;/dev/null 2&gt;&amp;1 || return 0 local NPM_VERSION NPM_VERSION=\"$(npm --version)\" NPM_VERSION=\"$&#123;NPM_VERSION:--1&#125;\" [ \"$&#123;NPM_VERSION%%[!-0-9]*&#125;\" -gt 0 ] || return 0 local NPM_GLOBAL_MODULES NPM_GLOBAL_MODULES=\"$( npm list -g --depth=0 | command sed -e '/ npm@/d' -e '/ (empty)$/d' )\" local MODULE_COUNT MODULE_COUNT=\"$( command printf %s\\\\n \"$NPM_GLOBAL_MODULES\" | command sed -ne '1!p' | # Remove the first line wc -l | tr -d ' ' # Count entries )\" if [ \"$&#123;MODULE_COUNT&#125;\" != '0' ]; then # shellcheck disable=SC2016 echo '=&gt; You currently have modules installed globally with `npm`. These will no' # shellcheck disable=SC2016 echo '=&gt; longer be linked to the active version of Node when you install a new node' # shellcheck disable=SC2016 echo '=&gt; with `nvm`; and they may (depending on how you construct your `$PATH`)' # shellcheck disable=SC2016 echo '=&gt; override the binaries of modules installed with `nvm`:' echo command printf %s\\\\n \"$NPM_GLOBAL_MODULES\" echo '=&gt; If you wish to uninstall them at a later point (or re-install them under your' # shellcheck disable=SC2016 echo '=&gt; `nvm` Nodes), you can remove them from the system Node as follows:' echo echo ' $ nvm use system' echo ' $ npm uninstall -g a_module' echo fi&#125;nvm_do_install() &#123; if [ -z \"$&#123;METHOD&#125;\" ]; then # Autodetect install method if nvm_has git; then install_nvm_from_git elif nvm_has nvm_download; then install_nvm_as_script else echo &gt;&amp;2 'You need git, curl, or wget to install nvm' exit 1 fi elif [ \"$&#123;METHOD&#125;\" = 'git' ]; then if ! nvm_has git; then echo &gt;&amp;2 \"You need git to install nvm\" exit 1 fi install_nvm_from_git elif [ \"$&#123;METHOD&#125;\" = 'script' ]; then if ! nvm_has nvm_download; then echo &gt;&amp;2 \"You need curl or wget to install nvm\" exit 1 fi install_nvm_as_script fi echo local NVM_PROFILE NVM_PROFILE=\"$(nvm_detect_profile)\" local PROFILE_INSTALL_DIR PROFILE_INSTALL_DIR=\"$(nvm_install_dir| sed \"s:^$HOME:\\$HOME:\")\" SOURCE_STR=\"\\nexport NVM_DIR=\\\"$&#123;PROFILE_INSTALL_DIR&#125;\\\"\\n[ -s \\\"\\$NVM_DIR/nvm.sh\\\" ] &amp;&amp; \\\\. \\\"\\$NVM_DIR/nvm.sh\\\" # This loads nvm\\n\" COMPLETION_STR=\"[ -s \\\"\\$NVM_DIR/bash_completion\\\" ] &amp;&amp; \\\\. \\\"\\$NVM_DIR/bash_completion\\\" # This loads nvm bash_completion\\n\" BASH_OR_ZSH=false if [ -z \"$&#123;NVM_PROFILE-&#125;\" ] ; then echo \"=&gt; Profile not found. Tried $&#123;NVM_PROFILE&#125; (as defined in \\$PROFILE), ~/.bashrc, ~/.bash_profile, ~/.zshrc, and ~/.profile.\" echo \"=&gt; Create one of them and run this script again\" echo \"=&gt; Create it (touch $&#123;NVM_PROFILE&#125;) and run this script again\" echo \" OR\" echo \"=&gt; Append the following lines to the correct file yourself:\" command printf \"$&#123;SOURCE_STR&#125;\" else if nvm_profile_is_bash_or_zsh \"$&#123;NVM_PROFILE-&#125;\"; then BASH_OR_ZSH=true fi if ! command grep -qc '/nvm.sh' \"$NVM_PROFILE\"; then echo \"=&gt; Appending nvm source string to $NVM_PROFILE\" command printf \"$&#123;SOURCE_STR&#125;\" &gt;&gt; \"$NVM_PROFILE\" else echo \"=&gt; nvm source string already in $&#123;NVM_PROFILE&#125;\" fi # shellcheck disable=SC2016 if $&#123;BASH_OR_ZSH&#125; &amp;&amp; ! command grep -qc '$NVM_DIR/bash_completion' \"$NVM_PROFILE\"; then echo \"=&gt; Appending bash_completion source string to $NVM_PROFILE\" command printf \"$COMPLETION_STR\" &gt;&gt; \"$NVM_PROFILE\" else echo \"=&gt; bash_completion source string already in $&#123;NVM_PROFILE&#125;\" fi fi if $&#123;BASH_OR_ZSH&#125; &amp;&amp; [ -z \"$&#123;NVM_PROFILE-&#125;\" ] ; then echo \"=&gt; Please also append the following lines to the if you are using bash/zsh shell:\" command printf \"$&#123;COMPLETION_STR&#125;\" fi # Source nvm # shellcheck source=/dev/null \\. \"$(nvm_install_dir)/nvm.sh\" nvm_check_global_modules nvm_install_node nvm_reset echo \"=&gt; Close and reopen your terminal to start using nvm or run the following to use it now:\" command printf \"$&#123;SOURCE_STR&#125;\" if $&#123;BASH_OR_ZSH&#125; ; then command printf \"$&#123;COMPLETION_STR&#125;\" fi&#125;## Unsets the various functions defined# during the execution of the install script#nvm_reset() &#123; unset -f nvm_has nvm_install_dir nvm_latest_version nvm_profile_is_bash_or_zsh \\ nvm_source nvm_node_version nvm_download install_nvm_from_git nvm_install_node \\ install_nvm_as_script nvm_try_profile nvm_detect_profile nvm_check_global_modules \\ nvm_do_install nvm_reset&#125;[ \"_$NVM_ENV\" = \"_testing\" ] || nvm_do_install&#125; # this ensures the entire script is downloaded #安装node fi&#125;## Unsets the various functions defined# during the execution of the install script#nvm_reset() &#123; unset -f nvm_has nvm_install_dir nvm_latest_version nvm_profile_is_bash_or_zsh \\ nvm_source nvm_node_version nvm_download install_nvm_from_git nvm_install_node \\ install_nvm_as_script nvm_try_profile nvm_detect_profile nvm_check_global_modules \\ nvm_do_install nvm_reset&#125;[ \"_$NVM_ENV\" = \"_testing\" ] || nvm_do_install&#125; # this ensures the entire script is downloaded # 安装node如果执行过程没有报错的话就说明nvm安装成功，接下来就开始安装node，并且切换到此版本 12nvm install v6.10.3nvm use v6.10.3","categories":[{"name":"-Linux","slug":"Linux","permalink":"http://lwenxu.coding.me/categories/Linux/"}],"tags":[]},{"title":"markdown语法","slug":"Tools/markdown语法","date":"2017-04-27T10:10:46.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2017/04/27/Tools/markdown语法/","link":"","permalink":"http://lwenxu.coding.me/2017/04/27/Tools/markdown语法/","excerpt":"Markdown 语法说明 (简体中文版) / (点击查看快速入门) 概述宗旨兼容 HTML特殊字符自动转换区块元素段落和换行标题区块引用列表代码区块分隔线区段元素链接强调代码图片其它反斜杠自动链接感谢概述","text":"Markdown 语法说明 (简体中文版) / (点击查看快速入门) 概述宗旨兼容 HTML特殊字符自动转换区块元素段落和换行标题区块引用列表代码区块分隔线区段元素链接强调代码图片其它反斜杠自动链接感谢概述 宗旨 Markdown 的目标是实现「易读易写」。 可读性，无论如何，都是最重要的。一份使用 Markdown 格式撰写的文件应该可以直接以纯文本发布，并且看起来不会像是由许多标签或是格式指令所构成。Markdown 语法受到一些既有 text-to-HTML 格式的影响，包括 Setext、atx、Textile、reStructuredText、Grutatext 和 EtText，而最大灵感来源其实是纯文本电子邮件的格式。 总之， Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像强调。Markdown 的列表看起来，嗯，就是列表。Markdown 的区块引用看起来就真的像是引用一段文字，就像你曾在电子邮件中见过的那样。 兼容 HTML Markdown 语法的目标是：成为一种适用于网络的书写语言。 Markdown 不是想要取代 HTML，甚至也没有要和它相近，它的语法种类很少，只对应 HTML 标记的一小部分。Markdown 的构想不是要使得 HTML 文档更容易书写。在我看来， HTML 已经很容易写了。Markdown 的理念是，能让文档更容易读、写和随意改。HTML 是一种发布的格式，Markdown 是一种书写的格式。就这样，Markdown 的格式语法只涵盖纯文本可以涵盖的范围。 不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。不需要额外标注这是 HTML 或是 Markdown；只要直接加标签就可以了。 要制约的只有一些 HTML 区块元素――比如 、、、 等标签，必须在前后加上空行与其它内容区隔开，还要求它们的开始标签与结尾标签不能用制表符或空格来缩进。Markdown 的生成器有足够智能，不会在 HTML 区块标签外加上不必要的 标签。 例子如下，在 Markdown 文件里加上一段 HTML 表格： 这是一个普通段落。 Foo 这是另一个普通段落。请注意，在 HTML 区块标签间的 Markdown 格式语法将不会被处理。比如，你在 HTML 区块内使用 Markdown 样式的强调会没有效果。 HTML 的区段（行内）标签如 、、 可以在 Markdown 的段落、列表或是标题里随意使用。依照个人习惯，甚至可以不用 Markdown 格式，而直接采用 HTML 标签来格式化。举例说明：如果比较喜欢 HTML 的 或 标签，可以直接使用这些标签，而不用 Markdown 提供的链接或是图像标签语法。 和处在 HTML 区块标签间不同，Markdown 语法在 HTML 区段标签间是有效的。 特殊字符自动转换 在 HTML 文件中，有两个字符需要特殊处理： < 和 & 。 < 符号用于起始标签，& 符号则用于标记 HTML 实体，如果你只是想要显示这些字符的原型，你必须要使用实体的形式，像是 &lt; 和 &amp;。 & 字符尤其让网络文档编写者受折磨，如果你要打「AT&T」 ，你必须要写成「AT&amp;T」。而网址中的 & 字符也要转换。比如你要链接到： http://images.google.com/images?num=30&amp;q=larry+bird你必须要把网址转换写为： http://images.google.com/images?num=30&amp;q=larry+bird才能放到链接标签的 href 属性里。不用说也知道这很容易忽略，这也可能是 HTML 标准检验所检查到的错误中，数量最多的。 Markdown 让你可以自然地书写字符，需要转换的由它来处理好了。如果你使用的 & 字符是 HTML 字符实体的一部分，它会保留原状，否则它会被转换成 &amp;。 所以你如果要在文档中插入一个版权符号 ©，你可以这样写： &copy;Markdown 会保留它不动。而若你写： AT&TMarkdown 就会将它转为： AT&amp;T类似的状况也会发生在 < 符号上，因为 Markdown 允许 兼容 HTML ，如果你是把 < 符号作为 HTML 标签的定界符使用，那 Markdown 也不会对它做任何转换，但是如果你写： 4 < 5Markdown 将会把它转换为： 4 &lt; 5不过需要注意的是，code 范围内，不论是行内还是区块， < 和 & 两个符号都一定会被转换成 HTML 实体，这项特性让你可以很容易地用 Markdown 写 HTML code （和 HTML 相对而言， HTML 语法中，你要把所有的 < 和 & 都转换为 HTML 实体，才能在 HTML 文件里面写出 HTML code。） 区块元素 段落和换行 一个 Markdown 段落是由一个或多个连续的文本行组成，它的前后要有一个以上的空行（空行的定义是显示上看起来像是空的，便会被视为空行。比方说，若某一行只包含空格和制表符，则该行也会被视为空行）。普通段落不该用空格或制表符来缩进。 「由一个或多个连续的文本行组成」这句话其实暗示了 Markdown 允许段落内的强迫换行（插入换行符），这个特性和其他大部分的 text-to-HTML 格式不一样（包括 Movable Type 的「Convert Line Breaks」选项），其它的格式会把每个换行符都转成 标签。 如果你确实想要依赖 Markdown 来插入 标签的话，在插入处先按入两个以上的空格然后回车。 的确，需要多费点事（多加空格）来产生 ，但是简单地「每个换行都转换为 」的方法在 Markdown 中并不适合， Markdown 中 email 式的 区块引用 和多段落的 列表 在使用换行来排版的时候，不但更好用，还更方便阅读。 标题 Markdown 支持两种标题的语法，类 Setext 和类 atx 形式。 类 Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），例如： This is an H1This is an H2任何数量的 = 和 - 都可以有效果。 类 Atx 形式则是在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶，例如： 这是 H1这是 H2这是 H6你可以选择性地「闭合」类 atx 样式的标题，这纯粹只是美观用的，若是觉得这样看起来比较舒适，你就可以在行尾加上 #，而行尾的 # 数量也不用和开头一样（行首的井字符数量决定标题的阶数）： 这是 H1这是 H2这是 H3区块引用 Blockquotes Markdown 标记区块引用是使用类似 email 中用 > 的引用方式。如果你还熟悉在 email 信件中的引言部分，你就知道怎么在 Markdown 文件中建立一个区块引用，那会看起来像是你自己先断好行，然后在每行的最前面加上 > ： This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisseid sem consectetuer libero luctus adipiscing.Markdown 也允许你偷懒只在整个段落的第一行最前面加上 > ： This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisseid sem consectetuer libero luctus adipiscing.区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 > ： This is the first level of quoting. This is nested blockquote. Back to the first level.引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等： 这是一个标题。 这是第一行列表项。 这是第二行列表项。 给出一些例子代码： return shell_exec(&quot;echo $input | $markdown_script&quot;);任何像样的文本编辑器都能轻松地建立 email 型的引用。例如在 BBEdit 中，你可以选取文字后然后从选单中选择增加引用阶层。 列表 Markdown 支持有序列表和无序列表。 无序列表使用星号、加号或是减号作为列表标记： Red Green Blue等同于： Red Green Blue也等同于： Red Green Blue有序列表则使用数字接着一个英文句点： Bird McHale Parish很重要的一点是，你在列表标记上使用的数字并不会影响输出的 HTML 结果，上面的列表所产生的 HTML 标记为： Bird McHale Parish 如果你的列表标记写成： Bird McHale Parish或甚至是： Bird McHale Parish你都会得到完全相同的 HTML 输出。重点在于，你可以让 Markdown 文件的列表数字和输出的结果相同，或是你懒一点，你可以完全不用在意数字的正确性。 如果你使用懒惰的写法，建议第一个项目最好还是从 1. 开始，因为 Markdown 未来可能会支持有序列表的 start 属性。 列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。 要让列表看起来更漂亮，你可以把内容用固定的缩进整理好： Lorem ipsum dolor sit amet, consectetuer adipiscing elit.Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi,viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit.Suspendisse id sem consectetuer libero luctus adipiscing.但是如果你懒，那也行： Lorem ipsum dolor sit amet, consectetuer adipiscing elit.Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi,viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit.Suspendisse id sem consectetuer libero luctus adipiscing.如果列表项目间用空行分开，在输出 HTML 时 Markdown 就会将项目内容用 标签包起来，举例来说： Bird Magic会被转换为： Bird Magic 但是这个： Bird Magic会被转换为： Bird Magic 列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符： This is a list item with two paragraphs. Lorem ipsum dolorsit amet, consectetuer adipiscing elit. Aliquam hendreritmi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreetvitae, risus. Donec sit amet nisl. Aliquam semper ipsumsit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing.如果你每行都有缩进，看起来会看好很多，当然，再次地，如果你很懒惰，Markdown 也允许： This is a list item with two paragraphs. This is the second paragraph in the list item. You'reonly required to indent the first line. Lorem ipsum dolorsit amet, consectetuer adipiscing elit. Another item in the same list.如果要在列表项目内放进引用，那 > 就需要缩进： A list item with a blockquote: This is a blockquoteinside a list item.如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： 一列表项包含一个列表区块： &lt;代码写在这&gt;当然，项目列表很可能会不小心产生，像是下面这样的写法： What a great season.换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠。 1986. What a great season.代码区块 和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 和 标签来把代码区块包起来。 要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以，例如，下面的输入： 这是一个普通段落： 这是一个代码区块。Markdown 会转换成： 这是一个普通段落： 这是一个代码区块。 这个每行一阶的缩进（4 个空格或是 1 个制表符），都会被移除，例如： Here is an example of AppleScript: tell application &quot;Foo&quot; beep end tell会被转换为： Here is an example of AppleScript: tell application \"Foo\" beep end tell 一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。 在代码区块里面， & 、 < 和 > 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，再加上缩进就可以了，剩下的 Markdown 都会帮你处理，例如： &lt;div class=&quot;footer&quot;&gt; &amp;copy; 2004 Foo Corporation &lt;/div&gt;会被转换为： &lt;div class=\"footer\"&gt; &amp;copy; 2004 Foo Corporation &lt;/div&gt; 代码区块中，一般的 Markdown 语法不会被转换，像是星号便只是星号，这表示你可以很容易地以 Markdown 语法撰写 Markdown 语法相关的文件。 分隔线 你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： 区段元素 链接 Markdown 支持两种形式的链接语法： 行内式和参考式两种形式。 不管是哪一种，链接文字都是用 [方括号] 来标记。 要建立一个行内式的链接，只要在方块括号后面紧接着圆括号并插入网址链接即可，如果你还想要加上链接的 title 文字，只要在网址后面，用双引号把 title 文字包起来即可，例如： This is an example inline link. This link has no title attribute.会产生： This is an example inline link. This link has no title attribute. 如果你是要链接到同样主机的资源，你可以使用相对路径： See my About page for details.参考式的链接是在链接文字的括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记： This is an example reference-style link.你也可以选择性地在两个方括号中间加上一个空格： This is [an example] id reference-style link.接着，在文件的任意处，你可以把这个标记的链接内容定义出来： 链接内容定义的形式为： 方括号（前面可以选择性地加上至多三个空格来缩进），里面输入链接文字接着一个冒号接着一个以上的空格或制表符接着链接的网址选择性地接着 title 内容，可以用单引号、双引号或是括弧包着下面这三种链接的定义都是相同： 请注意：有一个已知的问题是 Markdown.pl 1.0.1 会忽略单引号包起来的链接 title。 链接网址也可以用方括号包起来： 你也可以把 title 属性放到下一行，也可以加一些缩进，若网址太长的话，这样会比较好看： 网址定义只有在产生链接的时候用到，并不会直接出现在文件之中。 链接辨别标签可以有字母、数字、空白和标点符号，但是并不区分大小写，因此下面两个链接是一样的： [link text][a][link text][A]隐式链接标记功能让你可以省略指定链接标记，这种情形下，链接标记会视为等同于链接文字，要用隐式链接标记只要在链接文字后面加上一个空的方括号，如果你要让 \"Google\" 链接到 google.com，你可以简化成： Google然后定义链接内容： 由于链接文字可能包含空白，所以这种简化型的标记内也许包含多个单词： Visit Daring Fireball for more information.然后接着定义链接： 链接的定义可以放在文件中的任何一个地方，我比较偏好直接放在链接出现段落的后面，你也可以把它放在文件最后面，就像是注解一样。 下面是一个参考式链接的范例： I get 10 times more traffic from Google 1 than fromYahoo 2 or MSN 3. 如果改成用链接名称的方式写： I get 10 times more traffic from Google than fromYahoo or MSN. 上面两种写法都会产生下面的 HTML。 I get 10 times more traffic from Google than from Yahoo or MSN. 下面是用行内式写的同样一段内容的 Markdown 文件，提供作为比较之用： I get 10 times more traffic from Googlethan from Yahoo orMSN.参考式的链接其实重点不在于它比较好写，而是它比较好读，比较一下上面的范例，使用参考式的文章本身只有 81 个字符，但是用行内形式的却会增加到 176 个字元，如果是用纯 HTML 格式来写，会有 234 个字元，在 HTML 格式中，标签比文本还要多。 使用 Markdown 的参考式链接，可以让文件更像是浏览器最后产生的结果，让你可以把一些标记相关的元数据移到段落文字之外，你就可以增加链接而不让文章的阅读感觉被打断。 强调 Markdown 使用星号（*）和底线（_）作为标记强调字词的符号，被 * 或 _ 包围的字词会被转成用 标签包围，用两个 * 或 _ 包起来的话，则会被转成 ，例如： single asterisks single underscores double asterisks double underscores会转成： single asterisks single underscores double asterisks double underscores你可以随便用你喜欢的样式，唯一的限制是，你用什么符号开启标签，就要用什么符号结束。 强调也可以直接插在文字中间： unfriggingbelievable但是如果你的 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。 如果要在文字前后直接插入普通的星号或底线，你可以用反斜线： *this text is surrounded by literal asterisks*代码 如果要标记一小段行内代码，你可以用反引号把它包起来（`），例如： Use the printf() function.会产生： Use the printf() function. 如果要在代码区段内插入反引号，你可以用多个反引号来开启和结束代码区段： There is a literal backtick (`) here.这段语法会产生： There is a literal backtick (`) here. 代码区段的起始和结束端都可以放入一个空白，起始端后面一个，结束端前面一个，这样你就可以在区段的一开始就插入反引号： A single backtick in a code span: ` A backtick-delimited string in a code span: `foo`会产生： A single backtick in a code span: ` A backtick-delimited string in a code span: `foo` 在代码区段内，& 和方括号都会被自动地转成 HTML 实体，这使得插入 HTML 原始码变得很容易，Markdown 会把下面这段： Please don't use any &lt;blink&gt; tags.转为： Please don't use any &lt;blink&gt; tags. 你也可以这样写： &amp;#8212; is the decimal-encoded equivalent of &amp;mdash;.以产生： &amp;#8212; is the decimal-encoded equivalent of &amp;mdash;. 图片 很明显地，要在纯文字应用中设计一个「自然」的语法来插入图片是有一定难度的。 Markdown 使用一种和链接很相似的语法来标记图片，同样也允许两种样式： 行内式和参考式。 行内式的图片语法看起来像是： 详细叙述如下： 一个惊叹号 !接着一个方括号，里面放上图片的替代文字接着一个普通括号，里面放上图片的网址，最后还可以用引号包住并加上 选择性的 'title' 文字。参考式的图片语法则长得像这样： 「id」是图片参考的名称，图片参考的定义方式则和连结参考一样： 到目前为止， Markdown 还没有办法指定图片的宽高，如果你需要的话，你可以使用普通的 标签。 其它 自动链接 Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用方括号包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如： http://example.com/Markdown 会转为： http://example.com/邮址的自动链接也很类似，只是 Markdown 会先做一个编码转换的过程，把文字字符转成 16 进位码的 HTML 实体，这样的格式可以糊弄一些不好的邮址收集机器人，例如： &#x61;&#x64;&#x64;&#x72;&#101;&#x73;&#x73;&#64;&#101;&#120;&#97;&#x6d;&#112;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109;Markdown 会转成： &#x61;&#x64;&#x64;&#x72;&#x65;&#115;&#115;&#64;&#101;&#120;&#x61;&#109;&#x70;&#x6C;e&#x2E;&#99;&#111;&#109;在浏览器里面，这段字串（其实是 address@example.com）会变成一个可以点击的「address@example.com」链接。 （这种作法虽然可以糊弄不少的机器人，但并不能全部挡下来，不过总比什么都不做好些。不管怎样，公开你的信箱终究会引来广告信件的。） 反斜杠 Markdown 可以利用反斜杠来插入一些在语法中有其它意义的符号，例如：如果你想要用星号加在文字旁边的方式来做出强调效果（但不用 标签），你可以在星号的前面加上反斜杠： *literal asterisks*Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号： \\ 反斜线` 反引号 星号_ 底线{} 花括号[] 方括号() 括弧井字号 加号 减号. 英文句点! 惊叹号","categories":[{"name":"-其他","slug":"其他","permalink":"http://lwenxu.coding.me/categories/其他/"}],"tags":[]},{"title":"关于gitlab的deploy无权push的问题","slug":"Linux/关于gitlab的deploy无权push的问题","date":"2017-04-27T09:48:58.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2017/04/27/Linux/关于gitlab的deploy无权push的问题/","link":"","permalink":"http://lwenxu.coding.me/2017/04/27/Linux/关于gitlab的deploy无权push的问题/","excerpt":"今天准备两个人协同开发一个项目，然后建立了一个组。一开始是给了deploye权限，但是他说没有权限上传，我就把权限提高但是我把权限提到master之后还是不行，清缓存什么的都做了还是不行，提交的时候一直出现以下错误：错误提示：","text":"今天准备两个人协同开发一个项目，然后建立了一个组。一开始是给了deploye权限，但是他说没有权限上传，我就把权限提高但是我把权限提到master之后还是不行，清缓存什么的都做了还是不行，提交的时候一直出现以下错误：错误提示： git -c diff.mnemonicprefix=false -c core.quotepath=false push -v origin master:masterPushing to http://xxx/xxx/xxx_HTML.git POST git-receive-pack (47642 bytes) remote: GitLab: You don’t have permission[K To http://xxx/xxx/xxx_HTML.git! [remote rejected] master -&gt; master (pre-receive hook declined)error: failed to push some refs to ‘http://xxx/xxx/xxx_HTML.git&#39; 最后还是找到了解决方案了，主要就是项目一般对于master分支对组中的成员是受保护的，具体方案如下：找到项目：在项目的【Setting】中的【Protected branches】可以设置哪些分支是被保护的，默认情况下【master】分支是处于被保护状态下的，develop角色的人是无法提交到master分支的，在下面的【Developers can push】打上钩就可以了。","categories":[{"name":"Web","slug":"Web","permalink":"http://lwenxu.coding.me/categories/Web/"}],"tags":[{"name":"工具","slug":"工具","permalink":"http://lwenxu.coding.me/tags/工具/"}]},{"title":"Dell黑苹果折腾","slug":"Mac/Dell黑苹果折腾","date":"2017-03-12T12:58:25.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2017/03/12/Mac/Dell黑苹果折腾/","link":"","permalink":"http://lwenxu.coding.me/2017/03/12/Mac/Dell黑苹果折腾/","excerpt":"早在大一的时候就开始折腾黑苹果了，当时第一次看到mac的界面的时候我就深深的爱上了这款操作系统，而且最重要的是他是集Linux与Windows的优点于一身的系统。","text":"早在大一的时候就开始折腾黑苹果了，当时第一次看到mac的界面的时候我就深深的爱上了这款操作系统，而且最重要的是他是集Linux与Windows的优点于一身的系统。我喜欢Linux但是有时需要一些Windows程序的时候wine并不能给我很好的支持，各种问题让我很多时候并不是在编码而是一直处在折腾操作系统的处境，虽然也能学到一些东西，但是我用这个操作系统的根本目的其实还是编码，这样一来反而成为拖累我的累赘。Linux下最好的莫过于他的终端了，迅速简洁的完成各项工做。Windows则是什么东西都有但是很多时候需要安装一些东西例如依赖，对css进行编译各种莫名其妙的问题，或许是版本或许是网络的问题，有些在终端下很简单的操作变得非常复杂，但是很多其他的软件在使用上真的是无可挑剔，一些调用机制写的很完善。最后我选择了一个折中的办法就是Mac，它集中了两个我最喜欢的功能，终端和较多满足日常需要的应用软件，只是有些操作感觉有些怪怪的毕竟Windows用的时间太长了。目前在我电脑上的这个黑苹果基本是完美驱动了，就差一个WiFi无解，intel的无线网卡貌似都不行，而且网卡的接口设计比较奇怪，市面上不容易找到又与之相匹配又容易驱动的无线网卡了，倒也无所谓目前主要用的还是有线。 制作启动盘 首先需要下载mac镜像可以直接下载带有Colver的镜像，使用transMac烧录。 烧录的时间可能会有点长，一般完成了以后你只能看到一个EFI分区，这个是引导分区，U盘剩下的空间装的都是mac操作系统。放入一些必要的驱动文件一般三个左右，最重要的是config.plist这个文件如果有错误系统无法启动，所以可能有很多时间都是花费在调节这个文件然后系统引导成功。如果运气比较好的话可能一次就直接进入系统了，这个时候仅仅需要安装。 安装操作系统安装操作系统这一步还是很简单的，开始使用磁盘工具抹掉你要安装的位置，然后开始安装，安装一半第一次重启以后你会看到一个新的mac引导，这个时候还是选择从U盘启动，继续安装操作系统，在完全第二次自动重启以后就可以选择从硬盘启动了，这个时候需要做一点点的设置，之后就完成安装了。 安装驱动进入系统以后你会发现可能你的界面掉帧，没有网络，没有声音。这是因为还没有安装驱动，建议一开始不要放到系统的驱动目录下，那样不仅消耗时间而且如果驱动出错导致系统完全无法启动，建议将驱动先放在U盘的kexts文件夹下面，一次次测试等到完全通过以后在放进去，重建缓存。 DSDTDSDT也是为了解决一些很棘手的问题，例如不能休眠，不能显示电量，自动重启啊什么的，首先需要生成本地的ACPI二进制文件可以在Colver中使用F4即可生成，然后将生成的二进制文件反汇编成文本文件即以dsl结尾的文件，这种文件可以直接使用工具打开修改，然后在编译成二进制的文件即aml结尾的文件放到引导目录下。","categories":[],"tags":[{"name":"Mac","slug":"Mac","permalink":"http://lwenxu.coding.me/tags/Mac/"}]},{"title":"我的2016","slug":"Life/我的2016","date":"2017-02-27T14:31:10.000Z","updated":"2019-04-14T06:04:28.000Z","comments":true,"path":"2017/02/27/Life/我的2016/","link":"","permalink":"http://lwenxu.coding.me/2017/02/27/Life/我的2016/","excerpt":"​ 每一年过去，我都会在我的博客记录这一年的总结，回顾过去一年的得失，又可以展望一下新的一年。每次看到这些文字就好像看到了我这一年的旅程。","text":"​ 每一年过去，我都会在我的博客记录这一年的总结，回顾过去一年的得失，又可以展望一下新的一年。每次看到这些文字就好像看到了我这一年的旅程。 网络中心说到2016，那就不得不提网络中心，也就是在这我才开始真正接触Web开发。在大一上学期时候偶然的接触到了Linux和Github体会到了开源的强大，不知不觉的就被Linux吸引了。当时就尝试Linux的各种发行版Debian，Kali，CentOS，Arch，Gentoo记得当时最多的时候是电脑上有六个操作系统。不过也就是在那个时候学会了内核编译，系统编译，vim，make，各种服务搭建。当时看到网络中心招人的时候，我还是挺想去的，本来是去那想当一名Linux系统管理员，最后没成想上了PHP的贼船。因为网络中心的主力开发语言是PHP，所以首先就得先学一下原生PHP，然后让我们在看几个框架。最开始Web开发给我的印象感觉很简单，估计就是HTML+CSS+JS然后就能开发网站了，和C++、JAVA那种编译型语言差远了。直到那个时候我才发现我错了，单不说系统开发，就一个简单的网站必须要有HTML，CSS，JavaScript，PHP，Mysql，Linux，最少还要懂一些安全，防止XSS攻击和SQL注入等等安全问题。用一个词来形容当时的我再合适不过就是“浮躁”。当时想为了学到更多，了解更多，尽快的接触到开发。大概三四天就把原生PHP学完了，然后就开始接触框架ThinkPHP，CakePHP，Yii框架。反正当时是硬着头皮去看文档，对于里面提到的MVC三层架构，RBAC权限模型，AOP切面编程是感觉一头雾水，但当时还是把手册给翻完了，可能是为了寻求心理安慰。到最后也只用了ThinkPHP框架写了一个登陆留言系统，然后又转向Shell脚本，ruby on rails ，Anglar Js。就这样上半学期就算在各种折腾和浮躁中结束了。 烛照暑假的时候也没太闲着，在家只待了六天就赶到学校了。因为当时在这边找了一个Web公司的实习机会。公司的老板是一个西大的学长，是一个出色的Python程序员，幽默，认真。以前是绿盟公司的面试官，也是我的第一个面试官，一开始我还是挺紧张的，大概聊了四五分钟后情绪基本就稳定下来了，然后开始问一些关于Linux和Web前端的问题，虽然问题不是很难，但是我感觉回答的不太满意。后来我想了一些，应该还是自己对技术太浮躁了，太过眼高手低了。接下来的主要工作就是关于服务器和Web前端。搭建mail服务器，开发机，Linux镜像打包，Docker，Ansible，持续集成。其实很多东西以前听说过有的用过，只是在用于生产环境以后就不得不去考虑更多，降低后来人的学习使用成本。然后那些不会的就自行Google而且老板和同事也特别热心，开发机的思路都是他帮我提供的。当时工作一直比较认真，和老板还有同事的关系也很好。平常大家工作都挺努力的，休息的时候气氛特别活跃。其实我挺喜欢那种一群年轻人为了同一个目标聚在一起朝着一个方向努力，然后又不失活跃的那种。在那的一个半月对我的技术和态度有了很大影响，在公司工作就必须对自己的工作负责，认真做好。还有就是这个行业个人永远无法和团队相比的，一个人单枪匹马的是很难做出优秀的产品，尤其是在互联网发展如此迅速的今天，等一个人开发出第一个版本说不定这个技术早就已经过时了。 NwuPT（嘉木）解释一下嘉木是一个ipv6资源分享站点，相对于目前的学校计费的ipv4所有的资源都是免流量下载的。其实这个项目早在2016年年初就开始了，发起人是一个大四的学长。当时他也是找了我好几次，让我也参与，可是一直腾不开时间。然后招募的其他程序员也没在写东西。大概是9月中旬的时候我开始接手这个项目，但是确实找不到开发人员。然后我想着先自己写一份代码，等站点运行起来了以后在招募，没想到这个项目竟然写了半年，大概在12月中旬才勉强上线，上线以后还有各种问题又修修补补等到放假才算基本稳定。当时开发和服务器运维都是我一个人在做，真的是精力跟不上。有时候上课都在想有些地方怎么解决，然后期末成绩也感觉一塌糊涂。不过每次看到站点运行起来了心里还是很兴奋的，毕竟投入了那么大的精力。然后在寒假又花了几天重新修改了代码，目前还有点问题没有完全解决。还在测试中，总之这次没问题了以后就准备开放源代码，为开源做点贡献，也让代码更加的丰富起来，毕竟一个人的能力有限。也希望在座的有意向的同学也能参与进来。 寒假其实每年寒假我都挺期待过年的，虽然说现在过年没有了以前过年时候的那种浓浓的年味，但我还是很期待。过年的时候就可以见到很多很久很久没见到的亲人，每年大家都挺忙的，很少有见面的机会，能聚在一起会感到挺温暖的。有空的时候经常也和高中同学出去，一起聊聊天，回想以前的高中生活，那时候很苦，当时唯一的想法就是赶紧上大学，可现在上了大学又挺怀念高中的生活。剩下的时间就陪爸妈聊聊天，看了一点框架的源码，用ThinkPHP写了一个Linux镜像站，目前在解决服务器问题，也快要上线了。 2017展望对于我来说2017算是一个比较关键的一年，希望我能在2017年做好以下几件事，也算是和大家共勉：坚持早睡，在寒假算是基本养成了，以前总是晚上休息不好，白天一直头疼，从上大学一直持续到现在。睡眠充足后很少出现这样的情况了。坚持阅读，我希望2017一定不能把这件事落下，无论多忙，只有阅读才能使自己提升，无论是技术方面，还是性格修养。阅读是唯一一个短期内可能没什么太大帮助，但是长期积累下来一定会对你有巨大影响的一件事。坚持写博客，写博客不仅仅是对自己的知识的巩固。而且如果你经常在网络上找资料就会发现好多博客是互相抄袭，最可气的还不能解决问题，可以让自己的博客真正帮助开发者解决一些实际问题。 最后，人不是独立的个体，活在世上不管是有意还是无形，总归会受到一些人的帮助，所以要始终心存感恩。","categories":[{"name":"杂记","slug":"杂记","permalink":"http://lwenxu.coding.me/categories/杂记/"}],"tags":[]},{"title":"PT站开始内测啦","slug":"PT/PT站开始内测啦","date":"2016-10-09T15:33:21.000Z","updated":"2018-12-19T18:44:54.000Z","comments":true,"path":"2016/10/09/PT/PT站开始内测啦/","link":"","permalink":"http://lwenxu.coding.me/2016/10/09/PT/PT站开始内测啦/","excerpt":"从暑假一直就在筹备这件事情，但是最后由于种种原因一直搁置到了开学。在中秋的时候正式开始着手做这件事情，基本每天都在改代码，前后台夹杂，改起来比较复杂，所以改到现在前台还不是很好看。","text":"从暑假一直就在筹备这件事情，但是最后由于种种原因一直搁置到了开学。在中秋的时候正式开始着手做这件事情，基本每天都在改代码，前后台夹杂，改起来比较复杂，所以改到现在前台还不是很好看。但是还是想先用起来，目前已经把文件结构基本清楚了，所以先做一次内测，没大问题先用一段时间在准备再将前台重写… 那么什么是PT站?咱们普通上网使用的是Ipv4协议上网，我们说的ip也是说的ipv4的地址，这个一般是我们需要在运营商购买的。然而还有一个类似于ipv4的协议叫做ipv6，虽然它比ipv4更有优势，但是目前ipv6基本属于空闲状态，所以在运营商那里买的话也很便宜。一般学校从运营商买的网都是带有ipv6的，我们就可以使用这部分空闲资源。但是咱学校不是限流量吗，这好像并没有什么用。值得注意的是用ipv4上网使用的是ipv4的流量，而用ipv6上网使用的是ipv6的流量，所以说两者独立，而学校只计算ipv4的流量，那么咱们使用的ipv6就可以算作不计流量了。ok，说了那么多就是ipv4需要计算流量，ipv6不计算流量，而PT站使用的ipv6，所以ipv6是免流的。 怎么使用PT站？首先是最最重要的就是如果你使用的是360的浏览器请务必要把浏览器的模式改成极速模式，千万不要使用兼容模式，由于这个站点的框架不支持IE8及以下的浏览器如果直接访问的话，很可能会出现网页排版错乱的情况。之后我会尽快再写一版主题，解决这个问题。修改方法如下图：","categories":[{"name":"PT站","slug":"PT站","permalink":"http://lwenxu.coding.me/categories/PT站/"}],"tags":[]},{"title":"秒速5厘米","slug":"Life/秒速5厘米","date":"2016-10-04T14:31:10.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2016/10/04/Life/秒速5厘米/","link":"","permalink":"http://lwenxu.coding.me/2016/10/04/Life/秒速5厘米/","excerpt":"正文开学的第二周晚上停电，也就在那晚看完了樱花抄，今天又看完了宇航员和秒速五厘米。樱花抄也是我最喜欢的一部分，一个唯美的名字…少年时形影不离的朋友，从互相有好感，","text":"正文开学的第二周晚上停电，也就在那晚看完了樱花抄，今天又看完了宇航员和秒速五厘米。樱花抄也是我最喜欢的一部分，一个唯美的名字…少年时形影不离的朋友，从互相有好感，到一次次的分别，每次分别让两个人的距离越来越远，让彼此见面的机会越来越少。年少的的互相倾慕，追寻纯真的爱情。贵树与明里约好在车站相见，那份紧张与兴奋想必是少年时都会有的心情。从早上开始下着寒冷的雨，中午时雨又变成了雪。放学后，贵树按约定乘坐电车前往岩舟车站。雪越来越大，时间好像被无限的拉长，当路程到一半时，已经到了约定的时间。急切，不安，失望…当到达约定的车站时已经是十一点，车站空无一人。贵树失望的走进车站，看到竟是孤单一人的明里，明里抓着贵树的衣角抽泣着。委屈，心疼，开心….候车室内贵树吃过明里做的茶点，一同前往其信中的樱花树，大雪过后的雪地留下了两人歪歪斜斜的脚印，在树下相拥亲吻…那天晚上，两人在田边休息了一晚。次日，贵树乘坐早上的第一班电车和明里告别了,那时的天空显得特别的高远，清晰，真实。秒速5厘米篇中明里和贵树也会经常做梦，梦到那段青涩的爱恋，那时的明里也要结婚了，贵树和三年的女朋友分手了。相遇总是很微妙的事情，在贵树辞去工作，明里结婚后的一个下午他们擦肩而过，贵树下定决心转身时，疾驰而过的列车挡住了他的视线，列车通过后明里早已离去。青春，像一杯清茶，弥漫芳香。每个人都经历过青春，过程或快乐，或悲伤，但终是逃不过时间的流逝。再美好的青春也总有那么多缺憾，无法弥补，无法追逐，只能放在记忆的脑海里，偶尔怀念，怀念曾今那样的自己，怀念曾经不可一世的感情。我们在成长的道路上渐行渐远，回首间突然发现，曾经不顾一切追逐的事情，或许转瞬间就已遥不可及。我们每个人都如同电影里的主人公，不断相遇，不断地错过，难逃命运的着捉弄，于是乎才明白，当初为何不把想做的事做完，想说的话亲口说给想见的人听，时间就是这样无情，你离开了，错过了当时想要表达心意的机会，便是一生的遗憾，却也缺憾成美，流淌在记忆的时光里缅怀那段青涩的爱恋！","categories":[{"name":"杂记","slug":"杂记","permalink":"http://lwenxu.coding.me/categories/杂记/"}],"tags":[]},{"title":"关于apache端口被占用","slug":"Linux/关于apache端口被占用","date":"2016-04-04T09:59:44.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2016/04/04/Linux/关于apache端口被占用/","link":"","permalink":"http://lwenxu.coding.me/2016/04/04/Linux/关于apache端口被占用/","excerpt":"正文无论我们在安装单个的apache还是装集成环境xampp都是有可能遇到apache意外停止。查看错误日志会发现一般都是端口被占用，一般是被虚拟机占用了，这时一般有两种方法，改apache的端口号，或者把占用apache的端口号的那个服务干掉。","text":"正文无论我们在安装单个的apache还是装集成环境xampp都是有可能遇到apache意外停止。查看错误日志会发现一般都是端口被占用，一般是被虚拟机占用了，这时一般有两种方法，改apache的端口号，或者把占用apache的端口号的那个服务干掉。 方案一：改端口号在apache的配置文件里找到httpd-ssl.conf文件然后ctrl+f查找port然后改成444或者其他的，只要没被占用的就可以，然后重启apache。MySQL出问题了也是这样的解决方案。 方案二：杀占用的服务win+r打开运行，输入cmd打开命令提示符，输入 1netstat -ano 找到占用443端口的服务，找到他的pid ，然后输入 1kill /f /pid 端口号 就能结束此服务，然后重启apache即可。 也可以使用任务管理器，停掉对应的服务。","categories":[{"name":"Web","slug":"Web","permalink":"http://lwenxu.coding.me/categories/Web/"}],"tags":[]},{"title":"Linux小记","slug":"Linux/Linux小记","date":"2016-03-20T14:53:08.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2016/03/20/Linux/Linux小记/","link":"","permalink":"http://lwenxu.coding.me/2016/03/20/Linux/Linux小记/","excerpt":"正文定义别名：1alias vi='vim' 查看别名：1alias 让某个用户永久生效","text":"正文定义别名：1alias vi='vim' 查看别名：1alias 让某个用户永久生效 1vim ~/.bashrc 删除别名1ualias vi 快捷键：12345678ctrl+u 删除或剪切光标左侧的所有字符ctrl+y 粘贴ctrl+r 搜索历史命令ctrl+d 推出登陆ctrl+z 暂停放入后台ctrl+l 清屏ctrl+a 光标移到开头ctrl+e 光标移到结尾 *是任意多个任意字符(任意可以是0)12345678 ls *abc``` 会显示所有以abc结尾的或者就是abc的文件## []匹配括号中的任意一个，必须是一个。``` bash ls [abc]df 匹配以abc其中一个开始，以df结尾的，文件名是三个字符 ？这个是匹配任意一个字符1ls ?asc 四个字符，以asc结尾[^]与2同只是取反‘’单引号中所有的特殊符号都没有特殊的含义“”双引号特殊符号都有特殊意义``反引号等价于$()里面的系统命令会先执行反引号和括号里面的命令1echo `ls` 显示本目录下的文件名 \\去掉特殊符号的意义1echo \\$date 显示的是$date去掉了$的特殊意义 清空历史命令：1history -c 强制保存到历史命令文件(~/.bash_history)中：1history -w 更改历史命令保存文件存的条数12vim /etc/profile （profile是环境变量的配置文件）HISTZISE=1000 历史命令的调用：123!n //重复执行第n条命令!! //重复执行上一条命令!字符串 //重复执行最后一条的含有字符串的命令 将错误与正确信息都存在文件里12ls &amp;&gt;&gt; abc (以追加的形式)ls &amp;&gt; abc （以覆盖的方式） 普通的重定向12ls &gt;&gt; abcls &gt; abc 只执行命令不进行结果的输出，在脚本中经常使用1ls &amp;&gt;/dev/null 分开重定向：1ls &gt;&gt; abc 2&gt;&gt;def (正确的是放在abc，错误的放在def)","categories":[{"name":"Linux","slug":"Linux","permalink":"http://lwenxu.coding.me/categories/Linux/"}],"tags":[]},{"title":"虚拟机的三种网络连接方式","slug":"Linux/虚拟机的三种网络连接方式","date":"2016-03-20T14:53:08.000Z","updated":"2018-12-19T18:44:52.000Z","comments":true,"path":"2016/03/20/Linux/虚拟机的三种网络连接方式/","link":"","permalink":"http://lwenxu.coding.me/2016/03/20/Linux/虚拟机的三种网络连接方式/","excerpt":"正文 VMWare提供了三种工作模式，它们是bridged(桥接模式)、NAT(网络地址转换模式)和host-only(主机模式)。要想在网络管理和维护中合理应用它们，你就应该先了解一下这三种工作模式。","text":"正文 VMWare提供了三种工作模式，它们是bridged(桥接模式)、NAT(网络地址转换模式)和host-only(主机模式)。要想在网络管理和维护中合理应用它们，你就应该先了解一下这三种工作模式。 1.bridged(桥接模式) 在这种模式下，VMWare虚拟出来的操作系统就像是局域网中的一台独立的主机，它可以访问网内任何一台机器。在桥接模式下，你需要手工为虚拟 系统配置IP地址、子网掩码，而且还要和宿主机器处于同一网段，这样虚拟系统才能和宿主机器进行通信。同时，由于这个虚拟系统是局域网中的一个独立的主机 系统，那么就可以手工配置它的TCP/IP配置信息，以实现通过局域网的网关或路由器访问互联网。 使用桥接模式的虚拟系统和宿主机器的关系，就像连接在同一个Hub上的两台电脑。想让它们相互通讯，你就需要为虚拟系统配置IP地址和子网掩码，否则就无法通信。 如果你想利用VMWare在局域网内新建一个虚拟服务器，为局域网用户提供网络服务，就应该选择桥接模式。 2.host-only(主机模式) 在某些特殊的网络调试环境中，要求将真实环境和虚拟环境隔离开，这时你就可采用host-only模式。在host-only模式中，所有的虚拟系统是可以相互通信的，但虚拟系统和真实的网络是被隔离开的。 提示:在host-only模式下，虚拟系统和宿主机器系统是可以相互通信的，相当于这两台机器通过双绞线互连。 在host-only模式下，虚拟系统的TCP/IP配置信息(如IP地址、网关地址、DNS服务器等)，都是由VMnet1(host-only)虚拟网络的DHCP服务器来动态分配的。 如果你想利用VMWare创建一个与网内其他机器相隔离的虚拟系统，进行某些特殊的网络调试工作，可以选择host-only模式。 3.NAT(网络地址转换模式) 使用NAT模式，就是让虚拟系统借助NAT(网络地址转换)功能，通过宿主机器所在的网络来访问公网。也就是说，使用NAT模式可以实现在虚拟 系统里访问互联网。NAT模式下的虚拟系统的TCP/IP配置信息是由VMnet8(NAT)虚拟网络的DHCP服务器提供的，无法进行手工修改，因此虚 拟系统也就无法和本局域网中的其他真实主机进行通讯。采用NAT模式最大的优势是虚拟系统接入互联网非常简单，你不需要进行任何其他的配置，只需要宿主机 器能访问互联网即可。 如果你想利用VMWare安装一个新的虚拟系统，在虚拟系统中不用进行任何手工配置就能直接访问互联网，建议你采用NAT模式。 提示:以上所提到的NAT模式下的VMnet8虚拟网络，host-only模式下的VMnet1虚拟网络，以及bridged模式下的 VMnet0虚拟网络，都是由VMWare虚拟机自动配置而生成的，不需要用户自行设置。VMnet8和VMnet1提供DHCP服务，VMnet0虚拟 网络则不提供。","categories":[{"name":"Web","slug":"Web","permalink":"http://lwenxu.coding.me/categories/Web/"}],"tags":[]},{"title":"Hexo","slug":"Tools/Hexo","date":"2016-03-09T05:01:47.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2016/03/09/Tools/Hexo/","link":"","permalink":"http://lwenxu.coding.me/2016/03/09/Tools/Hexo/","excerpt":"动因 新学期开始了，这个学期准备养成开始写博客的好习惯。以前什么东西都是在QQ空间里， 后来觉得技术性稍微强一点的就是CSDN和博客园。但是啊我觉得他们的广告和版式确实 有点让人不忍直视，毕竟是搞技术的不如自己搭一个博客吧。于是就有了下面的折腾了。 能踩的坑我都帮你们踩过了，大家按照我的步骤一步步往下搭就好，那么现在开始吧！ # 正文","text":"动因 新学期开始了，这个学期准备养成开始写博客的好习惯。以前什么东西都是在QQ空间里， 后来觉得技术性稍微强一点的就是CSDN和博客园。但是啊我觉得他们的广告和版式确实 有点让人不忍直视，毕竟是搞技术的不如自己搭一个博客吧。于是就有了下面的折腾了。 能踩的坑我都帮你们踩过了，大家按照我的步骤一步步往下搭就好，那么现在开始吧！ # 正文 ## 首先声明一下： 平台：windows hexo版本：3.X ## 所需文件: 1. [Node.js] [http://nodejs.cn/] 2. [Git] (https://git-scm.com/downloads/) （下载后直接安装就好:next，next，finsh） 配置hexo：找到刚才安装的git bash然后你需要在本地硬盘里面创建一个文件夹用来存放hexo的配置文件，例如我在这里创建的地方是F：/hexo ，那么我们现在打开git bash然后输入 12cd F：cd hexo 现在你就会进入到你刚才创建的hexo文件夹了。然后就开始安装hexo了。依次在git bash中输入以下内容，时间会因为网速而不同： 123451.npm install hexo-cli -g2.hexo init2.npm install hexo-deployer-git --save3.hexo g4.hexo s 这样hexo就安装完成了，下面我们要看看hexo给我们的初始界面是什么样的就执行以下命令： (以//开始的是注释，不要复制，给你们说明用的。) 121.hexo g //生成静态文件2.hexo s //开启本地服务器，用于页面预览 之后我们就到浏览器中看看我们的hexo长什么样子了，就在浏览器地址栏输入localhost:4000回车是不是看到了一篇hello world而且界面很漂亮。 配置Github：安装完hexo只是我们在能看到啊，要让所有人都看到我们要把它同步到github上面，就相当于吧本地文件上传到一个免费服务器，别人都看得到。首先你需要注册一个github账号，搜索github然后点击注册就好，按照他的提示一步一步来，注意要把用户名记住啊，那个倒时很有用的。这里我的就是xpf199741，密码是自然的。注册完了就去添加一个仓库就是叫repository的东西然后取一个名字，注意仓库名字必须是“用户名.github.io”，例如我的就是xpf199741.github.io前面一定要是用户名后面的也要遵循，否则后面步骤肯定通不过。 1ssh-keygen -t rsa -C \"你的注册github的电子邮箱地址\" 大家在复制的时候把电子邮箱更改一下啊，有停顿时候回车就是了，然后在本地的c盘用户目录下面产生一个.ssh文件夹然后进去，打开id_rsa.pub，复制里面的全部内容。然后回到网页版的github上进入Settings，左边选择SSH Keys，Add SSH Key,title随便填，粘贴key（就是刚才复制的内容）。 然后回到git bash再输入： 1ssh -T git@github.com 如果如果是第一次的会提示是否continue，输入yes就会看到：You’ve successfully authenticated, but GitHub does not provide shell access 。这就表示已成功链接。 链接Github与hexo：编辑F：\\hexo下的_config.yml文件在行末添加一下内容： 1234deploy: type: git repository: git@github.com:xpf199741/xpf199741.github.io.git branch: master 把xpf199741改成你的就好了，但是注意一下：hexo的配置文件中任何’:’后面都是带一个空格的在git bash里输入： 12hexo ghexo d 执行上面的第二个命令，可能会要你输入用户名和密码，输入密码是不显示任何东西的，输完回车就可以了。然后在浏览器中输入 1xpf199741.github.io.git 是不是在浏览器中看到了hexo的内容，不同于第一次看到的是，这次是在线的，所有人都可以看到。至此你应该已经学会了搭建hexo咯。 尾声再遇到什么问题可在下面评论,之后我会继续更新hexo的美化，配置，使用。","categories":[],"tags":[]},{"title":"PhpStrom 快捷键","slug":"Tools/PHPStrom 快捷键","date":"2016-03-09T05:01:47.000Z","updated":"2018-12-19T18:44:56.000Z","comments":true,"path":"2016/03/09/Tools/PHPStrom 快捷键/","link":"","permalink":"http://lwenxu.coding.me/2016/03/09/Tools/PHPStrom 快捷键/","excerpt":"插入编辑位置 alt+鼠标左跳到代码块的 开始/结束 ctrl+[ / ctrl+]选中代码块的开始/结束的地方到当前位置 ctrl+shift+[ / ctrl+shift+]删除行 ctrl+d删除到单词结束 ctrl+delete删除至单词开始 ctrl+backspace","text":"插入编辑位置 alt+鼠标左跳到代码块的 开始/结束 ctrl+[ / ctrl+]选中代码块的开始/结束的地方到当前位置 ctrl+shift+[ / ctrl+shift+]删除行 ctrl+d删除到单词结束 ctrl+delete删除至单词开始 ctrl+backspace 疯狂退格 ctrl+shift+backspace显示模版 ctrl+alt+shift+j块注释 ctrl+shift+/格式化代码 ctrl+shift+alt+lalt + ` vcspostfix风格补齐代码$a.echo echo $a;$a.else if(!$a){}else{}$foo.fe feach($foo as $it)$a.if if($a){}$a.isset if(isset($a)){}$a.null if($a==null)$a.notnull if($a!==null)$a.var_dump var_dump($a)prof protect functionprosf protect static functionprifprisfpubfpubsfeco echo “”;fore foreachforek foreach ($a $key=&gt;$value)","categories":[],"tags":[]}]}